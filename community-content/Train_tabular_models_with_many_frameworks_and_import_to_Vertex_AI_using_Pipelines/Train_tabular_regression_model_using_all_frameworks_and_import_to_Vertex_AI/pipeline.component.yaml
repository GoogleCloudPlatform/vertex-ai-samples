name: Train tabular regression model using all frameworks pipeline
metadata:
  annotations:
    author: Alexey Volkov <alexey.volkov@ark-kun.com>
    canonical_location: https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/samples/Google_Cloud_Vertex_AI/Train_tabular_regression_model_using_all_frameworks_and_import_to_Vertex_AI/pipeline.component.yaml
    sdk: https://cloud-pipelines.net/pipeline-editor/
implementation:
  graph:
    tasks:
      Download from GCS:
        componentRef:
          digest: 4175c9ff143cb8cc75d05451c0a0ebdf5a0d6d020816e29f5e9cefbb7d56f241
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/27a5ea25e849c9e8c0cb6ed65518bc3ece259aaf/components/google-cloud/storage/download/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          GCS path: gs://ml-pipeline-dataset/Chicago_taxi_trips/chicago_taxi_trips_2019-01-01_-_2019-02-01_limit=10000.csv
        annotations:
          editor.position: '{"x":550,"y":40,"width":180,"height":40}'
      Select columns using Pandas on CSV data:
        componentRef:
          digest: 9b9500f461c1d04f1e48992de9138db14a6800f23649d73048673d5ea6dc56ad
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/8c78aae096806cff3bc331a40566f42f5c3e9d4b/components/pandas/Select_columns/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: Data
              taskId: Download from GCS
          column_names: '["tips", "trip_seconds", "trip_miles", "pickup_community_area", "dropoff_community_area", "fare", "tolls", "extras"]'
        annotations:
          editor.position: '{"x":550,"y":140,"width":180,"height":54}'
      Fill all missing values using Pandas on CSV data:
        componentRef:
          digest: a1b0c29a4615f2e3652aa5d31b9255fa15700e146627c755f8fc172f82e71af7
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/23405971f5f16a41b16c343129b893c52e4d1d48/components/pandas/Fill_all_missing_values/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: transformed_table
              taskId: Select columns using Pandas on CSV data
              type: CSV
          replacement_value: '0'
        annotations:
          editor.position: '{"x":550,"y":250,"width":180,"height":54}'
      Split rows into subsets:
        componentRef:
          digest: a609c3c9196484290f24a1174955f95b27f07a7b458aa5cb8cde28866cb2cb46
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/daae5a4abaa35e44501818b1534ed7827d7da073/components/dataset_manipulation/Split_rows_into_subsets/in_CSV/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: transformed_table
              taskId: Fill all missing values using Pandas on CSV data
              type: CSV
          fraction_1: '0.8'
        annotations:
          editor.position: '{"x":550,"y":360,"width":180,"height":40}'
      Create fully connected pytorch network:
        componentRef:
          digest: d03d8248fd358a0275ec33568ee7dd7dce576cc112b09dfafe2651e4d97e04a9
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/1a2ef3eeb77bc278f33cad0dd29008ea2431e191/components/PyTorch/Create_fully_connected_network/component.yaml
        arguments:
          input_size: '7'
          hidden_layer_sizes: '[10]'
          activation_name: elu
        annotations:
          editor.position: '{"x":380,"y":490,"width":180,"height":54}'
      Create fully connected tensorflow network:
        componentRef:
          digest: bfcafbc5ce711b1f69cabf1338212d10d50136a73db9f9f7c984de7b80b4bfb0
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/9ca0f9eecf5f896f65b8538bbd809747052617d1/components/tensorflow/Create_fully_connected_network/component.yaml
        arguments:
          input_size: '7'
          hidden_layer_sizes: '[10]'
          activation_name: elu
        annotations:
          editor.position: '{"x":40,"y":500,"width":180,"height":54}'
      Train model using Keras on CSV:
        componentRef:
          digest: 42ae60c889034dbad74815653e95b4f7d576b5f47f803173e8679c7b54984609
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/c504a4010348c50eaaf6d4337586ccc008f4dcef/components/tensorflow/Train_model_using_Keras/on_CSV/component.yaml
        arguments:
          training_data:
            taskOutput:
              outputName: split_1
              taskId: Split rows into subsets
              type: CSV
          model:
            taskOutput:
              outputName: model
              taskId: Create fully connected tensorflow network
              type: TensorflowSavedModel
          label_column_name: tips
          number_of_epochs: '10'
          metric_names: '["mean_absolute_error"]'
        annotations:
          editor.position: '{"x":40,"y":620,"width":180,"height":54}'
      Train pytorch model from csv:
        componentRef:
          digest: 40f3185eb61e9727f41a4e0c05dd3d3b44bd802aa0f378cfc31756560033949a
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/d8c4cf5e6403bc65bcf8d606e6baf87e2528a3dc/components/PyTorch/Train_PyTorch_model/from_CSV/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: model
              taskId: Create fully connected pytorch network
              type: PyTorchScriptModule
          training_data:
            taskOutput:
              outputName: split_1
              taskId: Split rows into subsets
              type: CSV
          label_column_name: tips
        annotations:
          editor.position: '{"x":380,"y":620,"width":180,"height":40}'
      Train XGBoost model on CSV:
        componentRef:
          digest: 538c5a01eb38deaf532d619f0bbeaff4efc550fe1f0f776fc06791097b68ceac
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/58d3a47f904f32a64af8403330ba7e2134cae46d/components/XGBoost/Train/component.yaml
        arguments:
          training_data:
            taskOutput:
              outputName: split_1
              taskId: Split rows into subsets
              type: CSV
          label_column_name: tips
        annotations:
          editor.position: '{"x":720,"y":620,"width":180,"height":40}'
      Train linear regression model using scikit learn from CSV:
        componentRef:
          digest: c7fe7912ab0d1fb45d201d452e9ce6be5544e7d8c6d229db7a4b931ff58560f3
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/f807e02b54d4886c65a05f40848fd51c72407f40/components/ML_frameworks/Scikit_learn/Train_linear_regression_model/from_CSV/component.yaml
        arguments:
          dataset:
            taskOutput:
              outputName: split_1
              taskId: Split rows into subsets
              type: CSV
          label_column_name: tips
        annotations:
          editor.position: '{"x":1030,"y":620,"width":180,"height":54}'
      Predict with TensorFlow model on CSV data:
        componentRef:
          digest: 921bb1563e93a78233b8acceab87055b9154ccf5595d056028cf0396ca224cd4
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/59c759ce6f543184e30db6817d2a703879bc0f39/components/tensorflow/Predict/on_CSV/component.yaml
        arguments:
          dataset:
            taskOutput:
              outputName: split_2
              taskId: Split rows into subsets
              type: CSV
          model:
            taskOutput:
              outputName: trained_model
              taskId: Train model using Keras on CSV
              type: TensorflowSavedModel
          label_column_name: tips
        annotations:
          editor.position: '{"x":160,"y":750,"width":180,"height":54}'
      Create PyTorch Model Archive with base handler:
        componentRef:
          digest: 8298b5ee1b0f0879f893add4cf352c8dec7cf9e21bb9db134c91a2d046cdb0ec
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/46d51383e6554b7f3ab4fd8cf614d8c2b422fb22/components/PyTorch/Create_PyTorch_Model_Archive/with_base_handler/component.yaml
        arguments:
          Model:
            taskOutput:
              outputName: trained_model
              taskId: Train pytorch model from csv
              type: PyTorchScriptModule
          Model name: model
          Model version: '1.0'
        annotations:
          editor.position: '{"x":380,"y":750,"width":180,"height":54}'
      Xgboost predict on CSV:
        componentRef:
          digest: 0876233a0c7306fefec188bd70f059b46d1fb5aa57be231799570e3bbbdd0d95
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/4694ec97baccf59284c2a1db4aa2250c22291eab/components/XGBoost/Predict/component.yaml
        arguments:
          data:
            taskOutput:
              outputName: split_2
              taskId: Split rows into subsets
              type: CSV
          model:
            taskOutput:
              outputName: model
              taskId: Train XGBoost model on CSV
              type: XGBoostModel
          label_column_name: tips
        annotations:
          editor.position: '{"x":810,"y":750,"width":180,"height":40}'
      Upload Scikit learn pickle model to Google Cloud Vertex AI:
        componentRef:
          digest: 81c91c8d7d21ec97e0872f669d68bd89edea87279d703685db54aa94743bebcd
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/c6a8b67d1ada2cc17665c99ff6b410df588bee28/components/google-cloud/Vertex_AI/Models/Upload_Scikit-learn_pickle_model/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: model
              taskId: Train linear regression model using scikit learn from CSV
              type: ScikitLearnPickleModel
        annotations:
          editor.position: '{"x":1030,"y":750,"width":180,"height":70}'
      Upload Tensorflow model to Google Cloud Vertex AI:
        componentRef:
          digest: 2e45263ff640b1a688e359b6936e27a81b2407749a84f340af2aa5547e0cb92c
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/c6a8b67d1ada2cc17665c99ff6b410df588bee28/components/google-cloud/Vertex_AI/Models/Upload_Tensorflow_model/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: trained_model
              taskId: Train model using Keras on CSV
              type: TensorflowSavedModel
        annotations:
          editor.position: '{"x":40,"y":880,"width":180,"height":54}'
      Upload PyTorch model archive to Google Cloud Vertex AI:
        componentRef:
          digest: 4450212fae7b9001482aca7eb78b28413c205506eccf08a04e7754a8dfa99004
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/c6a8b67d1ada2cc17665c99ff6b410df588bee28/components/google-cloud/Vertex_AI/Models/Upload_PyTorch_model_archive/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          model_archive:
            taskOutput:
              outputName: Model archive
              taskId: Create PyTorch Model Archive with base handler
              type: PyTorchModelArchive
        annotations:
          editor.position: '{"x":380,"y":880,"width":180,"height":70}'
      Upload XGBoost model to Google Cloud Vertex AI:
        componentRef:
          digest: 5a5a273c403670743820986c03a4175b7cb4595a556524fefcce403656286977
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/c6a8b67d1ada2cc17665c99ff6b410df588bee28/components/google-cloud/Vertex_AI/Models/Upload_XGBoost_model/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: model
              taskId: Train XGBoost model on CSV
              type: XGBoostModel
        annotations:
          editor.position: '{"x":720,"y":880,"width":180,"height":54}'
    outputValues: {}
