name: Train tabular classification model using PyTorch pipeline
metadata:
  annotations:
    author: Alexey Volkov <alexey.volkov@ark-kun.com>
    canonical_location: https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/samples/Google_Cloud_Vertex_AI/Train_tabular_classification_model_using_PyTorch_and_import_to_Vertex_AI/pipeline.component.yaml
    sdk: https://cloud-pipelines.net/pipeline-editor/
implementation:
  graph:
    tasks:
      Download from GCS:
        componentRef:
          digest: 4175c9ff143cb8cc75d05451c0a0ebdf5a0d6d020816e29f5e9cefbb7d56f241
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/27a5ea25e849c9e8c0cb6ed65518bc3ece259aaf/components/google-cloud/storage/download/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          GCS path: gs://ml-pipeline-dataset/Chicago_taxi_trips/chicago_taxi_trips_2019-01-01_-_2019-02-01_limit=10000.csv
        annotations:
          editor.position: '{"x":240,"y":40,"width":180,"height":40}'
      Select columns using Pandas on CSV data:
        componentRef:
          digest: 9b9500f461c1d04f1e48992de9138db14a6800f23649d73048673d5ea6dc56ad
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/8c78aae096806cff3bc331a40566f42f5c3e9d4b/components/pandas/Select_columns/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: Data
              taskId: Download from GCS
          column_names: '["tips", "trip_seconds", "trip_miles", "pickup_community_area", "dropoff_community_area", "fare", "tolls", "extras"]'
        annotations:
          editor.position: '{"x":240,"y":140,"width":180,"height":54}'
      Fill all missing values using Pandas on CSV data:
        componentRef:
          digest: a1b0c29a4615f2e3652aa5d31b9255fa15700e146627c755f8fc172f82e71af7
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/23405971f5f16a41b16c343129b893c52e4d1d48/components/pandas/Fill_all_missing_values/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: transformed_table
              taskId: Select columns using Pandas on CSV data
              type: CSV
          replacement_value: '0'
        annotations:
          editor.position: '{"x":240,"y":250,"width":180,"height":54}'
      Create fully connected pytorch network:
        componentRef:
          digest: d03d8248fd358a0275ec33568ee7dd7dce576cc112b09dfafe2651e4d97e04a9
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/1a2ef3eeb77bc278f33cad0dd29008ea2431e191/components/PyTorch/Create_fully_connected_network/component.yaml
        arguments:
          input_size: '7'
          hidden_layer_sizes: '[10]'
          activation_name: elu
          output_activation_name: sigmoid
        annotations:
          editor.position: '{"x":40,"y":360,"width":180,"height":54}'
      Binarize column using Pandas on CSV data:
        componentRef:
          digest: d699afd4d7cae862708717cc160f4394ed0c04e536e9515923ef1e8865f01d44
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/1e2558325f4c708aca75827c8acc13d230ee7e9f/components/pandas/Binarize_column/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: transformed_table
              taskId: Fill all missing values using Pandas on CSV data
              type: CSV
          column_name: tips
          predicate: ' > 0'
          new_column_name: class
        annotations:
          editor.position: '{"x":240,"y":360,"width":180,"height":54}'
      Train pytorch model from csv:
        componentRef:
          digest: 40f3185eb61e9727f41a4e0c05dd3d3b44bd802aa0f378cfc31756560033949a
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/d8c4cf5e6403bc65bcf8d606e6baf87e2528a3dc/components/PyTorch/Train_PyTorch_model/from_CSV/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: model
              taskId: Create fully connected pytorch network
              type: PyTorchScriptModule
          training_data:
            taskOutput:
              outputName: transformed_table
              taskId: Binarize column using Pandas on CSV data
              type: CSV
          label_column_name: class
          loss_function_name: binary_cross_entropy
        annotations:
          editor.position: '{"x":240,"y":490,"width":180,"height":40}'
      Create PyTorch Model Archive with base handler:
        componentRef:
          digest: 8298b5ee1b0f0879f893add4cf352c8dec7cf9e21bb9db134c91a2d046cdb0ec
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/46d51383e6554b7f3ab4fd8cf614d8c2b422fb22/components/PyTorch/Create_PyTorch_Model_Archive/with_base_handler/component.yaml
        arguments:
          Model:
            taskOutput:
              outputName: trained_model
              taskId: Train pytorch model from csv
              type: PyTorchScriptModule
          Model name: model
          Model version: '1.0'
        annotations:
          editor.position: '{"x":240,"y":590,"width":180,"height":54}'
      Upload PyTorch model archive to Google Cloud Vertex AI:
        componentRef:
          digest: 4450212fae7b9001482aca7eb78b28413c205506eccf08a04e7754a8dfa99004
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/c6a8b67d1ada2cc17665c99ff6b410df588bee28/components/google-cloud/Vertex_AI/Models/Upload_PyTorch_model_archive/workaround_for_buggy_KFPv2_compiler/component.yaml
        arguments:
          model_archive:
            taskOutput:
              outputName: Model archive
              taskId: Create PyTorch Model Archive with base handler
              type: PyTorchModelArchive
        annotations:
          editor.position: '{"x":240,"y":720,"width":180,"height":70}'
    outputValues: {}
