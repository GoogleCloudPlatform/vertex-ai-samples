{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed3b25b1-ce38-4930-97d7-3346165d8d4e",
      "metadata": {
        "id": "12cb1b47a1b7"
      },
      "source": [
        "# Inventory prediction on ecommerce data using Vertex AI\n",
        "\n",
        "## Table of contents\n",
        "* [Overview](#section-1)\n",
        "* [Dataset](#section-2)\n",
        "* [Objective](#section-3)\n",
        "* [Costs](#section-4)\n",
        "* [Load the required data from BigQuery](#section-5)\n",
        "* [Explore and Analyze the dataset](#section-6)\n",
        "* [Feature Preprocessing](#section-7)\n",
        "* [Model building](#section-8) \n",
        "\t* [Train the model](#section-9)\n",
        "\t*[Evaluate the model](#section-10)\n",
        "* [Save the model to a Cloud Storage bucket](#section-11) \n",
        "* [Create a model in Vertex AI](#section-12) \n",
        "* [Create an Endpoint](#section-13) \n",
        "* [Deploy the model to the created Endpoint](#section-14)\n",
        "* [What-If Tool](#section-15) \n",
        "* [Clean up](#section-16) \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "## Overview\n",
        "<a name=\"section-1\"></a>\n",
        "\n",
        "This notebook explores how one can build a machine-learning model for *Inventory prediction* on an e-commerce dataset. Further, there are also steps included in this notebook to deploy the model on Vertex AI using the Vertex AI sdk and analyze the deployed model using the [What-If tool](https://pair-code.github.io/what-if-tool/).\n",
        "\n",
        "*Note:* This notebook file was designed to run in a Vertex AI Workbench managed notebooks instance using the TensorFlow 2 (Local) kernel. Some components of this notebook may not work in other notebook environments.\n",
        "\n",
        "## Dataset\n",
        "<a name=\"section-2\"></a>\n",
        "\n",
        "The dataset used in this notebook consists of inventory data since 2018 for an online ecommerce store. This dataset is publicly available at `looker-private-demo.ecomm.inventory_items` BigQuery table which can be accessed by pinning the `looker-private-demo` project in BigQuery. The table consists of various fields related to each of the inventory items like the item's `id`,`product_id`, price, when it came to the inventory, when it has been sold etc. Among these fields, the current notebook makes use of the following fields assuming their purpose is as described below :\n",
        "\n",
        "- `id`: The Id of the inventory item.\n",
        "- `product_id`: The Id of the product.\n",
        "- `created_at`: When the item has arrived at the inventory/store.\n",
        "- `sold_at`: When the item was sold(*Null if still unsold*).\n",
        "- `cost`: Cost at which the item was sold.\n",
        "- `product_category`: Category of the product.\n",
        "- `product_brand`: Brand of the product (dropped later as there are too many values).\n",
        "- `product_retail_price`: Price of of the product.\n",
        "- `product_department`: Department to which the product belongs to.\n",
        "- `product_distribution_center_id`: Which distribution center(probably region) the product is being sold from.\n",
        "\n",
        "The dataset can be found encoded already to hide any private information of the store. For example, the distribution centers have been assigned ids ranging from 1-10.\n",
        "\n",
        "## Objectives\n",
        "<a name=\"section-3\"></a>\n",
        "\n",
        "The objectvies of this notebook includes :\n",
        "* Load the dataset from BigQuery using *Bigquery In Notebooks* integration.\n",
        "* Analyze the dataset.\n",
        "* Preprocess the features in the dataset.\n",
        "* Build a RandomForest Classifier model that predicts if a product will get sold in the next 60 days.\n",
        "* Evaluate the model.\n",
        "* Deploy the model using Vertex AI.\n",
        "* Configure and test the What-If tool.\n",
        "\n",
        "## Costs\n",
        "<a name=\"section-4\"></a>\n",
        "\n",
        "This tutorial uses the following billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "- Bigquery\n",
        "- Cloud Storage\n",
        "\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing), [Bigquery pricing](https://cloud.google.com/bigquery/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage.\n",
        "\n",
        "## Before you begin\n",
        "### Set your project ID\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb2d6ba-3028-458c-8afd-eb72ea1530d7",
      "metadata": {
        "id": "4be1250b19cf"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b008e8ae-ae48-4933-89f4-65cb96983c4c",
      "metadata": {
        "id": "7aa7d44eefc3"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f26b5fa-828b-4104-8b9e-b2728dac30e5",
      "metadata": {
        "id": "81351cf1ced9"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b70318-b75e-4f8d-9fd3-10521adeeee0",
      "metadata": {
        "id": "a47045884647"
      },
      "source": [
        "### Timestamp\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90c1e94-79ac-4aba-8589-d6348181937a",
      "metadata": {
        "id": "2171869c7cef"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fecaa4fb-c8a3-4538-9112-9875c99e4353",
      "metadata": {
        "id": "15d91ce9a98e"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "The following steps are required, regardless of your notebook environment.\n",
        "\n",
        "When you submit a training job using the Cloud SDK, you upload a Python package containing your training code to a Cloud Storage bucket. Vertex AI runs the code from this package. In this tutorial, Vertex AI needs the trained model to be saved to Cloud Storage bucket for deployment. Using the model artifact, you can then create Vertex AI model and endpoint resources in order to serve the online predictions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all Cloud Storage buckets.\n",
        "\n",
        "You may also change the `REGION` variable, which is used for operations throughout the rest of this notebook. Make sure to choose a region where Vertex AI services are available. You may not use a Multi-Regional Storage bucket for training with Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2db85b7-050f-4ac8-8548-01c493c7c985",
      "metadata": {
        "id": "814a9c014e16"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "REGION = \"[your-region]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a5ab69-b45e-45f5-aeea-433782e889f4",
      "metadata": {
        "id": "ce71cab23cda"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
        "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
        "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee5bd777-6b5c-4433-a671-026e6db7aaa1",
      "metadata": {
        "id": "aa6e246297be"
      },
      "source": [
        "**Only if your bucket doesn't already exist:** Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d744577-19fb-4a7c-a84d-9cf787ffe98a",
      "metadata": {
        "id": "a0cc49ab6e69"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd137de6-ea0c-4ac6-b192-a896885205a5",
      "metadata": {
        "id": "df4ee328db14"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5611c3b-2f10-45eb-b457-6cfa1306b86e",
      "metadata": {
        "id": "637ea7607c58"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7c1aeea-6411-4d2e-9e98-3a95c6dba963",
      "metadata": {
        "id": "9c1d4f460b09"
      },
      "source": [
        "## Tutorial\n",
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a9ce5d-699c-4aac-9b9a-098048a7c22f",
      "metadata": {
        "id": "a36a786f4538"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as metrics\n",
        "from google.cloud import storage\n",
        "from google.cloud.bigquery import Client\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from witwidget.notebook.visualization import WitConfigBuilder, WitWidget"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2350fd00-96d3-46c8-9bdd-63ace0dce921",
      "metadata": {
        "id": "34f2b9e8bc9a"
      },
      "source": [
        "### Load the required data from BigQuery\n",
        "<a name=\"section-5\"></a>\n",
        "\n",
        "The following cell integrates with BigQuery from the same project through the Vertex AI's *BigQuery In Notebooks* feature. It can run a SQL query similarly as it would run in the BigQuery console. \n",
        "\n",
        "\n",
        "*Note:* This feature would only work in a notebook on Vertex AI Workbench's managed-notebook instances."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e10d7f-a5a8-46f6-a45d-818ffd66acb2",
      "metadata": {
        "id": "13863517f8c8"
      },
      "source": [
        "#@bigquery\n",
        "SELECT \n",
        "    id,\n",
        "    product_id, \n",
        "    created_at,\n",
        "    sold_at,\n",
        "    cost,\n",
        "    product_category,\n",
        "    product_brand,\n",
        "    product_retail_price,\n",
        "    product_department,\n",
        "    product_distribution_center_id\n",
        "FROM \n",
        "looker-private-demo.ecomm.inventory_items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59fa3c1-d412-4bf6-9ebd-c80a86a1c6ce",
      "metadata": {
        "id": "50ed21be5ab7"
      },
      "source": [
        "After executing the above cell, clicking **Query and load as DataFrame** button adds the following python cell that loads the queried data into a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62782c2-9b17-44c3-84a1-480978c846fd",
      "metadata": {
        "id": "e89e5832338a"
      },
      "outputs": [],
      "source": [
        "# The following two lines are only necessary to run once.\n",
        "# Comment out otherwise for speed-up.\n",
        "client = Client()\n",
        "\n",
        "query = \"\"\"SELECT \n",
        "    id,\n",
        "    product_id, \n",
        "    created_at,\n",
        "    sold_at,\n",
        "    cost,\n",
        "    product_category,\n",
        "    product_brand,\n",
        "    product_retail_price,\n",
        "    product_department,\n",
        "    product_distribution_center_id\n",
        "FROM \n",
        "looker-private-demo.ecomm.inventory_items\"\"\"\n",
        "job = client.query(query)\n",
        "df = job.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d50372-b5ad-4123-85ae-8284bfeab903",
      "metadata": {
        "id": "4f9fc651fa8e"
      },
      "source": [
        "## Explore and analyze the dataset\n",
        "<a name=\"section-6\"></a>\n",
        "\n",
        "Check the first five rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b44ba3b-ade9-445e-bf91-5b03ca596966",
      "metadata": {
        "id": "da9f53ab3559"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df2ec583-1122-47d2-bf2a-f6c0d5ba201f",
      "metadata": {
        "id": "5aa703b3f070"
      },
      "source": [
        "Check the fields in the dataset and their data-types and number of null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0296df18-5a86-4a0f-8c58-7e3997d31d3f",
      "metadata": {
        "id": "b00164626bad"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c019a7ea-aa2f-4f66-a9b8-01ea185e5ddd",
      "metadata": {
        "id": "730f6c2954f5"
      },
      "source": [
        "We can notice that apart from the `sold_at` datetime field, there aren't any fields that consist of null values in the dataset. As we are dealing with the inventory-item data, it is absolutely plausible that there will be some items that haven't been sold yet and hence the null values.\n",
        "\n",
        "Further, we convert the date fields to a proper date format to process them in the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a9d896-43d7-4594-80bc-7da5eaa6cd67",
      "metadata": {
        "id": "1ff70c9450ee"
      },
      "outputs": [],
      "source": [
        "# convert to proper date columns\n",
        "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], format=\"%Y-%m-%d\")\n",
        "df[\"sold_at\"] = pd.to_datetime(df[\"sold_at\"].dt.strftime(\"%Y-%m-%d\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46034da-2024-4e24-a4e3-d2339e70ff9a",
      "metadata": {
        "id": "50fc83a65c71"
      },
      "source": [
        "Check the date ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b911c489-5118-47ff-8b14-a2c26cabdc23",
      "metadata": {
        "id": "db6ac4523678"
      },
      "outputs": [],
      "source": [
        "# check the date ranges\n",
        "print(\"Min-sold_at : \", df[\"sold_at\"].min())\n",
        "print(\"Max-sold_at : \", df[\"sold_at\"].max())\n",
        "\n",
        "print(\"Min-created_at : \", df[\"created_at\"].min())\n",
        "print(\"Max-created_at : \", df[\"created_at\"].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2e850f-9590-4cb2-a6f5-8b4c918e1137",
      "metadata": {
        "id": "c8ec80d03032"
      },
      "source": [
        "Extract month from the date field `created_at`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d44f325-35bd-4840-a8fd-33ce0b17f4cf",
      "metadata": {
        "id": "2694255a5bf2"
      },
      "outputs": [],
      "source": [
        "# calculate the month when the item has arrived\n",
        "df[\"arrival_month\"] = df[\"created_at\"].dt.month"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760efdbb-3db6-48aa-8d32-58f21a477491",
      "metadata": {
        "id": "5d9a610a5c10"
      },
      "source": [
        "Calculate the average number of days a product had been in the inventory until it was sold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2decd13-e171-4ca5-8f5e-3f4da0fe092b",
      "metadata": {
        "id": "5d4df4604949"
      },
      "outputs": [],
      "source": [
        "# calculate the number of days the item hasn't been sold.\n",
        "df[\"shelf_days\"] = (df[\"sold_at\"] - df[\"created_at\"]).dt.days"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567c2ac3-1066-4e4d-aa3b-4ce81c066e3a",
      "metadata": {
        "id": "d276e789a9a1"
      },
      "source": [
        "Calculate the discount-percentages that apply to the products."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d681d9e-ead2-4b49-bac4-7abba52c7d39",
      "metadata": {
        "id": "c143c79dc7d1"
      },
      "outputs": [],
      "source": [
        "# calculate the discount offered\n",
        "df[\"discount_perc\"] = (df[\"product_retail_price\"] - df[\"cost\"]) / df[\n",
        "    \"product_retail_price\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ff14a1-cfdd-4623-aec7-5dc4eadb64cb",
      "metadata": {
        "id": "d5d9ce9bb19b"
      },
      "source": [
        "Check the unique products and their brands in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b325a469-8dae-4963-bccb-8ab24fe729d5",
      "metadata": {
        "id": "ac2e5ca3912e"
      },
      "outputs": [],
      "source": [
        "# check total unique items\n",
        "df[\"product_id\"].unique().shape, df[\"product_brand\"].unique().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca6d78d-7ffb-4ef5-b3cb-aa95d1788323",
      "metadata": {
        "id": "e667cd5fbb35"
      },
      "source": [
        "The fields `product_id` and `product_brand` seem to have a lot of unique values. For the purpose of prediction, we will use `product_id` as the primary-key and `product_brand` is dropped as it has too many values/levels. \n",
        "\n",
        "Segregate the required numerical and categorical fields to analyze the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273f8d73-d09d-4b30-8898-35bfdd8b7d9e",
      "metadata": {
        "id": "042f5cd1ff2e"
      },
      "outputs": [],
      "source": [
        "categ_cols = [\n",
        "    \"product_category\",\n",
        "    \"product_department\",\n",
        "    \"product_distribution_center_id\",\n",
        "    \"arrival_month\",\n",
        "]\n",
        "num_cols = [\"cost\", \"product_retail_price\", \"discount_perc\", \"shelf_days\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8774598c-ab9a-4812-9377-333d816f7555",
      "metadata": {
        "id": "6fa0a2d8b5ca"
      },
      "source": [
        "Check the count of individual categories for each categorical field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb985ca5-dafb-4447-aa9f-d0555bb114f5",
      "metadata": {
        "id": "16da0524b2ed"
      },
      "outputs": [],
      "source": [
        "for i in categ_cols:\n",
        "    print(i, \" - \", df[i].unique().shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ed531e-957c-4a64-a794-fa4461af220d",
      "metadata": {
        "id": "268ed7b88e23"
      },
      "source": [
        "Check the distribution of the numerial fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4901cc0-1d13-418b-a309-0f0c0477055f",
      "metadata": {
        "id": "bf50a707aa90"
      },
      "outputs": [],
      "source": [
        "df[num_cols].describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e5c972-5d9c-48ca-a922-bac76fcd0db2",
      "metadata": {
        "id": "8888f572c8d1"
      },
      "source": [
        "Generate bar-plots for categorical fields and histograms and box-plots for numerical fields to check their distributions in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dbf4d3f-9528-4802-a385-dbe0783fd99c",
      "metadata": {
        "id": "112fe37b915f"
      },
      "outputs": [],
      "source": [
        "for i in categ_cols:\n",
        "    df[i].value_counts(normalize=True).plot(kind=\"bar\")\n",
        "    plt.title(i)\n",
        "    plt.show()\n",
        "\n",
        "for i in num_cols:\n",
        "    _, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    df[i].plot(kind=\"box\", ax=ax[0])\n",
        "    df[i].plot(kind=\"hist\", ax=ax[1])\n",
        "    ax[0].set_title(i + \"-Boxplot\")\n",
        "    ax[1].set_title(i + \"-Histogram\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f39269f2-15b1-451b-b9c1-9fdb150e60e3",
      "metadata": {
        "id": "0250e32de345"
      },
      "source": [
        "Most of the fields like discount, department, distribution center-id have a decent dsitribution. For the field `product_category`, there are some categories that don't constitute 2% of the dataset at least. Although there are  outliers noticed for some numerical fields, they are exempted from removing as there can be products that are expensive or belonging to a particular category that doesn't often see many sales. \n",
        "\n",
        "## Feature preprocessing\n",
        "<a name=\"section-7\"></a>\n",
        "\n",
        "Next, we aggregate the data based on suitable categorical fields in the data and take the average of number of days it took for the product to get sold. For a given `product_id`, there can be multiple item `id`s in this dataset and we want to predict at the product level if that particular product is going to be sold in the next couple of months or not. More accurately describing, we are aggregating the data based on each of the product configurations present in this dataset like the price, cost, category and at which center it is being sold. This way the model can predict *whether a product with so and so properties is going to be sold in the next couple of months or not*.\n",
        "\n",
        "For the number of days a product got sold in, we will find the average of the `shelf_days` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f19503-3077-402c-93a6-54e3a3c8ff7a",
      "metadata": {
        "id": "8daf9985aa23"
      },
      "outputs": [],
      "source": [
        "groupby_cols = [\n",
        "    \"product_id\",\n",
        "    \"product_distribution_center_id\",\n",
        "    \"product_category\",\n",
        "    \"product_department\",\n",
        "    \"arrival_month\",\n",
        "    \"product_retail_price\",\n",
        "    \"cost\",\n",
        "    \"discount_perc\",\n",
        "]\n",
        "value_cols = [\"shelf_days\"]\n",
        "\n",
        "\n",
        "df_prod = df[groupby_cols + value_cols].groupby(by=groupby_cols).mean().reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb93904-bf61-4c77-84a7-d99952f21d2e",
      "metadata": {
        "id": "fbaf4c3f5a83"
      },
      "source": [
        "Check the aggregated product level data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e4208c-7f69-4b95-99c9-c72a2aca6e6b",
      "metadata": {
        "id": "74afffc4380a"
      },
      "outputs": [],
      "source": [
        "df_prod.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d57144-c0ba-4d66-aac3-13b983df81e3",
      "metadata": {
        "id": "c9aafbab9c88"
      },
      "source": [
        "Look for null values in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa06a557-cb3d-4b92-b80e-c5af02d6ae69",
      "metadata": {
        "id": "26523245c145"
      },
      "outputs": [],
      "source": [
        "df_prod.isna().sum() / df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7b9a807-c72f-49f2-8811-61af54ea4ef9",
      "metadata": {
        "id": "bafab84172e7"
      },
      "source": [
        "Only the `shelf_days` field has null values that correspond to the `product_id`s that have no sold items. \n",
        "\n",
        "Plot the distribution of the aggregated `shelf_days` field by generating a box-plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a206e6eb-3d36-4db4-8e0d-58158174d041",
      "metadata": {
        "id": "efe00052e1fd"
      },
      "outputs": [],
      "source": [
        "df_prod[\"shelf_days\"].plot(kind=\"box\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2227dad0-9472-4ed8-9f38-25ed77f67de1",
      "metadata": {
        "id": "8acaa01b21bd"
      },
      "source": [
        "Here, we can see that most of the products are sold within 60 days since they've arrived in the inventory/store. For this tutorial, we will train a machine-learning model that predicts the probability of a product being sold in 60 days.\n",
        "\n",
        "### Encode the categorical fields\n",
        "Encode the the `shelf_days` field to generate the target field `sold_in_2mnt` indicitating if the product was sold in 60 days or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dbe2b11-bb27-4138-a959-36d8a6b07ccf",
      "metadata": {
        "id": "383915875d38"
      },
      "outputs": [],
      "source": [
        "df_prod[\"sold_in_2mnt\"] = df_prod[\"shelf_days\"].apply(\n",
        "    lambda x: 1 if x >= 0 and x < 60 else 0\n",
        ")\n",
        "df_prod[\"sold_in_2mnt\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6893a836-f036-4433-bfbf-f3c1859c69e6",
      "metadata": {
        "id": "4dd380c38579"
      },
      "source": [
        "Segregate the features into variables for model building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc4e307-ae39-4a17-b03e-fbd241fb71dc",
      "metadata": {
        "id": "40d373151be5"
      },
      "outputs": [],
      "source": [
        "target = \"sold_in_2mnt\"\n",
        "categ_cols = [\n",
        "    \"product_category\",\n",
        "    \"product_department\",\n",
        "    \"product_distribution_center_id\",\n",
        "    \"arrival_month\",\n",
        "]\n",
        "num_cols = [\"product_retail_price\", \"cost\", \"discount_perc\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d3d4b7-a47b-4a46-9ce8-da521df8d014",
      "metadata": {
        "id": "87ce893f2d45"
      },
      "source": [
        "Encode the `product_department` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315e495a-8ad5-4503-8c47-ffcf0d65efea",
      "metadata": {
        "id": "bd68935d2a12"
      },
      "outputs": [],
      "source": [
        "df[\"product_deprtment\"] = (\n",
        "    df[\"product_department\"].apply(lambda x: 1 if x == \"Women\" else 0).value_counts()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a35c5134-05d3-492d-a45d-bac0eae97987",
      "metadata": {
        "id": "6d23387828fd"
      },
      "source": [
        "Encode the rest of the categorical fields for model building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a9755a-221c-43a5-a62b-5a305247bc53",
      "metadata": {
        "id": "8bbdbfa3a4cf"
      },
      "outputs": [],
      "source": [
        "# Create dummy variables for each categ. variable\n",
        "for i in categ_cols:\n",
        "    ml = pd.get_dummies(df_prod[i], prefix=i + \"_\", drop_first=True)\n",
        "    df_new = pd.concat([df_prod, ml], axis=1)\n",
        "\n",
        "df_new.drop(columns=categ_cols, inplace=True)\n",
        "df_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3047754-24d2-4baf-9f78-b3fd7352b8fa",
      "metadata": {
        "id": "f8c85be588b4"
      },
      "source": [
        "### Normalize the numerical fields\n",
        "\n",
        "Normalize the fields `product_retail_price` and `cost` to the 0-1 scale using Min-Max normalization technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5356cb6-db25-40ed-b0f8-76e8a7a5c7b5",
      "metadata": {
        "id": "0790352a2ce9"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler = scaler.fit(df_new[[\"product_retail_price\", \"cost\"]])\n",
        "df_new[[\"product_retail_price_norm\", \"cost_norm\"]] = scaler.transform(\n",
        "    df_new[[\"product_retail_price\", \"cost\"]]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5e9da54-53e7-4bab-835f-2e3546c29c25",
      "metadata": {
        "id": "86e444ca1e02"
      },
      "source": [
        "## Model building\n",
        "<a name=\"section-8\"></a>\n",
        "\n",
        "### Train the model\n",
        "<a name=\"section-9\"></a>\n",
        "\n",
        "Collect the required fields from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b93d6f-0abd-467b-9f28-37a92a853c7e",
      "metadata": {
        "id": "360ab6634571"
      },
      "outputs": [],
      "source": [
        "cols = [\n",
        "    \"discount_perc\",\n",
        "    \"arrival_month__2\",\n",
        "    \"arrival_month__3\",\n",
        "    \"arrival_month__4\",\n",
        "    \"arrival_month__5\",\n",
        "    \"arrival_month__6\",\n",
        "    \"arrival_month__7\",\n",
        "    \"arrival_month__8\",\n",
        "    \"arrival_month__9\",\n",
        "    \"arrival_month__10\",\n",
        "    \"arrival_month__11\",\n",
        "    \"arrival_month__12\",\n",
        "    \"product_retail_price_norm\",\n",
        "    \"cost_norm\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e69f75-eabf-4ce3-b8ab-c38cbc04b78a",
      "metadata": {
        "id": "500051a07ae8"
      },
      "source": [
        "Split the data into train(80%) and test(20%) sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6088da78-16be-4ed0-8b45-e06ca8054290",
      "metadata": {
        "id": "44ab347a30da"
      },
      "outputs": [],
      "source": [
        "X = df_new[cols].copy()\n",
        "y = df_new[target].copy()\n",
        "train_X, test_X, train_y, test_y = train_test_split(\n",
        "    X, y, train_size=0.8, test_size=0.2, random_state=7\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe69185f-ea51-4f07-a73c-458bf89bdc6d",
      "metadata": {
        "id": "c29820548054"
      },
      "source": [
        "Create the classifier and fit it on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd1ed9b-9bc4-46f8-b036-38a57e55bf63",
      "metadata": {
        "id": "5b88ca090e82"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(random_state=7, n_estimators=100)\n",
        "model.fit(train_X[cols], train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b2aaab8-db9e-4dd0-91c9-e285231b6c0b",
      "metadata": {
        "id": "ef4e662be2c3"
      },
      "source": [
        "### Evaluate the model\n",
        "<a name=\"section-10\"></a>\n",
        "\n",
        "\n",
        "Predict on the test set and check the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79121b25-13af-4a53-9929-b3b87c689a0e",
      "metadata": {
        "id": "22f02b56dfb4"
      },
      "outputs": [],
      "source": [
        "pred_y = model.predict(test_X[cols])\n",
        "\n",
        "# Calculate the accuracy as our performance metric\n",
        "accuracy = metrics.accuracy_score(test_y, pred_y)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "417935ae-d48d-4deb-9a04-fa4d5ee25e72",
      "metadata": {
        "id": "6f8bd1bc40c8"
      },
      "source": [
        "Generate the confusion-matrix on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12717f8f-71d6-4cff-b15c-00e52c13636f",
      "metadata": {
        "id": "c6f38583e47b"
      },
      "outputs": [],
      "source": [
        "confusion = metrics.confusion_matrix(test_y, pred_y)\n",
        "print(f\"Confusion matrix:\\n{confusion}\")\n",
        "\n",
        "print(\"\\nNormalized confusion matrix:\")\n",
        "for row in confusion:\n",
        "    print(row / row.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78efc529-9ff3-4506-a280-cd220434037d",
      "metadata": {
        "id": "e5be657cf605"
      },
      "source": [
        "The model performance can be stated in terms of specificity(True-negative rate) and sensitivity(True-postivie rate). In the normalized confusion matrix, the top left value represents the True-negative rate and the bottom right value represents the True-positive rate.\n",
        "\n",
        "## Save the model to a Cloud Storage bucket\n",
        "<a name=\"section-11\"></a>\n",
        "\n",
        "Next, save the model to the created Cloud Storage bucket for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef7d10f4-57e0-4763-805d-cb6d5d5c7168",
      "metadata": {
        "id": "f133a2b37e72"
      },
      "outputs": [],
      "source": [
        "# save the trained model to a local file \"model.joblib\"\n",
        "FILE_NAME = \"model.joblib\"\n",
        "joblib.dump(model, FILE_NAME)\n",
        "\n",
        "# Upload the saved model file to Cloud Storage\n",
        "BLOB_PATH = \"inventory_prediction/\"\n",
        "BLOB_NAME = os.path.join(BLOB_PATH, FILE_NAME)\n",
        "\n",
        "bucket = storage.Client().bucket(BUCKET_NAME)\n",
        "\n",
        "blob = bucket.blob(BLOB_NAME)\n",
        "blob.upload_from_filename(FILE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696e17b0-9267-4fcd-b86a-a2267a153ef1",
      "metadata": {
        "id": "870deb700dbe"
      },
      "source": [
        "## Create a model in Vertex AI\n",
        "<a name=\"section-12\"></a>\n",
        "\n",
        "Specify the corresponding model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159002c4-2929-49ca-8a94-107956cda0e0",
      "metadata": {
        "id": "abba6fb0e95e"
      },
      "outputs": [],
      "source": [
        "MODEL_DISPLAY_NAME = \"inventory_prediction_model\"\n",
        "ARTIFACT_GCS_PATH = f\"gs://{BUCKET_NAME}/{BLOB_PATH}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdcbc8a2-488e-47b8-a7c1-d3ac95ddda93",
      "metadata": {
        "id": "abdf27ad5868"
      },
      "source": [
        "Create a Vertex AI model resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e599258-ad35-427d-abe7-91db89bd8f8f",
      "metadata": {
        "id": "7f5056eebe27"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=MODEL_DISPLAY_NAME,\n",
        "    artifact_uri=ARTIFACT_GCS_PATH,\n",
        "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(model.display_name)\n",
        "print(model.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc7ec92-1d4b-456a-bdfc-75b90c1bc328",
      "metadata": {
        "id": "b79b95b76f04"
      },
      "source": [
        "## Create an Endpoint\n",
        "<a name=\"section-13\"></a>\n",
        "\n",
        "Set the display name for the endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f255545-cca7-4dc1-8354-5bd960b376cd",
      "metadata": {
        "id": "3772df492ba8"
      },
      "outputs": [],
      "source": [
        "ENDPOINT_DISPLAY_NAME = \"inventory_prediction_endpoint\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76cc86d8-3800-46ac-bb73-abd8d62dc1ec",
      "metadata": {
        "id": "7a7a33af9232"
      },
      "source": [
        "Create an endpoint resource on Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff43e472-4396-40e7-8515-cbc909894768",
      "metadata": {
        "id": "de9b0b9098f9"
      },
      "outputs": [],
      "source": [
        "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
        "\n",
        "print(endpoint.display_name)\n",
        "print(endpoint.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f1fc9b-138c-4e0c-a6b0-5a6efad3eab2",
      "metadata": {
        "id": "8013ca32c1a3"
      },
      "source": [
        "## Deploy the model to the created Endpoint\n",
        "<a name=\"section-14\"></a>\n",
        "\n",
        "Configure the deployment name, machine type, and other parameters for the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f9a595e-ceec-4c63-b419-dace7227362d",
      "metadata": {
        "id": "f70de6008667"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_MODEL_NAME = \"inventory_prediction_deployment\"\n",
        "MACHINE_TYPE = \"n1-standard-2\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add5fb0f-d1cb-472f-be85-c7c2659c6f2a",
      "metadata": {
        "id": "9a20c48a5cc9"
      },
      "source": [
        "Deploy the model to the created endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d28a77-1cbc-4d9d-b431-c4c7a2c8773c",
      "metadata": {
        "id": "7739e77d3a4a"
      },
      "outputs": [],
      "source": [
        "model.deploy(\n",
        "    endpoint=endpoint,\n",
        "    deployed_model_display_name=DEPLOYED_MODEL_NAME,\n",
        "    machine_type=MACHINE_TYPE,\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(\"Model display-name - \", model.display_name)\n",
        "print(\"Model resource-name - \", model.resource_name)\n",
        "endpoint.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f43e82b0-676c-419d-ba6f-8c49451bfa8a",
      "metadata": {
        "id": "0566b8cbd2e8"
      },
      "source": [
        "Note the `DEPLOYED_MODEL_ID` for deleting the deployment during clean up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa572fbf-07bf-484e-bb9b-bb8e87ca9c97",
      "metadata": {
        "id": "2c1f8add7fcb"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_MODEL_ID = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc83f210-3b53-478f-a5f2-016927b43fd6",
      "metadata": {
        "id": "75cbc77cbcd9"
      },
      "source": [
        "## What-If Tool\n",
        "<a name=\"section-15\"></a>\n",
        "\n",
        "The What-If Tool can be used to analyze the model predictions on test data. See a brief introduction to the [What-If Tool](https://pair-code.github.io/what-if-tool/get-started/). In this tutorial, the What-If Tool will be configured and run on the model deployed on Vertex AI Endpoints in the previous steps.\n",
        "\n",
        "WitConfigBuilder provides the set_ai_platform_model() method to configure the What-If Tool with a model deployed as a version on Ai Platform models. This feature currently supports only Ai Platform but not Vertex AI models. Fortunately, there is also an option to pass a custom function for generating predictions through the set_custom_predict_fn() method where either the locally trained model or a function that returns predictions from a Vertex AI model can be passed.\n",
        "\n",
        "### Prepare test samples\n",
        "Save some samples from the test data for both the available classes (Fraud/not-Fraud) to analyze the model using the What-If Tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82618cf-1570-443d-a13b-0b27fc2c6d32",
      "metadata": {
        "id": "81839e084a9e"
      },
      "outputs": [],
      "source": [
        "# collect some samples for each class-label from the test data\n",
        "sample_size = 200\n",
        "pos_samples = test_y[test_y == 1].sample(sample_size).index\n",
        "neg_samples = test_y[test_y == 0].sample(sample_size).index\n",
        "test_samples_y = pd.concat([test_y.loc[pos_samples], test_y.loc[neg_samples]])\n",
        "test_samples_X = test_X.loc[test_samples_y.index].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4890b3d7-efb8-4a4d-8fa8-0d2f55af29e5",
      "metadata": {
        "id": "8974bf829a5f"
      },
      "source": [
        "## Running the What-If Tool on the deployed Vertex AI model\n",
        "\n",
        "Define a function to fetch the predictions from the deployed model and run it on the created test data configuring the What-If tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd0a712-a15a-4a45-8818-f1ab9d39baef",
      "metadata": {
        "id": "1cf06d79a585"
      },
      "outputs": [],
      "source": [
        "# configure the target and class-labels\n",
        "TARGET_FEATURE = target\n",
        "LABEL_VOCAB = [\"not-sold\", \"sold\"]\n",
        "\n",
        "# function to return predictions from the deployed Model\n",
        "\n",
        "\n",
        "def endpoint_predict_sample(instances: list):\n",
        "    prediction = endpoint.predict(instances=instances)\n",
        "    preds = [[1 - i, i] for i in prediction.predictions]\n",
        "    return preds\n",
        "\n",
        "\n",
        "# Combine the features and labels into one array for the What-If Tool\n",
        "test_examples = np.hstack(\n",
        "    (test_samples_X.to_numpy(), test_samples_y.to_numpy().reshape(-1, 1))\n",
        ")\n",
        "\n",
        "# Configure the WIT with the prediction function\n",
        "config_builder = (\n",
        "    WitConfigBuilder(test_examples.tolist(), test_samples_X.columns.tolist() + [target])\n",
        "    .set_custom_predict_fn(endpoint_predict_sample)\n",
        "    .set_target_feature(TARGET_FEATURE)\n",
        "    .set_label_vocab(LABEL_VOCAB)\n",
        ")\n",
        "\n",
        "# run the WIT-widget\n",
        "WitWidget(config_builder, height=800)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53cab026-5022-44b2-a055-bf654a47e12d",
      "metadata": {
        "id": "6638bb7caaeb"
      },
      "source": [
        "### Understanding the What-If tool\n",
        "\n",
        "In the **Datapoint editor** tab, you can highlight a dot in the result set and ask the What If tool to pick the \"nearest counterfactual\". This is a row of data closest to the row of data you selected but with the opposite outcome. Features in the left-hand table are editable and can show what tweaks are needed to get a particular row of data to flip from one outcome to another. For example, altering the *discount_percentage* feature would show how it impacts the prediction. \n",
        "\n",
        "<img src=\"images/Datapoint_editor.png\">\n",
        "\n",
        "Under the **Performance & Fairness** tab, you can slice the prediction results by a second variable. This allows digging deeper and understanding how different segments of the data react to the model's predictions.  For example, in the following image, the higher the *discount_percentage*, the lesser the false negatives and the lower the *discount_percentage*, the higher the false positives. \n",
        "\n",
        "<img src=\"images/Performance_and_fairness.png\">\n",
        "\n",
        "The **Features** tab in the end provides you an intuitive and interactive way to understand the features present in the data. Similar to the exploratory data analysis steps performed in this notebook, What-If tool provides a visual and statistical description on the features.\n",
        "\n",
        "<img src=\"images/features.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a49790-0167-428c-8c00-d16d255832ee",
      "metadata": {
        "id": "d17d23fab0b1"
      },
      "source": [
        "## Clean up\n",
        "<a name=\"section-16\"></a>\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can delete the Google Cloud project you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "Undeploy the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce29713a-ae90-4c2b-9bb6-34b9893e4e51",
      "metadata": {
        "id": "ff1d9ce89db8"
      },
      "outputs": [],
      "source": [
        "endpoint.undeploy(deployed_model_id=DEPLOYED_MODEL_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e227459d-d1ca-4952-8e21-4e7439743f6e",
      "metadata": {
        "id": "e741829407b5"
      },
      "source": [
        "Delete the endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a4a2eb-23ac-4389-ab55-c6a5eac33341",
      "metadata": {
        "id": "c9675acf4eab"
      },
      "outputs": [],
      "source": [
        "endpoint.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb80d62e-a34d-4841-a2ce-f07817f2c111",
      "metadata": {
        "id": "c2034b17325e"
      },
      "source": [
        "Delete the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c65d7d-230a-4108-b0b3-da0182bcb1b5",
      "metadata": {
        "id": "5adff8193eae"
      },
      "outputs": [],
      "source": [
        "model.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ea4b9b-062c-4b41-8e5a-bd570011d3c5",
      "metadata": {
        "id": "7bfcf86db9ca"
      },
      "source": [
        "Remove the contents of the Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca19ad7-35fa-45f3-b47e-fff2eb03e5a2",
      "metadata": {
        "id": "f68de1489758"
      },
      "outputs": [],
      "source": [
        "! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "inventory_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
