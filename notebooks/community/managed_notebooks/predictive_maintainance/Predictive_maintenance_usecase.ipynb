{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dd1bf63e-8386-4b5c-a17d-2c750cf79746",
      "metadata": {
        "id": "aef73cfa8725"
      },
      "source": [
        "# Predictive Maintenance \n",
        "## Table of contents\n",
        "* [Overview](#section-1)\n",
        "* [Dataset](#section-2)\n",
        "* [Objective](#section-3)\n",
        "* [Costs](#section-4)\n",
        "* [Data Analysis](#section-5)\n",
        "* [Fit a Regression model](#section-6)\n",
        "* [Evaluate the trained model](#section-7)\n",
        "* [Save the model](#section-8)\n",
        "* [Running a notebook end-to-end using **Executor**](#section-9)\n",
        "* [Hosting the model on Vertex AI](#section-10)\n",
        "   * [Create an Endpoint](#section-11)\n",
        "   * [Deploy the model to the created Endpoint](#section-12)\n",
        "   * [Test calling the endpoint](#section-13)\n",
        "* [Clean up](#section-14)\n",
        "\n",
        "\n",
        "## Overview\n",
        "<a name=\"section-1\"></a>\n",
        "This notebook demonstrates performing predictive maintenance on industrial data using machine learning techniques, deploying the machine learning model on Vertex-AI and automating the workflow using executor feature of Vertex-AI.\n",
        "\n",
        "<b>Note</b>: This notebook is designed to run on managed notebooks instance of Vertex AI Workbench. Some components of this notebook may not work in other notebook environments.\n",
        "\n",
        "## Dataset\n",
        "<a name=\"section-2\"></a>\n",
        "The dataset used in this notebook is a part of the [NASA Turbofan Engine Degradation Dataset](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/) which consists of simulated time-series data for four sets of fleet-engines under different combinations of operational conditions and fault modes. In this notebook, only one of the engine's simulated data(FD001) has been considered to analyze and train a model that can predict the engine's remaining useful life.\n",
        "\n",
        "## Objective\n",
        "<a name=\"section-3\"></a>\n",
        "In this notebook :\n",
        "\n",
        "- Loading the required dataset from Cloud Storage bucket.\n",
        "- Analysizing the fields present in the dataset.\n",
        "- Selecting the required data for the predictive maintenance model.\n",
        "- Training an XGBoost regression model for predicting the remaining useful life.\n",
        "- Evaluating the model.\n",
        "- Running the notebook end-to-end as a training job using Executor.\n",
        "- Deploying the model on Vertex-AI.\n",
        "- Clean up.\n",
        "\n",
        "\n",
        "## Costs\n",
        "<a name=\"section-4\"></a>\n",
        "This tutorial uses the following billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "- Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d0a049-890b-4b8b-8365-2df32c9cb224",
      "metadata": {
        "id": "5b15a97278df"
      },
      "source": [
        "## Kernel selection\n",
        "Select <b>XGBoost</b> kernel while running this notebook on Vertex-AIs managed instances or ensure that the following libraries are installed in the environment where this notebook is being run.\n",
        "- XGBoost\n",
        "- Pandas\n",
        "- Seaborn\n",
        "- Sklearn\n",
        "\n",
        "Along with the above libraries, the following google-cloud libraries are also used in this notebook.\n",
        "\n",
        "- google.cloud.aiplatform\n",
        "- google.cloud.storage\n",
        "\n",
        "## Set your project ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c0ea84-950f-47ae-99f4-26d513717e85",
      "metadata": {
        "id": "d229c5c1db1b"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03a1fde7-c0d5-4b21-9fec-a67a40d163a6",
      "metadata": {
        "id": "f66f96816fd0"
      },
      "source": [
        "#### Timestamp\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06ff403-58af-4d8a-9eec-c3066dfada4f",
      "metadata": {
        "id": "ac7ff88c7f84"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb49945-6c14-49fa-92bd-53ab576e3fca",
      "metadata": {
        "id": "ea53caa30628"
      },
      "source": [
        "## Select or Create Cloud Storage Bucket for storing the model\n",
        "\n",
        "When you create a model resource on Vertex-AI using the Cloud SDK, you need to give a Cloud Storage bucket uri of the model where the model is stored. Using the model saved, you can then create Vertex AI model and endpoint resources in order to serve online predictions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all Cloud Storage buckets.You may also change the REGION variable, which is used for operations throughout the rest of this notebook. Make sure to choose a region where Vertex AI services are available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8064f8f-b7dd-41f4-a763-09f4d7c45a77",
      "metadata": {
        "id": "4a1a3af1611d"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cbd8e18-3a4b-46ae-8f1a-f84a03d3f18b",
      "metadata": {
        "id": "31f8a617f42f"
      },
      "outputs": [],
      "source": [
        "# Set a default bucketname in case bucket name is not given\n",
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None:\n",
        "    from datetime import datetime\n",
        "\n",
        "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
        "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca4db75-6d9e-4d8a-b606-11b299d86444",
      "metadata": {
        "id": "e27907c70873"
      },
      "source": [
        "<b>Only if your bucket doesn't already exist</b>: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43f72a5a-d66b-49b6-8cea-1810cd8718b8",
      "metadata": {
        "id": "dbd413ba606f"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3e90e5-36a9-4185-8e42-d5aa47e9e099",
      "metadata": {
        "id": "7481ea67bbe2"
      },
      "source": [
        "Next, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca5ede2-3738-4c2e-a07a-f4e97bc8c718",
      "metadata": {
        "id": "0237e1b73154"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e1f4df-2581-4054-aef6-82b608b28c42",
      "metadata": {
        "id": "4c0f6aac282a"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a733f45d",
      "metadata": {
        "id": "33f840806ed4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# load the required libraries\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from google.cloud import aiplatform, storage\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f954e77-70ca-440c-ba20-ffefa4235f02",
      "metadata": {
        "id": "08bcba53eb99"
      },
      "source": [
        "Load the data and check the data shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6784c21",
      "metadata": {
        "id": "2890f46a1907"
      },
      "outputs": [],
      "source": [
        "# load the data from the source\n",
        "INPUT_PATH = \"gs://vertex_ai_managed_services_demo/mfg_predictive_maintenance/train_FD001.txt\"  # data source\n",
        "raw_data = pd.read_csv(INPUT_PATH, sep=\" \", header=None)\n",
        "# check the data\n",
        "print(raw_data.shape)\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09267bf-cddf-48b2-83ab-06d084822d0c",
      "metadata": {
        "id": "8cfc304d35b5"
      },
      "source": [
        "The data itself doesn't contain any feature names and thus needs its columns to be re-named. The data source already provides us with some data description. Apparently, the <b>ID</b> column represents the unit-number of the fleet-engine and <b>Cycle</b> represents the time in cycles. <b>OpSet1</b>,<b>Opset2</b> & <b>Opset3</b> represent the three operational settings that are described in the original data source and have a substantial effect on engine performance. The rest of the fields show sensor readings collected from 21 different sensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1843c1c",
      "metadata": {
        "id": "34251837c120"
      },
      "outputs": [],
      "source": [
        "# name the columns (based on the original data source page)\n",
        "raw_data = raw_data[[f for f in range(0, 26)]]\n",
        "raw_data.columns = [\n",
        "    \"ID\",\n",
        "    \"Cycle\",\n",
        "    \"OpSet1\",\n",
        "    \"OpSet2\",\n",
        "    \"OpSet3\",\n",
        "    \"SensorMeasure1\",\n",
        "    \"SensorMeasure2\",\n",
        "    \"SensorMeasure3\",\n",
        "    \"SensorMeasure4\",\n",
        "    \"SensorMeasure5\",\n",
        "    \"SensorMeasure6\",\n",
        "    \"SensorMeasure7\",\n",
        "    \"SensorMeasure8\",\n",
        "    \"SensorMeasure9\",\n",
        "    \"SensorMeasure10\",\n",
        "    \"SensorMeasure11\",\n",
        "    \"SensorMeasure12\",\n",
        "    \"SensorMeasure13\",\n",
        "    \"SensorMeasure14\",\n",
        "    \"SensorMeasure15\",\n",
        "    \"SensorMeasure16\",\n",
        "    \"SensorMeasure17\",\n",
        "    \"SensorMeasure18\",\n",
        "    \"SensorMeasure19\",\n",
        "    \"SensorMeasure20\",\n",
        "    \"SensorMeasure21\",\n",
        "]\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaab311f-404a-42a2-85e2-42c515882836",
      "metadata": {
        "id": "da8c475ddc86"
      },
      "source": [
        "## Data Analysis\n",
        "<a name=\"section-5\"></a>\n",
        "The current dataset consists of timeseries data for various unit IDs. The data is represented in terms of cycles. Lets first see the distribution of number of cycles across the units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3c9651",
      "metadata": {
        "id": "e18ef3931be5"
      },
      "outputs": [],
      "source": [
        "# plot the cycle count for each IDs\n",
        "raw_data[[\"ID\", \"Cycle\"]].groupby(by=[\"ID\"]).count().plot(kind=\"bar\", figsize=(12, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b85e4206-44f8-4805-b246-4a316095e10b",
      "metadata": {
        "id": "43c3f01352ad"
      },
      "source": [
        "On an average, there seems to be around 225 cycles per each ID in the dataset. Further, lets check the data-types of the fields and the number of null records in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d8b737",
      "metadata": {
        "id": "d83cddab2b28"
      },
      "outputs": [],
      "source": [
        "# check the data-types\n",
        "raw_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ddf59e-f02d-4018-a38c-2ff06ac718b3",
      "metadata": {
        "id": "da698b792397"
      },
      "source": [
        "The data doesn't have any null records or any categorical fields. Next, lets check the numerical distribution of the fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a7d964",
      "metadata": {
        "id": "18d8731e68aa"
      },
      "outputs": [],
      "source": [
        "# check the numerical characteristics of the data\n",
        "raw_data.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42d68273-3080-41f6-b77b-37977d8b403c",
      "metadata": {
        "id": "b632592001d5"
      },
      "source": [
        "Features **OpSet3**, **SensorMeasure1**,**SensorMeasure10**, **SensorMeasure18** & **SensorMeasure19** seem to be constant throughout the dataset and thus can be eliminated. Apart from the fields that are constant throughout the data, fields that are correlated highly can also be considered for dropping. Having highly correlated fields in the data often leads to multi-collinearity situation which unnecessarily increases the size of feature-space even if it doesn't affect the accuracy much. Such fields can be identified through correlation-matrices and heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "429a2e6e",
      "metadata": {
        "id": "2d41a0e277b2"
      },
      "outputs": [],
      "source": [
        "# plot the correlation matrix\n",
        "plt.figure(figsize=(15, 10))\n",
        "cols = [\n",
        "    i\n",
        "    for i in raw_data.columns\n",
        "    if i\n",
        "    not in [\n",
        "        \"ID\",\n",
        "        \"Cycle\",\n",
        "        \"OpSet3\",\n",
        "        \"SensorMeasure1\",\n",
        "        \"SensorMeasure10\",\n",
        "        \"SensorMeasure18\",\n",
        "        \"SensorMeasure19\",\n",
        "    ]\n",
        "]\n",
        "corr_mat = raw_data[cols].corr()\n",
        "matrix = np.triu(corr_mat)\n",
        "\n",
        "sns.heatmap(corr_mat, annot=True, mask=matrix, fmt=\".1g\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e2ec73-70b8-4c78-b4d0-622da75c8d93",
      "metadata": {
        "id": "284debdf4294"
      },
      "source": [
        "Fields **SensorMeasure7**, **SensorMeasure12**, **SensorMeasure20** & **SensorMeasure21** correlate highly with many other fields. These fields can be omitted. Further, **SensorMeasure8**, **SensorMeasure11** and **SensorMeasure4** seem highly correlated with each other and so any one of them, say **SensorMeasure4** can be kept and the rest can be omitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db50db2e-4a79-4492-9c4a-29db3ad9779e",
      "metadata": {
        "id": "40477e592ce7"
      },
      "outputs": [],
      "source": [
        "cols = [\n",
        "    i\n",
        "    for i in cols\n",
        "    if i\n",
        "    not in [\n",
        "        \"SensorMeasure7\",\n",
        "        \"SensorMeasure12\",\n",
        "        \"SensorMeasure20\",\n",
        "        \"SensorMeasure21\",\n",
        "        \"SensorMeasure8\",\n",
        "        \"SensorMeasure11\",\n",
        "    ]\n",
        "]\n",
        "corr_mat = raw_data[cols].corr()\n",
        "matrix = np.triu(corr_mat)\n",
        "plt.figure(figsize=(9, 5))\n",
        "sns.heatmap(corr_mat, annot=True, mask=matrix, fmt=\".1g\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfac3d67-44b4-4f9a-956d-c1eb26b94a69",
      "metadata": {
        "id": "8197cdef2cff"
      },
      "source": [
        "As the current objective is to predict the remaining useful life(RUL) of each unit(ID), the target variable needs to be identified. Since we're dealing with a timeseries data that represents the lifetime of a unit, remaining useful life of a unit can be calculated by subtracting the current cycle from the maximum cycle of that unit.\n",
        "\n",
        "\t\t\t\t\tRUL = Max. Cycle - Current Cycle    \n",
        "## RUL calculation and Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43292cef",
      "metadata": {
        "id": "b9cd2797cdae"
      },
      "outputs": [],
      "source": [
        "# get max-cycle of the ids\n",
        "cols = [\"ID\", \"Cycle\"] + cols\n",
        "max_cycles_df = (\n",
        "    raw_data.groupby([\"ID\"], sort=False)[\"Cycle\"]\n",
        "    .max()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"Cycle\": \"MaxCycleID\"})\n",
        ")\n",
        "# merge back to original dataset\n",
        "FD001_df = pd.merge(raw_data, max_cycles_df, how=\"inner\", on=\"ID\")\n",
        "# calculate rul from max-cycle and current-cycle\n",
        "FD001_df[\"RUL\"] = FD001_df[\"MaxCycleID\"] - FD001_df[\"Cycle\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b22e01-86ad-46f2-bd89-22e4c7a0f2a1",
      "metadata": {
        "id": "53a73de9ee27"
      },
      "source": [
        "To ensure that the target field is generated properly, the RUL field can be plotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1db9c0-54c3-455a-89e1-2447fb7eba92",
      "metadata": {
        "id": "ecd5aa0a130f"
      },
      "outputs": [],
      "source": [
        "# plot the RUL vs Cycles\n",
        "one_engine = []\n",
        "for i, r in FD001_df.iterrows():\n",
        "    rul = r[\"RUL\"]\n",
        "    one_engine.append(rul)\n",
        "    if rul == 0:\n",
        "        plt.plot(one_engine)\n",
        "        one_engine = []\n",
        "\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee3f8670-40ea-403c-88da-1e7be1b974a5",
      "metadata": {
        "id": "fc3b82355cdc"
      },
      "source": [
        "The above plot suggests that the RUL i.e., the remaining cycles is decreasing as the current cycle increases which is expected. Further, lets see the how the other fields relate to RUL in the current dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9be253-b8cc-4363-b31f-4bc135dabd56",
      "metadata": {
        "id": "30284ff6c8ab"
      },
      "outputs": [],
      "source": [
        "# plot feature vs the RUL\n",
        "def plot_feature(feature):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in FD001_df[\"ID\"].unique():\n",
        "        if i % 10 == 0:  # only plot every 10th ID\n",
        "            plt.plot(\"RUL\", feature, data=FD001_df[FD001_df[\"ID\"] == i])\n",
        "    plt.xlim(250, 0)  # reverse the x-axis so RUL counts down to zero\n",
        "    plt.xticks(np.arange(0, 275, 25))\n",
        "    plt.ylabel(feature)\n",
        "    plt.xlabel(\"RUL\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for i in cols:\n",
        "    if i not in [\"ID\", \"Cycle\"]:\n",
        "        plot_feature(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2fc91f-18c4-4787-9def-5529dac38f60",
      "metadata": {
        "id": "828154ec8d90"
      },
      "source": [
        "The following set of observations can be made from the outcome of the above cell :\n",
        "- Fields **SensorMeasure5** and **SensorMeasure16** don't show much variance with the RUL and seem constant all the time. Hence, they can be removed.\n",
        "- Fields **SensorMeasure2**, **SensorMeasure3**, **SensorMeasure4**, **SensorMeasure13**, **SensorMeasure15** & **SensorMeasure17** show a similar rising trend.\n",
        "- **SensorMeasure9** and **SensorMeasure14** show a similar trend.\n",
        "- **SensorMeasure6** shows flatline most of the time except at a very few places and therefore can be ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b1ab39",
      "metadata": {
        "id": "28395edac8f7"
      },
      "outputs": [],
      "source": [
        "# remove the unnecessary fields\n",
        "cols = [\n",
        "    i\n",
        "    for i in cols\n",
        "    if i not in [\"ID\", \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure16\"]\n",
        "]\n",
        "cols"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b2cd26-306d-4cd7-8d80-9dded91e120f",
      "metadata": {
        "id": "cae198bd96ef"
      },
      "source": [
        "## Split the data into Train and Test\n",
        "\n",
        "Divide the dataset with the selected features into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924dbc82",
      "metadata": {
        "id": "40a38e17b6b0"
      },
      "outputs": [],
      "source": [
        "# split data into train and test\n",
        "X = FD001_df[cols].copy()\n",
        "y = FD001_df[\"RUL\"].copy()\n",
        "\n",
        "# split the data into 70-30 ratio of train-test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=0.7, random_state=36\n",
        ")\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75000a62-ee52-4d7a-a9b7-6785c0df5b24",
      "metadata": {
        "id": "43a26d74c687"
      },
      "source": [
        "## Fit a Regression model\n",
        "<a name=\"section-6\"></a>\n",
        "Initialize and train a regression model using XGBoost library with the calculated RUL as the target feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838a97f1",
      "metadata": {
        "id": "306a693a00ff"
      },
      "outputs": [],
      "source": [
        "model = xgb.XGBRegressor()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d55ea499-1e76-45b5-9c76-b09b14fc759f",
      "metadata": {
        "id": "ef2a6b567e33"
      },
      "source": [
        "## Evaluate the trained model\n",
        "<a name=\"section-7\"></a>\n",
        "\n",
        "Check the R2 scores of the model on train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f785846c",
      "metadata": {
        "id": "e30af6e41081"
      },
      "outputs": [],
      "source": [
        "# print test R2 score\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_score = r2_score(y_train, y_train_pred)\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_score = r2_score(y_test, y_test_pred)\n",
        "print(\"Train score:\", train_score)\n",
        "print(\"Test score:\", test_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f40abb0-b23f-497c-9ef0-d08a5c2eed61",
      "metadata": {
        "id": "a9e00d61b71c"
      },
      "source": [
        "Check the RMSE errors on train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ff1adc-1208-439b-8f95-bc1cebfad4a4",
      "metadata": {
        "id": "5e32f5bcd6b0"
      },
      "outputs": [],
      "source": [
        "# print train and test RMSEs\n",
        "train_error = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "test_error = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "print(\"Train error:\", train_error)\n",
        "print(\"Test error:\", test_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c278f1-9c97-4bbf-adaf-e7f496271a37",
      "metadata": {
        "id": "18e4cf950007"
      },
      "source": [
        "Plot the predicted values against the target values. The closer the plot to a straight line passing through origin with a unit slope, the better the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b63a1f",
      "metadata": {
        "id": "5bde609ba3f9"
      },
      "outputs": [],
      "source": [
        "# plot the train and test predictions\n",
        "plt.scatter(y_train, y_train_pred)\n",
        "plt.xlabel(\"Target\")\n",
        "plt.ylabel(\"Prediction\")\n",
        "plt.title(\"Train\")\n",
        "plt.show()\n",
        "plt.scatter(y_test, y_test_pred)\n",
        "plt.xlabel(\"Target\")\n",
        "plt.ylabel(\"Prediction\")\n",
        "plt.title(\"Test\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af49c092-233e-46fa-9ee9-bb80071ee479",
      "metadata": {
        "id": "cbbcd5de298f"
      },
      "source": [
        "## Save the model\n",
        "<a name=\"section-8\"></a>\n",
        "\n",
        "Save the model to a booster file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "468ff746-bcdd-4763-828a-773e3956fd3c",
      "metadata": {
        "id": "0fdd760d9a74"
      },
      "outputs": [],
      "source": [
        "# save the trained model to a local file \"model.bst\"\n",
        "FILE_NAME = \"model.bst\"\n",
        "model.save_model(FILE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657fa715-75c0-4997-948f-5986717fbb20",
      "metadata": {
        "id": "a83c6f381722"
      },
      "source": [
        "Copy the model to the cloud-storage bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6c956c-b248-4b7c-ba2b-c86092dd473e",
      "metadata": {
        "id": "81fa220c7fd4"
      },
      "outputs": [],
      "source": [
        "# Upload the saved model file to Cloud Storage\n",
        "BLOB_PATH = \"mfg_predictive_maintenance/\"\n",
        "BLOB_NAME = os.path.join(BLOB_PATH, FILE_NAME)\n",
        "bucket = storage.Client().bucket(BUCKET_NAME)\n",
        "blob = bucket.blob(BLOB_NAME)\n",
        "blob.upload_from_filename(FILE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964f7268-4f75-4e70-a323-66b09dd1d8fd",
      "metadata": {
        "id": "4bd88d7f4bbb"
      },
      "source": [
        "## Running a notebook end-to-end using **Executor**\n",
        "<a name=\"section-9\"></a>\n",
        "\n",
        "### Automating the notebook execution\n",
        "All the steps followed till now can be run as a training job without using any additional code using the Notebook executor. Notebook executor can help you run a notebook file from start to end, with your choice of the environment, machine type, input parameters, and other characteristics. After setting up an execution, the notebook is executed as a job in Vertex AI custom training. Your jobs can be monitored from the Notebook Executor pane in the menu on the left.\n",
        "\n",
        "<img src=\"images/executor.PNG\">\n",
        "\n",
        "Executor also lets you choose the environment and machine type while automating the runs similar to Vertex AI training jobs without switching to the training jobs UI. Apart from the custom container that replicates the existing kernel by default, pre-built environments like TensorFlow Enterprise, PyTorch, and others can also be selected to run the notebook. Furthermore the required compute power can be specified by choosing from the list of machine types available, including GPUs.\n",
        "\n",
        "## Scheduled runs on executor\n",
        "Notebook runs can also be scheduled recurringly with the executor. To do so, select Schedule-based recurring executions as the run type instead of One-time execution. The frequency of the job and the time when it executes is provided when you create the execution.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_Vertex_AI_Workbench.max-1100x1100.jpg\">\n",
        "\n",
        "## Parameterizing the variables\n",
        "Executor lets you run a notebook with different sets of input parameters.If youâ€™ve added parameter tags to any of your notebook cells, you can pass in your parameter values to the executor. More about how to use this feature can be found on this [blog](https://cloud.google.com/blog/products/ai-machine-learning/schedule-and-execute-notebooks-with-vertex-ai-workbench).\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_Vertex_AI_Workbench.max-700x700.jpg\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2ff7691-dfbc-42b5-a727-4825f1e970b4",
      "metadata": {
        "id": "57522cb1d5e7"
      },
      "source": [
        "## Hosting the model on Vertex AI\n",
        "<a name=\"section-10\"></a>\n",
        "\n",
        "### Create a model resource\n",
        "\n",
        "The saved model from the cloud storage can be deployed easily using the Vertex-AI sdk. To do so, first create a model resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5813f8-c171-4a2f-8cbf-dba5a4cd91a1",
      "metadata": {
        "id": "246206c9eedc"
      },
      "outputs": [],
      "source": [
        "ARTIFACT_GCS_PATH = f\"gs://{BUCKET_NAME}/{BLOB_PATH}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79192cab-dfad-4b2d-8f96-81a559863f2e",
      "metadata": {
        "id": "49f1acde47e3"
      },
      "outputs": [],
      "source": [
        "# Create a Vertex AI model resource\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=MODEL_DISPLAY_NAME,\n",
        "    artifact_uri=ARTIFACT_GCS_PATH,\n",
        "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-1:latest\",\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(model.display_name)\n",
        "print(model.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfcba65-be85-4cb2-ac55-2a924f34d3dc",
      "metadata": {
        "id": "7784e605fe20"
      },
      "source": [
        "### Create an Endpoint\n",
        "<a name=\"section-11\"></a>\n",
        "\n",
        "\n",
        "Next, create an endpoint resource for deploying the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a095322c-6d20-4ce5-a7a5-7d45138c353e",
      "metadata": {
        "id": "6ae2e3b9555e"
      },
      "outputs": [],
      "source": [
        "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
        "\n",
        "print(endpoint.display_name)\n",
        "print(endpoint.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d293268e-5f20-40c8-baa7-1e895ce307e7",
      "metadata": {
        "id": "08128843a059"
      },
      "source": [
        "### Deploy the model to the created Endpoint\n",
        "<a name=\"section-12\"></a>\n",
        "\n",
        "\n",
        "Configure the deployment name, machine type, and other parameters for the deployment and deploy the model to the created endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3011ec30-1d2d-4444-9d1f-3fd28b4be0e1",
      "metadata": {
        "id": "ca41cac871d6"
      },
      "outputs": [],
      "source": [
        "MACHINE_TYPE = \"n1-standard-2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55e8f65c-37d8-4cf4-be7a-e4e7d5dc76b1",
      "metadata": {
        "id": "3c3e7597d233"
      },
      "outputs": [],
      "source": [
        "# deploy the model to the endpoint\n",
        "model.deploy(\n",
        "    endpoint=endpoint,\n",
        "    deployed_model_display_name=DEPLOYED_MODEL_NAME,\n",
        "    machine_type=MACHINE_TYPE,\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(model.display_name)\n",
        "print(model.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16df0528-f26c-4738-b701-7925ba6db08d",
      "metadata": {
        "id": "5d24eb85cf12"
      },
      "source": [
        "## Test calling the endpoint\n",
        "<a name=\"section-13\"></a>\n",
        "\n",
        "Send some sample data to the deployed model on the endpoint to get predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb9d25b-c45e-4614-9713-2d3ec9e9be81",
      "metadata": {
        "id": "fb6b0fc29a16"
      },
      "outputs": [],
      "source": [
        "# get predictions on sample data\n",
        "instances = X_test.iloc[0:2].to_numpy().tolist()\n",
        "print(endpoint.predict(instances=instances).predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a62e6d2c-fc86-4b01-a383-4f0259d0ff90",
      "metadata": {
        "id": "3cec4549f32c"
      },
      "source": [
        "## Clean up\n",
        "<a name=\"section-14\"></a>\n",
        "\n",
        "Undeploy the model from endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52be4ba0-8d7a-4169-913b-364e9c80bb14",
      "metadata": {
        "id": "737a7b8eb6d6"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_MODEL_ID = \"\"\n",
        "endpoint.undeploy(deployed_model_id=DEPLOYED_MODEL_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c28f62-1506-480b-b453-d98cae16fa85",
      "metadata": {
        "id": "96e427b77791"
      },
      "source": [
        "Delete the endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f30e38a-2770-40b0-ac74-4c266dff639b",
      "metadata": {
        "id": "ace028ac23ea"
      },
      "outputs": [],
      "source": [
        "endpoint.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba57032-3687-40f7-a4e3-7dd595ea0994",
      "metadata": {
        "id": "4b77998d0512"
      },
      "source": [
        "Delete the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0902d96-5d04-4929-a15d-9bd04c8ddba0",
      "metadata": {
        "id": "e034150a4c94"
      },
      "outputs": [],
      "source": [
        "model.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9619b84e-043e-45ec-95a5-f327e47a98da",
      "metadata": {
        "id": "23cb2deb122d"
      },
      "source": [
        "Remove the contents of the Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574b4055-1c34-4dbc-b716-e4a903815c7e",
      "metadata": {
        "id": "98aaac27d85d"
      },
      "outputs": [],
      "source": [
        "! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Predictive_maintenance_usecase.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
