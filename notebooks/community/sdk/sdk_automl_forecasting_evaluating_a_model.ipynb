{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHLV0D7Y5jtU"
      },
      "source": [
        "# Vertex AI Model Builder SDK: AutoML Forecasting Model Training Example\n",
        "\n",
        "To use this Colaboratory notebook, you copy the notebook to your own Google Drive and open it with Colaboratory (or Colab). You can run each step, or cell, and see its results. To run a cell, use Shift+Enter. Colab automatically displays the return value of the last line in each cell. For more information about running notebooks in Colab, see the [Colab welcome page](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
        "\n",
        "This notebook demonstrates how to create an AutoML Forecasting model based on a time series dataset. The process of exporting and visualizing test set predictions will be mentioned as well. It will require you provide a bucket where the dataset will be stored.\n",
        "\n",
        "Note: you may incur charges for training, prediction, storage or usage of other GCP products in connection with testing this SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lld3eeJUs5yM"
      },
      "source": [
        "# Install Vertex AI SDK, Authenticate, and upload of a Dataset to your GCS bucket\n",
        "\n",
        "After the SDK installation the kernel will be automatically restarted. You may see this error message `Your session crashed for an unknown reason` which is normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMZLb8Arr2AG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 uninstall -y google-cloud-aiplatform\n",
        "!pip3 install google-cloud-aiplatform\n",
        "\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApsLDJjdsGPN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0SNmTBeD2nV"
      },
      "source": [
        "### Enter your project and GCS bucket\n",
        "\n",
        "Enter your Project ID in the cell below. Then run the cell to make sure the Cloud SDK uses the right project for all the commands in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s19AzYSGLIb9"
      },
      "source": [
        "**If you don't know your project ID**, you may be able to get your project ID using gcloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwlVqT6RKxG7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5E8VB3jLOFC"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrED76XTK9OB"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkJk7agzT6F9"
      },
      "source": [
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcRkdZBaUAz4"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFfpJs3DQsfo"
      },
      "source": [
        "Set the name of your Cloud Storage bucket below. It must be unique across all Cloud Storage buckets.\n",
        "\n",
        "You may also change the REGION variable, which is used for operations throughout the rest of this notebook. Make sure to [choose a region where Vertex AI services are available](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions). You may not use a Multi-Regional Storage bucket for training with Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqSQT6Z6bekX"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"\"  # @param {type:\"string\"}\n",
        "REGION = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukGsLjm-Ki14"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
        "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6AQjKlnx0mf"
      },
      "source": [
        "The datasets we are using are samples from the [Iowa Liquor Retail Sales](https://pantheon.corp.google.com/marketplace/product/iowa-department-of-commerce/iowa-liquor-sales) dataset. The training sample contains the sales from 2020 and the prediction sample (used in the batch prediction step) contains the January - April sales from 2021."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_T10yTTqcS_"
      },
      "outputs": [],
      "source": [
        "TRAINING_DATASET_BQ_PATH = (\n",
        "    \"bq://bigquery-public-data:iowa_liquor_sales_forecasting.2020_sales_train\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk43VP_IqcTE"
      },
      "source": [
        "# Initialize Vertex AI SDK\n",
        "\n",
        "Initialize the *client* for Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCiC9gBWqcTF"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35QVNhACqcTJ"
      },
      "source": [
        "# Create a Managed Time Series Dataset from BigQuery\n",
        "\n",
        "This section will create a dataset from a BigQuery table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OfCqaYRqcTJ"
      },
      "outputs": [],
      "source": [
        "ds = aiplatform.datasets.TimeSeriesDataset.create(\n",
        "    display_name=\"iowa_liquor_sales_train_job\", bq_source=[TRAINING_DATASET_BQ_PATH]\n",
        ")\n",
        "\n",
        "ds.resource_name\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-bBqipfqcTS"
      },
      "source": [
        "# Launch a Training Job to Create a Model\n",
        "\n",
        "Once we have defined your training script, we will create a model, export the test set predictions, and output the BigQuery location of the test set predictions in the training log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA41rT_mb-rV"
      },
      "outputs": [],
      "source": [
        "time_column = \"date\"\n",
        "time_series_identifier_column = \"store_name\"\n",
        "target_column = \"sale_dollars\"\n",
        "\n",
        "job = aiplatform.AutoMLForecastingTrainingJob(\n",
        "    display_name=\"train-iowa-liquor-sales-automl-1\",\n",
        "    optimization_objective=\"minimize-rmse\",\n",
        "    column_specs={\n",
        "        time_column: \"timestamp\",\n",
        "        target_column: \"numeric\",\n",
        "        \"city\": \"categorical\",\n",
        "        \"zip_code\": \"categorical\",\n",
        "        \"county\": \"categorical\",\n",
        "    },\n",
        ")\n",
        "\n",
        "dataset_id = \"iowa_liquor_sales_train_job\"\n",
        "bq_table_name = \"iowa_liquor_sales_test_pred\"\n",
        "bq_evaluated_examples_uri = \"bq://{}:{}:{}\".format(\n",
        "    PROJECT_ID, dataset_id, bq_table_name\n",
        ")\n",
        "# This will take around an hour to run\n",
        "model = job.run(\n",
        "    dataset=ds,\n",
        "    target_column=target_column,\n",
        "    time_column=time_column,\n",
        "    time_series_identifier_column=time_series_identifier_column,\n",
        "    available_at_forecast_columns=[time_column],\n",
        "    unavailable_at_forecast_columns=[target_column],\n",
        "    time_series_attribute_columns=[\"city\", \"zip_code\", \"county\"],\n",
        "    forecast_horizon=30,\n",
        "    context_window=30,\n",
        "    data_granularity_unit=\"day\",\n",
        "    data_granularity_count=1,\n",
        "    weight_column=None,\n",
        "    export_evaluated_data_items=True,\n",
        "    budget_milli_node_hours=500,\n",
        "    model_display_name=\"iowa-liquor-sales-forecast-model\",\n",
        "    predefined_split_column_name=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "muSC-mvgHno7"
      },
      "outputs": [],
      "source": [
        "# @title # Fetch Model Evaluation Metrics\n",
        "# @markdown Fetch the model evaluation metrics calculated during training on the test set.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "list_evaluation_pager = model.api_client.list_model_evaluations(\n",
        "    parent=model.resource_name\n",
        ")\n",
        "for model_evaluation in list_evaluation_pager:\n",
        "    metrics_dict = {m[0]: m[1] for m in model_evaluation.metrics.items()}\n",
        "    df = pd.DataFrame(metrics_dict.items(), columns=[\"Metric\", \"Value\"])\n",
        "    print(df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHbB3u5EDFbZ"
      },
      "outputs": [],
      "source": [
        "time_column = \"date\"\n",
        "time_series_identifier_column = \"store_name\"\n",
        "target_column = \"sale_dollars\"\n",
        "MY_PROJECT = PROJECT_ID\n",
        "\n",
        "eval_ex_uri = job.evaluated_data_items_bigquery_uri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eaEHv_Kdm3B8"
      },
      "outputs": [],
      "source": [
        "# @title # Visualize the Forecasts\n",
        "# @markdown The following snippet visualizes the test set predictions from the forecasting training job above to aid in model evaluation.\n",
        "# @markdown Visit the given link to view the generated forecasts in [Data Studio](https://support.google.com/datastudio/answer/6283323?hl=en).\n",
        "\n",
        "import urllib\n",
        "\n",
        "\n",
        "def _sanitize_bq_uri(bq_uri):\n",
        "    if bq_uri.startswith(\"bq://\"):\n",
        "        bq_uri = bq_uri[5:]\n",
        "    return bq_uri.replace(\":\", \".\")\n",
        "\n",
        "\n",
        "eval_ex_uri_clean = _sanitize_bq_uri(eval_ex_uri)\n",
        "\n",
        "\n",
        "def get_data_studio_link(\n",
        "    eval_input_uri, time_column, time_series_identifier_column, target_column\n",
        "):\n",
        "\n",
        "    base_url = \"https://datastudio.google.com/c/u/0/reporting\"\n",
        "    query = (\n",
        "        \"SELECT \\\\n\"\n",
        "        \" CAST({} as DATETIME) timestamp_col,\\\\n\"\n",
        "        \" CAST({} as STRING) time_series_identifier_col,\\\\n\"\n",
        "        \" CAST({} as NUMERIC) actual_values,\\\\n\"\n",
        "        \" CAST(predicted_{}.value as NUMERIC) predicted_values,\\\\n\"\n",
        "        \" CAST(predicted_on_{} as DATETIME) predicted_on_Date_col,\\\\n\"\n",
        "        \" CAST({} as NUMERIC) - CAST(predicted_{}.value as NUMERIC) residuals,\\\\n\"\n",
        "        \" * \\\\n\"\n",
        "        \"FROM `{}` input\"\n",
        "    )\n",
        "    query = query.format(\n",
        "        time_column,\n",
        "        time_series_identifier_column,\n",
        "        target_column,\n",
        "        target_column,\n",
        "        time_column,\n",
        "        target_column,\n",
        "        target_column,\n",
        "        eval_input_uri,\n",
        "    )\n",
        "    params = {\n",
        "        \"templateId\": \"5df87696-b427-49d8-aeec-b885f9b7080f\",\n",
        "        \"ds0.connector\": \"BIG_QUERY\",\n",
        "        \"ds0.projectId\": MY_PROJECT,\n",
        "        \"ds0.billingProjectId\": MY_PROJECT,\n",
        "        \"ds0.type\": \"CUSTOM_QUERY\",\n",
        "        \"ds0.sql\": query,\n",
        "    }\n",
        "    params_str_parts = []\n",
        "    for k, v in params.items():\n",
        "        params_str_parts.append('\"{}\":\"{}\"'.format(k, v))\n",
        "    params_str = \"\".join([\"{\", \",\".join(params_str_parts), \"}\"])\n",
        "    return \"{}?{}\".format(base_url, urllib.parse.urlencode({\"params\": params_str}))\n",
        "\n",
        "\n",
        "print(\n",
        "    get_data_studio_link(\n",
        "        eval_ex_uri_clean, time_column, time_series_identifier_column, target_column\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24NPJ7nCRchZ"
      },
      "source": [
        "# Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq3ZSsAkRnXh"
      },
      "outputs": [],
      "source": [
        "# Delete model resource\n",
        "model.delete(sync=True)\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "! gsutil -m rm -r $BUCKET_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk_automl_forecasting_evaluating_a_model.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
