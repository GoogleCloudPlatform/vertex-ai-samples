{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWW_k7u_zaER"
      },
      "source": [
        "## Table Of Contents\n",
        "* [Overview](#section-1)\n",
        "* [Dataset](#section-2)\n",
        "* [Objective](#section-3)\n",
        "* [Costs](#section-4)\n",
        "* [Create a BigQuery dataset](#section-5)\n",
        "* [Explore Data](#section-6)\n",
        "* [Preparing the training data](#section-7)\n",
        "\t* [Identifying the label for each user](#section-7-subsection-1)\n",
        "    * [Extracting demographic data for each user](#section-7-subsection-2)\n",
        "\t* [Extracting behavioral data for each user](#section-7-subsection-3)\n",
        "\t* [Combining the label, demographic and behavioral data together as training data](#section-7-subsection-4)\n",
        "\n",
        "* [Training the propensity model with BigQuery ML](#section-8)\n",
        "* [Model Evaluation](#section-9)\n",
        "\t* [Confusion matrix: predicted vs actual values](#section-9-subsection-1)\n",
        "\t* [ROC Curve](#section-9-subsection-2)\n",
        "* [Model prediction](#section-10)  \n",
        "* [Export predictions table to Google Cloud Storage](#section-11)\n",
        "* [Clean up](#section-12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "277178e15cdb"
      },
      "source": [
        "## Overview\n",
        "<a name=\"section-1\"></a>\n",
        "\n",
        "This notebook shows you how you can train, evaluate, and deploy a propensity model in BigQuery ML to predict user retention on a mobile game, based on app measurement data from Google Analytics 4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nznL3qK4z8Jm"
      },
      "source": [
        "## Dataset\n",
        "<a name=\"section-2\"></a>\n",
        "\n",
        "This notebook uses [this public BigQuery dataset](https://console.cloud.google.com/bigquery?p=firebase-public-project&d=analytics_153293282&t=events_20181003&page=table), contains raw event data from a real mobile gaming app called Flood It! ([Android app](https://play.google.com/store/apps/details?id=com.labpixies.flood), [iOS app](https://itunes.apple.com/us/app/flood-it!/id476943146?mt=8)). The [data schema](https://support.google.com/analytics/answer/7029846) originates from Google Analytics for Firebase, but is the same schema as [Google Analytics 4](https://support.google.com/analytics/answer/9358801); this notebook applies to use cases that use either Google Analytics for Firebase or Google Analytics 4 data.\n",
        "\n",
        "Google Analytics 4 (GA4) uses an [event-based](https://support.google.com/analytics/answer/9322688) measurement model. Events provide insight on what is happening in an app or on a website, such as user actions, system events, or errors. Every row in the dataset is an event, with various characteristics relevant to that event stored in a nested format within the row. While Google Analytics logs many types of events already by default, developers can also customize the types of events they also wish to log.\n",
        "\n",
        "Note that as you cannot simply use the raw event data to train a machine learning model, in this notebook, you will also learn the important steps of how to pre-process the raw data into an appropriate format to use as training data for classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH0CZGku0BPp"
      },
      "source": [
        "## Objective and Problem Statement\n",
        "<a name=\"section-3\"></a>\n",
        "By the end of this notebook, you will know how to:\n",
        "* Explore the export of Google Analytics 4 data on BigQuery\n",
        "* Prepare the training data using demographic, behavioral data, and the label (churn/not-churn)\n",
        "* Train a XGBoost model using BigQuery ML\n",
        "* Evaluate model using BigQuery ML\n",
        "* Make predictions on which users will churn using BigQuery ML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589ffe790261"
      },
      "source": [
        "## Costs\n",
        "<a name=\"section-4\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1fb94b2cc17"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e658ce27668"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91957451e8d3"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b7e574c49d0"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c8d9d56557d"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "\n",
        "{TODO: Adjust wording in the first paragraph to fit your use case - explain how your tutorial uses the Cloud Storage bucket. The example below shows how Vertex AI uses the bucket for training.}\n",
        "\n",
        "When you submit a training job using the Cloud SDK, you upload a Python package\n",
        "containing your training code to a Cloud Storage bucket. Vertex AI runs\n",
        "the code from this package. In this tutorial, Vertex AI also saves the\n",
        "trained model that results from your job in the same bucket. Using this model artifact, you can then\n",
        "create Vertex AI model and endpoint resources in order to serve\n",
        "online predictions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
        "Cloud Storage buckets.\n",
        "\n",
        "You may also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook. Make sure to [choose a region where Vertex AI services are\n",
        "available](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions). You may\n",
        "not use a Multi-Regional Storage bucket for training with Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ba4c9b14e39"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "REGION = \"[your-region]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97081b47da24"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
        "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a15a71d5afd6"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a666a5460643"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80c5b47fec8e"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1025bc49c63"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3b13ceaebe"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c05096f78e7e"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlfwBj4P0rHD"
      },
      "source": [
        "## Create a BigQuery dataset\n",
        "<a name=\"section-5\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9TLkb8f0tCE"
      },
      "source": [
        "In this notebook, you will need to create a dataset in your project called `bqmlga4`. To create it, run the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f9a7052f37d"
      },
      "source": [
        "#@bigquery\n",
        "-- create a dataset in Bigquery\n",
        "\n",
        "CREATE SCHEMA bqmlga4\n",
        "OPTIONS(\n",
        "  location=\"us\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcd477550f3f"
      },
      "source": [
        "## Explore Data\n",
        "<a name=\"section-6\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV7wi8X51eNw"
      },
      "source": [
        "The sample dataset contains raw event data, as shown in the next cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad23990e2df2"
      },
      "outputs": [],
      "source": [
        "%%bigquery --project \tvertex-ai-dev\n",
        "\n",
        "SELECT \n",
        "    *\n",
        "FROM\n",
        "  `firebase-public-project.analytics_153293282.events_*`\n",
        "    \n",
        "LIMIT 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d8a8483a2f6"
      },
      "source": [
        "#@bigquery\n",
        "SELECT \n",
        "    *\n",
        "FROM\n",
        "  `firebase-public-project.analytics_153293282.events_*`\n",
        "    \n",
        "TABLESAMPLE SYSTEM (1 PERCENT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYBMN963Qydl"
      },
      "source": [
        "It may be helpful to take a look at the overall schema used in Google Analytics 4. As mentioned earlier, Google Analytics 4 uses an event based measurement model and each row in this dataset is an event. [Click here](https://support.google.com/analytics/answer/7029846) to view the complete schema and details about each column. As you can see above, certain columns are nested records and contain detailed information:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaM8co6eRsOp"
      },
      "source": [
        "* `app_info`\n",
        "* `device`\n",
        "* `ecommerce`\n",
        "* `event_params`\n",
        "* `geo`\n",
        "* `traffic_source`\n",
        "* `user_properties`\n",
        "* `items`*\n",
        "* `web_info`*\n",
        "\n",
        "_* present by default in GA4 datasets_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLUv-7xNRhAj"
      },
      "source": [
        "As we can see below, there are 15K users and 5.7M events in this dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74c054f90876"
      },
      "source": [
        "#@bigquery\n",
        "SELECT \n",
        "    COUNT(DISTINCT user_pseudo_id) as count_distinct_users,\n",
        "    COUNT(event_timestamp) as count_events\n",
        "FROM\n",
        "  `firebase-public-project.analytics_153293282.events_*`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iHaV9-q1k1i"
      },
      "source": [
        "## Preparing the training data\n",
        "<a name=\"section-7\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P358Jo_s8WC0"
      },
      "source": [
        "You cannot simply use raw event data to train a machine learning model as it would not be in the right shape and format to use as training data. So in this section, you will learn how to pre-process the raw data into an appropriate format to use as training data for classification models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXl1kSh1yPXk"
      },
      "source": [
        "To predict which user is going to _churn_ or _return_, the ideal training data format for classification should look like the following:  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv8ibjMNy_bV"
      },
      "source": [
        "|User ID|User demographic data|User behavioral data|Churned|\n",
        "|-|-|-|-|\n",
        "|User1|(e.g., country, device_type)|(e.g., # of times they did something within a time period)|1\n",
        "|User2|(e.g., country, device_type)|(e.g., # of times they did something within a time period)|0\n",
        "|User3|(e.g., country, device_type)|(e.g., # of times they did something within a time period)|1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HydYCB2jzrzn"
      },
      "source": [
        "Characteristics of the training data:\n",
        "- each row is a separate unique user ID\n",
        "- feature(s) for **demographic data**\n",
        "- feature(s) for **behavioral data**\n",
        "- the actual **label** that you want to train the model to predict (e.g., 1 = churned, 0 = returned)\n",
        "\n",
        "You can train a model with only demographic data or behavioral data, but having a combination of both will likely help you create a more predictive model. For this reason, in this section, you will learn how to pre-process the raw data to follow this training data format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICpTsrfg2-Cw"
      },
      "source": [
        "The following sections will walk you through preparing the demographic data, behavioral data, and the label before joining them all together as the training data.\n",
        "\n",
        "1. Identifying the label for each user (churned or returned)\n",
        "1. Extracting demographic data for each user\n",
        "1. Extracting behavioral data for each user\n",
        "1. Combining the label, demographic and behavioral data together as training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYHefnNx21lO"
      },
      "source": [
        "#### Step 1: Identifying the label for each user\n",
        "<a name=\"section-7-subsection-1\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt6a5Kv-25iq"
      },
      "source": [
        "The raw dataset doesn't have a feature that simply identifies users as \"churned\" or \"returned\", so in this section, you will need to create this label based on some of the existing columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgqxD30Hl6FM"
      },
      "source": [
        "There are many ways to define user churn, but for the purposes of this notebook, you will predict 1-day churn as users who do not come back and use the app again after 24 hr of the user's first engagement. \n",
        "\n",
        "In other words, after 24 hr of a user's first engagement with the app:\n",
        "- if the user _shows no event data thereafter_, the user is considered **churned**. \n",
        "- if the user _does have at least one event datapoint thereafter_, then the user is considered **returned**\n",
        "\n",
        "You may also want to remove users who were unlikely to have ever returned anyway after spending just a few minutes with the app, which is sometimes referred to as \"bouncing\". For example, we can say want to build our model only on users who spent at least 10 minutes with the app (users who didn't bounce).\n",
        "\n",
        "So your updated definition of a **churned user** for this notebook is:\n",
        "> \"any user who spent at least 10 minutes on the app, but after 24 hour from when they first engaged with the app, never used the app again\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YyxwMQQ1uQW"
      },
      "source": [
        "In SQL, since the raw data contains all of the events for every user, from their first touch (app installation) to their last touch, you can use this information to create two columns: `churned` and `bounced`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_JCCtuZVzne"
      },
      "source": [
        "Take a look at the following SQL query and the results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb5c29c83181"
      },
      "source": [
        "#@bigquery\n",
        "CREATE OR REPLACE VIEW bqmlga4.returningusers AS (\n",
        "  WITH firstlasttouch AS (\n",
        "    SELECT\n",
        "      user_pseudo_id,\n",
        "      MIN(event_timestamp) AS user_first_engagement,\n",
        "      MAX(event_timestamp) AS user_last_engagement\n",
        "    FROM\n",
        "      `firebase-public-project.analytics_153293282.events_*`\n",
        "    WHERE event_name=\"user_engagement\"\n",
        "    GROUP BY\n",
        "      user_pseudo_id\n",
        "\n",
        "  )\n",
        "  SELECT\n",
        "    user_pseudo_id,\n",
        "    user_first_engagement,\n",
        "    user_last_engagement,\n",
        "    EXTRACT(MONTH from TIMESTAMP_MICROS(user_first_engagement)) as month,\n",
        "    EXTRACT(DAYOFYEAR from TIMESTAMP_MICROS(user_first_engagement)) as julianday,\n",
        "    EXTRACT(DAYOFWEEK from TIMESTAMP_MICROS(user_first_engagement)) as dayofweek,\n",
        "\n",
        "    (user_first_engagement + 86400000000) AS ts_24hr_after_first_engagement,\n",
        "\n",
        "IF (user_last_engagement < (user_first_engagement + 86400000000),\n",
        "    1,\n",
        "    0 ) AS churned,\n",
        "\n",
        "IF (user_last_engagement <= (user_first_engagement + 600000000),\n",
        "    1,\n",
        "    0 ) AS bounced,\n",
        "  FROM\n",
        "    firstlasttouch\n",
        "  GROUP BY\n",
        "    1,2,3\n",
        "    );\n",
        "\n",
        "SELECT \n",
        "  * \n",
        "FROM \n",
        "  bqmlga4.returningusers \n",
        "LIMIT 100;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d10507bd2366"
      },
      "source": [
        "#@bigquery\n",
        "SELECT \n",
        "  * \n",
        "FROM \n",
        "  bqmlga4.returningusers "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOoqPb2J2Q5f"
      },
      "source": [
        "For the `churned` column, `churned=0` if the user performs an action after 24 hours since their first touch, otherwise if their last action was only within the first 24 hours, then `churned=1`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC3sIc0C2a4Z"
      },
      "source": [
        "For the `bounced` column, `bounced=1` if the user's last action was within the first ten minutes since their first touch with the app, otherwise `bounced=0`. We can use this column to filter our training data later on, by conditionally querying for users where `bounced = 0`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulbfb8SY2fSM"
      },
      "source": [
        "You might wonder how many of these 15k users bounced and returned? You can run the following query to check:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21119ffadd56"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "    bounced,\n",
        "    churned, \n",
        "    COUNT(churned) as count_users\n",
        "FROM\n",
        "    bqmlga4.returningusers\n",
        "GROUP BY 1,2\n",
        "ORDER BY bounced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z29RsKJi2uwO"
      },
      "source": [
        "For the training data, you will only end up using data where `bounced = 0`. Based on the 15k users, you can see that 5,557 (\\~41%) users bounced within the first ten minutes of their first engagement with the app, but of the remaining 8,031 users, 1,883 users (\\~23%) churned after 24 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f328a88b39e1"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "    COUNTIF(churned=1)/COUNT(churned) as churn_rate\n",
        "FROM\n",
        "    bqmlga4.returningusers\n",
        "WHERE bounced = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08a5324dac82"
      },
      "source": [
        "There are 23% churners in the data which is not bad for training a churn prediction model. If the class-imablance seems to be high, oversampling or undersampling techniques can be considered to balance the class distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daSQViux_XWR"
      },
      "source": [
        "#### Step 2. Extracting demographic data for each user\n",
        "<a name=\"section-7-subsection-2\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7417ae7aa9c4"
      },
      "source": [
        "This section is focused on extracting the demographic information for each user. Different demographic information about the user is available in the dataset already, including `app_info`, `device`, `ecommerce`, `event_params`, `geo`. Demographic features can help the model predict whether users on certain devices or countries are more likely to churn.\n",
        "\n",
        "For this notebook, you can start just with `geo.country`, `device.operating_system`, and `device.language`. If you are using your own dataset and have joinable first-party data, this section is a good opportunity to add any additional attributes for each user that may not be readily available in Google Analytics 4.\n",
        "\n",
        "Note that a user's demographics may occasionally change (e.g. moving from one country to another). For simplicity, you will just use the demographic information that Google Analytics 4 provides when the user LAST engaged with the app as indicated by `MAX(event_timestamp)`. This enables every unique user to be represented by a single row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bb11498b1ea"
      },
      "source": [
        "#@bigquery\n",
        "CREATE OR REPLACE VIEW bqmlga4.user_demographics AS (\n",
        "\n",
        "  WITH first_values AS (\n",
        "      SELECT\n",
        "          user_pseudo_id,\n",
        "          geo.country as country,\n",
        "          device.operating_system as operating_system,\n",
        "          device.language as language,\n",
        "          ROW_NUMBER() OVER (PARTITION BY user_pseudo_id ORDER BY event_timestamp DESC) AS row_num\n",
        "      FROM `firebase-public-project.analytics_153293282.events_*`\n",
        "      WHERE event_name=\"user_engagement\"\n",
        "      )\n",
        "  SELECT * EXCEPT (row_num)\n",
        "  FROM first_values\n",
        "  WHERE row_num = 1\n",
        "  );\n",
        "\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.user_demographics\n",
        "LIMIT 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25422405548"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.user_demographics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ffc440f6ba"
      },
      "source": [
        "#### Step 3. Extracting behavioral data for each user\n",
        "<a name=\"section-7-subsection-3\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2f87ff04147"
      },
      "source": [
        "Behavioral data in the raw event data spans across multiple events -- and thus rows -- per user. The goal of this section is to aggregate and extract behavioral data for each user, resulting in one row of behavioral data per unique user.\n",
        "\n",
        "But what kind of behavioral data will you need to prepare? Since the end goal of this notebook is to predict, based on a user's activity within the first 24 hrs since app installation, whether that user will churn or return thereafter, then you will want to use behavioral data from the first 24 hrs in your training data. Later on, we can also extract some extra time-related features from `user_first_engagement`, such as the month or day of the first engagement.\n",
        "\n",
        "Google Analytics automatically collects [certain events](https://support.google.com/analytics/answer/6317485) that you can use to analyze behavior. In addition, there are certain recommended [events for games](https://support.google.com/analytics/answer/6317494). \n",
        "\n",
        "\n",
        "As a first step, you can explore all the unique events that exist in this dataset, based on `event_name`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6075561092"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "    event_name,\n",
        "    COUNT(event_name) as event_count\n",
        "FROM\n",
        "    `firebase-public-project.analytics_153293282.events_*`\n",
        "GROUP BY 1\n",
        "ORDER BY\n",
        "   event_count DESC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "074a03fae065"
      },
      "source": [
        "For this notebook, to predict whether a user will churn or return, you can start by counting the number of times a user engages in the following event types:\n",
        "\n",
        "* `user_engagement`\n",
        "* `level_start_quickplay`\n",
        "* `level_end_quickplay`\n",
        "* `level_complete_quickplay`\n",
        "* `level_reset_quickplay`\n",
        "* `post_score`\n",
        "* `spend_virtual_currency`\n",
        "* `ad_reward`\n",
        "* `challenge_a_friend`\n",
        "* `completed_5_levels`\n",
        "* `use_extra_steps`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d89bc9dfccc"
      },
      "source": [
        "In SQL, you can aggregate the behavioral data by calculating the total number of times when each of the above `event_names` occurred in the data set per user.\n",
        "\n",
        "If you are using your own dataset, you may have different event types that you can aggregate and extract. Your app may be sending very different `event_names` to Google Analytics so be sure to use events most suitable to your scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47843e3b022"
      },
      "source": [
        "#@bigquery\n",
        "CREATE OR REPLACE VIEW bqmlga4.user_aggregate_behavior AS (\n",
        "WITH\n",
        "  events_first24hr AS (\n",
        "    SELECT\n",
        "      e.*\n",
        "    FROM\n",
        "      `firebase-public-project.analytics_153293282.events_*` e\n",
        "    JOIN\n",
        "      bqmlga4.returningusers r\n",
        "    ON\n",
        "      e.user_pseudo_id = r.user_pseudo_id\n",
        "    WHERE\n",
        "      e.event_timestamp <= r.ts_24hr_after_first_engagement\n",
        "    )\n",
        "SELECT\n",
        "  user_pseudo_id,\n",
        "  SUM(IF(event_name = 'user_engagement', 1, 0)) AS cnt_user_engagement,\n",
        "  SUM(IF(event_name = 'level_start_quickplay', 1, 0)) AS cnt_level_start_quickplay,\n",
        "  SUM(IF(event_name = 'level_end_quickplay', 1, 0)) AS cnt_level_end_quickplay,\n",
        "  SUM(IF(event_name = 'level_complete_quickplay', 1, 0)) AS cnt_level_complete_quickplay,\n",
        "  SUM(IF(event_name = 'level_reset_quickplay', 1, 0)) AS cnt_level_reset_quickplay,\n",
        "  SUM(IF(event_name = 'post_score', 1, 0)) AS cnt_post_score,\n",
        "  SUM(IF(event_name = 'spend_virtual_currency', 1, 0)) AS cnt_spend_virtual_currency,\n",
        "  SUM(IF(event_name = 'ad_reward', 1, 0)) AS cnt_ad_reward,\n",
        "  SUM(IF(event_name = 'challenge_a_friend', 1, 0)) AS cnt_challenge_a_friend,\n",
        "  SUM(IF(event_name = 'completed_5_levels', 1, 0)) AS cnt_completed_5_levels,\n",
        "  SUM(IF(event_name = 'use_extra_steps', 1, 0)) AS cnt_use_extra_steps,\n",
        "FROM\n",
        "  events_first24hr\n",
        "GROUP BY\n",
        "  1\n",
        "  );\n",
        "\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.user_aggregate_behavior\n",
        "LIMIT 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89f8c6c44b9c"
      },
      "source": [
        "#### Step 4: Combining the label, demographic and behavioral data together as training data\n",
        "<a name=\"section-7-subsection-4\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed161899b055"
      },
      "source": [
        "In this section, you can now combine these three intermediary views (label, demographic, and behavioral data) into the final training data. Here you can also specify `bounced = 0`, in order to limit the training data only to users who did not \"bounce\" within the first 10 minutes of using the app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd02c06df5e7"
      },
      "source": [
        "#@bigquery\n",
        "CREATE OR REPLACE VIEW bqmlga4.train AS (\n",
        "    \n",
        "  SELECT\n",
        "    dem.*,\n",
        "    IFNULL(beh.cnt_user_engagement, 0) AS cnt_user_engagement,\n",
        "    IFNULL(beh.cnt_level_start_quickplay, 0) AS cnt_level_start_quickplay,\n",
        "    IFNULL(beh.cnt_level_end_quickplay, 0) AS cnt_level_end_quickplay,\n",
        "    IFNULL(beh.cnt_level_complete_quickplay, 0) AS cnt_level_complete_quickplay,\n",
        "    IFNULL(beh.cnt_level_reset_quickplay, 0) AS cnt_level_reset_quickplay,\n",
        "    IFNULL(beh.cnt_post_score, 0) AS cnt_post_score,\n",
        "    IFNULL(beh.cnt_spend_virtual_currency, 0) AS cnt_spend_virtual_currency,\n",
        "    IFNULL(beh.cnt_ad_reward, 0) AS cnt_ad_reward,\n",
        "    IFNULL(beh.cnt_challenge_a_friend, 0) AS cnt_challenge_a_friend,\n",
        "    IFNULL(beh.cnt_completed_5_levels, 0) AS cnt_completed_5_levels,\n",
        "    IFNULL(beh.cnt_use_extra_steps, 0) AS cnt_use_extra_steps,\n",
        "    ret.user_first_engagement,\n",
        "    ret.month,\n",
        "    ret.julianday,\n",
        "    ret.dayofweek,\n",
        "    ret.churned\n",
        "  FROM\n",
        "    bqmlga4.returningusers ret\n",
        "  LEFT OUTER JOIN\n",
        "    bqmlga4.user_demographics dem\n",
        "  ON \n",
        "    ret.user_pseudo_id = dem.user_pseudo_id\n",
        "  LEFT OUTER JOIN \n",
        "    bqmlga4.user_aggregate_behavior beh\n",
        "  ON\n",
        "    ret.user_pseudo_id = beh.user_pseudo_id\n",
        "  WHERE ret.bounced = 0\n",
        "  );\n",
        "\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.train\n",
        "LIMIT 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68a2aa3e63ce"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eca01bded31"
      },
      "outputs": [],
      "source": [
        "# The following two lines are only necessary to run once.\n",
        "# Comment out otherwise for speed-up.\n",
        "from google.cloud.bigquery import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "query = \"\"\"SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.train\"\"\"\n",
        "job = client.query(query)\n",
        "df = job.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "121ca5d0d531"
      },
      "source": [
        "Check percentage of null values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c1a07395def"
      },
      "outputs": [],
      "source": [
        "(\n",
        "    100 * df[[\"operating_system\", \"language\", \"country\"]].isna().sum() / df.shape[0]\n",
        ").plot.bar(figsize=(15, 4))\n",
        "plt.title(\"Null-percentage of the columns\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05bb76e78220"
      },
      "source": [
        "## Training the propensity model with BigQuery ML\n",
        "<a name=\"section-8\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec1a7945f3cb"
      },
      "source": [
        "In this section, using the training data you prepared, you will now train machine learning models in SQL using BigQuery ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe89ff9223d7"
      },
      "source": [
        "We will use [XGBoost](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree) model here. In this notebook, the model predicts whether the user will churn (1) or return (0) after 24 hours of the user's first engagement with the app.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1244e58f0560"
      },
      "source": [
        "#### Train an XGBoost model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bfabaccff00"
      },
      "source": [
        "The following code trains an XGBoost model. This may take several minutes to train.\n",
        "\n",
        "For more information on the default hyperparameters used, you can read the documentation:  \n",
        "[CREATE MODEL statement for Boosted Tree models using XGBoost](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e04e73f353d"
      },
      "source": [
        "#@bigquery\n",
        "CREATE OR REPLACE MODEL bqmlga4.churn_xgb\n",
        "\n",
        "OPTIONS(\n",
        "  MODEL_TYPE=\"BOOSTED_TREE_CLASSIFIER\",\n",
        "  DATA_SPLIT_METHOD='RANDOM',\n",
        "  DATA_SPLIT_EVAL_FRACTION=0.2,\n",
        "    \n",
        "  INPUT_LABEL_COLS=[\"churned\"]\n",
        ") AS\n",
        "\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64fc62cb6264"
      },
      "outputs": [],
      "source": [
        "%%bigquery --project vertex-ai-dev\n",
        "\n",
        "CREATE OR REPLACE MODEL bqmlga4.churn_xgb\n",
        "\n",
        "OPTIONS(\n",
        "  MODEL_TYPE=\"BOOSTED_TREE_CLASSIFIER\",\n",
        "  DATA_SPLIT_METHOD='RANDOM',\n",
        "  DATA_SPLIT_EVAL_FRACTION=0.2,\n",
        "    \n",
        "  INPUT_LABEL_COLS=[\"churned\"]\n",
        ") AS\n",
        "\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  bqmlga4.train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a189c676815"
      },
      "source": [
        "## Model Evaluation\n",
        "<a name=\"section-9\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33e0cb8eddd8"
      },
      "source": [
        "To evaluate the model, you can run [`ML.EVALUATE`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate) on a model that has finished training to inspect some of the metrics.\n",
        "\n",
        "The metrics are based on the test sample data that was automatically split during model creation ([documentation](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#data_split_method))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e736b0d3906b"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL bqmlga4.churn_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ab69bf8857"
      },
      "source": [
        "`ML.EVALUATE` generates the `precision`, `recall`, `accuracy` and `f1_score` using the default classification threshold of 0.5, which can be modified by using the optional [`THRESHOLD`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate#eval_threshold) parameter.\n",
        "\n",
        "Generally speaking, you can use the `log_loss` and `roc_auc` metrics to compare  model performance.\n",
        "\n",
        "The `log_loss` ranges between 0 and 1.0, and the closer the `log_loss` is the zero, the closer the predicted labels were to the actual labels.\n",
        "The `roc_auc` ranges between 0 and 1.0, and the closer the `roc_auc` is to 1.0, the better the model is at distinguishing between the classes.\n",
        "\n",
        "For more information on these metrics, you can read through the definitions on [precision and recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall), [accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy), [f1-score](https://en.wikipedia.org/wiki/F-score), [log_loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification#Logistic_loss) and [roc_auc](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a219caf7e0fc"
      },
      "source": [
        "#### Confusion matrix: predicted vs actual values\n",
        "<a name=\"section-9-subsection-1\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc448a895918"
      },
      "source": [
        "In addition to model evaluation metrics, you may also want to use a confusion matrix to inspect how well the model predicted the labels, compared to the actual labels.\n",
        "\n",
        "With the rows indicating the actual labels, and the columns as the predicted labels, the resulting format for ML.CONFUSION_MATRIX for binary classification looks like:\n",
        "\n",
        "| | Predicted_0 | Predicted_1|\n",
        "|-|-|-|\n",
        "|Actual_0| True Negatives | False Positives|\n",
        "|Actual_1| False Negatives | True Positives|\n",
        "\n",
        "For more information on confusion matrices, you can read through a detailed explanation [here](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89cf66f58b74"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "  expected_label,\n",
        "  _0 AS predicted_0,\n",
        "  _1 AS predicted_1\n",
        "FROM\n",
        "  ML.CONFUSION_MATRIX(MODEL bqmlga4.churn_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c57eb63ee0b"
      },
      "source": [
        "#### ROC Curve\n",
        "<a name=\"section-9-subsection-2\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126bf7ab6607"
      },
      "source": [
        "#@bigquery\n",
        "SELECT * FROM ML.ROC_CURVE(MODEL bqmlga4.churn_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc3d2981c877"
      },
      "source": [
        "## Model prediction\n",
        "<a name=\"section-10\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "431ffebc5667"
      },
      "source": [
        "You can run [`ML.PREDICT`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict) to make predictions on the propensity to churn. The following code returns all the information from `ML.PREDICT`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "befa36fe5913"
      },
      "source": [
        "#@bigquery\n",
        "CREATE OR REPLACE VIEW bqmlga4.prediction_data AS(\n",
        "(SELECT * FROM bqmlga4.train where churned=1 limit 10)\n",
        "union all\n",
        "(SELECT * FROM bqmlga4.train where churned=0 limit 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a6831e141b7"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
        "  (SELECT * FROM bqmlga4.prediction_data)\n",
        "            ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fccf138adcfa"
      },
      "source": [
        "For propensity modeling, the most important output is the probability of a behavior occuring. The following query returns the probability that the user will return after 24 hrs. The higher the probability and closer it is to 1, the more likely the user is predicted to churn, and the closer it is to 0, the more likely the user is predicted to return."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e311ec7695fa"
      },
      "source": [
        "#@bigquery\n",
        "SELECT\n",
        "  user_pseudo_id,\n",
        "  churned,\n",
        "  predicted_churned,\n",
        "  predicted_churned_probs[OFFSET(0)].prob as probability_churned\n",
        "  \n",
        "FROM\n",
        "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
        "  (SELECT * FROM bqmlga4.train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1af4216bbb3d"
      },
      "source": [
        "## Export predictions table to Google Cloud Storage\n",
        "<a name=\"section-11\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2839b839f440"
      },
      "source": [
        "There are several ways to export the predictions table to Google Cloud Storage (GCS), so that you can use them in a separate service. Perhaps the easiest way is to export directly to GCS using SQL ([documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements#export_data_statement))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f7472e3b580"
      },
      "source": [
        "#@bigquery\n",
        "EXPORT DATA OPTIONS (\n",
        "uri=\"gs://gamingchurnpredictions/*.csv\", \n",
        "  format=CSV,\n",
        "  header=True, \n",
        "  overwrite=True \n",
        "    \n",
        ") AS \n",
        "SELECT\n",
        "  * from bqmlga4.predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08ca03535d87"
      },
      "source": [
        "## Clean up\n",
        "<a name=\"section-12\"></a>\n",
        "\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial(The following code deletes entire dataset).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04a96ad8abdc"
      },
      "outputs": [],
      "source": [
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "# TODO(developer): Set model_id to the ID of the model to fetch.\n",
        "dataset_id = \"your-project-id.dataset-name\"\n",
        "\n",
        "# Use the delete_contents parameter to delete a dataset and its contents.\n",
        "# Use the not_found_ok parameter to not receive an error if the dataset has already been deleted.\n",
        "client.delete_dataset(\n",
        "    dataset_id, delete_contents=True, not_found_ok=True\n",
        ")  # Make an API request.\n",
        "\n",
        "print(\"Deleted dataset '{}'.\".format(dataset_id))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Gaming_Churn_Prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
