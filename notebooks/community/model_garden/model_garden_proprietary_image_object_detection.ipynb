{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TirJ-SGQseby"
      },
      "source": [
        "# Vertex AI Model Garden: Google Proprietary Model Image Object Detection\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwGLvtIeECLK"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use Google proprietary image object detection model training/deployment in [Vertex AI Model Garden](https://cloud.google.com/model-garden).\n",
        "\n",
        "### Objective\n",
        "\n",
        "* Train new models using Vertex SDK\n",
        "\n",
        "* Test trained models\n",
        "  * View the trained model in [Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)\n",
        "  * Deploy uploaded models\n",
        "  * Run predictions\n",
        "\n",
        "* Cleanup resources\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the Salads category of the [OpenImages dataset](https://www.tensorflow.org/datasets/catalog/open_images_v4) from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview). This dataset does not require any feature engineering. The version of the dataset you will use in this tutorial is stored in a public Cloud Storage bucket. The trained model predicts the bounding box locations and corresponding type of salad items in an image from a class of five items: salad, seafood, tomato, baked goods, or cheese."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEukV6uRk_S3"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvqs-ehKlaYh"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade google-cloud-aiplatform\n",
        "\n",
        "# Automatically restart kernel after installs\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wExiMUxFk91"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# The project and bucket are for experiments below.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# You can choose a region from https://cloud.google.com/about/locations.\n",
        "# Only regions prefixed by \"us\", \"europe\", or \"asia\" are supported.\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "REGION_PREFIX = REGION.split(\"-\")[0]\n",
        "assert REGION_PREFIX in (\n",
        "    \"us\",\n",
        "    \"europe\",\n",
        "    \"asia\",\n",
        "), f'{REGION} is not supported. It must be prefixed by \"us\", \"europe\", or \"asia\".'\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6IFz75WGCam"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riG_qUokg0XZ"
      },
      "outputs": [],
      "source": [
        "OBJECTIVE = \"iod\"\n",
        "\n",
        "# Dataset constants.\n",
        "DATASET_PREFIX = \"dataset-iod\"\n",
        "\n",
        "# Training constants.\n",
        "TRAINING_JOB_PREFIX = \"train\"\n",
        "# The image object detection salad dataset used to train the model\n",
        "DATASET_FILE = \"gs://cloud-samples-data/vision/salads.csv\"\n",
        "\n",
        "# Evaluation constants.\n",
        "EVALUATION_METRIC = \"AP50\"\n",
        "\n",
        "DEPLOY_JOB_PREFIX = \"deploy\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFPe_GezXg8"
      },
      "source": [
        "### Define common libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcYUGwr-AJGY"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.cloud import aiplatform\n",
        "from PIL import Image, ImageColor, ImageDraw, ImageFont\n",
        "\n",
        "\n",
        "def get_job_name_with_datetime(prefix: str):\n",
        "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def load_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    return Image.fromarray(np.uint8(img)).convert(\"RGB\")\n",
        "\n",
        "\n",
        "def display_image(image):\n",
        "    _ = plt.figure(figsize=(20, 15))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image)\n",
        "\n",
        "\n",
        "def draw_bounding_box_on_image(\n",
        "    image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()\n",
        "):\n",
        "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    im_width, im_height = image.size\n",
        "    (left, right, top, bottom) = (\n",
        "        xmin * im_width,\n",
        "        xmax * im_width,\n",
        "        ymin * im_height,\n",
        "        ymax * im_height,\n",
        "    )\n",
        "    draw.line(\n",
        "        [(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],\n",
        "        width=thickness,\n",
        "        fill=color,\n",
        "    )\n",
        "\n",
        "    # If the total height of the display strings added to the top of the bounding\n",
        "    # box exceeds the top of the image, stack the strings below the bounding box\n",
        "    # instead of above.\n",
        "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
        "    # Each display_str has a top and bottom margin of 0.05x.\n",
        "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "    if top > total_display_str_height:\n",
        "        text_bottom = top\n",
        "    else:\n",
        "        text_bottom = top + total_display_str_height\n",
        "    # Reverse list and print from bottom to top.\n",
        "    for display_str in display_str_list[::-1]:\n",
        "        text_width, text_height = font.getsize(display_str)\n",
        "        margin = np.ceil(0.05 * text_height)\n",
        "        draw.rectangle(\n",
        "            [\n",
        "                (left, text_bottom - text_height - 2 * margin),\n",
        "                (left + text_width, text_bottom),\n",
        "            ],\n",
        "            fill=color,\n",
        "        )\n",
        "        draw.text(\n",
        "            (left + margin, text_bottom - text_height - margin),\n",
        "            display_str,\n",
        "            fill=\"black\",\n",
        "            font=font,\n",
        "        )\n",
        "        text_bottom -= text_height - 2 * margin\n",
        "\n",
        "\n",
        "def draw_boxes(image, boxes, class_names, scores, max_boxes=40, min_score=0.05):\n",
        "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "    colors = list(ImageColor.colormap.values())\n",
        "    try:\n",
        "        font = ImageFont.truetype(\n",
        "            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\", 25\n",
        "        )\n",
        "    except OSError:\n",
        "        print(\"Font not found, using default font.\")\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for i in range(min(len(boxes), max_boxes)):\n",
        "        if scores[i] >= min_score:\n",
        "            ymin, xmin, ymax, xmax = boxes[i]\n",
        "            display_str = \"{}: {}%\".format(class_names[i], int(100 * scores[i]))\n",
        "            color = colors[hash(class_names[i]) % len(colors)]\n",
        "            draw_bounding_box_on_image(\n",
        "                image,\n",
        "                ymin,\n",
        "                xmin,\n",
        "                ymax,\n",
        "                xmax,\n",
        "                color,\n",
        "                font,\n",
        "                display_str_list=[display_str],\n",
        "            )\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZLVI9TtUuif"
      },
      "source": [
        "## Create a dataset\n",
        "\n",
        "This tutorial uses a version of the Salads dataset that is stored in a public Cloud Storage bucket, using a CSV index file.\n",
        "\n",
        "Start by doing a quick peek at the data. You count the number of examples by counting the number of rows in the CSV index file  (`wc -l`) and then peek at the first few rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr60Y1fpUuO9"
      },
      "outputs": [],
      "source": [
        "count = ! gsutil cat $DATASET_FILE | wc -l\n",
        "print(\"Number of Examples\", int(count[0]))\n",
        "\n",
        "print(\"First 10 rows\")\n",
        "! gsutil cat $DATASET_FILE | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZEdBfNZUxQn"
      },
      "source": [
        "Next, create the `Dataset` resource using the `create` method for the `ImageDataset` class, which takes the following parameters:\n",
        "\n",
        "- `display_name`: The human readable name for the `Dataset` resource.\n",
        "- `gcs_source`: A list of one or more dataset index files to import the data items into the `Dataset` resource.\n",
        "- `import_schema_uri`: The data labeling schema for the data items.\n",
        "\n",
        "This operation may take several minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlDqM5APU0As"
      },
      "outputs": [],
      "source": [
        "dataset = aiplatform.ImageDataset.create(\n",
        "    display_name=DATASET_PREFIX + \"_salads\",\n",
        "    gcs_source=[DATASET_FILE],\n",
        "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.bounding_box,\n",
        ")\n",
        "\n",
        "print(dataset.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB_xY9ipr7ZU"
      },
      "source": [
        "## Train new models\n",
        "\n",
        "### Create and run training pipeline\n",
        "\n",
        "To train an AutoML model, you perform two steps:\n",
        "1.  Create a training pipeline.\n",
        "2.  Run the pipeline.\n",
        "\n",
        "#### Create training pipeline\n",
        "\n",
        "An AutoML training pipeline is created with the `AutoMLImageTrainingJob` class, with the following parameters:\n",
        "\n",
        "- `display_name`: The human readable name for the `TrainingJob` resource.\n",
        "- `prediction_type`: The type task to train the model for.\n",
        "  - `classification`: An image classification model.\n",
        "  - `object_detection`: An image object detection model.\n",
        "- `model_type`: The type of model for deployment. For image object detection, we current support the following:\n",
        "  - `SPINENET`: A model that is available in Vertex Model Garden image object detection training with customizable hyperparameters. Best tailored to be used within Google Cloud, and cannot be exported externally.\n",
        "  - `YOLO`: A model that is available in Vertex Model Garden image object detection training with customizable hyperparameters. Best tailored to be used within Google Cloud, and cannot be exported externally.\n",
        "- `checkpoint_name`: Optional. The field is reserved for Model Garden model training, based on the provided pre-trained model checkpoint.\n",
        "- `trainer_config`: Optional. The field is usually used together with the Model Garden model training, when passing the customized configs for the trainer. `anchor_size` cannot be used with `YOLO`.\n",
        "\n",
        "  Example with all supported parameters:\n",
        "```\n",
        "  trainer_config = {\n",
        "    'global_batch_size': '8',\n",
        "    'learning_rate': '0.001',\n",
        "    'optimizer_type': 'sgd',\n",
        "    'optimizer_momentum': '0.9',\n",
        "    'train_steps': '10000',\n",
        "    'accelerator_count': '2',\n",
        "    'anchor_size': '8',\n",
        "  }\n",
        "```\n",
        "  The global_batch_size should be divisible by accelerator_count.\n",
        "  Supported values for optimizer_type are 'sgd', 'adam', 'adamw', 'lamb', 'rmsprop', 'lars', 'adagrad', and 'slide'.\n",
        "  Supported values for accelerator_count are '2', '4', and '8'.\n",
        "- `metric_spec`: Dictionary representing metrics to optimize. The dictionary key is the metric_id, which is reported by your training job, with possible values being ('loss', 'AP50') and the dictionary value is the optimization goal of the metric('minimize' or 'maximize').\n",
        "For example:  `metric_spec = {'loss': 'minimize', 'AP50': 'maximize'}`\n",
        "- `parameter_spec`:Dictionary representing parameters to optimize. The dictionary key is the `metric_id`, which is passed into your training job as a command line key word argument, and the dictionary value is the parameter\n",
        "specification of the metric. Supported parameter specifications can be found in aiplatform.hyperparameter_tuning.\n",
        "```\n",
        "  from google.cloud.aiplatform.aiplatform import hpt as hpt\n",
        "\n",
        "  parameter_spec = {\n",
        "    'learning_rate': hpt.DoubleParameterSpec(min=1e-7, max=1, scale='linear'), \\\n",
        "  }\n",
        "```\n",
        "- `search_algorithm`: The search algorithm specified for the Study. Accepts one of the following:\n",
        "  - `None`: If you do not specify an algorithm, your job uses the default\n",
        "  Vertex AI algorithm. The default algorithm applies Bayesian optimization\n",
        "  to arrive at the optimal solution with a more effective search over the\n",
        "  parameter space.\n",
        "  - `grid`: A simple grid search within the feasible space. This option is\n",
        "  particularly useful if you want to specify a quantity of trials that is greater than the number of points in the feasible space. In such cases, if you do not specify a grid search, the Vertex AI default algorithm may generate duplicate suggestions. To use grid search, all parameter specs must be of type `IntegerParameterSpec`, `CategoricalParameterSpec`, or `DiscreteParameterSpec`.\n",
        "  - `random`: A simple random search within the feasible space.\n",
        "- `measurement_selection`: This indicates which measurement to use\n",
        "if/when the service automatically selects the final measurement from\n",
        "previously reported intermediate measurements.\n",
        "  Accepts: `best`, `last` Choose this based on two considerations:\n",
        "    - A): Do you expect your measurements to monotonically improve? If so,\n",
        "    choose `last`. On the other hand, if you\\'re in a situation where\n",
        "    your system can **over-train** and you expect the performance to get\n",
        "    better for a while but then start declining, choose `best`.\n",
        "    - B): Are your measurements significantly noisy and/or irreproducible? If\n",
        "    so, `best` will tend to be over-optimistic, and it may be better\n",
        "    to choose `last`. If both or neither of (A) and (B) apply, it\n",
        "    doesn't matter which selection type is chosen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um_XKbmpTaHx"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "TRAINER_CONFIG = {\n",
        "    \"global_batch_size\": \"8\",\n",
        "    \"learning_rate\": \"0.001\",\n",
        "    \"train_steps\": \"10000\",\n",
        "    \"accelerator_count\": \"2\",\n",
        "}\n",
        "METRIC_SPEC_KEY = \"AP50\"\n",
        "METRIC_SPEC_VALUE = \"maximize\"\n",
        "SEARCH_ALGORITHM = \"random\"\n",
        "MEASUREMENT_SELECTION = \"best\"\n",
        "MODEL_TYPE = \"SPINENET\"  # @param {type:\"string\"} one of the values [\"SPINENET\", \"YOLO\"]\n",
        "\n",
        "PARAMETER_SPEC = {}\n",
        "if MODEL_TYPE == \"YOLO\":\n",
        "    PARAMETER_SPEC = {\n",
        "        \"learning_rate\": hpt.DiscreteParameterSpec(\n",
        "            values=[0.001, 0.1],\n",
        "            scale=\"linear\",\n",
        "        ),\n",
        "        \"weight_decay\": hpt.DiscreteParameterSpec(\n",
        "            values=[0.0001, 0.001],\n",
        "            scale=\"linear\",\n",
        "        ),\n",
        "    }\n",
        "else:\n",
        "    PARAMETER_SPEC = {\n",
        "        \"learning_rate\": hpt.DiscreteParameterSpec(\n",
        "            values=[0.001, 0.01], scale=\"linear\"\n",
        "        ),\n",
        "        \"anchor_size\": hpt.DiscreteParameterSpec(values=[2, 4], scale=\"reverse_log\"),\n",
        "    }\n",
        "\n",
        "job = aiplatform.AutoMLImageTrainingJob(\n",
        "    display_name=get_job_name_with_datetime(TRAINING_JOB_PREFIX),\n",
        "    prediction_type=\"object_detection\",\n",
        "    model_type=MODEL_TYPE,\n",
        "    base_model=None,\n",
        "    trainer_config=TRAINER_CONFIG,\n",
        "    metric_spec={METRIC_SPEC_KEY: METRIC_SPEC_VALUE},\n",
        "    parameter_spec=PARAMETER_SPEC,\n",
        "    search_algorithm=SEARCH_ALGORITHM,\n",
        "    measurement_selection=MEASUREMENT_SELECTION,\n",
        ")\n",
        "\n",
        "print(job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwcCjwlBTQIz"
      },
      "source": [
        "#### Run the training pipeline\n",
        "\n",
        "Next, run the DAG to start the training job by invoking the method `run`, with the following parameters:\n",
        "\n",
        "- `dataset`: The `Dataset` resource to train the model.\n",
        "- `model_display_name`: The human readable name for the trained model.\n",
        "- `training_fraction_split`: The percentage of the dataset to use for training.\n",
        "- `test_fraction_split`: The percentage of the dataset to use for test (holdout data).\n",
        "- `validation_fraction_split`: The percentage of the dataset to use for validation.\n",
        "- `budget_milli_node_hours`: (optional) Maximum training time specified in unit of millihours (1000 = hour).\n",
        "- `disable_early_stopping`: If `True`, training may be completed before using the entire budget if the service believes it cannot further improve on the model objective measurements.\n",
        "\n",
        "The `run` method when completed returns the `Model` resource.\n",
        "\n",
        "The execution of the training pipeline will take up to 60 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aec22792ee84"
      },
      "outputs": [],
      "source": [
        "model = job.run(\n",
        "    dataset=dataset,\n",
        "    model_display_name=get_job_name_with_datetime(\"salads\"),\n",
        "    training_fraction_split=0.8,\n",
        "    validation_fraction_split=0.1,\n",
        "    test_fraction_split=0.1,\n",
        "    budget_milli_node_hours=20000,\n",
        "    disable_early_stopping=False,\n",
        ")\n",
        "\n",
        "print(\"Model is: \", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0BGaofgsMsy"
      },
      "source": [
        "## Test trained models\n",
        "This section shows how to test the trained models.\n",
        "1. Deploy models from Model Registry\n",
        "2. Run online predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj723H4NXu4v"
      },
      "outputs": [],
      "source": [
        "# @title Deploy model from Model Registry\n",
        "# Model does not support dedicated deployment resources.\n",
        "# An n1-standard-4 machine with 1 P100 GPU will be used.\n",
        "\n",
        "deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "print(\"The deployed job name is: \", deploy_model_name)\n",
        "\n",
        "endpoint = model.deploy(\n",
        "    deployed_model_display_name=deploy_model_name,\n",
        "    traffic_split={\"0\": 100},\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=1,\n",
        ")\n",
        "\n",
        "endpoint_id = endpoint.name\n",
        "print(\"endpoint id is: \", endpoint_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTYvgFv6XyEe"
      },
      "outputs": [],
      "source": [
        "# @title Run online predictions\n",
        "\n",
        "# test image file path from a Cloud Storage bucket\n",
        "test_filepath = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "with tf.io.gfile.GFile(test_filepath, \"rb\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "# The format of each instance should conform to the deployed model's prediction input schema.\n",
        "instances = [{\"content\": base64.b64encode(content).decode(\"utf-8\")}]\n",
        "\n",
        "prediction = endpoint.predict(instances=instances)\n",
        "\n",
        "img = load_img(test_filepath)\n",
        "display_image(img)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNPNJyUnrKY3"
      },
      "source": [
        "# Run batch predictions\n",
        "Now that your Model resource is trained, you can make a batch prediction by invoking the `batch_predict()` method, with the following parameters:\n",
        "\n",
        "* `job_display_name`: The human readable name for the batch prediction job.\n",
        "* `gcs_source`: A jsonl file path from a Cloud Storage bucket, with a list of one or more images.\n",
        "* `gcs_destination_prefix`: The Cloud Storage location for storing the batch prediction resuls.\n",
        "* `sync`: If set to True, the call block while waiting for the asynchronous batch job to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-MnutG5rNKR"
      },
      "outputs": [],
      "source": [
        "# A jsonl file path from a Cloud Storage bucket, with all the to-be-predicted images.\n",
        "gcs_source = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "batch_predict_job = model.batch_predict(\n",
        "    job_display_name=get_job_name_with_datetime(\"flowers_bp\"),\n",
        "    gcs_source=gcs_source,\n",
        "    gcs_destination_prefix=f\"gs://{BUCKET_URI}\",\n",
        "    sync=False,\n",
        ")\n",
        "print(batch_predict_job)\n",
        "\n",
        "# Wait for the batch prediction job to finish\n",
        "batch_predict_job.wait()\n",
        "\n",
        "\n",
        "# Get the batch prediction results\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
        "\n",
        "prediction_results = list()\n",
        "for blob in bp_iter_outputs:\n",
        "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
        "        prediction_results.append(blob.name)\n",
        "\n",
        "tags = list()\n",
        "for prediction_result in prediction_results:\n",
        "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
        "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
        "        for line in gfile.readlines():\n",
        "            line = json.loads(line)\n",
        "            print(line)\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frcGP5HFX1XN"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2m8-u0IX4dX"
      },
      "outputs": [],
      "source": [
        "# Delete the dataset.\n",
        "if \"dataset\" in globals():\n",
        "    dataset.delete()\n",
        "\n",
        "# Undeploy model and delete endpoint.\n",
        "if \"endpoint\" in globals():\n",
        "    endpoint.undeploy_all()\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "# Delete models.\n",
        "if \"model\" in globals():\n",
        "    model.delete()\n",
        "\n",
        "# Delete the batch predictio job.\n",
        "if \"batch_prediction_job\" in globals():\n",
        "    batch_predict_job.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_proprietary_image_object_detection.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
