{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Vertex AI Model Garden - JAX Vision Transformer\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_vision_transformer.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_vision_transformer.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_jax_vision_transformer.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24743cf4a1e1"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates finetuning a [JAX ViT-B16 model](https://github.com/google-research/vision_transformer#available-vit-models) for image classification task on GPU and deploying them on Vertex AI for online prediction.\n",
        "\n",
        "Learn more about [Generative AI Support in Vertex AI](https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-model-garden-and-generative-ai-studio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how fine-tune, deploy and predict with a Vertex AI pretrained JAX Vision Transformer based model.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- Vertex AI Model Garden\n",
        "- Vertex AI Training\n",
        "- Vertex AI Model Registry\n",
        "- Vertex AI Online Prediction\n",
        "\n",
        "The steps performed are:\n",
        "\n",
        "- Finetune a JAX Vision Transformer based model.\n",
        "- Upload the model to [Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction).\n",
        "- Deploy the model on [Endpoint](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints).\n",
        "- Run online predictions for image classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This notebook uses the [tf_flowers dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers) and has a section which shows how to download and prepare it. You can follow similar process to use your own custom dataset too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "# Install the packages.\n",
        "! pip3 install --upgrade google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages.\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twgKk-LsLmX3"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6b2ccc891ed"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "\n",
        "import numpy as np\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS1hQiGuLmX4"
      },
      "outputs": [],
      "source": [
        "staging_bucket = os.path.join(BUCKET_URI, \"jax_vit_staging\")\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=staging_bucket)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cc825514deb"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42bd4fa2b2d"
      },
      "outputs": [],
      "source": [
        "# The pre-built training docker image.\n",
        "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/jax-vit-train-gpu\"\n",
        "# The pre-built TF SavedModel conversion docker image.\n",
        "MODEL_CONVERSION_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/jax-vit-model-conversion\"\n",
        "# The pre-built prediction docker image.\n",
        "OPTIMIZED_TF_RUNTIME_IMAGE_URI = (\n",
        "    \"us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c250872074f"
      },
      "source": [
        "### Define common functions\n",
        "\n",
        "This section defines functions for:\n",
        "\n",
        "- Splitting the [tf_flowers dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers) images into `train` and `test` folders.\n",
        "- Converting a Cloud Storage path such as `gs://bucket-name` to GCSFuse path format such as `/gcsfuse/bucket-name`.\n",
        "- Encoding a local image file to a string for prediction input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcYUGwr-AJGY"
      },
      "outputs": [],
      "source": [
        "def split(base_dir, test_ratio=0.1):\n",
        "    \"\"\"Splits images and moves them to train and test folders.\"\"\"\n",
        "    paths = glob.glob(f\"{base_dir}/*/*.jpg\")\n",
        "    random.shuffle(paths)\n",
        "    counts = dict(test=0, train=0)\n",
        "    for i, path in enumerate(paths):\n",
        "        split = \"test\" if i < test_ratio * len(paths) else \"train\"\n",
        "        *_, class_name, basename = path.split(\"/\")\n",
        "        dst = f\"{base_dir}/{split}/{class_name}/{basename}\"\n",
        "        if not os.path.isdir(os.path.dirname(dst)):\n",
        "            os.makedirs(os.path.dirname(dst))\n",
        "        shutil.move(path, dst)\n",
        "        counts[split] += 1\n",
        "    print(f'Moved {counts[\"train\"]:,} train and {counts[\"test\"]:,} test images.')\n",
        "\n",
        "\n",
        "def gcs_fuse_path(path: str) -> str:\n",
        "    \"\"\"Try to convert path to gcsfuse path if it starts with gs:// else do not modify it.\"\"\"\n",
        "    path = path.strip()\n",
        "    if path.startswith(\"gs://\"):\n",
        "        return \"/gcs/\" + path[5:]\n",
        "    return path\n",
        "\n",
        "\n",
        "def load_bytes_from_local_image(local_image_path, new_width=-1):\n",
        "    \"\"\"Returns encoded image string for prediction input.\"\"\"\n",
        "    image = Image.open(local_image_path)\n",
        "    if new_width <= 0:\n",
        "        new_image = image\n",
        "    else:\n",
        "        width, height = image.size\n",
        "        print(\"original input image size: \", width, \" , \", height)\n",
        "        new_height = int(height * new_width / width)\n",
        "        print(\"new input image size: \", new_width, \" , \", new_height)\n",
        "        new_image = image.resize((new_width, new_height))\n",
        "    buffered = BytesIO()\n",
        "    new_image.save(buffered, format=\"JPEG\")\n",
        "    encoded_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "    return encoded_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0wWrfhDC8ni"
      },
      "source": [
        "### Prepare dataset\n",
        "\n",
        "If you are not using [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview#all_datasets), then you need to prepare your dataset and store it on Cloud Storage. The following example shows\n",
        "how to do this for the [tf_flowers dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers). If using TensorFlow Datasets, you pass\n",
        "the dataset name such as `tf_flowers` to the `--config.dataset` flag and bypass this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW31Ws1RN9AC"
      },
      "outputs": [],
      "source": [
        "local_flower_data_directory = \"./flower_photos\"  # @param {type:\"string\"}\n",
        "FLOWER_DATA_GCS_PATH = os.path.join(BUCKET_URI, \"flower_dataset\")\n",
        "# The flower dataset has 5 classes.\n",
        "NUM_CLASSES = 5\n",
        "# NOTE: For custom dataset, the training code picks the class names\n",
        "# from the folder structure and then sorts them to create a mapping\n",
        "# from class-index to class-name. This is why the mapping below\n",
        "# looks different from default `tf_flowers` documentation.\n",
        "LABEL_IDX_TO_STR = {\n",
        "    0: \"daisy\",\n",
        "    1: \"dandelion\",\n",
        "    2: \"roses\",\n",
        "    3: \"sunflowers\",\n",
        "    4: \"tulips\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heMhYO-DD4II"
      },
      "outputs": [],
      "source": [
        "# Download flower data to a local directory.\n",
        "! rm -rf $local_flower_data_directory;\n",
        "! (cd \"./\" && curl https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz | tar xz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtWxe2y8Gqzl"
      },
      "outputs": [],
      "source": [
        "# Since the default file format of above \"tf_flowers\" dataset is\n",
        "# flower_photos/{class_name}/{filename}.jpg\n",
        "# we first need to split it into a \"train\" (90%) and a \"test\" (10%) set:\n",
        "# flower_photos/train/{class_name}/{filename}.jpg\n",
        "# flower_photos/test/{class_name}/{filename}.jpg\n",
        "\n",
        "split(local_flower_data_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g043ydQ_wlpk"
      },
      "outputs": [],
      "source": [
        "# Move Flower data from local directory to Cloud Storage.\n",
        "# This step takes around 2 mins to finish.\n",
        "! gsutil -m cp -R $local_flower_data_directory/train/* $FLOWER_DATA_GCS_PATH/train/\n",
        "! gsutil -m cp -R $local_flower_data_directory/test/* $FLOWER_DATA_GCS_PATH/test/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCpLmWPMpJQ8"
      },
      "source": [
        "## Finetune with JAX Vision Transformer\n",
        "\n",
        "Create and run the training job with the model-garden JAX vision transformer training docker using the Vertex AI SDK. The training uses one V100 GPU and runs for around 10 mins once the training job begins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aec22792ee84"
      },
      "outputs": [],
      "source": [
        "# Set up training docker arguments.\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "JOB_NAME = \"jax_vision_transformer\" + TIMESTAMP\n",
        "\n",
        "finetuning_workdir = os.path.join(BUCKET_URI, JOB_NAME)\n",
        "pre_trained_dir = \"gs://vit_models/imagenet21k\"\n",
        "docker_args_list = [\n",
        "    \"--config\",\n",
        "    \"vit_jax/configs/vit.py:b16\",\n",
        "    \"--config.dataset\",\n",
        "    f\"{gcs_fuse_path(FLOWER_DATA_GCS_PATH)}\",\n",
        "    \"--config.pp.train\",\n",
        "    \"train\",\n",
        "    \"--config.pp.test\",\n",
        "    \"test\",\n",
        "    \"--config.pretrained_dir\",\n",
        "    f\"{gcs_fuse_path(pre_trained_dir)}\",\n",
        "    \"--config.batch\",\n",
        "    \"128\",\n",
        "    \"--config.batch_eval\",\n",
        "    \"128\",\n",
        "    \"--config.base_lr\",\n",
        "    \"0.01\",\n",
        "    \"--config.shuffle_buffer\",\n",
        "    \"1000\",\n",
        "    \"--config.total_steps\",\n",
        "    \"100\",\n",
        "    \"--config.warmup_steps\",\n",
        "    \"10\",\n",
        "    \"--config.pp.crop\",\n",
        "    \"224\",\n",
        "    \"--workdir\",\n",
        "    f\"{gcs_fuse_path(finetuning_workdir)}\",\n",
        "]\n",
        "print(docker_args_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ELphfgj1f3Q"
      },
      "outputs": [],
      "source": [
        "# Create and run the training job.\n",
        "# Click on the generated link in the output under \"View backing custom job:\" to see your run in the Cloud Console.\n",
        "NUM_GPU = 1\n",
        "container_uri = TRAIN_DOCKER_URI\n",
        "job = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=JOB_NAME,\n",
        "    container_uri=container_uri,\n",
        ")\n",
        "model = job.run(\n",
        "    args=docker_args_list,\n",
        "    base_output_dir=f\"{finetuning_workdir}\",\n",
        "    replica_count=1,\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_V100\",\n",
        "    accelerator_count=NUM_GPU,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2qiROKIONnI"
      },
      "source": [
        "## Convert JAX Vision Transformer model to TF SavedModel\n",
        "\n",
        "Convert the previously fine-tuned JAX model to a TF SavedModel for online prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y7slAFLOwlV"
      },
      "outputs": [],
      "source": [
        "# Set up model conversion docker arguments.\n",
        "# Note: Many of the arguments below are similar to the training job\n",
        "# such as the model name and train and test data related parameters.\n",
        "\n",
        "jax_checkpoint_dir = finetuning_workdir\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "JOB_NAME = \"jax_model_conversion\" + TIMESTAMP\n",
        "saved_model_dir = os.path.join(BUCKET_URI, \"jax2tf_\" + TIMESTAMP)\n",
        "\n",
        "docker_args_list = [\n",
        "    \"--config\",\n",
        "    \"vit_jax/configs/vit.py:b16\",\n",
        "    \"--num_classes\",\n",
        "    f\"{NUM_CLASSES}\",\n",
        "    \"--saved_model_dir\",\n",
        "    f\"{saved_model_dir}\",\n",
        "    \"--jax_checkpoint_dir\",\n",
        "    f\"{jax_checkpoint_dir}\",\n",
        "    \"--config.pretrained_dir\",\n",
        "    f\"{pre_trained_dir}\",\n",
        "    \"--config.dataset\",\n",
        "    f\"{gcs_fuse_path(FLOWER_DATA_GCS_PATH)}\",\n",
        "    \"--config.pp.train\",\n",
        "    \"train\",\n",
        "    \"--config.pp.test\",\n",
        "    \"test\",\n",
        "    \"--config.pp.crop\",\n",
        "    \"224\",\n",
        "]\n",
        "print(docker_args_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Acfh1VWUsTL"
      },
      "outputs": [],
      "source": [
        "# Create and run the model conversion job.\n",
        "# Click on the generated link in the output under \"View backing custom job:\" to see your run in the Cloud Console.\n",
        "container_uri = MODEL_CONVERSION_DOCKER_URI\n",
        "job = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=JOB_NAME,\n",
        "    container_uri=container_uri,\n",
        ")\n",
        "model_conversion_workdir = os.path.join(BUCKET_URI, JOB_NAME)\n",
        "model = job.run(\n",
        "    args=docker_args_list,\n",
        "    base_output_dir=f\"{model_conversion_workdir}\",\n",
        "    replica_count=1,\n",
        "    machine_type=\"n1-standard-4\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iILhhP3TfO8B"
      },
      "source": [
        "## Run online prediction\n",
        "\n",
        "Run online prediction with the converted TF SavedModel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswgX6JqRwFK"
      },
      "source": [
        "Upload TF SavedModel and deploy it to an endpoint for prediction. This step takes around 15 minutes to finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74yqis5ufO8B"
      },
      "outputs": [],
      "source": [
        "jax_vit_model = aiplatform.Model.upload(\n",
        "    display_name=\"jax_vit\",\n",
        "    artifact_uri=saved_model_dir,\n",
        "    serving_container_image_uri=OPTIMIZED_TF_RUNTIME_IMAGE_URI,\n",
        "    serving_container_args=[],\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "jax_vit_endpoint = jax_vit_model.deploy(\n",
        "    deployed_model_display_name=\"jax_vit_deployed\",\n",
        "    traffic_split={\"0\": 100},\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_V100\",\n",
        "    accelerator_count=1,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiozz1aVR7Pe"
      },
      "source": [
        "Load a local test image file, encode it into a string, send it to the endpoint for prediction, and then generate the final class label from the predicted class probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxj4Xv_DhHXj"
      },
      "outputs": [],
      "source": [
        "test_directory = os.path.join(local_flower_data_directory, \"test/tulips\")\n",
        "local_test_image_path = os.path.join(test_directory, os.listdir(test_directory)[0])\n",
        "print(local_test_image_path)\n",
        "instances_list = [\n",
        "    {\n",
        "        \"bytes_inputs\": {\n",
        "            \"b64\": load_bytes_from_local_image(local_test_image_path, new_width=240)\n",
        "        }\n",
        "    }\n",
        "]\n",
        "instances = [json_format.ParseDict(s, Value()) for s in instances_list]\n",
        "results = jax_vit_endpoint.predict(instances=instances)\n",
        "logits = results.predictions[0]\n",
        "predicted_label = LABEL_IDX_TO_STR[int(np.argmax(logits))]\n",
        "print(\"predicted_label: \", predicted_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Delete endpoint resource.\n",
        "jax_vit_endpoint.delete(force=True)\n",
        "\n",
        "# Delete model resource.\n",
        "jax_vit_model.delete()\n",
        "\n",
        "# Delete Cloud Storage objects that were created.\n",
        "delete_bucket = True\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_jax_vision_transformer.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
