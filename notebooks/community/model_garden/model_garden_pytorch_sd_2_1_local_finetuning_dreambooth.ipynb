{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Vertex AI Model Garden - Stable Diffusion V2.1 (Local Dreambooth Finetune)\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_pytorch_sd_2_1_local_finetuning_dreambooth.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_sd_2_1_local_finetuning_dreambooth.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3de7470326a2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to finetune [stabilityai/stable-diffusion-2-1](https://huggingface.co/stabilityai/stable-diffusion-2-1) with [Dreambooth](https://huggingface.co/docs/diffusers/training/dreambooth) locally in a Colab notebook and to test it with a local `text-2-image` prediction pipeline.\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Finetune the stabilityai/stable-diffusion-2-1 model with [Dreambooth](https://huggingface.co/docs/diffusers/training/dreambooth) locally in a notebook.\n",
        "- Run predictions for text-to-image in a local pipeline.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Colab Enterprise\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloab Enterprise pricing](https://cloud.google.com/colab/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6546207faba5"
      },
      "source": [
        "## Dreambooth Finetune in a notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "969e7ccbc033"
      },
      "outputs": [],
      "source": [
        "# @title Check if the Colab VM has GPU\n",
        "\n",
        "# @markdown **Important:** This notebook requires a GPU runtime to function correctly.\n",
        "# @markdown The default Colab runtime does not have a GPU and will not work. Please\n",
        "# @markdown create a GPU runtime by following the instructions at:\n",
        "# @markdown   1. [Create a runtime template](https://cloud.google.com/vertex-ai/docs/colab/create-runtime-template#create)\n",
        "# @markdown   1. [Create a runtime](https://cloud.google.com/vertex-ai/docs/colab/create-runtime#create) \\\n",
        "# @markdown\n",
        "# @markdown Once you have created a GPU runtime, you can use this notebook to run Dreambooth training locally within Colab.\n",
        "\n",
        "import subprocess\n",
        "\n",
        "if subprocess.run(\"nvidia-smi\").returncode:\n",
        "    raise RuntimeError(\n",
        "        \"Cannot communicate with GPU. Make sure you are using a GPU Colab runtime. \"\n",
        "        \"Go to the Runtimes menu and select/create a runtime with GPUs.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2707b02ef5df"
      },
      "outputs": [],
      "source": [
        "# @title Prepare the virtual environment\n",
        "\n",
        "! pip install --upgrade pip\n",
        "# Git clone the Huggingface diffusers code repo\n",
        "! git clone --depth 1 --branch v0.25.1 https://github.com/huggingface/diffusers.git\n",
        "\n",
        "print(\"Installing diffusers from the source\")\n",
        "! pip install -e /content/diffusers\n",
        "print(\"Installing the requirements for dreambooth finetune\")\n",
        "! pip install -r /content/diffusers/examples/dreambooth/requirements.txt\n",
        "\n",
        "! pip install bitsandbytes==0.43.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d133319b6a53"
      },
      "outputs": [],
      "source": [
        "# @title Prepare the example dataset\n",
        "\n",
        "# @markdown For this example, we'll download some images from Huggingface. If you\n",
        "# @markdown have already had a dataset you wish to use, please choose the option\n",
        "# @markdown `Use your own` and upload from your local computer.\n",
        "#\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "from google.colab import files\n",
        "from huggingface_hub import snapshot_download\n",
        "from PIL import Image\n",
        "\n",
        "local_dir = \"/content/dreambooth/dog/\"\n",
        "! rm -rf $local_dir\n",
        "! mkdir -p $local_dir\n",
        "\n",
        "dataset_source = \"Huggingface\"  # @param [\"Huggingface\", \"Use your own\"]\n",
        "if dataset_source == \"Huggingface\":\n",
        "    snapshot_download(\n",
        "        \"diffusers/dog-example\",\n",
        "        local_dir=local_dir,\n",
        "        repo_type=\"dataset\",\n",
        "        ignore_patterns=\".gitattributes\",\n",
        "    )\n",
        "else:\n",
        "    uploaded = files.upload()\n",
        "    for name, data in uploaded.items():\n",
        "        shutil.copy2(name, local_dir)\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows, cols, resize=256):\n",
        "    if resize is not None:\n",
        "        imgs = [img.resize((resize, resize)) for img in imgs]\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "# change path to display images from your local dir\n",
        "img_paths = \"/content/dreambooth/dog/*.jpeg\"\n",
        "imgs = [Image.open(path) for path in glob.glob(img_paths)]\n",
        "\n",
        "num_imgs_to_preview = 5\n",
        "image_grid(imgs[:num_imgs_to_preview], 1, num_imgs_to_preview)\n",
        "\n",
        "! rm -rf $local_dir/.huggingface\n",
        "! ls -alt $local_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8cbdbbc97728"
      },
      "outputs": [],
      "source": [
        "# @title Train\n",
        "\n",
        "import locale\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "! accelerate config default\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-2-1\" # @param {type:\"string\"}\n",
        "instance_prompt = \"a photo of sks dog\" # @param {type:\"string\"}\n",
        "learning_rate = 2e-6 # @param {type:\"number\"}\n",
        "resolution = 768 # @param {type:\"number\"}\n",
        "train_steps = 200 # @param {type:\"number\"}\n",
        "output_dir = \"/content/dreambooth/output_dir\"\n",
        "\n",
        "local_dir = \"/content/dreambooth/dog/\"\n",
        "\n",
        "!accelerate launch \\\n",
        "  /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"$model_id\" \\\n",
        "  --instance_data_dir=\"$local_dir\" \\\n",
        "  --class_data_dir=\"$local_dir\" \\\n",
        "  --output_dir=\"$output_dir\" \\\n",
        "  --instance_prompt=\"$instance_prompt\" \\\n",
        "  --resolution=\"$resolution\" \\\n",
        "  --learning_rate=\"$learning_rate\" \\\n",
        "  --max_train_steps=\"$train_steps\" \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --use_8bit_adam \\\n",
        "  --checkpointing_steps=100 \\\n",
        "  --seed=42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "356db37ed6ce"
      },
      "outputs": [],
      "source": [
        "# @title Load the finetuned model checkpoint to a local diffusion pipeline.\n",
        "\n",
        "# @markdown `text-to-image` lets you send text prompts to the pipeline to generate images.\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    pretrained_model_or_path=output_dir,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "prompt = \"a photo of sks dog in a bucket\"  # @param {type: \"string\"}\n",
        "height = 768  # @param {type:\"number\"}\n",
        "width = 768  # @param {type:\"number\"}\n",
        "num_inference_steps = 25  # @param {type:\"number\"}\n",
        "guidance_scale = 7.5  # @param {type:\"number\"}\n",
        "\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    guidance_scale=guidance_scale,\n",
        ").images\n",
        "display(images[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_garden_pytorch_sd_2_1_local_finetuning_dreambooth.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
