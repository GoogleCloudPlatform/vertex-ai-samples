{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TirJ-SGQseby"
      },
      "source": [
        "# Vertex AI Model Garden TFVision With Image Segmentation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwGLvtIeECLK"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use [TFVision](https://github.com/tensorflow/models/blob/master/official/vision/MODEL_GARDEN.md) in Vertex AI Model Garden.\n",
        "\n",
        "### Objective\n",
        "\n",
        "* Train new models\n",
        "  * Convert input data to training formats\n",
        "  * Create [hyperparameter tuning jobs](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) to train new models\n",
        "  * Find and export best models\n",
        "\n",
        "* Test trained models\n",
        "  * Upload models to model registry\n",
        "  * Deploy uploaded models\n",
        "  * Run predictions\n",
        "\n",
        "* Cleanup resources\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEukV6uRk_S3"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z__i0w0lCAsW"
      },
      "source": [
        "### Colab Only\n",
        "\n",
        "Run the following commands for Colab and skip this section if you use Workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvqs-ehKlaYh"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform\n",
        "\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wExiMUxFk91"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# The project and bucket are for experiments below.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# You can choose a region from https://cloud.google.com/about/locations.\n",
        "# Only regions prefixed by \"us\", \"asia\", or \"europe\" are supported.\n",
        "REGION = \"europe-west4\"  # @param {type:\"string\"}\n",
        "REGION_PREFIX = REGION.split(\"-\")[0]\n",
        "assert REGION_PREFIX in (\n",
        "    \"us\",\n",
        "    \"europe\",\n",
        "    \"asia\",\n",
        "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "CHECKPOINT_BUCKET = os.path.join(BUCKET_URI, \"ckpt\")\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "# Download config files.\n",
        "CONFIG_DIR = os.path.join(BUCKET_URI, \"config\")\n",
        "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/semantic_segmentation/deeplabv3plus_resnet101_cityscapes_gpu_multiworker_mirrored.yaml\n",
        "! gsutil cp deeplabv3plus_resnet101_cityscapes_gpu_multiworker_mirrored.yaml $CONFIG_DIR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6IFz75WGCam"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riG_qUokg0XZ"
      },
      "outputs": [],
      "source": [
        "OBJECTIVE = \"isg\"\n",
        "\n",
        "# Data converter constants.\n",
        "DATA_CONVERTER_JOB_PREFIX = \"data_converter\"\n",
        "DATA_CONVERTER_CONTAINER = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/data-converter\"\n",
        "DATA_CONVERTER_MACHINE_TYPE = \"n1-highmem-8\"\n",
        "\n",
        "\n",
        "# Training constants.\n",
        "TRAINING_JOB_PREFIX = \"train\"\n",
        "TRAIN_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/tfvision-oss\"\n",
        "TRAIN_MACHINE_TYPE = \"n1-highmem-16\"\n",
        "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
        "TRAIN_NUM_GPU = 2\n",
        "TRAIN_DEEPLABV3PLUS_CONFIG = os.path.join(\n",
        "    CONFIG_DIR, \"deeplabv3plus_resnet101_cityscapes_gpu_multiworker_mirrored.yaml\"\n",
        ")\n",
        "\n",
        "# Evaluation constants.\n",
        "EVALUATION_METRIC = \"mean_iou\"\n",
        "\n",
        "# Export constants.\n",
        "EXPORT_JOB_PREFIX = \"export\"\n",
        "EXPORT_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/tfvision-model-export\"\n",
        "EXPORT_MACHINE_TYPE = \"n1-highmem-8\"\n",
        "\n",
        "# Prediction constants.\n",
        "# You can deploy models with\n",
        "#   pre-build-dockers: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers.\n",
        "#   and optimized tensorflow runtime dockers: https://cloud.google.com/vertex-ai/docs/predictions/optimized-tensorflow-runtime.\n",
        "# The example in this notebook uses optimized tensorflow runtime dockers.\n",
        "# You can adjust accelerator types and machine types to get faster predictions.\n",
        "PREDICTION_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-11:latest\"\n",
        "SERVING_CONTAINER_ARGS = [\"--allow_precompilation\", \"--allow_compression\"]\n",
        "PREDICTION_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
        "PREDICTION_MACHINE_TYPE = \"n1-standard-4\"\n",
        "UPLOAD_JOB_PREFIX = \"upload\"\n",
        "DEPLOY_JOB_PREFIX = \"deploy\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFPe_GezXg8"
      },
      "source": [
        "### Define common libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcYUGwr-AJGY"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import yaml\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def get_job_name_with_datetime(prefix: str):\n",
        "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def predict_custom_trained_model(\n",
        "    project: str,\n",
        "    endpoint_id: str,\n",
        "    instances: Union[Dict, List[Dict]],\n",
        "    location: str = \"us-central1\",\n",
        "):\n",
        "    # The AI Platform services require regional API endpoints.\n",
        "    client_options = {\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n",
        "    # Initialize client that will be used to create and send requests.\n",
        "    # This client only needs to be created once, and can be reused for multiple requests.\n",
        "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "    parameters_dict = {}\n",
        "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
        "    endpoint = client.endpoint_path(\n",
        "        project=project, location=location, endpoint=endpoint_id\n",
        "    )\n",
        "    response = client.predict(\n",
        "        endpoint=endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    return response.predictions, response.deployed_model_id\n",
        "\n",
        "\n",
        "def load_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    return Image.fromarray(np.uint8(img)).convert(\"RGB\")\n",
        "\n",
        "\n",
        "def display_image(original_image, category_image_color, score_image_grayscale):\n",
        "    _, axarr = plt.subplots(1, 3, figsize=(20, 15))\n",
        "    axarr[0].imshow(original_image)\n",
        "    axarr[1].imshow(category_image_color)\n",
        "    axarr[2].imshow(score_image_grayscale.convert(\"RGB\"))\n",
        "\n",
        "\n",
        "def get_prediction_instances(test_filepath, new_width=-1):\n",
        "    if new_width <= 0:\n",
        "        with tf.io.gfile.GFile(test_filepath, \"rb\") as input_file:\n",
        "            encoded_string = base64.b64encode(input_file.read()).decode(\"utf-8\")\n",
        "    else:\n",
        "        img = load_img(test_filepath)\n",
        "        width, height = img.size\n",
        "        print(\"original input image size: \", width, \" , \", height)\n",
        "        new_height = int(height * new_width / width)\n",
        "        new_img = img.resize((new_width, new_height))\n",
        "        print(\"resized input image size: \", new_width, \" , \", new_height)\n",
        "        buffered = BytesIO()\n",
        "        new_img.save(buffered, format=\"JPEG\")\n",
        "        encoded_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    instances = [\n",
        "        {\n",
        "            \"encoded_image\": {\"b64\": encoded_string},\n",
        "        }\n",
        "    ]\n",
        "    return instances\n",
        "\n",
        "\n",
        "def get_label_map(label_map_yaml_filepath):\n",
        "    with tf.io.gfile.GFile(label_map_yaml_filepath, \"rb\") as input_file:\n",
        "        label_map = yaml.safe_load(input_file.read())\n",
        "    return label_map\n",
        "\n",
        "\n",
        "def get_best_trial(model_dir, max_trial_count, evaluation_metric):\n",
        "    best_trial_dir = \"\"\n",
        "    best_trial_evaluation_results = {}\n",
        "    best_performance = -1\n",
        "\n",
        "    for i in range(max_trial_count):\n",
        "        current_trial = i + 1\n",
        "        current_trial_dir = os.path.join(model_dir, \"trial_\" + str(current_trial))\n",
        "        current_trial_best_ckpt_dir = os.path.join(current_trial_dir, \"best_ckpt\")\n",
        "        current_trial_best_ckpt_evaluation_filepath = os.path.join(\n",
        "            current_trial_best_ckpt_dir, \"info.json\"\n",
        "        )\n",
        "        with tf.io.gfile.GFile(current_trial_best_ckpt_evaluation_filepath, \"rb\") as f:\n",
        "            eval_metric_results = json.load(f)\n",
        "            current_performance = eval_metric_results[evaluation_metric]\n",
        "            if current_performance > best_performance:\n",
        "                best_performance = current_performance\n",
        "                best_trial_dir = current_trial_dir\n",
        "                best_trial_evaluation_results = eval_metric_results\n",
        "    return best_trial_dir, best_trial_evaluation_results\n",
        "\n",
        "\n",
        "def create_coco_stuff_label_colormap():\n",
        "    \"\"\"Creates a label colormap used in COCO-Stuff segmentation benchmark.\n",
        "\n",
        "    Returns:\n",
        "      A colormap for visualizing segmentation results.\n",
        "    \"\"\"\n",
        "    return np.asarray(\n",
        "        [\n",
        "            [54, 178, 118],\n",
        "            [0, 85, 178],\n",
        "            [150, 178, 22],\n",
        "            [107, 0, 0],\n",
        "            [0, 0, 89],\n",
        "            [0, 117, 178],\n",
        "            [47, 178, 124],\n",
        "            [178, 116, 0],\n",
        "            [0, 0, 178],\n",
        "            [79, 178, 92],\n",
        "            [134, 0, 0],\n",
        "            [22, 178, 150],\n",
        "            [178, 87, 0],\n",
        "            [178, 146, 0],\n",
        "            [0, 5, 178],\n",
        "            [0, 0, 125],\n",
        "            [0, 53, 178],\n",
        "            [0, 132, 178],\n",
        "            [111, 178, 60],\n",
        "            [178, 131, 0],\n",
        "            [0, 29, 178],\n",
        "            [178, 109, 0],\n",
        "            [178, 35, 0],\n",
        "            [0, 148, 178],\n",
        "            [9, 172, 163],\n",
        "            [0, 0, 178],\n",
        "            [178, 124, 0],\n",
        "            [178, 102, 0],\n",
        "            [0, 156, 175],\n",
        "            [178, 43, 0],\n",
        "            [0, 0, 170],\n",
        "            [178, 94, 0],\n",
        "            [0, 0, 134],\n",
        "            [67, 178, 105],\n",
        "            [99, 178, 73],\n",
        "            [0, 37, 178],\n",
        "            [86, 178, 86],\n",
        "            [15, 178, 156],\n",
        "            [0, 0, 152],\n",
        "            [178, 21, 0],\n",
        "            [0, 124, 178],\n",
        "            [0, 61, 178],\n",
        "            [178, 50, 0],\n",
        "            [0, 109, 178],\n",
        "            [137, 178, 35],\n",
        "            [0, 13, 178],\n",
        "            [0, 101, 178],\n",
        "            [0, 0, 116],\n",
        "            [0, 45, 178],\n",
        "            [41, 178, 131],\n",
        "            [0, 0, 161],\n",
        "            [178, 72, 0],\n",
        "            [0, 0, 143],\n",
        "            [116, 0, 0],\n",
        "            [28, 178, 143],\n",
        "            [170, 6, 0],\n",
        "            [156, 178, 15],\n",
        "            [89, 0, 0],\n",
        "            [143, 178, 28],\n",
        "            [73, 178, 99],\n",
        "            [118, 178, 54],\n",
        "            [92, 178, 79],\n",
        "            [152, 0, 0],\n",
        "            [178, 153, 0],\n",
        "            [98, 0, 0],\n",
        "            [178, 65, 0],\n",
        "            [60, 178, 111],\n",
        "            [169, 175, 3],\n",
        "            [105, 178, 67],\n",
        "            [178, 13, 0],\n",
        "            [163, 178, 9],\n",
        "            [3, 164, 169],\n",
        "            [125, 0, 0],\n",
        "            [175, 168, 0],\n",
        "            [178, 138, 0],\n",
        "            [178, 28, 0],\n",
        "            [35, 178, 137],\n",
        "            [0, 140, 178],\n",
        "            [0, 0, 98],\n",
        "            [131, 178, 41],\n",
        "            [0, 77, 178],\n",
        "            [0, 0, 107],\n",
        "            [0, 93, 178],\n",
        "            [143, 0, 0],\n",
        "            [178, 58, 0],\n",
        "            [161, 0, 0],\n",
        "            [0, 69, 178],\n",
        "            [178, 160, 0],\n",
        "            [178, 80, 0],\n",
        "            [0, 21, 178],\n",
        "            [124, 178, 47],\n",
        "            [255, 214, 0],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_segmentation_prediction(prediction):\n",
        "    score_bytes = prediction[\"score_bytes\"]\n",
        "    score_image_grayscale = Image.open(\n",
        "        BytesIO(base64.b64decode(dict(score_bytes)[\"b64\"]))\n",
        "    )\n",
        "    category_bytes = prediction[\"category_bytes\"]\n",
        "    category_image_grayscale = Image.open(\n",
        "        BytesIO(base64.b64decode(dict(category_bytes)[\"b64\"]))\n",
        "    )\n",
        "\n",
        "    # Visualize category images.\n",
        "    color_map = create_coco_stuff_label_colormap()\n",
        "    category_image_grayscale_np = np.array(category_image_grayscale)\n",
        "    rendered_image_shape = category_image_grayscale_np.shape + (3,)\n",
        "    category_image_color_np = np.zeros(rendered_image_shape, dtype=np.uint8)\n",
        "    unique_labels = np.unique(category_image_grayscale_np)\n",
        "    for label in unique_labels:\n",
        "        if label == 0:\n",
        "            continue\n",
        "        category_image_color_np[category_image_grayscale_np == label] = color_map[\n",
        "            label % len(color_map)\n",
        "        ]\n",
        "    category_image_color = Image.fromarray(category_image_color_np)\n",
        "\n",
        "    return score_image_grayscale, category_image_color\n",
        "\n",
        "\n",
        "def upload_checkpoint_to_gcs(checkpoint_url):\n",
        "    filename = os.path.basename(checkpoint_url)\n",
        "    checkpoint_name = filename.replace(\".tar.gz\", \"\")\n",
        "    print(\"Download checkpoint from\", checkpoint_url, \"and store to\", CHECKPOINT_BUCKET)\n",
        "    ! wget $checkpoint_url -O $filename\n",
        "    ! mkdir -p $checkpoint_name\n",
        "    ! tar -xvzf $filename -C $checkpoint_name\n",
        "\n",
        "    # Search for relative path to the checkpoint.\n",
        "    checkpoint_path = None\n",
        "    for root, dirs, files in os.walk(checkpoint_name):\n",
        "        for file in files:\n",
        "            if file.endswith(\".index\"):\n",
        "                checkpoint_path = os.path.join(root, os.path.splitext(file)[0])\n",
        "                checkpoint_path = os.path.relpath(checkpoint_path, checkpoint_name)\n",
        "                break\n",
        "\n",
        "    ! gsutil cp -r $checkpoint_name $CHECKPOINT_BUCKET/\n",
        "    checkpoint_uri = os.path.join(CHECKPOINT_BUCKET, checkpoint_name, checkpoint_path)\n",
        "    print(\"Checkpoint uploaded to\", checkpoint_uri)\n",
        "    return checkpoint_uri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB_xY9ipr7ZU"
      },
      "source": [
        "## Train new models\n",
        "This section shows how to train new models.\n",
        "1. Convert input data to training formats\n",
        "2. Create hyperparameter tuning jobs to train new models\n",
        "3. Find and export best models\n",
        "\n",
        "If you already trained models, please go to the section `Test trained models`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Prepare input data for training\n",
        "\n",
        "Prepare data in the format as described [here](https://cloud.google.com/vertex-ai/docs/image-data/classification/prepare-data), and then convert them to the training formats as below:\n",
        "\n",
        "* `input_file_path`: The input file path in coco json formats.\n",
        "* `split_ratio`: The proportion of data to split into train/validation/test.\n",
        "* `num_shard`: The number of shards for train/validation/test.\n",
        "* `output_dir`: The output directory, which will container prepared train/test/validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IndQ_m6ddUEM"
      },
      "outputs": [],
      "source": [
        "# This job will convert input data as training format, with given split ratios\n",
        "# and number of shards on train/test/validation.\n",
        "data_converter_job_name = get_job_name_with_datetime(\n",
        "    DATA_CONVERTER_JOB_PREFIX + \"_\" + OBJECTIVE\n",
        ")\n",
        "\n",
        "input_file_path = \"\"  # @param {type:\"string\"}\n",
        "split_ratio = \"0.8,0.1,0.1\"\n",
        "num_shard = \"10,10,10\"\n",
        "data_converter_output_dir = os.path.join(BUCKET_URI, data_converter_job_name)\n",
        "\n",
        "\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": DATA_CONVERTER_MACHINE_TYPE,\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": DATA_CONVERTER_CONTAINER,\n",
        "            \"command\": [],\n",
        "            \"args\": [\n",
        "                \"--input_file_path=%s\" % input_file_path,\n",
        "                \"--input_file_type=coco_json\",\n",
        "                \"--objective=%s\" % OBJECTIVE,\n",
        "                \"--num_shard=%s\" % num_shard,\n",
        "                \"--split_ratio=%s\" % split_ratio,\n",
        "                \"--output_dir=%s\" % data_converter_output_dir,\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "data_converter_custom_job = aiplatform.CustomJob(\n",
        "    display_name=data_converter_job_name,\n",
        "    project=PROJECT_ID,\n",
        "    worker_pool_specs=worker_pool_specs,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "data_converter_custom_job.run()\n",
        "\n",
        "input_train_data_path = os.path.join(data_converter_output_dir, \"train.tfrecord*\")\n",
        "input_validation_data_path = os.path.join(data_converter_output_dir, \"val.tfrecord*\")\n",
        "label_map_path = os.path.join(data_converter_output_dir, \"label_map.yaml\")\n",
        "print(\"input_train_data_path for training: \", input_train_data_path)\n",
        "print(\"input_validation_data_path for training: \", input_validation_data_path)\n",
        "print(\"label_map_path for prediction: \", label_map_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6dU2IrIqW3H"
      },
      "source": [
        "### Create a Vertex AI custom job with hyperparameter tuning\n",
        "\n",
        "You use the Vertex AI SDK to create and run the hyperparameter tuning job with Vertex AI Model Garden Training Dockers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaff6f5be7f6"
      },
      "source": [
        "#### Define the following specifications\n",
        "* `worker_pool_specs`: Dictionary specifying the machine type and Docker image. This example defines a single node cluster with one `n1-standard-4` machine with two `NVIDIA_TESLA_T4` GPUs.\n",
        "* `parameter_spec`: Dictionary specifying the parameters to optimize. The dictionary key is the string assigned to the command line argument for each hyperparameter in your training application code, and the dictionary value is the parameter specification. The parameter specification includes the type, min/max values, and scale for the hyperparameter.\n",
        "* `metric_spec`: Dictionary specifying the metric to optimize. The dictionary key is the `hyperparameter_metric_tag` that you set in your training application code, and the value is the optimization goal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um_XKbmpTaHx"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "label_map = get_label_map(label_map_path)\n",
        "num_classes = len(label_map[\"label_map\"]) + 1\n",
        "\n",
        "# Input train and validation datasets can be found from the section above\n",
        "# `Convert input data for training`.\n",
        "# Set prepared datasets if exists.\n",
        "# input_train_data_path = ''\n",
        "# input_validation_data_path = ''\n",
        "\n",
        "# Refer to https://github.com/tensorflow/models/blob/master/official/vision/MODEL_GARDEN.md\n",
        "# for more model details.\n",
        "experiment = \"deeplabv3plus\"  # @param [\"deeplabv3plus\"]\n",
        "\n",
        "train_job_name = get_job_name_with_datetime(TRAINING_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "model_dir = os.path.join(BUCKET_URI, train_job_name)\n",
        "\n",
        "# The arguments here are mainly for test purposes. Please update them\n",
        "# to get better performances.\n",
        "experiment_container_args_dict = {\n",
        "    # deeplabv3plus experiment args.\n",
        "    \"deeplabv3plus\": {\n",
        "        \"experiment\": \"seg_deeplabv3plus_pascal\",\n",
        "        \"config_file\": TRAIN_DEEPLABV3PLUS_CONFIG,\n",
        "        \"input_train_data_path\": input_train_data_path,\n",
        "        \"input_validation_data_path\": input_validation_data_path,\n",
        "        \"objective\": OBJECTIVE,\n",
        "        \"model_dir\": model_dir,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"global_batch_size\": 2,\n",
        "        \"prefetch_buffer_size\": 12,\n",
        "        \"train_steps\": 500,\n",
        "        \"output_size\": \"1024,2048\",\n",
        "        \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/deeplabv3plus/dilated-resnet-101-deeplabv3plus.tar.gz\",\n",
        "    }\n",
        "}\n",
        "experiment_container_args = experiment_container_args_dict[experiment]\n",
        "\n",
        "# Copy checkpoint to GCS bucket if specified.\n",
        "init_checkpoint = experiment_container_args.get(\"init_checkpoint\")\n",
        "if init_checkpoint:\n",
        "    experiment_container_args[\"init_checkpoint\"] = upload_checkpoint_to_gcs(\n",
        "        init_checkpoint\n",
        "    )\n",
        "\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": TRAIN_MACHINE_TYPE,\n",
        "            \"accelerator_type\": TRAIN_ACCELERATOR_TYPE,\n",
        "            \"accelerator_count\": TRAIN_NUM_GPU,\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": TRAIN_CONTAINER_URI,\n",
        "            \"args\": [\n",
        "                \"--mode=train_and_eval\",\n",
        "            ]\n",
        "            + [\"--{}={}\".format(k, v) for k, v in experiment_container_args.items()],\n",
        "        },\n",
        "    },\n",
        "]\n",
        "\n",
        "metric_spec = {\"model_performance\": \"maximize\"}\n",
        "\n",
        "LEARNING_RATES = [0.001]\n",
        "# Models will be trained with each learning rate separately and max trial count is the number of learning rates.\n",
        "MAX_TRIAL_COUNT = len(LEARNING_RATES)\n",
        "parameter_spec = {\n",
        "    \"learning_rate\": hpt.DiscreteParameterSpec(values=LEARNING_RATES, scale=\"linear\"),\n",
        "}\n",
        "\n",
        "print(worker_pool_specs, metric_spec, parameter_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwcCjwlBTQIz"
      },
      "source": [
        "#### Run hyperparameter tuning jobs\n",
        "* `max_trial_count`: Sets an upper bound on the number of trials the service will run. The recommended practice is to start with a smaller number of trials and get a sense of how impactful your chosen hyperparameters are before scaling up.\n",
        "\n",
        "* `parallel_trial_count`:  If you use parallel trials, the service provisions multiple training processing clusters. The worker pool spec that you specify when creating the job is used for each individual training cluster.  Increasing the number of parallel trials reduces the amount of time the hyperparameter tuning job takes to run; however, it can reduce the effectiveness of the job overall. This is because the default tuning strategy uses results of previous trials to inform the assignment of values in subsequent trials.\n",
        "\n",
        "* `search_algorithm`: The available search algorithms are grid, random, or default (None). The default option applies Bayesian optimization to search the space of possible hyperparameter values and is the recommended algorithm.\n",
        "\n",
        "Click on the generated link in the output to see your run in the Cloud Console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aec22792ee84"
      },
      "outputs": [],
      "source": [
        "train_custom_job = aiplatform.CustomJob(\n",
        "    display_name=train_job_name,\n",
        "    project=PROJECT_ID,\n",
        "    worker_pool_specs=worker_pool_specs,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "train_hpt_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name=train_job_name,\n",
        "    custom_job=train_custom_job,\n",
        "    metric_spec=metric_spec,\n",
        "    parameter_spec=parameter_spec,\n",
        "    max_trial_count=MAX_TRIAL_COUNT,\n",
        "    parallel_trial_count=1,\n",
        "    project=PROJECT_ID,\n",
        "    search_algorithm=None,\n",
        ")\n",
        "\n",
        "train_hpt_job.run()\n",
        "\n",
        "print(\"experiment is: \", experiment)\n",
        "print(\"model_dir is: \", model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV-Djz-frBni"
      },
      "source": [
        "### Export best models as TF Saved Model format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09Rz1AYspK19"
      },
      "outputs": [],
      "source": [
        "# This job will export models from TF checkpoints to TF saved model format.\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# model_dir is from the section above.\n",
        "best_trial_dir, best_trial_evaluation_results = get_best_trial(\n",
        "    model_dir, MAX_TRIAL_COUNT, EVALUATION_METRIC\n",
        ")\n",
        "print(\"best_trial_dir: \", best_trial_dir)\n",
        "print(\"best_trial_evaluation_results: \", best_trial_evaluation_results)\n",
        "\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": EXPORT_MACHINE_TYPE,\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": EXPORT_CONTAINER_URI,\n",
        "            \"command\": [],\n",
        "            \"args\": [\n",
        "                \"--objective=%s\" % OBJECTIVE,\n",
        "                \"--experiment=%s\" % experiment_container_args[\"experiment\"],\n",
        "                \"--config_file=%s/params.yaml\" % best_trial_dir,\n",
        "                \"--checkpoint_path=%s/best_ckpt\" % best_trial_dir,\n",
        "                \"--export_dir=%s/best_model\" % model_dir,\n",
        "                \"--input_image_size=%s\" % experiment_container_args[\"output_size\"],\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "model_export_name = get_job_name_with_datetime(EXPORT_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "model_export_custom_job = aiplatform.CustomJob(\n",
        "    display_name=model_export_name,\n",
        "    project=PROJECT_ID,\n",
        "    worker_pool_specs=worker_pool_specs,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "\n",
        "model_export_custom_job.run()\n",
        "\n",
        "print(\"best model is saved to: \", os.path.join(model_dir, \"best_model\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0BGaofgsMsy"
      },
      "source": [
        "## Test trained models\n",
        "This section shows how to test with trained models.\n",
        "1. Upload and deploy models\n",
        "2. Run predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYuQowyZEtxK"
      },
      "outputs": [],
      "source": [
        "# @title Upload and deploy models\n",
        "# model_dir is from the section above.\n",
        "trained_model_dir = os.path.join(model_dir, \"best_model/saved_model\")\n",
        "\n",
        "upload_job_name = get_job_name_with_datetime(UPLOAD_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=upload_job_name,\n",
        "    artifact_uri=trained_model_dir,\n",
        "    serving_container_image_uri=PREDICTION_CONTAINER_URI,\n",
        "    serving_container_args=SERVING_CONTAINER_ARGS,\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(\"The uploaded model name is: \", upload_job_name)\n",
        "\n",
        "deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "print(\"The deployed job name is: \", deploy_model_name)\n",
        "\n",
        "endpoint = model.deploy(\n",
        "    deployed_model_display_name=deploy_model_name,\n",
        "    machine_type=PREDICTION_MACHINE_TYPE,\n",
        "    traffic_split={\"0\": 100},\n",
        "    accelerator_type=PREDICTION_ACCELERATOR_TYPE,\n",
        "    accelerator_count=1,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=1,\n",
        ")\n",
        "\n",
        "endpoint_id = endpoint.name\n",
        "print(\"endpoint id is: \", endpoint_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbIW9me1F2RY"
      },
      "outputs": [],
      "source": [
        "# @title Run predictions\n",
        "# endpoint_id was generated in the section above (`Upload and deploy models`).\n",
        "endpoint_id = endpoint.name\n",
        "\n",
        "# The test image file path.\n",
        "test_filepath = \"\"  # @param {type:\"string\"}\n",
        "score_threshold = 0.5  # @param {type:\"number\"}\n",
        "# If the input image is too large, we will resize it for prediction.\n",
        "instances = get_prediction_instances(test_filepath, new_width=1000)\n",
        "\n",
        "# The label map file was generated from the section above (`Convert input data for training`).\n",
        "label_map = get_label_map(label_map_path)[\"label_map\"]\n",
        "\n",
        "predictions, _ = predict_custom_trained_model(\n",
        "    project=PROJECT_ID, location=REGION, endpoint_id=endpoint_id, instances=instances\n",
        ")\n",
        "\n",
        "score_image_grayscale, category_image_color = parse_segmentation_prediction(\n",
        "    dict(predictions[0])\n",
        ")\n",
        "display_image(\n",
        "    load_img(test_filepath), category_image_color, score_image_grayscale.convert(\"RGB\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkH2nrpdp4sp"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax6vQVZhp9pR"
      },
      "outputs": [],
      "source": [
        "# Undeploy model and delete endpoint.\n",
        "endpoint.delete(force=True)\n",
        "# Delete models.\n",
        "model.delete()\n",
        "# Delete custom and hpt jobs.\n",
        "if data_converter_custom_job.list(filter=f'display_name=\"{data_converter_job_name}\"'):\n",
        "    data_converter_custom_job.delete()\n",
        "if train_hpt_job.list(filter=f'display_name=\"{train_job_name}\"'):\n",
        "    train_hpt_job.delete()\n",
        "if model_export_custom_job.list(filter=f'display_name=\"{model_export_name}\"'):\n",
        "    model_export_custom_job.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_tfvision_image_segmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
