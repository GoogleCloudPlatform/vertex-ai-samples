{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "695f89ad915d"
      },
      "source": [
        "# Vertex AI Model Garden - TIMM\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "    (a Python-3 CPU notebook is recommended)\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "da3390e6929e"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates finetuning the PyTorch [timm](https://github.com/rwightman/pytorch-image-models) models and deploying the models on [Vertex AI](https://cloud.google.com/vertex-ai).\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Setup environment.\n",
        "- Create a custom training job on Vertex AI to train or finetune a model.\n",
        "- Deploy the model on Vertex AI for online prediction.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cec528342232"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2462e90298b5"
      },
      "source": [
        "### Setup cloud project\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project). Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n",
        "\n",
        "1. [Enable Artifact Registry](https://cloud.google.com/artifact-registry/docs/enable-service) and [create a repository](https://cloud.google.com/artifact-registry/docs/repositories/create-repos) for storing docker images.\n",
        "\n",
        "1. [Create a GCS bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs.\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faabc134731f"
      },
      "source": [
        "### Setup required libraries\n",
        "\n",
        "It's highly recommended to run this notebook on [Vertex AI workbench](https://cloud.google.com/vertex-ai-workbench), where you don't need to manually install any additional libraries.\n",
        "\n",
        "If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk) and [gsutil](https://cloud.google.com/storage/docs/gsutil_install)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28744d77495c"
      },
      "source": [
        "### Colab Only\n",
        "Run the following commands for colab and skip this section if you use workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72f4e86b394c"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform\n",
        "\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21cb80304bcc"
      },
      "source": [
        "### Setup environment variables\n",
        "\n",
        "This notebook supports models in https://huggingface.co/docs/timm/models.\n",
        "\n",
        "You can also run\n",
        "`python -c \"from timm import list_models; print(list_models(pretrained=True))\"`\n",
        "locally to see all pretrained models.\n",
        "\n",
        "The following models have been verified:\n",
        "\n",
        "* vit_tiny_patch16_224\n",
        "* beit_base_patch16_224\n",
        "* deit3_small_patch16_224\n",
        "* efficientnet_b2\n",
        "* mobilenetv2_100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6522c4f387fa"
      },
      "outputs": [],
      "source": [
        "# The cloud project id.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "# The region for running jobs.\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# The model you want to train and serve.\n",
        "# We use a ViT model as the example.\n",
        "MODEL_NAME = \"vit_tiny_patch16_224\"  # @param {type:\"string\"}\n",
        "\n",
        "# The GCS bucket name without gs:// prefix for training outputs.\n",
        "# For example: test_bucket\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0a831a68a17"
      },
      "source": [
        "## Run training jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6921e62f80fb"
      },
      "outputs": [],
      "source": [
        "# The training docker uri.\n",
        "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-timm-train\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e312e606b6af"
      },
      "source": [
        "### Create a training job on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c84682becc22"
      },
      "source": [
        "Before creating a training job, you need to prepare the dataset for training and evaluation.\n",
        "\n",
        "For example, you can use [ImageNet-1K](https://huggingface.co/datasets/imagenet-1k) held on a GCS bucket as the input dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8f2c5d82ba2"
      },
      "outputs": [],
      "source": [
        "# The path to data directory on GCS without gs:// prefix.\n",
        "# In the form of: <bucket-name>/path-to-data\n",
        "GCS_DATA_DIR = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d084605a2c3d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# Init common setup.\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
        "\n",
        "# Input and output path.\n",
        "data_dir = f\"/gcs/{GCS_DATA_DIR}\"\n",
        "output_dir = f\"/gcs/{GCS_BUCKET}/timm\"\n",
        "\n",
        "# Worker pool spec.\n",
        "# Single node with multiple GPUs.\n",
        "machine_type = \"n1-highmem-32\"\n",
        "num_nodes = 1\n",
        "gpu_type = \"NVIDIA_TESLA_P100\"\n",
        "num_gpus = 4\n",
        "\n",
        "# Model specific config.\n",
        "job_name = f\"pytorch-{MODEL_NAME}\"\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "job = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=job_name,\n",
        "    container_uri=TRAIN_DOCKER_URI,\n",
        ")\n",
        "model = job.run(\n",
        "    args=[\n",
        "        \"--standalone\",\n",
        "        f\"--nnodes={num_nodes}\",\n",
        "        f\"--nproc_per_node={num_gpus}\",\n",
        "        \"train.py\",\n",
        "        data_dir,\n",
        "        f\"--model={MODEL_NAME}\",\n",
        "        \"--pretrained\",\n",
        "        f\"--output={output_dir}\",\n",
        "        f\"--batch-size={batch_size}\",\n",
        "        f\"--epochs={epochs}\",\n",
        "    ],\n",
        "    replica_count=num_nodes,\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=gpu_type,\n",
        "    accelerator_count=num_gpus,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71599c729dc5"
      },
      "source": [
        "### Create a hyperparameter tuning job on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbacf1cc0dfa"
      },
      "source": [
        "You can use a [hyperparameter tuning](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) job to find the best configuration of your hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c938322f5e0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "# Init common setup.\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
        "\n",
        "# Input and output path.\n",
        "data_dir = f\"/gcs/{GCS_DATA_DIR}\"\n",
        "output_dir = f\"/gcs/{GCS_BUCKET}/timm\"\n",
        "\n",
        "# Model specific config.\n",
        "job_name = f\"pytorch-hp-{MODEL_NAME}\"\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Worker pool spec.\n",
        "machine_type = \"n1-highmem-16\"\n",
        "num_nodes = 1\n",
        "gpu_type = \"NVIDIA_TESLA_V100\"\n",
        "num_gpus = 2\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": machine_type,\n",
        "            \"accelerator_type\": gpu_type,\n",
        "            \"accelerator_count\": num_gpus,\n",
        "        },\n",
        "        \"replica_count\": num_nodes,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": TRAIN_DOCKER_URI,\n",
        "            \"args\": [\n",
        "                \"--standalone\",\n",
        "                f\"--nnodes={num_nodes}\",\n",
        "                f\"--nproc_per_node={num_gpus}\",\n",
        "                \"train.py\",\n",
        "                data_dir,\n",
        "                f\"--model={MODEL_NAME}\",\n",
        "                \"--pretrained\",\n",
        "                f\"--output={output_dir}\",\n",
        "                f\"--batch-size={batch_size}\",\n",
        "                f\"--epochs={epochs}\",\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "# Hyperparameter job specs.\n",
        "metric_spec = {\"top1_accuracy\": \"maximize\"}\n",
        "parameter_spec = {\n",
        "    \"lr\": hpt.DoubleParameterSpec(min=0.001, max=0.05, scale=\"log\"),\n",
        "}\n",
        "max_trial_count = 2\n",
        "parallel_trial_count = 2\n",
        "\n",
        "# Launch jobs.\n",
        "training_job = aiplatform.CustomJob(\n",
        "    display_name=job_name, worker_pool_specs=worker_pool_specs\n",
        ")\n",
        "hp_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name=job_name,\n",
        "    custom_job=training_job,\n",
        "    metric_spec=metric_spec,\n",
        "    parameter_spec=parameter_spec,\n",
        "    max_trial_count=max_trial_count,\n",
        "    parallel_trial_count=parallel_trial_count,\n",
        "    search_algorithm=None,\n",
        ")\n",
        "hp_job.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "804744907f66"
      },
      "source": [
        "## Deply model for online prediction\n",
        "\n",
        "This section uploads the model to Model Registry and deploys it on the Endpoint.\n",
        "\n",
        "The model deployment step will take ~15 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f56645f29b25"
      },
      "outputs": [],
      "source": [
        "# The serve docker uri.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-timm-serve\"\n",
        "# The port number used by torchserve traffic.\n",
        "SERVE_PORT = 7080\n",
        "# The path to model checkpoint file, including gs:// prefix.\n",
        "MODEL_PT_PATH = \"gs://path_to_model_best.pth.tar\"  # @param {type:\"string\"}\n",
        "# [Optional] the path to index_to_name.json, including gs:// prefix.\n",
        "INDEX_TO_NAME_FILE = \"gs://path_to_index_to_name.json\"  # @param {type:\"string\"}\n",
        "\n",
        "# Converts gs:// uris to /gcs/ to use GCS Fuse.\n",
        "# See https://github.com/GoogleCloudPlatform/gcsfuse.\n",
        "MODEL_PT_PATH = MODEL_PT_PATH.replace(\"gs://\", \"/gcs/\")\n",
        "INDEX_TO_NAME_FILE = INDEX_TO_NAME_FILE.replace(\"gs://\", \"/gcs/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4c5a187a0a8"
      },
      "source": [
        "### Upload and deply model on Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86f319c8780a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# Init common setup.\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
        "\n",
        "# Upload model.\n",
        "serving_env = {\n",
        "    \"MODEL_NAME\": MODEL_NAME,\n",
        "    \"MODEL_PT_PATH\": MODEL_PT_PATH,\n",
        "    \"INDEX_TO_NAME_FILE\": INDEX_TO_NAME_FILE,\n",
        "}\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=MODEL_NAME,\n",
        "    serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "    serving_container_ports=[SERVE_PORT],\n",
        "    serving_container_predict_route=f\"/predictions/timm_serving\",\n",
        "    serving_container_health_route=\"/ping\",\n",
        "    serving_container_environment_variables=serving_env,\n",
        ")\n",
        "# Or reuse a pre-uploaded model.\n",
        "# model = aiplatform.Model('projects/123456789/locations/us-central1/models/123456789@1')\n",
        "\n",
        "# Create an endpoint.\n",
        "endpoint = aiplatform.Endpoint.create(display_name=f\"pytorch-timm-endpoint\")\n",
        "# Or reuse a pre-created endpoint.\n",
        "# endpoint = aiplatform.Endpoint('projects/123456789/locations/us-central1/endpoints/123456789')\n",
        "\n",
        "# Deploy model to endpoint.\n",
        "model.deploy(\n",
        "    endpoint=endpoint,\n",
        "    machine_type=\"n1-standard-8\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_T4\",\n",
        "    accelerator_count=1,\n",
        "    traffic_percentage=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf2227e86c7d"
      },
      "source": [
        "You can mange your uploaded models in the [Model Registry](https://pantheon.corp.google.com/vertex-ai/models) and your endpoints in the [Endpoints](https://pantheon.corp.google.com/vertex-ai/endpoints)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f78f46207a6"
      },
      "source": [
        "### Test online prediction\n",
        "\n",
        "Please upload an image to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55dd72728707"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# You can get the deployed endpoint object by its resource name returned by Endpoint.create(). For example:\n",
        "# endpoint = aiplatform.Endpoint('projects/816369962409/locations/us-central1/endpoints/8809168414485512192')\n",
        "\n",
        "# Please upload an image and enter its filename below.\n",
        "IMAGE_FILENAME = \"cat.jpg\"  # @param {type:\"string\"}\n",
        "\n",
        "# Alternatively, uncomment the follow line to download a cat image for demonstration.\n",
        "# ! wget http://images.cocodataset.org/val2017/000000039769.jpg -O cat.jpg\n",
        "\n",
        "with open(IMAGE_FILENAME, \"rb\") as f:\n",
        "    image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "instances = [{\"data\": {\"b64\": image_b64}}]\n",
        "\n",
        "prediction = endpoint.predict(instances=instances)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34c031b202e0"
      },
      "source": [
        "### Clean Up Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7378359e2e2e"
      },
      "outputs": [],
      "source": [
        "endpoint.undeploy_all()\n",
        "model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_pytorch_timm.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
