{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApNHZJmT2AMH"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfxrFG052AMI"
      },
      "source": [
        "# Vertex AI Model Garden - TIMM\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "    (a Python-3 CPU notebook is recommended)\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76BCoQcm2AMJ"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates running local inference using the [timm](https://github.com/rwightman/pytorch-image-models) library, finetuning the PyTorch [timm models](https://github.com/huggingface/pytorch-image-models#models), and deploying the models on [Vertex AI](https://cloud.google.com/vertex-ai).\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Setup environment.\n",
        "- Run inference locally using the timm library.\n",
        "- Create a custom training job on Vertex AI to train or finetune a model.\n",
        "- Deploy the model on Vertex AI for online prediction.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iU1NKfh2AMJ"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l3GN-QL2AMJ"
      },
      "source": [
        "### Setup cloud project\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project). Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n",
        "\n",
        "1. [Enable Artifact Registry](https://cloud.google.com/artifact-registry/docs/enable-service) and [create a repository](https://cloud.google.com/artifact-registry/docs/repositories/create-repos) for storing docker images.\n",
        "\n",
        "1. [Create a Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs.\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. [Create a service account](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console) with `Vertex AI User` and `Storage Object Admin` roles for deploying fine tuned model to Vertex AI endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyAQXmgf2AMK"
      },
      "source": [
        "### Setup required libraries\n",
        "\n",
        "It's highly recommended to run this notebook on [Vertex AI workbench](https://cloud.google.com/vertex-ai-workbench), where you don't need to manually install any additional libraries.\n",
        "\n",
        "If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk) and [gsutil](https://cloud.google.com/storage/docs/gsutil_install)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1f36f4b5c3"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb041d87f50a"
      },
      "outputs": [],
      "source": [
        "! pip3 install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uF7Kb112AMK"
      },
      "source": [
        "### Colab Only\n",
        "Run the following commands for colab and skip this section if you use workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lP6dnfy2AMK"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform\n",
        "\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo65Wg9Y2AMK"
      },
      "source": [
        "### Setup environment variables\n",
        "\n",
        "This notebook supports models in https://huggingface.co/docs/timm/models.\n",
        "\n",
        "You can also run\n",
        "`python -c \"from timm import list_models; print(list_models(pretrained=True))\"`\n",
        "locally to see all pretrained models.\n",
        "\n",
        "The following models have been manually verified to work with this notebook:\n",
        "\n",
        "* vit_tiny_patch16_224\n",
        "* beit_base_patch16_224\n",
        "* deit3_small_patch16_224\n",
        "* efficientnet_b2\n",
        "* mobilenetv2_100\n",
        "* resnet50\n",
        "* resnest50d\n",
        "* convnext_base\n",
        "* cspdarknet53\n",
        "* inception_v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3msH2i5V2AMK"
      },
      "outputs": [],
      "source": [
        "# The cloud project id.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "# The region for running jobs.\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# The model you want to train and serve. Please select a model from the verified model list above.\n",
        "# We use a ViT model as the example.\n",
        "MODEL_NAME = \"vit_tiny_patch16_224\"  # @param {type:\"string\"}\n",
        "\n",
        "# The Cloud Storage bucket name without gs:// prefix for training outputs.\n",
        "# For example: test_bucket\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The service account for deploying fine tuned model. It looks like:\n",
        "# '<account_name>@<project>.iam.gserviceaccount.com'\n",
        "# Follow step 6 above to create this account.\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14a500024b7b"
      },
      "source": [
        "## Run local inference\n",
        "\n",
        "This section runs local inference on an image using the model chosen in above section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54859170c1ad"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7505a2bf3897"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17e6d8a0dac3"
      },
      "source": [
        "### Load a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b6bbe928998"
      },
      "outputs": [],
      "source": [
        "model = timm.create_model(MODEL_NAME, pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f2ce8fa5439"
      },
      "source": [
        "### Load and preprocess the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6390302c9761"
      },
      "outputs": [],
      "source": [
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "\n",
        "# The example downloads a test image. You can upload and use your own images\n",
        "# by changing IMAGE_FILENAME.\n",
        "! wget https://github.com/pytorch/hub/raw/master/images/dog.jpg -O test.jpg\n",
        "IMAGE_FILENAME = \"test.jpg\"  # @param {type:\"string\"}\n",
        "\n",
        "# You can also copy over images stored in a GCS bucket with the line below.\n",
        "# ! gsutil cp \"gs://path/to/image\" \"test.jpg\"\n",
        "\n",
        "img = Image.open(IMAGE_FILENAME).convert(\"RGB\")\n",
        "tensor = transform(img).unsqueeze(0)  # transform and add batch dimension\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a6e2ea460ad"
      },
      "source": [
        "### Get the model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a7a666a0aef"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    out = model(tensor)\n",
        "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "print(probabilities.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691139fc5789"
      },
      "source": [
        "### Get the top-5 predictions class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "147249af5dec"
      },
      "outputs": [],
      "source": [
        "# Get imagenet class mappings\n",
        "url, filename = (\n",
        "    \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\",\n",
        "    \"imagenet_classes.txt\",\n",
        ")\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "with open(\"imagenet_classes.txt\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8740b668da6"
      },
      "source": [
        "### Print top categories per image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f18bcd806f2"
      },
      "outputs": [],
      "source": [
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "# prints class names and probabilities like:\n",
        "# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4120d1585355"
      },
      "source": [
        "## Run training jobs\n",
        "\n",
        "This section runs a regular training job or a hyperparameter tuning job on Vertex AI.\n",
        "\n",
        "Before creating a training job, you need to prepare the dataset for training and evaluation.\n",
        "\n",
        "For example, you can use [ImageNet-1K](https://huggingface.co/datasets/imagenet-1k) held on a Cloud Storage bucket as the input dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy4gKksX2AMK"
      },
      "outputs": [],
      "source": [
        "# The prebuilt training docker uri.\n",
        "TRAIN_DOCKER_URI = (\n",
        "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-timm-train\"\n",
        ")\n",
        "\n",
        "# The path to data directory on Cloud Storage without gs:// prefix.\n",
        "# In the form of: <bucket-name>/path-to-data\n",
        "GCS_DATA_DIR = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DnlJhO72AMK"
      },
      "source": [
        "### Create a training job on Vertex AI\n",
        "\n",
        "This section creates a training job on Vertex AI. If you want to create a hyperparameter tuning job instead, you can skip to the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R5JWJGS2AML"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Init common setup.\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
        "\n",
        "# Input and output path.\n",
        "data_dir = f\"/gcs/{GCS_DATA_DIR}\"\n",
        "output_dir = f\"/gcs/{GCS_BUCKET}/timm\"\n",
        "\n",
        "# Worker pool spec.\n",
        "# Single node with multiple GPUs.\n",
        "machine_type = \"n1-highmem-32\"\n",
        "num_nodes = 1\n",
        "gpu_type = \"NVIDIA_TESLA_P100\"  # @param {type:\"string\"}\n",
        "num_gpus = 4  # @param {type:\"integer\"}\n",
        "\n",
        "# Model specific config.\n",
        "job_name = f\"pytorch-{MODEL_NAME}\"\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "job = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=job_name,\n",
        "    container_uri=TRAIN_DOCKER_URI,\n",
        ")\n",
        "model = job.run(\n",
        "    args=[\n",
        "        \"--standalone\",\n",
        "        f\"--nnodes={num_nodes}\",\n",
        "        f\"--nproc_per_node={num_gpus}\",\n",
        "        \"train.py\",\n",
        "        data_dir,\n",
        "        f\"--model={MODEL_NAME}\",\n",
        "        \"--pretrained\",\n",
        "        f\"--output={output_dir}\",\n",
        "        f\"--batch-size={batch_size}\",\n",
        "        f\"--epochs={epochs}\",\n",
        "    ],\n",
        "    replica_count=num_nodes,\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=gpu_type,\n",
        "    accelerator_count=num_gpus,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf6P7ZI82AML"
      },
      "source": [
        "### Create a hyperparameter tuning job on Vertex AI\n",
        "\n",
        "You can use a [hyperparameter tuning](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) job to find the best configuration of your hyperparameters.\n",
        "\n",
        "You can skip this section if you already trained a model in the previous section and do not want to tune the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy_aCff_2AML"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "# Init common setup.\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
        "\n",
        "# Input and output path.\n",
        "data_dir = f\"/gcs/{GCS_DATA_DIR}\"\n",
        "output_dir = f\"/gcs/{GCS_BUCKET}/timm\"\n",
        "\n",
        "# Model specific config.\n",
        "job_name = f\"pytorch-hp-{MODEL_NAME}\"\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Worker pool spec.\n",
        "machine_type = \"n1-highmem-16\"\n",
        "num_nodes = 1\n",
        "gpu_type = \"NVIDIA_TESLA_V100\"  # @param {type:\"string\"}\n",
        "num_gpus = 2  # @param {type:\"integer\"}\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": machine_type,\n",
        "            \"accelerator_type\": gpu_type,\n",
        "            \"accelerator_count\": num_gpus,\n",
        "        },\n",
        "        \"replica_count\": num_nodes,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": TRAIN_DOCKER_URI,\n",
        "            \"args\": [\n",
        "                \"--standalone\",\n",
        "                f\"--nnodes={num_nodes}\",\n",
        "                f\"--nproc_per_node={num_gpus}\",\n",
        "                \"train.py\",\n",
        "                data_dir,\n",
        "                f\"--model={MODEL_NAME}\",\n",
        "                \"--pretrained\",\n",
        "                f\"--output={output_dir}\",\n",
        "                f\"--batch-size={batch_size}\",\n",
        "                f\"--epochs={epochs}\",\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "# Hyperparameter job specs.\n",
        "metric_spec = {\"top1_accuracy\": \"maximize\"}\n",
        "parameter_spec = {\n",
        "    \"lr\": hpt.DoubleParameterSpec(min=0.001, max=0.05, scale=\"log\"),\n",
        "}\n",
        "max_trial_count = 2\n",
        "parallel_trial_count = 2\n",
        "\n",
        "# Launch jobs.\n",
        "training_job = aiplatform.CustomJob(\n",
        "    display_name=job_name, worker_pool_specs=worker_pool_specs\n",
        ")\n",
        "hp_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name=job_name,\n",
        "    custom_job=training_job,\n",
        "    metric_spec=metric_spec,\n",
        "    parameter_spec=parameter_spec,\n",
        "    max_trial_count=max_trial_count,\n",
        "    parallel_trial_count=parallel_trial_count,\n",
        ")\n",
        "hp_job.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAyRWwqW2AML"
      },
      "source": [
        "## Deploy model for online prediction\n",
        "\n",
        "This section uploads the model to Model Registry and deploys it on an Endpoint resource.\n",
        "\n",
        "The model deployment step will take ~15 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbNbg0yR2AML"
      },
      "outputs": [],
      "source": [
        "# The prebuilt serving docker uri.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-timm-serve\"\n",
        "# The port number used by torchserve traffic.\n",
        "SERVE_PORT = 7080\n",
        "# The path to model checkpoint file, including gs:// prefix.\n",
        "MODEL_PT_PATH = \"gs://path_to_model_best.pth.tar\"  # @param {type:\"string\"}\n",
        "# [Optional] the path to index_to_name.json, including gs:// prefix.\n",
        "INDEX_TO_NAME_FILE = \"gs://path_to_index_to_name.json\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INPri3HQ2AML"
      },
      "source": [
        "### Upload and deploy model on Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOvqoAaN2AML"
      },
      "outputs": [],
      "source": [
        "# Upload model.\n",
        "serving_env = {\n",
        "    \"MODEL_ID\": \"timm-mobilenetv2-100\",\n",
        "    \"MODEL_NAME\": MODEL_NAME,\n",
        "    \"MODEL_PT_PATH\": MODEL_PT_PATH,\n",
        "    \"INDEX_TO_NAME_FILE\": INDEX_TO_NAME_FILE,\n",
        "}\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=MODEL_NAME,\n",
        "    serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "    serving_container_ports=[SERVE_PORT],\n",
        "    serving_container_predict_route=\"/predictions/timm_serving\",\n",
        "    serving_container_health_route=\"/ping\",\n",
        "    serving_container_environment_variables=serving_env,\n",
        ")\n",
        "# Or reuse a pre-uploaded model.\n",
        "# model = aiplatform.Model('projects/123456789/locations/us-central1/models/123456789@1')\n",
        "\n",
        "# Create an endpoint.\n",
        "endpoint = aiplatform.Endpoint.create(display_name=\"pytorch-timm-endpoint\")\n",
        "# Or reuse a pre-created endpoint.\n",
        "# endpoint = aiplatform.Endpoint('projects/123456789/locations/us-central1/endpoints/123456789')\n",
        "\n",
        "# Deploy model to endpoint.\n",
        "model.deploy(\n",
        "    endpoint=endpoint,\n",
        "    machine_type=\"n1-standard-8\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_T4\",\n",
        "    accelerator_count=1,\n",
        "    traffic_percentage=100,\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2gnYFEJ2AML"
      },
      "source": [
        "You can mange your uploaded models in the [Model Registry](https://pantheon.corp.google.com/vertex-ai/models) and your endpoints in the [Endpoints](https://pantheon.corp.google.com/vertex-ai/endpoints)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UP84Q5R2AMM"
      },
      "source": [
        "### Test online prediction\n",
        "\n",
        "You will now test the deployed endpoint. Please prepare an image to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL2Qbm2x2AMM"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "# You can get the deployed endpoint object by its resource name returned by Endpoint.create(). For example:\n",
        "# endpoint = aiplatform.Endpoint('projects/816369962409/locations/us-central1/endpoints/8809168414485512192')\n",
        "\n",
        "# Please upload an image and enter its filename below.\n",
        "IMAGE_FILENAME = \"test.jpg\"  # @param {type:\"string\"}\n",
        "\n",
        "# Alternatively, uncomment the following line to download a cat image for demonstration.\n",
        "# ! wget http://images.cocodataset.org/val2017/000000039769.jpg -O test.jpg\n",
        "\n",
        "with open(IMAGE_FILENAME, \"rb\") as f:\n",
        "    image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "instances = [{\"data\": {\"b64\": image_b64}}]\n",
        "\n",
        "prediction = endpoint.predict(instances=instances)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqSxSyT42AMM"
      },
      "source": [
        "### Clean Up Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMwdxiH-2AMM"
      },
      "outputs": [],
      "source": [
        "endpoint.undeploy_all()\n",
        "model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_pytorch_timm.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
