{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex AI Model Garden - Get started with Llama 3.2 models\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_2.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_openai_api_llama3_2.ipynb\"\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_2.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_2.ipynb\">\n",
        "      <img src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to get started with using the OpenAI library and demonstrates how to leverage multimodal capabilities of Llama 3.2 models as Model-as-service (MaaS).\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Configure OpenAI SDK for the Llama 3.2 Completions API\n",
        "- Chat with Llama 3.2 models with different prompts and model parameters\n",
        "- Build and use Llama 3.2 GenAI powered application for Car Damage Assessment.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform openai gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"<your-project-id>\"  # @param {type:\"string\"}\n",
        "\n",
        "# Only `us-central1` is supported region for Llama 3.2 models using Model-as-a-Service (MaaS).\n",
        "LOCATION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store tutorial artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"<your-bucket-name>\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gcloud storage buckets create --location {LOCATION} --project {PROJECT_ID} {BUCKET_URI}"      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wn8ZkcV86KR"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B8DawN9D9NLU"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVYoyDl165EE"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import libraries to use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c1tEW-U968h8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import uuid\n",
        "from io import BytesIO\n",
        "\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "# Chat completions API\n",
        "import openai\n",
        "from google.auth import default, transport\n",
        "from google.cloud import storage\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ti5YGgSSG-7"
      },
      "source": [
        "### Helpers functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "do6pdqyLSJif"
      },
      "outputs": [],
      "source": [
        "def visualize_image_from_bucket(bucket_name: str, blob_name: str) -> None:\n",
        "    \"\"\"Visualizes an image stored in a Google Cloud Storage bucket.\"\"\"\n",
        "    try:\n",
        "        # Create a client for interacting with Google Cloud Storage\n",
        "        storage_client = storage.Client()\n",
        "\n",
        "        # Get a reference to the bucket and blob\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(blob_name)\n",
        "\n",
        "        # Download the image data into memory\n",
        "        image_data = blob.download_as_bytes()\n",
        "\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(BytesIO(image_data))\n",
        "\n",
        "        # Display the image using matplotlib\n",
        "        plt.figure(figsize=(10, 10))  # Set the figure size (adjust as needed)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")  # Turn off axis labels\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error visualizing image: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqYCG2Fw7D3L"
      },
      "source": [
        "### Configure OpenAI SDK for the Llama 3.2 Chat Completions API\n",
        "\n",
        "To configure the OpenAI SDK for the Llama 3.2 Chat Completions API, you need to request the access token and initialize the client pointing to the Llama 3.2 endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0K6VSJRHhH2"
      },
      "source": [
        "#### Authentication\n",
        "\n",
        "You can request an access token from the default credentials for the current environment. Note that the access token lives for [1 hour by default](https://cloud.google.com/docs/authentication/token-types#at-lifetime); after expiration, it must be refreshed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i0qceuiQEPHv"
      },
      "outputs": [],
      "source": [
        "credentials, _ = default()\n",
        "auth_request = transport.requests.Request()\n",
        "credentials.refresh(auth_request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q04wJmA0HT6X"
      },
      "source": [
        "Then configure the OpenAI SDK to point to the Llama 3.2 Chat Completions API endpoint.\n",
        "\n",
        "Notice, only `us-central1` is supported region for Llama 3.2 models using Model-as-a-Service (MaaS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c-MRhsnlj6iw"
      },
      "outputs": [],
      "source": [
        "MODEL_LOCATION = \"us-central1\"\n",
        "MAAS_ENDPOINT = f\"{MODEL_LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "    api_key=credentials.token,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGokrtdiIHrX"
      },
      "source": [
        "#### Llama 3.2 models\n",
        "\n",
        "You can experiment with various supported Llama 3.2 models.\n",
        "\n",
        "This tutorial use Llama 3.2 90B Vision Instruct using Model-as-a-Service (MaaS). Using Model-as-a-Service (MaaS), you can access Llama 3.2 models in just a few clicks without any setup or infrastructure hassles.\n",
        "\n",
        "You can also access Llama models for self-service in Vertex AI Model Garden, allowing you to choose your preferred infrastructure. [Check out Llama 3.2 model card](https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama3-2?_ga=2.31261500.2048242469.1721714335-1107467625.1721655511) to learn how to deploy a Llama 3.2 models on Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r7OhyH46H2H5"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"meta/llama-3.2-90b-vision-instruct-maas\"  # @param {type:\"string\"} [\"meta/llama-3.2-90b-vision-instruct-maas\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD62NTpqHXd"
      },
      "source": [
        "### Chat with Llama 3.2\n",
        "\n",
        "Use the Chat Completions API to send a multi-model request to the Llama 3.2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkyp9kZSuJGx"
      },
      "source": [
        "#### Hello, Llama 3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CKVOZ1HEqRbY"
      },
      "outputs": [],
      "source": [
        "max_tokens = 4096\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_ID,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"gs://github-repo/img/gemini/intro/landmark1.jpg\"\n",
        "                    },\n",
        "                    \"type\": \"image_url\",\n",
        "                },\n",
        "                {\"text\": \"What’s in this image?\", \"type\": \"text\"},\n",
        "            ],\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": \"In this image, you have:\"},\n",
        "    ],\n",
        "    max_tokens=max_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3yz-Xuc9Nyf"
      },
      "source": [
        "You get the response as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LxpdxYCxH51u"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShR15nvo9Te4"
      },
      "source": [
        "You use the helper function to visualize the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ECUxyzWmSbuX"
      },
      "outputs": [],
      "source": [
        "visualize_image_from_bucket(\"github-repo\", \"img/gemini/intro/landmark1.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1rKbHUQt605"
      },
      "source": [
        "#### Ask Llama 3.2 using different model configuration\n",
        "\n",
        "Use the following parameters to generate different answers:\n",
        "\n",
        "*   `temperature` to control the randomness of the response\n",
        "*   `top_p` to control the quality of the response\n",
        "*   `stream` to stream the response back or not\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "owv-5Sz5rIEU"
      },
      "outputs": [],
      "source": [
        "temperature = 1.0  # @param {type:\"number\"}\n",
        "top_p = 1.0  # @param {type:\"number\"}\n",
        "stream = True  # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-qBuhcK-G1V"
      },
      "source": [
        "Get the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O1YU8bSivH0B"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL_ID,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"gs://github-repo/img/gemini/intro/landmark2.jpg\"\n",
        "                    },\n",
        "                    \"type\": \"image_url\",\n",
        "                },\n",
        "                {\"text\": \"What’s in this image?\", \"type\": \"text\"},\n",
        "            ],\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": \"In this image, you have:\"},\n",
        "    ],\n",
        "    temperature=temperature,\n",
        "    max_tokens=max_tokens,\n",
        "    top_p=top_p,\n",
        "    stream=stream,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o9-gF0U-Kba"
      },
      "source": [
        "Depending if `stream` parameter is enabled or not, you can print the response entirely or chunk by chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CoDHLGhyyt8d"
      },
      "outputs": [],
      "source": [
        "if stream:\n",
        "    for chunk in response:\n",
        "        print(chunk.choices[0].delta.content, end=\"\")\n",
        "else:\n",
        "    print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKBAMJuG9l_j"
      },
      "source": [
        "And again, let's check if the answer is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OqMthjHy9vXW"
      },
      "outputs": [],
      "source": [
        "visualize_image_from_bucket(\"github-repo\", \"img/gemini/intro/landmark2.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkoaelaKxm1r"
      },
      "source": [
        "#### Use Llama 3.2 with different multimodal tasks\n",
        "\n",
        "In this section, you will use Llama 3.2 to perform different multimodal tasks including image captioning and Visual Question Answering (VQA).\n",
        "\n",
        "For each task, you'll define a different prompt and submit a request to the model as you did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MuMkl7De_DR9"
      },
      "outputs": [],
      "source": [
        "visualize_image_from_bucket(\"github-repo\", \"img/gemini/intro/landmark3.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-en7AYQDyONt"
      },
      "source": [
        "##### Image captioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QANInNvizWbi"
      },
      "outputs": [],
      "source": [
        "prompt = \"Imagine you're telling a friend about this photo. What would you say?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2x8ML1Y_yfom"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL_ID,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"gs://github-repo/img/gemini/intro/landmark3.jpg\"\n",
        "                    },\n",
        "                    \"type\": \"image_url\",\n",
        "                },\n",
        "                {\"text\": prompt, \"type\": \"text\"},\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        "    max_tokens=max_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qQ6UUgpHztXZ"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBLESIw4zhto"
      },
      "source": [
        "##### Visual Question Answering (VQA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UrAybklfzhtz"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Analyze this image and answer the following questions:\n",
        "- What is the primary color in the image?\n",
        "- What is the overall mood or atmosphere conveyed in the scene?\n",
        "- Based on the visual clues, who might have taken the picture?\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VJYIZbGyzhtz"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL_ID,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"gs://github-repo/img/gemini/intro/landmark3.jpg\"\n",
        "                    },\n",
        "                    \"type\": \"image_url\",\n",
        "                },\n",
        "                {\"text\": prompt, \"type\": \"text\"},\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        "    max_tokens=max_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9vfWA2i9zwOZ"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnrXpv5Y3yFK"
      },
      "source": [
        "### Build with Llama 3.2 : Car Damage Assessment app using Gradio\n",
        "\n",
        "In this section, you use Llama 3.2 to build a simple GenAI powered application for Car Damage Assessment.\n",
        "\n",
        "In this scenario, the app has to cover the following tasks:\n",
        "\n",
        "*   Classify the type of damage\n",
        "*   Estimate the damage severity\n",
        "*   Estimate the damage cost\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD-Fo_2WRSBt"
      },
      "source": [
        "#### Define the UI functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tCbyAGF6ZpSN"
      },
      "outputs": [],
      "source": [
        "def upload_image_to_bucket(image_path: str) -> str:\n",
        "    \"\"\"Uploads an image to a Google Cloud Storage bucket.\"\"\"\n",
        "    try:\n",
        "        # Create a client for interacting with Google Cloud Storage\n",
        "        storage_client = storage.Client()\n",
        "\n",
        "        # Get a reference to the bucket\n",
        "        bucket = storage_client.bucket(BUCKET_NAME)\n",
        "\n",
        "        # Generate a unique blob name based on the file extension\n",
        "        file_extension = image_path.split(\".\")[-1].lower()\n",
        "        if file_extension in [\"jpg\", \"jpeg\"]:\n",
        "            blob_name = f\"car_damage_{uuid.uuid4()}.jpg\"\n",
        "        else:\n",
        "            blob_name = f\"car_damage_{uuid.uuid4()}.png\"\n",
        "\n",
        "        # Get a reference to the blob and upload the image\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_filename(image_path)\n",
        "\n",
        "        # Construct the URI of the uploaded image\n",
        "        image_uri = f\"gs://{BUCKET_NAME}/{blob_name}\"\n",
        "        return image_uri\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading image: {e}\")\n",
        "\n",
        "\n",
        "def parse_json_from_markdown(markdown_text: str) -> dict | None:\n",
        "    \"\"\"Extracts and parses JSON content embedded within Markdown text.\"\"\"\n",
        "    json_pattern = r\"```json\\n(.*?)\\n```\"\n",
        "    match = re.search(json_pattern, markdown_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        json_content = match.group(1)\n",
        "        try:\n",
        "            parsed_data = json.loads(json_content)\n",
        "            return parsed_data\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error: Invalid JSON content found. {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_image(image_uri):\n",
        "    \"\"\"Processes a car damage image using a multimodal LLM.\"\"\"\n",
        "\n",
        "    # Construct the prompt\n",
        "    prompt = \"\"\"\n",
        "    Analyze the provided image of a car and provide the following information:\n",
        "\n",
        "    1. Damage Type: Identify the primary type of damage visible in the image (e.g., dent, scratch, cracked windshield, etc.).\n",
        "    2. Severity: Estimate the severity of the damage on a scale of 1 to 5, where 1 is minor and 5 is severe.\n",
        "    3. Estimated Repair Cost: Provide an approximate range for the repair cost in USD.\n",
        "\n",
        "    Return the results in JSON format with damagetype, severity, and cost fields.\n",
        "    \"\"\"\n",
        "\n",
        "    # Call Llama model\n",
        "    credentials, _ = default()\n",
        "    auth_request = transport.requests.Request()\n",
        "    credentials.refresh(auth_request)\n",
        "\n",
        "    client = openai.OpenAI(\n",
        "        base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "        api_key=credentials.token,\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_ID,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"image_url\": {\"url\": image_uri}, \"type\": \"image_url\"},\n",
        "                    {\"text\": prompt, \"type\": \"text\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "    # Parse the response\n",
        "    response = response.choices[0].message.content\n",
        "    output = parse_json_from_markdown(response)\n",
        "\n",
        "    output = {\"damagetype\": \"scratch\", \"severity\": 5, \"cost\": 1000}\n",
        "    return output[\"damagetype\"], output[\"severity\"], output[\"cost\"]\n",
        "\n",
        "\n",
        "def demo_fn(image_path):\n",
        "    \"\"\"\n",
        "    Processes a car damage image using a multimodal LLM.\n",
        "    \"\"\"\n",
        "\n",
        "    # Upload the image\n",
        "    image_uri = upload_image_to_bucket(image_path)\n",
        "\n",
        "    # Process the image\n",
        "    damagetype, severity, cost = process_image(image_uri)\n",
        "\n",
        "    return damagetype, severity, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKa_C0QaZqVN"
      },
      "source": [
        "#### Run the application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8CSczAFiBamY"
      },
      "outputs": [],
      "source": [
        "demo = gr.Interface(\n",
        "    fn=demo_fn,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Damage Type\"),\n",
        "        gr.Slider(label=\"Severity\", minimum=1, maximum=10, step=1),\n",
        "        gr.Number(label=\"Cost\"),\n",
        "    ],\n",
        "    title=\"Car Damage Assessment\",\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UmFjQHeYd08T"
      },
      "outputs": [],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "Clean up resources created in this notebook.\n",
        "\n",
        "To delete to the search engine in Vertex AI, check out the following [documentation](https://cloud.google.com/generative-ai-app-builder/docs/delete-engine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OC7Ypb05ccUE"
      },
      "outputs": [],
      "source": [
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gcloud storage rm --recursive $BUCKET_NAME"      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_openai_api_llama3_2.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
