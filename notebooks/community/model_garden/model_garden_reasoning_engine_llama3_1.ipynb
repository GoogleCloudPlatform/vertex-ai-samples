{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex AI Model Garden + Reasoning Engine - Build, Deploy and Test Agents Using Llama 3.1 Models\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_reasoning_engine_llama3_1.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_reasoning_engine_llama3_1.ipynb\"\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_reasoning_engine_llama3_1.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_reasoning_engine_llama3_1.ipynb\">\n",
        "      <img src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[Reasoning Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview) (LangChain on Vertex AI) is a managed service in Vertex AI that helps you build and deploy agent-based reasoning framework. It gives you the flexibility to choose how much reasoning you want to delegate to the LLM and how much you want to handle with custom code.\n",
        "\n",
        "A previous [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_1.ipynb) demonstrates how to use Llama 3.1 models as Model-as-a-service (MaaS) to build `chatbot` and `translator` agents.\n",
        "\n",
        "This notebook demonstrated how to build, deploy and test these agents using [Reasoning Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview) in Vertex AI.\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Use the Vertex AI SDK to build three simple agents with the Llama 3.1 Completions API:\n",
        "  - A Chatbot Agent\n",
        "  - A Translator Agent\n",
        "  - An Agent uses Exchange Rate Tool\n",
        "- Test your agent locally.\n",
        "- Deploy and test your agent on the Reasoning Engine.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2uneqicMFF7"
      },
      "source": [
        "Install the latest version of the Vertex AI SDK for Python as well as extra dependencies related to Reasoning Engine and LangChain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet \\\n",
        "    \"google-cloud-aiplatform[langchain,reasoningengine]\" \\\n",
        "    cloudpickle==3.0.0 \\\n",
        "    pydantic==2.7.4 \\\n",
        "    requests \\\n",
        "    langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\", placeholder: \"[your-project-id]\"}\n",
        "LOCATION = \"\"  # @param {type:\"string\", placeholder: \"us-central1\"}\n",
        "BUCKET_NAME = \"\"  # @param {type:\"string\", placeholder: \"[your-bucket-name]\"}\n",
        "STAGING_BUCKET = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wn8ZkcV86KR"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "B8DawN9D9NLU"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVYoyDl165EE"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import libraries to use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "c1tEW-U968h8"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview import reasoning_engines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqYCG2Fw7D3L"
      },
      "source": [
        "### Configure the Llama 3.1 Chat Completions API for the `Reasoning Engine`.\n",
        "\n",
        "To use the Llama 3.1 Chat Completions API with `Reasoning Engine` capabilities, you need to request the access token and configure the langchain `ChatOpenAI` to point to the Llama 3.1 Chat Completions API endpoint.\n",
        "\n",
        "Notice, Llama 3.1 model deployed as a Model-as-a-Service (MaaS) is currently only supported in the `us-central1` region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "BRyjFBVHjDo6"
      },
      "outputs": [],
      "source": [
        "def model_builder(\n",
        "    *,\n",
        "    model_name: str,\n",
        "    model_kwargs=None,\n",
        "    project: str,  # Specified via vertexai.init\n",
        "    location: str,  # Specified via vertexai.init\n",
        "    **kwargs,\n",
        "):\n",
        "    import google.auth\n",
        "    from langchain_openai import ChatOpenAI\n",
        "\n",
        "    # Note: the credential lives for 1 hour by default.\n",
        "    # After expiration, it must be refreshed.\n",
        "    creds, _ = google.auth.default(\n",
        "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        "    )\n",
        "    auth_req = google.auth.transport.requests.Request()\n",
        "    creds.refresh(auth_req)\n",
        "\n",
        "    if model_kwargs is None:\n",
        "        model_kwargs = {}\n",
        "\n",
        "    endpoint = f\"https://{location}-aiplatform.googleapis.com\"\n",
        "    base_url = (\n",
        "        f\"{endpoint}/v1/projects/{project}/locations/{location}/endpoints/openapi\"\n",
        "    )\n",
        "\n",
        "    return ChatOpenAI(\n",
        "        model=model_name,\n",
        "        base_url=base_url,\n",
        "        api_key=creds.token,\n",
        "        **model_kwargs,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGokrtdiIHrX"
      },
      "source": [
        "#### Llama 3.1 models\n",
        "\n",
        "You can experiment with various supported Llama 3.1 models.\n",
        "\n",
        "This tutorial uses Llama 3 8B Instruct, 70B Instruct, and 405B Instruct using Model-as-a-Service (MaaS). Using Model-as-a-Service (MaaS), you can access Llama 3.1 models in just a few clicks without any setup or infrastructure hassles.\n",
        "\n",
        "You can also access Llama models for self-service in Vertex AI Model Garden, allowing you to choose your preferred infrastructure. [Check out Llama 3.1 model card](https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama3_1?_ga=2.31261500.2048242469.1721714335-1107467625.1721655511) to learn how to deploy a Llama 3.1 models on Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "r7OhyH46H2H5"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"meta/llama-3.1-405b-instruct-maas\"  # @param {type:\"string\"} [\"meta/llama-3.1-8b-instruct-maas\", \"meta/llama-3.1-8b-instruct-maas\", \"meta/llama-3.1-405b-instruct-maas\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD62NTpqHXd"
      },
      "source": [
        "### Chat with `Reasoning Agent`\n",
        "\n",
        "In previous [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_1.ipynb), we demonstrated how to `Ask Llama 3.1 using different model configuration`.\n",
        "\n",
        "In this colab, we will show you how to use the `Reasoning Agent` to send a request to the Llama 3.1 model with different model configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1rKbHUQt605"
      },
      "source": [
        "#### `Reasoning Engine` use Llama 3.1 with different configuration\n",
        "\n",
        "Use the following parameters to generate different answers:\n",
        "\n",
        "*   `temperature` to control the randomness of the response\n",
        "*   `max_tokens` to limit the response length\n",
        "*   `top_p` to control the quality of the response\n",
        "*   `apply_llama_guard` Model-as-a-Service (MaaS) integrates [Llama Guard](https://huggingface.co/meta-llama/Llama-Guard-3-8B) as a safety filter. It is switched on by default and can be switched off. Llama Guard enables us to safeguard model inputs and outputs. If a response is filtered, it will be populated with a `finish_reason` field (with value `content_filtered`) and a `refusal` field (stating the filtering reason).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "cellView": "form",
        "id": "owv-5Sz5rIEU"
      },
      "outputs": [],
      "source": [
        "temperature = 1.0  # @param {type:\"number\"}\n",
        "max_tokens = 50  # @param {type:\"integer\"}\n",
        "top_p = 1.0  # @param {type:\"number\"}\n",
        "apply_llama_guard = True  # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "cellView": "form",
        "id": "O1YU8bSivH0B"
      },
      "outputs": [],
      "source": [
        "agent = reasoning_engines.LangchainAgent(\n",
        "    model=MODEL_ID,  # Required.\n",
        "    model_builder=model_builder,  # Required.\n",
        "    model_kwargs={\n",
        "        \"temperature\": temperature,  # Optional.\n",
        "        \"max_tokens\": max_tokens,  # Optional.\n",
        "        \"top_p\": top_p,  # Optional.\n",
        "        \"extra_body\": {  # Optional.\n",
        "            \"google\": {\n",
        "                \"model_safety_settings\": {\n",
        "                    \"enabled\": apply_llama_guard,\n",
        "                    \"llama_guard_settings\": {},\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSGn6RIXmksF"
      },
      "source": [
        "Now we can test the model and agent behavior to ensure that it's working as expected before we deploy it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellView": "form",
        "id": "Ej8jwImlloho"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'Hello, Llama 3.1!', 'output': \"Hello! I'm Llama 3.1, an AI developed by Meta.\"}\n"
          ]
        }
      ],
      "source": [
        "response = agent.query(input=\"Hello, Llama 3.1!\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxw18avamrDb"
      },
      "source": [
        "#### Deploy your agent on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFdd07tWmus5"
      },
      "source": [
        "Now that you've specified a model, and reasoning for your agent and tested it out, you're ready to deploy your agent as a remote service in Vertex AI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cVQqCUknmXsQ"
      },
      "outputs": [],
      "source": [
        "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
        "    agent,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.7.4\",\n",
        "        \"requests\",\n",
        "        \"langchain-openai\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "cellView": "form",
        "id": "GttQ5Jp4nIpE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'output': \"Hello! I'm Llama 3.1, an artificial intelligence model developed by Meta, designed to process and generate human-like language. I can provide information, answer questions, and even create text based on a given prompt. How can I assist\", 'input': 'Hello, Llama 3.1!'}\n"
          ]
        }
      ],
      "source": [
        "response = remote_agent.query(input=\"Hello, Llama 3.1!\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIneG1wCoVhj"
      },
      "source": [
        "#### Reusing your deployed agent from other applications or SDKs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pjwHuEtoalu"
      },
      "source": [
        "You can now import and use the remotely deployed Reasoning Engine in this notebook session or in a different notebook or Python script. First you need to get its resource_name by calling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fSVjuGzkoZ_r"
      },
      "outputs": [],
      "source": [
        "REASONING_ENGINE_RESOURCE_NAME = remote_agent.resource_name\n",
        "print(REASONING_ENGINE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKGxnFF7oxKD"
      },
      "source": [
        "Afterwards you can use it by uncommenting and adapting the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0UXuYF2No0ay"
      },
      "outputs": [],
      "source": [
        "# from vertexai.preview import reasoning_engines\n",
        "\n",
        "# remote_agent = reasoning_engines.ReasoningEngine(REASONING_ENGINE_RESOURCE_NAME)\n",
        "# response = remote_agent.query(input=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnViHuPeo7kW"
      },
      "source": [
        "Or, you can query your agent from other programming languages using any of the [available client libraries in Vertex AI](https://cloud.google.com/vertex-ai/docs/start/client-libraries), including C#, Java, Node.js, Python, Go, or REST API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnrXpv5Y3yFK"
      },
      "source": [
        "### Use `Reasoning Engine` to build a simple translator agent:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dg_s4tZQpQL"
      },
      "source": [
        "In previous [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_1.ipynb), we demonstrates how to use `LangChain Expression Language` (LCEL) to build a simple chain which translates some `text_to_translate` to the specified `target_language`.\n",
        "\n",
        "In this colab, we will show you how to use the `Reasoning Agent` to build and deploy the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "PdKVIbfTQSpn"
      },
      "outputs": [],
      "source": [
        "def lcel_builder(*, model, **kwargs):\n",
        "    from langchain_core.output_parsers import StrOutputParser\n",
        "    from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "    template = \"\"\"Translate the following {text} to {target_language}:\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\", \"target_language\"], template=template\n",
        "    )\n",
        "\n",
        "    return prompt | model | StrOutputParser()\n",
        "\n",
        "\n",
        "agent = reasoning_engines.LangchainAgent(\n",
        "    model=MODEL_ID,\n",
        "    model_builder=model_builder,\n",
        "    runnable_builder=lcel_builder,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE3sizbzGFER"
      },
      "source": [
        "##### Translate a text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "SRJ-xuSI9ZQl"
      },
      "outputs": [],
      "source": [
        "text_to_translate = \"\"  # @param {type:\"string\", placeholder:\"Hello Llama 3.1!\"}\n",
        "target_language = \"\"  # @param {type:\"string\", placeholder:\"Italian\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "id": "yYzc1kCjEHGP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The translation of \"Hello Llama 3.1!\" to Italian is:\n",
            "\n",
            "Ciao Llama 3.1!\n",
            "\n",
            "Here's a breakdown of the translation:\n",
            "\n",
            "- \"Hello\" is translated to \"Ciao\", which is an informal way of saying \"hello\" in Italian.\n",
            "- \"Llama\" remains the same, as it's a proper noun.\n",
            "- \"3.1\" is a version number, so it remains the same.\n"
          ]
        }
      ],
      "source": [
        "response = agent.query(\n",
        "    input={\"text\": text_to_translate, \"target_language\": target_language}\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuE8Mrfjifpd"
      },
      "source": [
        "#### Deploy your agent on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jDfGHWcilOo"
      },
      "source": [
        "Now that you've specified a model, and reasoning for your agent and tested it out, you're ready to deploy your agent as a remote service in Vertex AI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xK04QP5zimSt"
      },
      "outputs": [],
      "source": [
        "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
        "    agent,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.7.4\",\n",
        "        \"requests\",\n",
        "        \"langchain-openai\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "id": "dPkm--FAirFT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The translation of \"Hello Llama 3.1!\" to Italian is:\n",
            "\n",
            "Ciao Llama 3.1!\n"
          ]
        }
      ],
      "source": [
        "response = remote_agent.query(\n",
        "    input={\"text\": text_to_translate, \"target_language\": target_language}\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGtk839LvaAC"
      },
      "source": [
        "#### Reusing your deployed agent from other applications or SDKs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVuwWjjvve6o"
      },
      "source": [
        "You can now import and use the remotely deployed Reasoning Engine in this notebook session or in a different notebook or Python script. First you need to get its resource_name by calling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MXvCtV2mvisP"
      },
      "outputs": [],
      "source": [
        "REASONING_ENGINE_RESOURCE_NAME = remote_agent.resource_name\n",
        "print(REASONING_ENGINE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KViITFMvmuN"
      },
      "source": [
        "Afterwards you can use it by uncommenting and adapting the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellView": "form",
        "id": "W_2TUqJ5vjg-"
      },
      "outputs": [],
      "source": [
        "# from vertexai.preview import reasoning_engines\n",
        "\n",
        "# remote_agent = reasoning_engines.ReasoningEngine(REASONING_ENGINE_RESOURCE_NAME)\n",
        "# response = remote_agent.query(input=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnbIM-UBvqVI"
      },
      "source": [
        "Or, you can query your agent from other programming languages using any of the [available client libraries in Vertex AI](https://cloud.google.com/vertex-ai/docs/start/client-libraries), including C#, Java, Node.js, Python, Go, or REST API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnJkVI5etFpX"
      },
      "source": [
        "### Agent uses Exchange Rate Tool\n",
        "\n",
        "[Function calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) lets developers create a description of a function in their code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "In this example, we will use a Exchange Rate tool in the Reasoning Engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWvAw2kptJNR"
      },
      "source": [
        "#### Define Python functions (tools)\n",
        "Tools and functions enable the generative model to interact with external systems, databases, document stores, and other APIs so that the model can get the most up-to-date information or take action with those systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cEMOvvxtMn_"
      },
      "source": [
        "In this example, you'll define a function called `get_exchange_rate` that uses the requests library to retrieve real-time currency exchange information from an API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KlsV8pZ1tNY2"
      },
      "outputs": [],
      "source": [
        "def get_exchange_rate(\n",
        "    currency_from: str = \"USD\",\n",
        "    currency_to: str = \"EUR\",\n",
        "    currency_date: str = \"latest\",\n",
        "):\n",
        "    \"\"\"Retrieves the exchange rate between two currencies on a specified date.\"\"\"\n",
        "    import requests\n",
        "    response = requests.get(\n",
        "        f\"https://api.frankfurter.app/{currency_date}\",\n",
        "        params={\"from\": currency_from, \"to\": currency_to},\n",
        "    )\n",
        "    return response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TN_UYbYtP55"
      },
      "source": [
        "Test the function with sample inputs to ensure that it's working as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1baChtMytR99"
      },
      "outputs": [],
      "source": [
        "get_exchange_rate(currency_from=\"USD\", currency_to=\"SEK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxjN1kIttV1u"
      },
      "source": [
        "Here, you'll use the LangChain agent template provided in the Vertex AI SDK for Reasoning Engine, which brings together the model, tools, and reasoning that you've built up so far:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Pwowd-TPtXtk"
      },
      "outputs": [],
      "source": [
        "agent = reasoning_engines.LangchainAgent(\n",
        "    model=MODEL_ID,                                            # Required.\n",
        "    model_builder=model_builder,                               # Required.\n",
        "    tools=[get_exchange_rate],                                 # Optional.\n",
        "    agent_executor_kwargs={\n",
        "        \"return_intermediate_steps\": True,\n",
        "        \"stream_runnable\": False,\n",
        "    },                                                         # Optional.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0uVinMNt8Yq"
      },
      "source": [
        "Now we can test the model and agent behavior to ensure that it's working as expected before we deploy it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IyM-HfRLt8Yr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': \"What's the exchange rate from US dollars to Swedish currency at 2024-07-26?\", 'output': 'The exchange rate from US dollars to Swedish currency at 2024-07-26 is 10.8034 SEK per USD.', 'intermediate_steps': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'ToolAgentAction'], 'kwargs': {'tool': 'get_exchange_rate', 'tool_input': {'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}, 'log': \"\\nInvoking: `get_exchange_rate` with `{'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}`\\n\\n\\n\", 'type': 'AgentActionMessageLog', 'message_log': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'get_exchange_rate', 'function': {'arguments': '{\"currency_date\":\"2024-07-26\",\"currency_from\":\"USD\",\"currency_to\":\"SEK\"}', 'name': 'get_exchange_rate'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 26, 'prompt_tokens': 43, 'total_tokens': 69, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta/llama3-405b-instruct-maas', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run-83535906-e484-445d-ac25-e766bee9fdc3-0', 'tool_calls': [{'name': 'get_exchange_rate', 'args': {'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}, 'id': 'get_exchange_rate', 'type': 'tool_call'}], 'usage_metadata': {'input_tokens': 43, 'output_tokens': 26, 'total_tokens': 69}, 'invalid_tool_calls': []}}], 'tool_call_id': 'get_exchange_rate'}}, {'amount': 1.0, 'base': 'USD', 'date': '2024-07-26', 'rates': {'SEK': 10.8034}}]]}\n"
          ]
        }
      ],
      "source": [
        "response = agent.query(input=\"What's the exchange rate from US dollars to Swedish currency at 2024-07-26?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thE-c3TGt8Yr"
      },
      "source": [
        "#### Deploy your agent on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z2y-_Ckt8Ys"
      },
      "source": [
        "Now that you've specified a model, and reasoning for your agent and tested it out, you're ready to deploy your agent as a remote service in Vertex AI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "knwSWq-st8Ys"
      },
      "outputs": [],
      "source": [
        "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
        "    agent,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.7.4\",\n",
        "        \"requests\",\n",
        "        \"langchain-openai\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Hn2ORpU5t8Ys"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': \"What's the exchange rate from US dollars to Swedish currency at 2024-07-26?\", 'output': 'The exchange rate from US dollars to Swedish currency at 2024-07-26 is 1 USD = 10.767 SEK.', 'intermediate_steps': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'ToolAgentAction'], 'kwargs': {'tool': 'get_exchange_rate', 'tool_input': {'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}, 'log': \"\\nInvoking: `get_exchange_rate` with `{'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}`\\n\\n\\n\", 'type': 'AgentActionMessageLog', 'message_log': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'get_exchange_rate', 'function': {'arguments': '{\"currency_date\":\"2024-07-26\",\"currency_from\":\"USD\",\"currency_to\":\"SEK\"}', 'name': 'get_exchange_rate'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 26, 'prompt_tokens': 43, 'total_tokens': 69, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta/llama3-405b-instruct-maas', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run-83535906-e484-445d-ac25-e766bee9fdc3-0', 'tool_calls': [{'name': 'get_exchange_rate', 'args': {'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}, 'id': 'get_exchange_rate', 'type': 'tool_call'}], 'usage_metadata': {'input_tokens': 43, 'output_tokens': 26, 'total_tokens': 69}, 'invalid_tool_calls': []}}], 'tool_call_id': 'get_exchange_rate'}}, {'base': 'USD', 'rates': {'SEK': 10.767}, 'date': '2024-10-04', 'amount': 1.0}]], 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage']}], 'tool_call_id': 'get_exchange_rate', 'log': '\\nInvoking: `get_exchange_rate` with `{\\'currency_date\\': \\'2024-07-26\\', \\'currency_from\\': \\'USD\\', \\'currency_to\\': \\'SEK\\'}`\\n\\n\\n', 'type': 'AgentActionMessageLog', 'tool_input': {'currency_date': '2024-07-26', 'currency_from': 'USD', 'currency_to': 'SEK'}, 'tool': 'get_exchange_rate'}}, {'base': 'USD', 'rates': {'SEK': 10.767}, 'date': '2024-10-04', 'amount': 1.0}]}\n"
          ]
        }
      ],
      "source": [
        "response = remote_agent.query(input=\"What's the exchange rate from US dollars to Swedish currency at 2024-07-26?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10OD29Vot8Ys"
      },
      "source": [
        "#### Reusing your deployed agent from other applications or SDKs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXmAfrONt8Ys"
      },
      "source": [
        "You can now import and use the remotely deployed Reasoning Engine in this notebook session or in a different notebook or Python script. First you need to get its resource_name by calling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hQ2UJhFpt8Ys"
      },
      "outputs": [],
      "source": [
        "REASONING_ENGINE_RESOURCE_NAME = remote_agent.resource_name\n",
        "print(REASONING_ENGINE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xySK1_NJt8Yt"
      },
      "source": [
        "Afterwards you can use it by uncommenting and adapting the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nBP4GmESt8Yt"
      },
      "outputs": [],
      "source": [
        "# from vertexai.preview import reasoning_engines\n",
        "\n",
        "# remote_agent = reasoning_engines.ReasoningEngine(REASONING_ENGINE_RESOURCE_NAME)\n",
        "# response = remote_agent.query(input=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5jYRuhft8Yt"
      },
      "source": [
        "Or, you can query your agent from other programming languages using any of the [available client libraries in Vertex AI](https://cloud.google.com/vertex-ai/docs/start/client-libraries), including C#, Java, Node.js, Python, Go, or REST API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "If you created a new project for this tutorial, delete the project. If you used an existing project and wish to keep it without the changes added in this tutorial, delete resources created for the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSraW3_8jdqx"
      },
      "source": [
        "### Deleting tutorial resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "cellView": "form",
        "id": "OC7Ypb05ccUE"
      },
      "outputs": [],
      "source": [
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "delete_reasoning_engine = False  # @param {type:\"boolean\"}\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_NAME\n",
        "\n",
        "if delete_reasoning_engine:\n",
        "    remote_agent.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_reasoning_engine_llama3_1.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
