{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ad30fe2-1fc1-47e3-8a9f-624170b5aae6"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "411c319c-49c9-412b-aff1-ce7832412bd7"
      },
      "source": [
        "# Vertex AI Model Garden: Video Object Tracking with Bytetrack\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_video_object_tracking_serve.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_video_object_tracking_serve.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_video_object_tracking_serve.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "    (a Python-3 CPU notebook is recommended)\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "962e636b5cee"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05131ed9-08a2-4825-b35c-46986f14789b"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This Jupyter notebook provides a step-by-step walkthrough of deploying a video object tracking model on Vertex AI Endpoint resource with the open-source [ByteTrack](https://github.com/ifzhang/ByteTrack) object tracking algorithm.\n",
        "\n",
        "### Objective\n",
        "* Set up a Vertex AI Endpoint resource with:\n",
        "    * TensorFlow Vision [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb) or\n",
        "    * Google Proprietary [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb)\n",
        "<br></br>\n",
        "* Test integrated tracking model\n",
        "    * Upload models to model registry\n",
        "    * Deploy uploaded models\n",
        "    * Run batch predictions\n",
        "    * Verify and visualize tracking results\n",
        "<br></br>\n",
        "* Cleanup resources\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgTNX8aOLDx"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDPiiagrONAe"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade pip\n",
        "! pip install fastapi==0.96.0\n",
        "! pip install google-cloud-aiplatform==1.25.0\n",
        "! pip install google-cloud-storage==2.9.0\n",
        "! pip install tensorflow==2.11.0\n",
        "! pip install uvicorn==0.22.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea399cf543a4"
      },
      "source": [
        "### Colab Only\n",
        "Run the following commands for Colab and skip this section if you are using Workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72f4e86b394c"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! pip install --upgrade google-cloud-aiplatform\n",
        "\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fc1fc14-2d77-4bf7-8f6d-c1afc10c848a"
      },
      "source": [
        "If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk) and [gsutil](https://cloud.google.com/storage/docs/gsutil_install)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6c1bc20-3495-448a-b242-01930ba8153c"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project). Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n",
        "\n",
        "1. [Enable Artifact Registry](https://cloud.google.com/artifact-registry/docs/enable-service) and [create a repository](https://cloud.google.com/artifact-registry/docs/repositories/create-repos) for storing docker images.\n",
        "\n",
        "1. [Create a GCS bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs.\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. [Create a service account](https://cloud.google.com/iam/docs/service-accounts-create?&_ga=2.233472348.-356102079.1688744268#iam-service-accounts-create-console) with Vertex AI User and Storage Object Admin roles for deploying fine tuned model to Vertex AI endpoint. [See how to grant Cloud Storage permissions to your service account](https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc52f3503d91"
      },
      "source": [
        "### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3ce64be5527"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ff96cc60ab6"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "To update your model artifacts without re-building the container, you must upload your model\n",
        "artifacts and any custom code to Cloud Storage.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
        "Cloud Storage buckets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34fad6505e5c"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7c755f51afe"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80497c1171f7"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e02b9811-b730-4573-83fa-9d47f2ce0436"
      },
      "source": [
        "### Setup remaining variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c2ce2fa-5a9b-40f6-b99d-6c1325775b36"
      },
      "outputs": [],
      "source": [
        "# Cloud project setup.\n",
        "\n",
        "# The folder in the GCS bucket with input videos.\n",
        "# Fill it without the 'gs://' prefix.\n",
        "INPUT_GCS_FOLDER = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The video filename for the videos to be process.\n",
        "# Fill it without the 'gs://' prefix.\n",
        "VIDEO_FILE_NAME = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The video filename extension like .mp4. Please include period.\n",
        "# Fill it without the 'gs://' prefix.\n",
        "VIDEO_FILE_EXTENSION = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The folder in the GCS bucket where to store output videos and text\n",
        "# annotations. Fill it without the 'gs://' prefix.\n",
        "OUTPUT_GCS_FOLDER = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The Vertex IOD endpoint for object detection.\n",
        "# It is like projects/<project_number>/locations/<location>/endpoints/<endpoint_id>\"\n",
        "DETECTION_ENDPOINT = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The label map for the Vertex IOD endpoint.\n",
        "# It is the path to a .yaml in GCS.\n",
        "# It is like gs://{BUCKET_NAME}/{FOLDER_NAME}/label_map.yaml\n",
        "ENDPOINT_LABEL_MAP = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# You can choose a region from https://cloud.google.com/about/locations.\n",
        "# Only regions prefixed by \"us\", \"asia\", or \"europe\" are supported.\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "REGION_PREFIX = REGION.split(\"-\")[0]\n",
        "assert REGION_PREFIX in (\n",
        "    \"us\",\n",
        "    \"europe\",\n",
        "    \"asia\",\n",
        "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'\n",
        "\n",
        "# The pre-built docker images\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/vot-serve:latest\"\n",
        "\n",
        "# Prediction constants\n",
        "PREDICTION_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
        "PREDICTION_MACHINE_TYPE = \"n1-standard-4\"\n",
        "\n",
        "# The serving port.\n",
        "SERVE_PORT = 7080\n",
        "\n",
        "# The serving route.\n",
        "SERVE_ROUTE = \"/predictions/vot_serving\"\n",
        "\n",
        "# The service account you created in step-6 above.\n",
        "# It is like \"<account_name>@<project>.iam.gserviceaccount.com\"\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82058975-23b5-4b97-9e14-dd9a29c578ed"
      },
      "source": [
        "### Initialize Vertex AI SDK\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0eb6283926b"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Init common setup.\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b2fa2cff870"
      },
      "source": [
        "### Define utility functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a78f988d-e5e2-4a57-ba0f-569e970514c0"
      },
      "outputs": [],
      "source": [
        "def get_job_name_with_datetime(prefix: str):\n",
        "    \"\"\"\n",
        "    Generate a job name string with the current date and time appended.\n",
        "\n",
        "    Args:\n",
        "        prefix: The prefix string to use for the job name.\n",
        "\n",
        "    Returns:\n",
        "        str: The job name string in the format \"{prefix}_{YYYYMMDD_HHMMSS}\".\n",
        "    \"\"\"\n",
        "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def deploy_model(\n",
        "    detection_endpoint=None,\n",
        "    label_map=None,\n",
        "    output_bucket=None,\n",
        "    save_video_results=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Deploy a model to a real-time prediction endpoint.\n",
        "\n",
        "    Args:\n",
        "        detection_endpoint: The endpoint URL for object detection.\n",
        "        label_map: Mapping of class IDs to class names.\n",
        "        output_bucket: GCS bucket to save results.\n",
        "        save_video_results: Whether to save video results.\n",
        "\n",
        "    Returns:\n",
        "        The created endpoint and deployed model objects.\n",
        "    \"\"\"\n",
        "    task = \"tracking\"\n",
        "    endpoint = aiplatform.Endpoint.create(display_name=f\"{task}-endpoint\")\n",
        "    serving_env = {\n",
        "        \"DETECTION_ENDPOINT\": detection_endpoint,\n",
        "        \"LABEL_MAP\": label_map,\n",
        "        \"OUTPUT_BUCKET\": output_bucket,\n",
        "        \"SAVE_VIDEO_RESULTS\": save_video_results,\n",
        "    }\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=task,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[SERVE_PORT],\n",
        "        serving_container_predict_route=SERVE_ROUTE,\n",
        "        serving_container_health_route=\"/ping\",\n",
        "        serving_container_environment_variables=serving_env,\n",
        "    )\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=PREDICTION_MACHINE_TYPE,\n",
        "        accelerator_type=PREDICTION_ACCELERATOR_TYPE,\n",
        "        accelerator_count=1,\n",
        "        service_account=SERVICE_ACCOUNT,\n",
        "    )\n",
        "    return endpoint, model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "242fc8cf-5a0e-483b-8c9d-77a474cedc4b"
      },
      "source": [
        "### Video Object Tracking with Vertex AI Endpoint and Model\n",
        "This section shows how to depoly the chained IOD and tracking model to Vertex AI to obtain predictions saved in a text file.\n",
        "\n",
        "* If you have not done so already, please set up a Vertex AI Endpoint resource with:\n",
        "    * TensorFlow Vision [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb) or\n",
        "    * Google Proprietary [notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyW_3gDz7Rk4"
      },
      "outputs": [],
      "source": [
        "# The Vertex IOD endpoint for object detection.\n",
        "# It is like projects/<project_number>/locations/<location>/endpoints/<endpoint_id>\"\n",
        "DETECTION_ENDPOINT = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPlXzhjx4fkj"
      },
      "source": [
        "This is the local URL for making requests to the tracking model serving container running on localhost. It points to the /predictions route on port SERVE_PORT that will handle model inference requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_dp2-wY4guH"
      },
      "outputs": [],
      "source": [
        "LOCAL_SERVE_URL = f\"http://localhost:{SERVE_PORT}/{SERVE_ROUTE}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seiABeZU5s-S"
      },
      "source": [
        "Run the serving container in a separate shell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No5ALIXA5tVl"
      },
      "outputs": [],
      "source": [
        "!nvidia-docker run -t --rm \\\n",
        "-p {SERVE_PORT}:{SERVE_PORT} \\\n",
        "-e DETECTION_ENDPOINT=f\"{DETECTION_ENDPOINT}\" \\\n",
        "-e LABEL_MAP=f\"{ENDPOINT_LABEL_MAP}\" \\\n",
        "-e OUTPUT_BUCKET=f\"gs://{GCS_BUCKET}/{OUTPUT_GCS_FOLDER}\" \\\n",
        "-e SAVE_VIDEO_RESULTS=1 \\\n",
        "-e CUDA_VISIBLE_DEVICES=0 \\\n",
        "{SERVE_DOCKER_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8a53d74-aa76-4429-adbe-0460ea29bae2"
      },
      "source": [
        "### Test endpoint locally and perform online prediction\n",
        "This section shows how to make prediction requests to the endpoint to obtain track IDs and bounding box coordinates for detected and tracked objects saved to a text file and/or annotated video output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6e51c57-b5e2-4ae7-888a-5391cceee5fb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"instances\": [\n",
        "            {\n",
        "                \"video_uri\": f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}1{VIDEO_FILE_EXTENSION}\"\n",
        "            },\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "r = requests.post(\n",
        "    LOCAL_SERVE_URL,\n",
        "    data=payload,\n",
        "    headers={\"content-type\": \"application/json\", \"Accept-Charset\": \"UTF-8\"},\n",
        ")\n",
        "preds = r.json()\n",
        "\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec86394f174d"
      },
      "source": [
        "# Batch Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ce0a1f-96dc-4371-8dc6-803143a98e17"
      },
      "source": [
        "### Setup input file for batch prediction and upload to gs bucket\n",
        "Provide batch prediction input in jsonl format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d79c03b3-7bce-4ddd-b362-f6663c026e9a"
      },
      "outputs": [],
      "source": [
        "INPUT_FILE = \"instances.jsonl\"\n",
        "VIDEO_PATH_1 = (\n",
        "    f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}1{VIDEO_FILE_EXTENSION}\"\n",
        ")\n",
        "VIDEO_PATH_2 = (\n",
        "    f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}2{VIDEO_FILE_EXTENSION}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc92efe1-e178-402e-a7dc-0397ee7ae402"
      },
      "outputs": [],
      "source": [
        "%%writefile $INPUT_FILE\n",
        "{\"data\": { \"video_uri\": VIDEO_PATH_1}}\n",
        "{\"data\": { \"video_uri\": VIDEO_PATH_2}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8473cca5-6442-41d6-ac5e-881b155bdb56"
      },
      "outputs": [],
      "source": [
        "!gsutil cp \"instances.jsonl\" f\"gs://{GCS_BUCKET}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5749b8eb-76c7-4a83-8755-0ce2c759b684"
      },
      "outputs": [],
      "source": [
        "gcs_input_uri = f\"gs://{GCS_BUCKET}/instances.jsonl\"\n",
        "dest_uri = f\"gs://{GCS_BUCKET}/{OUTPUT_GCS_FOLDER}\"\n",
        "print(gcs_input_uri)\n",
        "! gsutil cat $gcs_input_uri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e3064a7-ff6d-463d-9688-129c5c6cf4d0"
      },
      "source": [
        "### Create batch prediction job id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02609f01-5b61-42d7-a6e9-00ef6e3993f4"
      },
      "outputs": [],
      "source": [
        "JOB_PREFIX = \"<job name prefix>\"  # @param {type:\"string\"}\n",
        "job_name = get_job_name_with_datetime(JOB_PREFIX)\n",
        "print(job_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "948d95fc-16af-4921-8aaa-1c46cfd30eba"
      },
      "source": [
        "### Perform batch prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c63153c-22a8-42b9-b251-1d9fb4611001"
      },
      "outputs": [],
      "source": [
        "batch_predict_job = model.batch_predict(\n",
        "    job_display_name=job_name,\n",
        "    gcs_source=gcs_input_uri,\n",
        "    gcs_destination_prefix=dest_uri,\n",
        "    sync=False,\n",
        "    machine_type=PREDICTION_MACHINE_TYPE,\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")\n",
        "\n",
        "print(batch_predict_job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ca21ed1-b4c0-4a89-a04a-798f11bc85c3"
      },
      "outputs": [],
      "source": [
        "batch_predict_job.wait()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b148a5e-cf83-4c05-9e86-3ba5cf4b224a"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ec87451-3f4b-46f5-9352-c903a90df852"
      },
      "outputs": [],
      "source": [
        "# Undeploy model and delete endpoint\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "# Delete the model resource\n",
        "model.delete()\n",
        "\n",
        "delete_bucket = False\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gsutil rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_video_object_tracking_serve.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
