{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Vertex AI Model Garden - ImageBind\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_imagebind.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_imagebind.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_imagebind.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a> (A Python-3 CPU notebook is recommended)\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3de7470326a2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates deploying prebuilt Imagebind models for online prediction in Vertex AI.\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Upload the ImageBind model to [Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction).\n",
        "- Deploy the ImageBind to a [Vertex AI Endpoint resource](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints).\n",
        "- Run online prediction for feature embedding generation and zero-shot classification.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264c07757582"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "**NOTE**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioensNKM8ned"
      },
      "source": [
        "### Colab only\n",
        "Run the following commands for Colab and skip this section if you are using Workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2707b02ef5df"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()\n",
        "\n",
        "    # Restart the notebook kernel after installs.\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7adab99e41"
      },
      "source": [
        "### Setup Google Cloud project\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component.googleapis.com).\n",
        "\n",
        "1. [Create a Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs.\n",
        "\n",
        "1. [Create a service account](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console) with `Vertex AI User` and `Storage Object Admin` roles for deploying fine tuned model to Vertex AI endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c460088b873"
      },
      "source": [
        "Set the following variables for the experiment environment. The specified Cloud Storage bucket (BUCKET_URI) should be located in the specified region (REGION). Note that a multi-region bucket (eg. \"us\") is not considered a match for a single region covered by the multi-region range (eg. \"us-central1\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "855d6b96f291"
      },
      "outputs": [],
      "source": [
        "# Cloud project id.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The region you want to launch jobs in.\n",
        "REGION = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The Cloud Storage bucket for storing experiments output.\n",
        "# Start with gs:// prefix, e.g. gs://foo_bucket.\n",
        "BUCKET_URI = \"gs://\"  # @param {type:\"string\"}\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "\n",
        "import os\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "DATA_BUCKET = os.path.join(BUCKET_URI, \"data\")\n",
        "\n",
        "# The service account looks like:\n",
        "# '@.iam.gserviceaccount.com'\n",
        "# Please go to https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console\n",
        "# and create service account with `Vertex AI User` and `Storage Object Admin` roles.\n",
        "# The service account for deploying fine tuned model.\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e828eb320337"
      },
      "source": [
        "### Initialize Vertex AI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12cd25839741"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cc825514deb"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42bd4fa2b2d"
      },
      "outputs": [],
      "source": [
        "# The pre-built serving docker image.\n",
        "PREDICTION_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-imagebind-serve\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c250872074f"
      },
      "source": [
        "### Define common functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "354da31189dc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_job_name_with_datetime(prefix: str) -> str:\n",
        "    \"\"\"Gets the job name with date time when triggering deployment jobs.\"\"\"\n",
        "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def deploy_model(\n",
        "    model_name: str,\n",
        "    service_account: str,\n",
        "    task: str,\n",
        "    machine_type: str = \"g2-standard-8\",\n",
        "    accelerator_type: str = \"NVIDIA_L4\",\n",
        "    accelerator_count: str = 1,\n",
        ") -> tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
        "    \"\"\"Deploys prebuilt model in Vertex AI.\"\"\"\n",
        "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-{task}-endpoint\")\n",
        "    serving_env = {\n",
        "        \"MODEL_ID\": \"ImageBind-feature-embedding-generation-001\",\n",
        "        \"TASK\": task,\n",
        "    }\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=f\"{model_name}-{task}\",\n",
        "        serving_container_image_uri=PREDICTION_DOCKER_URI,\n",
        "        serving_container_ports=[7080],\n",
        "        serving_container_predict_route=\"/predictions/imagebind_serving\",\n",
        "        serving_container_health_route=\"/ping\",\n",
        "        serving_container_environment_variables=serving_env,\n",
        "    )\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=machine_type,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        deploy_request_timeout=1800,\n",
        "        service_account=service_account,\n",
        "    )\n",
        "    return model, endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8neJc8CnDDpu"
      },
      "source": [
        "## Deploy prebuilt ImageBind model\n",
        "\n",
        "This section deploys the prebuilt ImageBind model on Vertex AI endpoints for the tasks of feature embedding generation and zero-shot classification. The model deployment step will take ~15 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7edb830212d"
      },
      "outputs": [],
      "source": [
        "# Prepares example input data.\n",
        "! git clone https://github.com/facebookresearch/ImageBind.git\n",
        "%cd ImageBind/.assets\n",
        "! git reset --hard 95d27c7fd5a8362f3527e176c3a80ae5a4d880c0\n",
        "\n",
        "! gsutil cp -r . $DATA_BUCKET\n",
        "\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52c0776ea427"
      },
      "source": [
        "### Deploy prebuilt ImageBind model for feature embedding generation\n",
        "\n",
        "In this section, we deploys an ImageBind that generates feature embeddings for different data modalities.\n",
        "\n",
        "The peak GPU memory usage for the ImageBind model is ~8G. Please adjust the machine type, accelerator type and accelerator count accordingly. We use one V100 (16G) in deployments as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "641375dce6a1"
      },
      "outputs": [],
      "source": [
        "task = \"feature-embedding-generation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uak1pyEeExYM"
      },
      "outputs": [],
      "source": [
        "# Finds Vertex AI prediction supported accelerators and regions in\n",
        "#  https://cloud.google.com/vertex-ai/docs/predictions/configure-compute.\n",
        "\n",
        "# Sets V100 to deploy ImageBind.\n",
        "machine_type = \"n1-standard-8\"\n",
        "accelerator_type = \"NVIDIA_TESLA_V100\"\n",
        "accelerator_count = 1\n",
        "\n",
        "model, endpoint = deploy_model(\n",
        "    model_name=get_job_name_with_datetime(prefix=\"ImageBind-serve\"),\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        "    task=task,\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=accelerator_type,\n",
        "    accelerator_count=accelerator_count,\n",
        ")\n",
        "print(f\"Endpoint name: {endpoint.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGKIjgmDFRW2"
      },
      "source": [
        "NOTE: The prebuilt model weights will be downloaded on the fly after deployment succeeds. Thus, an additional 5 minutes of waiting time is needed **after** the above model deployment step succeeds and before you can run the next step below. Otherwise you might see a `ServiceUnavailable: 503 502:Bad Gateway` error when you send requests to the endpoint.\n",
        "\n",
        "Once deployment succeeds, you can send requests to the endpoint with text prompts, GCS paths to image, depth, thermal, video and audio data files, and IMU data.\n",
        "\n",
        "The input specification is:\n",
        "- **Text**: A list of text prompts, indexed by the key \"text\"\n",
        "- **Image**: A list of GCS paths to 3-channel RGB images, indexed by the key \"vision\"\n",
        "- **Depth image**: A list of GCS paths to 1-channel depth images, indexed by the key \"depth\"\n",
        "- **Thermal images**: A list of GCS paths to 1-channel thermal images, indexed by the key \"thermal\"\n",
        "- **Video**: A list of GCS paths to 3-channel RGB videos, indexed by the key \"video\"\n",
        "- **Audio**: A list of GCS paths to waveform files, indexed by the key \"audio\"\n",
        "- **IMU**: A list of tensors of the shape [6, 2000] (the first dimension corresponds to accelerometer and gyroscope measurements along the X, Y, Z axes; the second dimension corresponds to 10-second clips with sample rate 200Hz), indexed by the key \"imu\"\n",
        "\n",
        "See the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDHsCOqvFYBi"
      },
      "outputs": [],
      "source": [
        "# Loads an existing endpoint instance using the endpoint name:\n",
        "# - Using `endpoint_name = endpoint.name` allows us to get the endpoint name of\n",
        "#   the endpoint `endpoint` created in the cell above.\n",
        "# - Alternatively, you can set `endpoint_name = \"1234567890123456789\"` to load\n",
        "#   an existing endpoint with the ID 1234567890123456789.\n",
        "# You may uncomment the code below to load an existing endpoint.\n",
        "\n",
        "# endpoint_name = endpoint.name\n",
        "# # endpoint_name = \"\"  # @param {type:\"string\"}\n",
        "# aip_endpoint_name = (\n",
        "#     f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{endpoint_name}\"\n",
        "# )\n",
        "# endpoint = aiplatform.Endpoint(aip_endpoint_name)\n",
        "\n",
        "\n",
        "# If you encounter the issue like `ServiceUnavailable: 503 Took too long to respond when processing`,\n",
        "# you can reduce the amount of input data.\n",
        "instances = [\n",
        "    {\n",
        "        \"text\": [\"A dog.\", \"A car\", \"A bird\"],\n",
        "        \"vision\": [\n",
        "            os.path.join(DATA_BUCKET, \"dog_image.jpg\"),\n",
        "            os.path.join(DATA_BUCKET, \"car_image.jpg\"),\n",
        "            os.path.join(DATA_BUCKET, \"bird_image.jpg\"),\n",
        "        ],\n",
        "        \"audio\": [\n",
        "            os.path.join(DATA_BUCKET, \"dog_audio.wav\"),\n",
        "            os.path.join(DATA_BUCKET, \"car_audio.wav\"),\n",
        "            os.path.join(DATA_BUCKET, \"bird_audio.wav\"),\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "response = endpoint.predict(instances=instances)\n",
        "\n",
        "for modality, embedding in response.predictions[0].items():\n",
        "    print(f\"Modality {modality}: embedding shape {np.array(embedding).shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af21a3cff1e0"
      },
      "source": [
        "#### Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "911406c1561e"
      },
      "outputs": [],
      "source": [
        "# Undeploy model and delete endpoint.\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "# Delete model.\n",
        "model.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f10b8d5bb80a"
      },
      "source": [
        "### Deploy prebuilt ImageBind model for zero-shot classification\n",
        "\n",
        "In this section, we deploys an ImageBind that performs zero-shot classification between pairs of data modalities.\n",
        "\n",
        "The peak GPU memory usage for the ImageBind model is ~8G. Please adjust the machine type, accelerator type and accelerator count accordingly. We use one V100 (16G) in deployments as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bf7295919fc"
      },
      "outputs": [],
      "source": [
        "task = \"zero-shot-classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uak1pyEeExYM"
      },
      "outputs": [],
      "source": [
        "# Finds Vertex AI prediction supported accelerators and regions in\n",
        "#  https://cloud.google.com/vertex-ai/docs/predictions/configure-compute.\n",
        "\n",
        "# Sets V100 to deploy ImageBind.\n",
        "machine_type = \"n1-standard-8\"\n",
        "accelerator_type = \"NVIDIA_TESLA_V100\"\n",
        "accelerator_count = 1\n",
        "\n",
        "model, endpoint = deploy_model(\n",
        "    model_name=get_job_name_with_datetime(prefix=\"ImageBind-serve\"),\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        "    task=task,\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=accelerator_type,\n",
        "    accelerator_count=accelerator_count,\n",
        ")\n",
        "print(f\"Endpoint name: {endpoint.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGKIjgmDFRW2"
      },
      "source": [
        "NOTE: The prebuilt model weights will be downloaded on the fly after deployment succeeds. Thus, an additional 5 minutes of waiting time is needed **after** the above model deployment step succeeds and before you can run the next step below. Otherwise you might see a `ServiceUnavailable: 503 502:Bad Gateway` error when you send requests to the endpoint.\n",
        "\n",
        "Once deployment succeeds, you can send requests to the endpoint with text prompts, GCS paths to image, depth, thermal, video and audio data files, and IMU data.\n",
        "\n",
        "The input specification is:\n",
        "- **Text**: A list of text prompts, indexed by the key \"text\"\n",
        "- **Image**: A list of GCS paths to 3-channel RGB images, indexed by the key \"vision\"\n",
        "- **Depth image**: A list of GCS paths to 1-channel depth images, indexed by the key \"depth\"\n",
        "- **Thermal images**: A list of GCS paths to 1-channel thermal images, indexed by the key \"thermal\"\n",
        "- **Video**: A list of GCS paths to 3-channel RGB videos, indexed by the key \"video\"\n",
        "- **Audio**: A list of GCS paths to waveform files, indexed by the key \"audio\"\n",
        "- **IMU**: A list of tensors of the shape [6, 2000] (the first dimension corresponds to accelerometer and gyroscope measurements along the X, Y, Z axes; the second dimension corresponds to 10-second clips with sample rate 200Hz), indexed by the key \"imu\"\n",
        "\n",
        "See the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDHsCOqvFYBi"
      },
      "outputs": [],
      "source": [
        "# Loads an existing endpoint instance using the endpoint name:\n",
        "# - Using `endpoint_name = endpoint.name` allows us to get the endpoint name of\n",
        "#   the endpoint `endpoint` created in the cell above.\n",
        "# - Alternatively, you can set `endpoint_name = \"1234567890123456789\"` to load\n",
        "#   an existing endpoint with the ID 1234567890123456789.\n",
        "# You may uncomment the code below to load an existing endpoint.\n",
        "\n",
        "# endpoint_name = endpoint.name\n",
        "# # endpoint_name = \"\"  # @param {type:\"string\"}\n",
        "# aip_endpoint_name = (\n",
        "#     f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{endpoint_name}\"\n",
        "# )\n",
        "# endpoint = aiplatform.Endpoint(aip_endpoint_name)\n",
        "\n",
        "\n",
        "# If you encounter the issue like `ServiceUnavailable: 503 Took too long to respond when processing`,\n",
        "# you can reduce the amount of input data.\n",
        "instances = [\n",
        "    {\n",
        "        \"text\": [\"A dog.\", \"A car\", \"A bird\"],\n",
        "        \"vision\": [\n",
        "            os.path.join(DATA_BUCKET, \"dog_image.jpg\"),\n",
        "            os.path.join(DATA_BUCKET, \"car_image.jpg\"),\n",
        "            os.path.join(DATA_BUCKET, \"bird_image.jpg\"),\n",
        "        ],\n",
        "        \"audio\": [\n",
        "            os.path.join(DATA_BUCKET, \"dog_audio.wav\"),\n",
        "            os.path.join(DATA_BUCKET, \"car_audio.wav\"),\n",
        "            os.path.join(DATA_BUCKET, \"bird_audio.wav\"),\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "response = endpoint.predict(instances=instances)\n",
        "\n",
        "for modality_pair, probs in response.predictions[0].items():\n",
        "    print(f\"{modality_pair}:\\n{np.array(probs)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af21a3cff1e0"
      },
      "source": [
        "#### Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "911406c1561e"
      },
      "outputs": [],
      "source": [
        "# Undeploy model and delete endpoint.\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "# Delete model.\n",
        "model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_pytorch_imagebind.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
