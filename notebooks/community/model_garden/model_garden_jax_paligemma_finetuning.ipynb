{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OdZIyZwjgsQcOXnmE8X0xy40",
      "metadata": {
        "id": "OdZIyZwjgsQcOXnmE8X0xy40"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VJWDivOv3OWy",
      "metadata": {
        "id": "VJWDivOv3OWy"
      },
      "source": [
        "# Vertex AI Model Garden - PaliGemma (Finetuning)\n",
        "\n",
        "<table><tbody><tr>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_jax_paligemma_finetuning.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_paligemma_finetuning.ipynb\">\n",
        "      <img alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</tr></tbody></table>\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to do finetuning PaliGemma with a Vertex AI Custom Training Job, deploying the finetuned model to a Vertex AI Endpoint, and making online predictions.\n",
        "\n",
        "\n",
        "### Objective\n",
        "- Prepare data for finetuning.\n",
        "- Launch a Vertex AI Custom Training Job to finetune PaliGemma, storing the resulting model to a GCS bucket.\n",
        "- Deploy the finetuned PaliGemma model to a Vertex AI Endpoint.\n",
        "- Make predictions to the endpoint.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aFHbs1g6Wc-",
      "metadata": {
        "id": "2aFHbs1g6Wc-"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QvQjsmIJ6Y3f",
      "metadata": {
        "cellView": "form",
        "id": "QvQjsmIJ6Y3f"
      },
      "outputs": [],
      "source": [
        "# @title Setup Google Cloud project\n",
        "\n",
        "# @markdown ### Prerequisites\n",
        "# @markdown 1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "# @markdown 2. [Optional] [Create a Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs. Set the BUCKET_URI for the experiment environment. The specified Cloud Storage bucket (`BUCKET_URI`) should be located in the same region as where the notebook was launched. Note that a multi-region bucket (eg. \"us\") is not considered a match for a single region covered by the multi-region range (eg. \"us-central1\"). If not set, a unique GCS bucket will be created instead.\n",
        "\n",
        "# Import the necessary packages\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from typing import Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from google.cloud import aiplatform\n",
        "from PIL import Image\n",
        "\n",
        "# Get the default cloud project id.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# Enable the Vertex AI API and Compute Engine API, if not already.\n",
        "print(\"Enabling Vertex AI API and Compute Engine API.\")\n",
        "! gcloud services enable aiplatform.googleapis.com compute.googleapis.com\n",
        "\n",
        "# Cloud Storage bucket for storing the experiment artifacts.\n",
        "# A unique GCS bucket will be created for the purpose of this notebook. If you\n",
        "# prefer using your own GCS bucket, please change the value yourself below.\n",
        "now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_URI = \"gs://\"  # @param {type:\"string\"}\n",
        "assert BUCKET_URI.startswith(\"gs://\"), \"BUCKET_URI must start with `gs://`.\"\n",
        "# Create a unique GCS bucket for this notebook, if not specified by the user\n",
        "if BUCKET_URI is None or BUCKET_URI.strip() == \"\" or BUCKET_URI == \"gs://\":\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-tmp-{now}\"\n",
        "    ! gsutil mb -l {REGION} {BUCKET_URI}\n",
        "else:\n",
        "    BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "    shell_output = ! gsutil ls -Lb {BUCKET_NAME} | grep \"Location constraint:\" | sed \"s/Location constraint://\"\n",
        "    bucket_region = shell_output[0].strip().lower()\n",
        "    if bucket_region != REGION:\n",
        "        raise ValueError(\n",
        "            f\"Bucket region {bucket_region} is different from notebook region {REGION}\"\n",
        "        )\n",
        "print(f\"Using this GCS Bucket: {BUCKET_URI}\")\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "MODEL_BUCKET = os.path.join(BUCKET_URI, \"paligemma\")\n",
        "\n",
        "# Initialize Vertex AI API.\n",
        "print(\"Initializing Vertex AI API.\")\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "# Set up default SERVICE_ACCOUNT\n",
        "SERVICE_ACCOUNT = None\n",
        "shell_output = ! gcloud projects describe $PROJECT_ID\n",
        "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)\n",
        "\n",
        "# Provision permissions to the SERVICE_ACCOUNT with the GCS bucket\n",
        "BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.admin $BUCKET_NAME\n",
        "\n",
        "# The pre-built serving docker images.\n",
        "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/jax-paligemma-train-gpu:latest\"\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/jax-paligemma-serve-gpu:latest\"\n",
        "\n",
        "pretrained_filename_lookup = {\n",
        "    \"paligemma-224-float32\": \"pt_224.npz\",\n",
        "    \"paligemma-224-float16\": \"pt_224.f16.npz\",\n",
        "    \"paligemma-224-bfloat16\": \"pt_224.bf16.npz\",\n",
        "    \"paligemma-448-float32\": \"pt_448.npz\",\n",
        "    \"paligemma-448-float16\": \"pt_448.f16.npz\",\n",
        "    \"paligemma-448-bfloat16\": \"pt_448.bf16.npz\",\n",
        "    \"paligemma-896-float32\": \"pt_896.npz\",\n",
        "    \"paligemma-896-float16\": \"pt_896.f16.npz\",\n",
        "    \"paligemma-896-bfloat16\": \"pt_896.bf16.npz\",\n",
        "    \"paligemma-mix-224-float32\": \"mix_224.npz\",\n",
        "    \"paligemma-mix-224-float16\": \"mix_224.f16.npz\",\n",
        "    \"paligemma-mix-224-bfloat16\": \"mix_224.bf16.npz\",\n",
        "    \"paligemma-mix-448-float32\": \"mix_448.npz\",\n",
        "    \"paligemma-mix-448-float16\": \"mix_448.f16.npz\",\n",
        "    \"paligemma-mix-448-bfloat16\": \"mix_448.bf16.npz\",\n",
        "}\n",
        "\n",
        "\n",
        "def get_job_name_with_datetime(prefix: str) -> str:\n",
        "    \"\"\"Gets the job name with date time when triggering training or deployment\n",
        "    jobs in Vertex AI.\n",
        "    \"\"\"\n",
        "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def deploy_model(\n",
        "    model_name: str,\n",
        "    checkpoint_path: str,\n",
        "    machine_type: str = \"g2-standard-32\",\n",
        "    accelerator_type: str = \"NVIDIA_L4\",\n",
        "    accelerator_count: int = 1,\n",
        "    resolution: int = 224,\n",
        ") -> Tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
        "    \"\"\"Create a Vertex AI Endpoint and deploy the specified model to the endpoint.\"\"\"\n",
        "    model_name_with_time = get_job_name_with_datetime(model_name)\n",
        "    endpoint = aiplatform.Endpoint.create(\n",
        "        display_name=f\"{model_name_with_time}-endpoint\"\n",
        "    )\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_name_with_time,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[8080],\n",
        "        serving_container_predict_route=\"/predict\",\n",
        "        serving_container_health_route=\"/health\",\n",
        "        serving_container_environment_variables={\n",
        "            \"CKPT_PATH\": checkpoint_path,\n",
        "            \"RESOLUTION\": resolution,\n",
        "            \"MODEL_ID\": model_name,\n",
        "        },\n",
        "    )\n",
        "    print(\n",
        "        f\"Deploying {model_name_with_time} on {machine_type} with {accelerator_count} {accelerator_type} GPU(s).\"\n",
        "    )\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=machine_type,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        deploy_request_timeout=1800,\n",
        "        service_account=SERVICE_ACCOUNT,\n",
        "        enable_access_logging=True,\n",
        "        min_replica_count=1,\n",
        "        sync=True,\n",
        "    )\n",
        "    return model, endpoint\n",
        "\n",
        "\n",
        "def download_image(url: str) -> Image.Image:\n",
        "    \"\"\"Downloads an image from the specified URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "def resize_image(image: Image.Image, new_width: int = 1000) -> Image.Image:\n",
        "    width, height = image.size\n",
        "    print(f\"original input image size: {width}, {height}\")\n",
        "    new_height = int(height * new_width / width)\n",
        "    new_img = image.resize((new_width, new_height))\n",
        "    print(f\"resized input image size: {new_width}, {new_height}\")\n",
        "    return new_img\n",
        "\n",
        "\n",
        "def image_to_base64(image: Image.Image, format=\"JPEG\") -> str:\n",
        "    \"\"\"Converts an image to a base64 string.\"\"\"\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=format)\n",
        "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "    return image_str\n",
        "\n",
        "\n",
        "def caption_predict(\n",
        "    endpoint: aiplatform.Endpoint,\n",
        "    image: Image.Image = None,\n",
        "    language_code: str = \"en\",\n",
        "    new_width: int = 1000,\n",
        ") -> str:\n",
        "    \"\"\"Predicts a caption for a given image using an Endpoint.\"\"\"\n",
        "    # Resize and convert image to base64 string.\n",
        "    resized_image = resize_image(image, new_width)\n",
        "    resized_image_base64 = image_to_base64(resized_image)\n",
        "\n",
        "    # Format caption prompt\n",
        "    caption_prompt = f\"caption en {language_code}\\n\"\n",
        "\n",
        "    instances = [\n",
        "        {\n",
        "            \"prompt\": caption_prompt,\n",
        "            \"image\": resized_image_base64,\n",
        "        },\n",
        "    ]\n",
        "    response = endpoint.predict(instances=instances)\n",
        "    return response.predictions[0].get(\"response\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jo9Iv7WZGQub",
      "metadata": {
        "cellView": "form",
        "id": "Jo9Iv7WZGQub"
      },
      "outputs": [],
      "source": [
        "# @title Access PaliGemma models on Vertex AI for GPU based serving\n",
        "\n",
        "\n",
        "# @markdown Accept the model agreement to access the models:\n",
        "# @markdown 1. Open the [PaliGemma model card](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/363) from [Vertex AI Model Garden](https://cloud.google.com/model-garden).\n",
        "# @markdown 1. Review and accept the agreement in the pop-up window on the model card page. If you have previously accepted the model agreement, there will not be a pop-up window on the model card page and this step is not needed.\n",
        "# @markdown 1. After accepting the agreement of PaliGemma, a `gs://` URI containing PaliGemma pretrained models will be shared.\n",
        "# @markdown 1. Paste the link in the `VERTEX_AI_MODEL_GARDEN_PALIGEMMA` field below.\n",
        "# @markdown 1. The PaliGemma models will be copied into `BUCKET_URI`.\n",
        "VERTEX_AI_MODEL_GARDEN_PALIGEMMA = \"gs://\"  # @param {type:\"string\", isTemplate:true}\n",
        "assert (\n",
        "    VERTEX_AI_MODEL_GARDEN_PALIGEMMA\n",
        "), \"Please click the agreement of PaliGemma in Vertex AI Model Garden, and get the GCS path of PaliGemma model artifacts.\"\n",
        "print(\n",
        "    \"Copying PaliGemma model artifacts from\",\n",
        "    VERTEX_AI_MODEL_GARDEN_PALIGEMMA,\n",
        "    \"to \",\n",
        "    MODEL_BUCKET,\n",
        ")\n",
        "\n",
        "! gsutil -m cp -R $VERTEX_AI_MODEL_GARDEN_PALIGEMMA/* $MODEL_BUCKET\n",
        "\n",
        "model_path_prefix = MODEL_BUCKET"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XdVYFARuNsuG",
      "metadata": {
        "id": "XdVYFARuNsuG"
      },
      "source": [
        "## Finetune with Vertex AI Custom Training Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zSjxLZegONqH",
      "metadata": {
        "cellView": "form",
        "id": "zSjxLZegONqH"
      },
      "outputs": [],
      "source": [
        "# @title Data preparation\n",
        "\n",
        "# @markdown The dataset file format is to be image-string pairs stored in a jsonl file.\n",
        "# @markdown The value for `\"image\"` can be a GCS path or a URL.\n",
        "\n",
        "# @markdown ```\n",
        "# @markdown {\"image\": \"gs://bucket-name/image.jpg\", \"prompt\", \"prefix\": \"what animal is this?\", \"suffix\": \"suffix\": \"cat\"}\n",
        "# @markdown {\"image\": \"https://website.com/image.jpg\", \"prompt\", \"prefix\": \"what drink is this?\", \"suffix\": \"suffix\": \"soda\"}\n",
        "# @markdown ```\n",
        "\n",
        "dataset_gcs_uri = \"gs://\"  # @param {type: \"string\"}\n",
        "\n",
        "# @markdown [Optional] You can optionally specify the image fields in the JSONL file to use the\n",
        "# @markdown filename and fill in the `dataset_image_dir` with the location where the images are stored.\n",
        "dataset_image_dir = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jitdsEHDNqQk",
      "metadata": {
        "cellView": "form",
        "id": "jitdsEHDNqQk"
      },
      "outputs": [],
      "source": [
        "# @title Finetune\n",
        "# @markdown Use the Vertex AI SDK to create and run the custom training jobs.\n",
        "\n",
        "model_variant = \"mix\"  # @param [\"mix\", \"pt\"]\n",
        "model_resolution = 224  # @param [224, 448, 896]\n",
        "model_precision_type = \"float32\"  # @param [\"float32\", \"float16\", \"bfloat16\"]\n",
        "\n",
        "if model_variant == \"mix\":\n",
        "    model_name_prefix = \"paligemma-mix\"\n",
        "else:\n",
        "    model_name_prefix = \"paligemma\"\n",
        "\n",
        "base_model_name = f\"{model_name_prefix}-{model_resolution}-{model_precision_type}\"\n",
        "base_model_filename = pretrained_filename_lookup[base_model_name]\n",
        "base_model_uri = os.path.join(model_path_prefix, base_model_filename)\n",
        "\n",
        "# The accelerator to use.\n",
        "ACCELERATOR_TYPE = \"NVIDIA_L4\"  # @param [\"NVIDIA_TESLA_V100\", \"NVIDIA_L4\"]\n",
        "\n",
        "# Batch size for finetuning.\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "# Number of epochs to train.\n",
        "epochs = 1  # @param {type:\"integer\"}\n",
        "# Learning rate.\n",
        "learning_rate = 2e-4  # @param{type:\"number\"}\n",
        "\n",
        "# Worker pool spec.\n",
        "\n",
        "if ACCELERATOR_TYPE == \"NVIDIA_TESLA_V100\":\n",
        "    machine_type = \"n1-standard-8\"\n",
        "    accelerator_count = 2\n",
        "elif ACCELERATOR_TYPE == \"NVIDIA_L4\":\n",
        "    machine_type = \"g2-standard-24\"\n",
        "    accelerator_count = 2\n",
        "else:\n",
        "    raise ValueError(\n",
        "        f\"Cannot automatically determine machine type from {ACCELERATOR_TYPE}.\"\n",
        "    )\n",
        "\n",
        "replica_count = 1\n",
        "\n",
        "# Setup training job.\n",
        "job_name = get_job_name_with_datetime(\"paligemma-finetune\")\n",
        "\n",
        "# Pass training arguments and launch job.\n",
        "train_job = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=job_name,\n",
        "    container_uri=TRAIN_DOCKER_URI,\n",
        ")\n",
        "\n",
        "# Designate a GCS folder to store the LORA adapter.\n",
        "finetune_output_dir_name = get_job_name_with_datetime(\"paligemma-finetune\")\n",
        "finetune_output_dir = os.path.join(STAGING_BUCKET, finetune_output_dir_name)\n",
        "\n",
        "train_args = [\n",
        "    \"--config=big_vision/configs/proj/paligemma/transfers/vertexai_l4.py\",\n",
        "    f\"--workdir={finetune_output_dir}\",\n",
        "    f\"--config.model_init={base_model_uri}\",\n",
        "    f\"--config.input.data.fname={dataset_gcs_uri}\",\n",
        "    f\"--config.input.batch_size={batch_size}\",\n",
        "    f\"--config.total_epochs={epochs}\",\n",
        "    f\"--config.lr={learning_rate}\",\n",
        "]\n",
        "if dataset_image_dir:\n",
        "    train_args.append(f\"--config.input.data.fopen_keys.image={dataset_image_dir}\")\n",
        "train_job.run(\n",
        "    args=train_args,\n",
        "    replica_count=replica_count,\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=ACCELERATOR_TYPE,\n",
        "    accelerator_count=accelerator_count,\n",
        "    boot_disk_size_gb=500,\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")\n",
        "\n",
        "print(\"Checkpoint and log files was saved in: \", finetune_output_dir)\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WngKdCIzOTJV",
      "metadata": {
        "cellView": "form",
        "id": "WngKdCIzOTJV"
      },
      "outputs": [],
      "source": [
        "# @title View training loss\n",
        "\n",
        "# @markdown Metrics will be stored in a file named `big_vision_metrics.txt` in the GCS bucket, including training loss, examples seen, and core hours throughout training.\n",
        "\n",
        "# @markdown Run this cell to get and plot the training loss.\n",
        "\n",
        "# Get relevant metrics from metrics file.\n",
        "metrics_path = os.path.join(finetune_output_dir, \"big_vision_metrics.txt\")\n",
        "steps = []\n",
        "training_losses = []\n",
        "with tf.io.gfile.GFile(metrics_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        metric = json.loads(line)\n",
        "        steps.append(metric[\"step\"])\n",
        "        training_losses.append(metric[\"training_loss\"])\n",
        "\n",
        "# Plot training plot\n",
        "plt.plot(steps, training_losses)\n",
        "plt.title(\"Steps vs. Training Loss\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "toY-WPKDFesF",
      "metadata": {
        "id": "toY-WPKDFesF"
      },
      "outputs": [],
      "source": [
        "# @title Deploy\n",
        "\n",
        "# @markdown This section uploads the finetuned PaliGemma model to Model Registry and deploys it to a Vertex AI Endpoint. It takes approximately 15 minutes to finish.\n",
        "\n",
        "# @markdown Note: You cannot use accelerator type `NVIDIA_TESLA_V100` to serve prebuilt or finetuned PaliGemma models with resolution `896` and precision_type `float32`.\n",
        "\n",
        "last_checkpoint_path = os.path.join(finetune_output_dir, \"checkpoint.bv-LAST\")\n",
        "with tf.io.gfile.GFile(last_checkpoint_path, \"r\") as f:\n",
        "    final_checkpoint_name = \"checkpoint.bv-\" + f.read()\n",
        "    checkpoint_path = os.path.join(finetune_output_dir, final_checkpoint_name)\n",
        "\n",
        "model_name = f\"paligemma-{model_resolution}-{model_precision_type}-custom\"\n",
        "print(f\"Deploying custom PaliGemma model: {model_name}\")\n",
        "\n",
        "# @markdown Select the accelerator type to use to deploy the model:\n",
        "accelerator_type = \"NVIDIA_L4\"  # @param [\"NVIDIA_L4\", \"NVIDIA_TESLA_V100\"]\n",
        "if accelerator_type == \"NVIDIA_L4\":\n",
        "    machine_type = \"g2-standard-16\"\n",
        "    accelerator_count = 1\n",
        "elif accelerator_type == \"NVIDIA_TESLA_V100\":\n",
        "    if model_resolution == 896 and model_precision_type == \"float32\":\n",
        "        raise ValueError(\n",
        "            \"NVIDIA_TESLA_V100 is not sufficient. Multi-gpu is not supported for PaLIGemma.\"\n",
        "        )\n",
        "    else:\n",
        "        machine_type = \"n1-highmem-8\"\n",
        "        accelerator_count = 1\n",
        "else:\n",
        "    raise ValueError(\n",
        "        f\"Recommended machine settings not found for: {accelerator_type}. To use another another accelerator, please edit this code block to pass in an appropriate `machine_type`, `accelerator_type`, and `accelerator_count` to the deploy_model function by clicking `Show Code` and then modifying the code.\"\n",
        "    )\n",
        "# @markdown Find other Vertex AI prediction supported accelerators and regions at https://cloud.google.com/vertex-ai/docs/predictions/configure-compute.\n",
        "\n",
        "# @markdown You may need to manually set the `machine_type`, `accelerator_type`, and `accelerator_count` after clicking \"Show code\".\n",
        "\n",
        "model, endpoint = deploy_model(\n",
        "    model_name=model_name,\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=accelerator_type,\n",
        "    accelerator_count=accelerator_count,\n",
        "    resolution=model_resolution,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0v3GA8NU8SNp",
      "metadata": {
        "cellView": "form",
        "id": "0v3GA8NU8SNp"
      },
      "outputs": [],
      "source": [
        "# @title Image Captioning\n",
        "\n",
        "# @markdown This section uses the deployed PaliGemma model to caption and describe an image in a chosen language.\n",
        "\n",
        "# @markdown ![](https://images.pexels.com/photos/20427316/pexels-photo-20427316/free-photo-of-a-moped-parked-in-front-of-a-blue-door.jpeg?auto=compress&cs=tinysrgb&w=630&h=375&dpr=2)\n",
        "\n",
        "image_url = \"https://images.pexels.com/photos/20427316/pexels-photo-20427316/free-photo-of-a-moped-parked-in-front-of-a-blue-door.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2\"  # @param {type:\"string\"}\n",
        "\n",
        "image = download_image(image_url)\n",
        "display(image)\n",
        "\n",
        "# Make a prediction.\n",
        "image_base64 = image_to_base64(image)\n",
        "language_code = \"en\"  # @param {type: \"string\"}\n",
        "caption = caption_predict(endpoint, image, language_code)\n",
        "\n",
        "print(\"Caption: \", caption)\n",
        "# @markdown Please click \"Show Code\" to see more details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IrVZ030i4XMY",
      "metadata": {
        "id": "IrVZ030i4XMY"
      },
      "source": [
        "## Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YsMpOI1kYjil",
      "metadata": {
        "id": "YsMpOI1kYjil"
      },
      "outputs": [],
      "source": [
        "# @markdown Delete the experiment models and endpoints to recycle the resources\n",
        "# @markdown and avoid unnecessary continuous charges that may incur.\n",
        "\n",
        "# Delete the training job.\n",
        "train_job.delete()\n",
        "\n",
        "# Undeploy model and delete endpoint.\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "# Delete models.\n",
        "model.delete()\n",
        "\n",
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_jax_paligemma_finetuning.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
