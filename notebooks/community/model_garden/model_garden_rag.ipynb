{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdr9qXnG1HaN"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_X6E0Jl1NbD"
      },
      "source": [
        "## Model Garden RAG API\n",
        "\n",
        "Last updated: 9/11/2024\n",
        "\n",
        "## Onboarding\n",
        "If you have any questions, please reach out to *Vertex RAG API * team vertex-rag-eng@google.com, for the onboarding process.\n",
        "\n",
        "## 0. Set up the Environment and Test Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9mTxNC41S_1"
      },
      "outputs": [],
      "source": [
        "!pip3 install --force-reinstall google-cloud-aiplatform \"numpy<2.0.0\" --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILNZ8_hw1WaC"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install gcloud\n",
        "!pip install google-cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuzltFSF1ZWw"
      },
      "source": [
        "**Remember to restart after pip install.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj8SdgZM1cOP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7x73NiprHhJ"
      },
      "source": [
        "## Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldoxVA24qnAF"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.preview import rag\n",
        "from vertexai.preview.generative_models import GenerativeModel, Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB-fhAybq0T2"
      },
      "outputs": [],
      "source": [
        "# Set Project\n",
        "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2Rr1Ymlq3Uq"
      },
      "outputs": [],
      "source": [
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmxhW-LArK2L"
      },
      "source": [
        "## Create a RAG corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E1tVMx3rAXF"
      },
      "outputs": [],
      "source": [
        "# Configure a Google first-party embedding model\n",
        "embedding_model_config = rag.EmbeddingModelConfig(\n",
        "    publisher_model=\"publishers/google/models/text-embedding-004\"\n",
        ")\n",
        "\n",
        "# Configure a third-party model or a Google fine-tuned first-party model as a Vertex Endpoint resource\n",
        "# See https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_e5.ipynb for \n",
        "# deploying 3P embedding models to endpoints\n",
        "ENDPOINT_ID = \"your-model-endpoint-id\"  # @param {type:\"string\"}\n",
        "MODEL_ENDPOINT = \"projects/{PROJECT_ID}/locations/us-central1/endpoints/{ENDPOINT_ID}\"\n",
        "\n",
        "embedding_model_config = rag.EmbeddingModelConfig(\n",
        "    endpoint=MODEL_ENDPOINT,\n",
        ")\n",
        "\n",
        "# Configure a Weaviate Vector Database Instance for the corpus\n",
        "WEAVIATE_HTTP_ENDPOINT = \"weaviate-http-endpoint\"  # @param {type:\"string\"}\n",
        "COLLECTION_NAME = \"weaviate-collection-name\"  # @param {type:\"string\"}\n",
        "API_KEY = \"your-secret-manager-resource-name\"  # @param {type:\"string\"}\n",
        "\n",
        "vector_db = rag.Weaviate(\n",
        "    weaviate_http_endpoint=WEAVIATE_HTTP_ENDPOINT,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    api_key=API_KEY,\n",
        ")\n",
        "\n",
        "\n",
        "# Name your corpus\n",
        "DISPLAY_NAME = \"your-corpus-name\"  # @param {type:\"string\"}\n",
        "\n",
        "rag_corpus = rag.create_corpus(\n",
        "    display_name=DISPLAY_NAME, embedding_model_config=embedding_model_config, vector_db=vector_db\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16i1ZInQrFnL"
      },
      "outputs": [],
      "source": [
        "# Check the corpus just created\n",
        "rag.list_corpora()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSLWYGF8rfMf"
      },
      "source": [
        "## Upload a file to the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G5uyvbdraMY"
      },
      "outputs": [],
      "source": [
        "%%writefile test.txt\n",
        "\n",
        "Here's a demo for Llama3 RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2vnvVO9rtDF"
      },
      "outputs": [],
      "source": [
        "rag_file = rag.upload_file(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    path=\"test.txt\",\n",
        "    display_name=\"test.txt\",\n",
        "    description=\"my test\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOhO9-G2r1Gc"
      },
      "source": [
        "## Import files from Google Cloud Storage\n",
        "Remember to grant \"Viewer\" access to the \"Vertex RAG Data Service Agent\" (with the format of service-{project_number}@gcp-sa-vertex-rag.iam.gserviceaccount.com) for your Google Cloud Storage bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y64Hdd_9r5H9"
      },
      "outputs": [],
      "source": [
        "GS_BUCKET = \"gs://your-gs-bucket\"  # @param {type:\"string\"}\n",
        "\n",
        "response = await rag.import_files_async(  # noqa: F704\n",
        "    corpus_name=rag_corpus.name,\n",
        "    paths=[GS_BUCKET],\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=50,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiTAFiEasHLX"
      },
      "outputs": [],
      "source": [
        "# Check the files just imported. It may take a few seconds to process the imported files.\n",
        "list(rag.list_files(corpus_name=rag_corpus.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBsPDR-jsML5"
      },
      "source": [
        "## Import files from Google Drive\n",
        "Eligible paths can be https://drive.google.com/drive/folders/{folder_id} or https://drive.google.com/file/d/{file_id}.\n",
        "\n",
        "Remember to grant \"Viewer\" access to the \"Vertex RAG Data Service Agent\" (with the format of `service-{project_number}@gcp-sa-vertex-rag.iam.gserviceaccount.com`) for your Drive folder/files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u16-LvjT2Thi"
      },
      "outputs": [],
      "source": [
        "FILE_ID = \"your-file-id\"  # @param {type:\"string\"}\n",
        "FILE_PATH = f\"https://drive.google.com/file/d/{FILE_ID}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY4_6tshsPSA"
      },
      "outputs": [],
      "source": [
        "rag.import_files(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    paths=[FILE_PATH],\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl8gPm9l4DQ3"
      },
      "outputs": [],
      "source": [
        "# Check the files just imported. It may take a few seconds to process the imported files.\n",
        "list(rag.list_files(corpus_name=rag_corpus.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fbf43274d4e"
      },
      "source": [
        "## Import files from Slack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b280caeab721"
      },
      "outputs": [],
      "source": [
        "CHANNEL_ID = \"your-slack-channel-id\"  # @param {type:\"string\"}\n",
        "API_KEY_SECRET_VERSION = \"your-secret-manager-resource-name\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69d731dc8bd6"
      },
      "outputs": [],
      "source": [
        "slack_source = rag.SlackChannelsSource(\n",
        "    channels=[rag.SlackChannel(CHANNEL_ID, API_KEY_SECRET_VERSION)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c54695d94783"
      },
      "outputs": [],
      "source": [
        "response = await rag.import_files_async(  # noqa: F704\n",
        "    corpus_name=rag_corpus.name,\n",
        "    source=slack_source,\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=200,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19bd9fe1537b"
      },
      "outputs": [],
      "source": [
        "# Check the files just imported. It may take a few seconds to process the imported files.\n",
        "list(rag.list_files(corpus_name=rag_corpus.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90e3a7a9fd84"
      },
      "source": [
        "## Import files from Jira"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97716299c38f"
      },
      "outputs": [],
      "source": [
        "EMAIL = \"your-email\"  # @param {type:\"string\"}\n",
        "SERVER_URI = \"your-server.atlassian.net\"  # @param {type:\"string\"}\n",
        "PROJECT = \"your-project-name\"  # @param {type:\"string\"}\n",
        "CUSTOM_QUERY = \"your-custom-jql-query\"  # @param {type:\"string\"}\n",
        "API_KEY_SECRET_VERSION = \"your-secret-manager-resource-name\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "768705a29d61"
      },
      "outputs": [],
      "source": [
        "jira_query = rag.JiraQuery(\n",
        "    email=EMAIL,\n",
        "    jira_projects=[PROJECT],\n",
        "    custom_queries=[CUSTOM_QUERY],\n",
        "    api_key=API_KEY_SECRET_VERSION,\n",
        "    server_uri=SERVER_URI,\n",
        ")\n",
        "\n",
        "jira_source = rag.JiraSource(\n",
        "    queries=[jira_query],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05b54b5973ae"
      },
      "outputs": [],
      "source": [
        "response = await rag.import_files_async(  # noqa: F704\n",
        "    corpus_name=rag_corpus.name,\n",
        "    source=jira_source,\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=200,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbb764934c18"
      },
      "outputs": [],
      "source": [
        "# Check the files just imported. It may take a few seconds to process the imported files.\n",
        "list(rag.list_files(corpus_name=rag_corpus.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1-joFPys-FS"
      },
      "source": [
        "## Generate Content with Rag Retrieval Tool for self-deployed Llama3 model\n",
        "\n",
        "When retrieval query similarity distance < vector_distance_threshold, generate content will cite the retrieved context (from RagStore).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvTPfijxtAQO"
      },
      "outputs": [],
      "source": [
        "rag_resource = rag.RagResource(\n",
        "    rag_corpus=rag_corpus.name,\n",
        "    # Need to manually get the ids from rag.list_files.\n",
        "    # rag_file_ids=[],\n",
        ")\n",
        "\n",
        "rag_retrieval_tool = Tool.from_retrieval(\n",
        "    retrieval=rag.Retrieval(\n",
        "        source=rag.VertexRagStore(\n",
        "            rag_resources=[rag_resource],  # Currently only 1 corpus is allowed.\n",
        "            similarity_top_k=5,\n",
        "            vector_distance_threshold=0.4,\n",
        "        ),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3IffRu42nRp"
      },
      "outputs": [],
      "source": [
        "ENDPOINT = \"projects/{PROJECT_ID}/locations/us-central1/endpoints/{ENDPOINT_ID}\"  # @param {type:\"string\"}\n",
        "\n",
        "rag_model = GenerativeModel(ENDPOINT, tools=[rag_retrieval_tool])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFEEv2u0tVNz"
      },
      "outputs": [],
      "source": [
        "QUERY = \"What is RAG and why it is helpful?\"  # @param {type:\"string\"}\n",
        "\n",
        "response = rag_model.generate_content(QUERY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I2EniAZtiUt"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cje1WHtOtt2q"
      },
      "source": [
        "## Generate Content with Rag Retrieval Tool for non-self-deployed Llama3 model endpoint\n",
        "\n",
        "The retrieved contexts can be passed to any SDK or model generation API to generate final results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK7YmoIGtyki"
      },
      "outputs": [],
      "source": [
        "QUERY = \"What is RAG and why it is helpful?\"  # @param {type:\"string\"}\n",
        "\n",
        "rag_resource = rag.RagResource(\n",
        "    rag_corpus=rag_corpus.name,\n",
        "    # Need to manually get the ids from rag.list_files.\n",
        "    # rag_file_ids=[],\n",
        ")\n",
        "\n",
        "response = rag.retrieval_query(\n",
        "    rag_resources=[rag_resource],  # Currently only 1 corpus is allowed.\n",
        "    text=QUERY,\n",
        "    similarity_top_k=5,\n",
        "    vector_distance_threshold=0.4,\n",
        ")\n",
        "\n",
        "# The retrieved context can be passed to any SDK or model generation API to generate final results.\n",
        "retrieved_context = \" \".join(\n",
        "    [context.text for context in response.contexts.contexts]\n",
        ").replace(\"\\n\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--GwKlAO29bZ"
      },
      "outputs": [],
      "source": [
        "retrieved_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTHflSAhupiN"
      },
      "source": [
        "## API reference\n",
        "\n",
        "For more details on RAG corpus/file management and detailed support please visit https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/rag-api\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_rag.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
