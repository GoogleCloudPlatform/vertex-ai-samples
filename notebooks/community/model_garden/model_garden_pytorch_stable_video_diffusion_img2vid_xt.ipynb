{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Vertex AI Model Garden - Stable Video Diffusion Img2Vid XT (Research Purpose)\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_stable_video_diffusion_img2vid_xt.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_stable_video_diffusion_img2vid_xt.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_stable_video_diffusion_img2vid_xt.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "Open in Vertex AI Workbench\n",
        "    </a>\n",
        "    (a Python-3 GPU notebook with preinstalled HuggingFace/transformer libraries is recommended)\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3de7470326a2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates running local inference for [stabilityai/stable-video-diffusion-img2vid-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) on either [Colab](https://colab.research.google.com) or [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench). This notebook also demonstrates deploying it on Vertex AI for batch prediction for research purpose only.\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Run local predictions for image-to-video.\n",
        "- Upload the model and run batch predictions for image-to-video.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264c07757582"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "**NOTE**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioensNKM8ned"
      },
      "source": [
        "### Setup notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73ffa0c0b83"
      },
      "source": [
        "#### Colab only\n",
        "Run the following commands for Colab and skip this section if you are using Workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2707b02ef5df"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()\n",
        "\n",
        "! pip3 install --upgrade pip\n",
        "! pip3 install torch==2.0.1+cu118  -f https://download.pytorch.org/whl/torch_stable.html\n",
        "! pip3 install transformers==4.36.2\n",
        "! pip3 install diffusers==0.25.0\n",
        "! pip3 install datasets==2.9.0\n",
        "! pip3 install accelerate==0.25.0\n",
        "\n",
        "# Install gdown for downloading example training images.\n",
        "! pip3 install gdown\n",
        "# Remove wrong cublas version.\n",
        "! pip3 uninstall nvidia_cublas_cu11 --yes\n",
        "\n",
        "# Restart the notebook kernel after installs.\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb671e75ca7b"
      },
      "source": [
        "#### Workbench only\n",
        "1.   Follow [this link](https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_stable_video_diffusion_img2vid_xt.ipynb) to deploy the notebook to a Vertex AI Workbench Instance.\n",
        "2.   Select `Create a new Notebook`.\n",
        "3.   Click `Advanced Options`.\n",
        "4.   In the **Environment** tab, select `Debian 10` for **Operating System** and select `Custom Container` for **Environment**.\n",
        "5.   Set `Docker container image` to `us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/transformers-notebook`.\n",
        "6.   Under **Machine configuration**, select 1 `T4` GPU and select `Install NVIDIA GPU driver automatically for me`.\n",
        "7.   Click `Create` to create the Vertex AI Workbench instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7adab99e41"
      },
      "source": [
        "### Setup Google Cloud project\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. [Create a Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs.\n",
        "\n",
        "1. [Create a service account](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console) with `Vertex AI User` and `Storage Object Admin` roles for deploying fine tuned model to Vertex AI endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c460088b873"
      },
      "source": [
        "Fill following variables for experiments environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "855d6b96f291"
      },
      "outputs": [],
      "source": [
        "# Cloud project id.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The region you want to launch jobs in.\n",
        "REGION = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The Cloud Storage bucket for storing experiments output. Fill it without the 'gs://' prefix.\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The service account for deploying fine tuned model.\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e828eb320337"
      },
      "source": [
        "Initialize Vertex-AI API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12cd25839741"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cc825514deb"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42bd4fa2b2d"
      },
      "outputs": [],
      "source": [
        "# The pre-built serving docker image. It contains serving scripts and models.\n",
        "\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-diffusers-serve-opt:20240223_1230_RC00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c250872074f"
      },
      "source": [
        "### Define common functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "354da31189dc"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "\n",
        "import imageio\n",
        "from diffusers.utils import load_image\n",
        "from google.cloud import aiplatform, storage\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "def load_and_resize_image(image_url):\n",
        "    image = load_image(image_url)\n",
        "    # required by the model\n",
        "    new_width = round(image.size[0] / 8) * 8\n",
        "    new_height = round(image.size[1] / 8) * 8\n",
        "    return image.resize((new_width, new_height))\n",
        "\n",
        "\n",
        "def create_job_name(prefix):\n",
        "    user = os.environ.get(\"USER\")\n",
        "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    job_name = f\"{prefix}-{user}-{now}\"\n",
        "    return job_name\n",
        "\n",
        "\n",
        "def image_to_base64(image, format=\"JPEG\"):\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=format)\n",
        "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "    return image_str\n",
        "\n",
        "\n",
        "def display_video_frames(frames, fps=7, width=500):\n",
        "    io_obj = io.BytesIO()\n",
        "    imageio.mimsave(io_obj, frames, format=\".mp4\", fps=fps)\n",
        "    video_data = base64.b64encode(io_obj.getvalue()).decode(\"utf-8\")\n",
        "    html = \"\"\n",
        "    html += f\"<video controls width={width}>\"\n",
        "    html += f'<source src=\"data:video/mp4;base64,{video_data}\" type=\"video/mp4\">'\n",
        "    html += \"</video>\"\n",
        "    display(HTML(html))\n",
        "\n",
        "\n",
        "def upload_model(model_id, task):\n",
        "    model_name = model_id\n",
        "    serving_env = {\n",
        "        \"MODEL_ID\": model_id,\n",
        "        \"TASK\": task,\n",
        "        \"DEPLOY_SOURCE\": \"notebook\",\n",
        "    }\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_name,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[7080],\n",
        "        serving_container_predict_route=\"/predictions/diffusers_serving\",\n",
        "        serving_container_health_route=\"/ping\",\n",
        "        serving_container_environment_variables=serving_env,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_bucket_and_blob_name(filepath):\n",
        "    # The gcs path is of the form gs://<bucket-name>/<blob-name>\n",
        "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
        "    return tuple(gs_suffix.split(\"/\", 1))\n",
        "\n",
        "\n",
        "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
        "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
        "        if not os.path.isfile(local_file):\n",
        "            continue\n",
        "        filename = local_file[1 + len(local_dir_path) :]\n",
        "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
        "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_filename(local_file)\n",
        "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))\n",
        "\n",
        "\n",
        "def download_gcs_blob_as_json(gcs_file_path):\n",
        "    \"\"\"Download GCS blob and convert it to json.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket_name, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    return json.loads(blob.download_as_bytes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqRm3WhGDo94"
      },
      "source": [
        "## Image to Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDe1WDBsTGuH"
      },
      "outputs": [],
      "source": [
        "# @title Define model and task\n",
        "model_id = \"stabilityai/stable-video-diffusion-img2vid-xt\"\n",
        "task = \"image-to-video\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrNS02rEDyKg"
      },
      "outputs": [],
      "source": [
        "# @title Run inferences locally\n",
        "import torch\n",
        "from diffusers import StableVideoDiffusionPipeline\n",
        "\n",
        "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16, variant=\"fp16\"\n",
        ")\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n",
        "# Load the conditioning image\n",
        "image = load_and_resize_image(\n",
        "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd/rocket.png\"\n",
        ")\n",
        "\n",
        "generator = torch.manual_seed(42)\n",
        "frames_list = pipe([image], decode_chunk_size=8, generator=generator).frames\n",
        "\n",
        "display_video_frames(frames_list[0], fps=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG3p4-2eD0nQ"
      },
      "source": [
        "### Deploy model to run prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXPgPmkzD3f7"
      },
      "source": [
        "Deploy the stable video diffusion model for the `image-to-video` task.\n",
        "\n",
        "Once deployed, you can run batch prediction with a batch of images to generate videos.\n",
        "\n",
        "When deployed on one `NVIDIA_L4` GPU, the averaged inference time of a request is ~600 seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz0vrpddEIj_"
      },
      "outputs": [],
      "source": [
        "# @title Define upload model\n",
        "\n",
        "model = upload_model(model_id=model_id, task=task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCEX767pET2t"
      },
      "outputs": [],
      "source": [
        "# @title Prepare input\n",
        "import json\n",
        "\n",
        "image = load_and_resize_image(\n",
        "    \"https://images.pexels.com/videos/853848/free-video-853848.jpg\"\n",
        ")\n",
        "display(image)\n",
        "\n",
        "instances = [\n",
        "    {\"prompt\": \"placehoder\", \"image\": image_to_base64(image), \"motion_bucket_id\": 127}\n",
        "]\n",
        "\n",
        "# Convert and write JSON object to file\n",
        "os.makedirs(\"bath_prediction_input\", exist_ok=True)\n",
        "with open(\"bath_prediction_input/input.jsonl\", \"w\") as outfile:\n",
        "    for item in instances:\n",
        "        json_str = json.dumps(item)\n",
        "        outfile.write(json_str)\n",
        "        outfile.write(\"\\n\")\n",
        "\n",
        "upload_local_dir_to_gcs(\n",
        "    \"bath_prediction_input\", f\"gs://{GCS_BUCKET}/image_to_video/input\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzW5MsK7EEym"
      },
      "source": [
        "Upload model. For batch predictions, only model upload is needed. you don't need to deploy the model to any endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLnf_TukFuKc"
      },
      "outputs": [],
      "source": [
        "# @title Run batch prediction\n",
        "\n",
        "machine_type = \"n1-standard-32\"\n",
        "accelerator_type = \"NVIDIA_TESLA_P100\"\n",
        "accelerator_count = 2\n",
        "\n",
        "batch_prediction_job = model.batch_predict(\n",
        "    instances_format=\"jsonl\",\n",
        "    job_display_name=\"batch_predict_image_to_video\",\n",
        "    gcs_source=[f\"gs://{GCS_BUCKET}/image_to_video/input/input.jsonl\"],\n",
        "    gcs_destination_prefix=f\"gs://{GCS_BUCKET}/image_to_video/output\",\n",
        "    machine_type=machine_type,\n",
        "    accelerator_type=accelerator_type,\n",
        "    accelerator_count=accelerator_count,\n",
        "    starting_replica_count=1,\n",
        ")\n",
        "\n",
        "batch_prediction_job.wait()\n",
        "\n",
        "print(batch_prediction_job.display_name)\n",
        "print(batch_prediction_job.resource_name)\n",
        "print(batch_prediction_job.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTp_AMSUF4k3"
      },
      "outputs": [],
      "source": [
        "# @title Display results\n",
        "\n",
        "gcs_output_file = (\n",
        "    batch_prediction_job.output_info.gcs_output_directory\n",
        "    + \"/prediction.results-00000-of-00001\"\n",
        ")\n",
        "prediction_result = download_gcs_blob_as_json(gcs_output_file)\n",
        "\n",
        "\n",
        "html = \"\"\n",
        "html += \"<video controls width=500>\"\n",
        "html += f'<source src=\"data:video/mp4;base64,{prediction_result[\"prediction\"]}\" type=\"video/mp4\">'\n",
        "html += \"</video>\"\n",
        "HTML(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b53b883257b4"
      },
      "outputs": [],
      "source": [
        "# @title Delete model.\n",
        "model.delete()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_garden_pytorch_stable_video_diffusion_img2vid_xt.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
