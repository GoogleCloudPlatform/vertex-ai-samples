{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3069d95",
      "metadata": {
        "cellView": "form",
        "id": "d3069d95"
      },
      "outputs": [],
      "source": [
        "# @title Copyright & License (click to expand)\n",
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "546c53de",
      "metadata": {
        "id": "546c53de"
      },
      "source": [
        "# Vertex AI Batch Prediction with Model Monitoring\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_monitoring/batch_prediction_model_monitoring.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_monitoring/batch_prediction_model_monitoring.ipynb\">\n",
        "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53fd1070",
      "metadata": {
        "id": "53fd1070"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, you will learn how to use Model Monitoring with batch prediction requests on a deployed Vertex AI Model resource. In a companion notebook, <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\" target=\"_blank\">Vertex AI Model Monitoring with Explainable AI Feature Attributions</a>, you can learn about how to apply model monitoring to streaming, real-time predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b26c855",
      "metadata": {
        "id": "8b26c855"
      },
      "source": [
        "### Objective\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- Vertex AI Model Monitoring\n",
        "- Vertex AI Batch Prediction\n",
        "- Vertex AI Model resource\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Upload a pre-trained model as a Vertex AI Model resource.\n",
        "- Generate batch prediction requests.\n",
        "- Interpret the statistics, visualizations, other data reported by the model monitoring feature.\n",
        "\n",
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertext AI\n",
        "* Google Cloud Storage\n",
        "\n",
        "Learn about [Vertext AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d52ba95b",
      "metadata": {
        "id": "d52ba95b"
      },
      "source": [
        "### What is Vertex AI batch prediction?\n",
        "\n",
        "<a href=\"https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions\" target=\"_blank\">Batch Prediction</a> is a service that processes a collection (i.e. a batch) of machine learning inference requests in bulk, with less stringent response time requirements than real-time or streaming predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e64fb18a",
      "metadata": {
        "id": "e64fb18a"
      },
      "source": [
        "### What is Vertex AI model monitoring?\n",
        "\n",
        "<a href=\"https://cloud.google.com/vertex-ai/docs/model-monitoring\" target=\"_blank\">Model Monitoring</a> is a service that automatically determines \n",
        "whether production machine learning traffic differs from  training data, or varies substantially over time, in terms of model predictions or feature attributions. When that happens, you can be alerted automatically and responsively, whereby, you can detect model decay which may negatively impact your operations -- such as your customer experience and/or revenue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d839347",
      "metadata": {
        "id": "9d839347"
      },
      "source": [
        "### The example model\n",
        "\n",
        "The model you'll use in this notebook is based on [this blog post](https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game-developers-using-google-analytics-4-ga4-and-bigquery-ml). The idea behind this model is that your company has extensive log data describing how your game users have interacted with the site. The raw data contains the following categories of information:\n",
        "\n",
        "- identity - unique player identitity numbers\n",
        "- demographic features - information about the player, such as the geographic region in which a player is located\n",
        "- behavioral features - counts of the number of times a  player has triggered certain game events, such as reaching a new level\n",
        "- churn propensity - this is the label or target feature, it provides an estimated probability that this player will churn, i.e. stop being an active player.\n",
        "\n",
        "The blog article referenced above explains how to use BigQuery to store the raw data, pre-process it for use in machine learning, and train a model. Because this notebook focuses on model monitoring, rather than training models, you're going to reuse a pre-trained version of this model, which has been exported to Google Cloud Storage. In the next section, you will setup your environment and import this model into your own project."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "738fce1f",
      "metadata": {
        "id": "738fce1f"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the packages required for executing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4536fe4e",
      "metadata": {
        "id": "4536fe4e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "assert sys.version_info.major == 3, \"This notebook requires Python 3.\"\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "# Install Python package dependencies.\n",
        "! pip3 install -q tensorflow-data-validation $USER_FLAG\n",
        "! pip3 install -q google-api-core $USER_FLAG\n",
        "! pip3 install -q google-cloud-aiplatform $USER_FLAG"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e98402b",
      "metadata": {
        "id": "6e98402b"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the SDK, you need to restart the notebook kernel so it can find the packages. You can restart kernel from *Kernel -> Restart Kernel*, or running the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9775c9ff",
      "metadata": {
        "id": "9775c9ff"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5737134",
      "metadata": {
        "id": "d5737134"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb1a1d5",
      "metadata": {
        "id": "cfb1a1d5"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8535e4",
      "metadata": {
        "id": "cf8535e4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a2d397",
      "metadata": {
        "id": "05a2d397"
      },
      "source": [
        "Otherwise, set your project ID here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2be4bd",
      "metadata": {
        "id": "1c2be4bd"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"python-docs-samples-tests\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c129705c",
      "metadata": {
        "id": "c129705c"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71404c9f",
      "metadata": {
        "id": "71404c9f"
      },
      "source": [
        "#### Set your email address\n",
        "This is used for delivering model monitoring notifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1d2b69",
      "metadata": {
        "id": "4b1d2b69"
      },
      "outputs": [],
      "source": [
        "EMAIL_ADDRESS = \"[your-email-address]\"  # @param {type:\"string\"}\n",
        "if not EMAIL_ADDRESS or EMAIL_ADDRESS == \"[your-email-address]\":\n",
        "    print(\"EMAIL_ADDRESS not specified, please correct before proceeding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83340af4",
      "metadata": {
        "id": "83340af4"
      },
      "source": [
        "#### Set your region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4814ea21",
      "metadata": {
        "id": "4814ea21"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a546c3",
      "metadata": {
        "id": "20a546c3"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Vertex AI Workbench notebooks**, your environment is already\n",
        "authenticated. Skip this step.\n",
        "\n",
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c51076",
      "metadata": {
        "id": "06c51076"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Determine notebook environment.\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "if not IS_WORKBENCH_NOTEBOOK and not IS_USER_MANAGED_WORKBENCH_NOTEBOOK:\n",
        "    if IS_COLAB:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b01af18",
      "metadata": {
        "id": "6b01af18"
      },
      "source": [
        "### Upload the model\n",
        "\n",
        "The churn propensity model you'll be using in this notebook has been trained in BigQuery ML and exported to a Google Cloud Storage bucket. This illustrates how you can easily export a trained model and move a model from one cloud service to another. \n",
        "\n",
        "Next, import the model. **If you've already imported your model, you can skip this step.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9638ad2c",
      "metadata": {
        "id": "9638ad2c"
      },
      "source": [
        "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926e3ba8",
      "metadata": {
        "id": "926e3ba8"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "from tensorflow_data_validation.utils import io_util \n",
        "from tensorflow_metadata.proto.v0 import statistics_pb2\n",
        "\n",
        "MODEL_DISPLAY_NAME=f\"batch_prediction_monitoring_test_model_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
        "CONTAINER_IMAGE_URI=\"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-4:latest\"\n",
        "ARTIFACT_URI=\"gs://mco-mm/churn\"\n",
        "\n",
        "output = ! gcloud ai models upload \\\n",
        "  --region=$REGION \\\n",
        "  --display-name=$MODEL_DISPLAY_NAME \\\n",
        "  --artifact-uri=$ARTIFACT_URI \\\n",
        "  --container-image-uri=$CONTAINER_IMAGE_URI \\\n",
        "  --format=\"value(model)\"\n",
        "MODEL_ID = output[1].split(\"/\")[5]\n",
        "print(f\"Model {MODEL_ID} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4305ddf",
      "metadata": {
        "id": "a4305ddf"
      },
      "source": [
        "## Submit a batch prediction request with model monitoring enabled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "053fde99",
      "metadata": {
        "id": "053fde99"
      },
      "source": [
        "### Create Cloud Storage buckets\n",
        "\n",
        "This cell creates two Cloud Storage buckets:\n",
        "\n",
        "- `gs://PROJECT_ID_bp_mm_input` contains the batch prediction request data.\n",
        "- `gs://PROJECT_ID_bp_mm_output` contains the batch prediction output as well as the model monitoring results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b832ad31",
      "metadata": {
        "id": "b832ad31"
      },
      "outputs": [],
      "source": [
        "# Copy files to your projects gs bucket to avoid permission issues.\n",
        "# Ignore any error(s) for bucket already exists.\n",
        "OUTPUT_GS_PATH = f\"gs://{PROJECT_ID.replace('-', '_')}_bp_mm_output\"\n",
        "INPUT_GS_PATH = f\"gs://{PROJECT_ID.replace('-', '_')}_bp_mm_input\"\n",
        "PUBLIC_TRAINING_DATASET = \"gs://bp_mm_public_data/churn/churn_bp_insample.csv\"\n",
        "TRAINING_DATASET = f\"{INPUT_GS_PATH}/churn_bp_insample.csv\"\n",
        "TRAINING_DATASET_FORMAT = \"csv\"\n",
        "\n",
        "! gsutil mb -p {PROJECT_ID} -l {REGION} -b on {INPUT_GS_PATH}\n",
        "! gsutil mb -p {PROJECT_ID} -l {REGION} -b on {OUTPUT_GS_PATH}\n",
        "! gsutil copy $PUBLIC_TRAINING_DATASET $INPUT_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34c95126",
      "metadata": {
        "id": "34c95126"
      },
      "source": [
        "### Create batch prediction job\n",
        "\n",
        "This step parameterizes and builds the data structure representing the batch prediction request, with model monitoring enabled.\n",
        "\n",
        "The BatchPredictionJob object specifies the input source, the data format, and the computing resources requests for the batch prediction. Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/samples/aiplatform-create-batch-prediction-job-sample\" target=\"_blank\">BatchPredictionJob</a>.\n",
        "\n",
        "The ModelMonitoringConfig object specifies the alerting email address, the training dataset, the features to be monitored, and their associated alerting thresholds. Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/model-monitoring\" target=\"_blank\">ModelMonitoringConfig</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a54368a",
      "metadata": {
        "id": "3a54368a"
      },
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "INPUT_URI = \"gs://bp_mm_public_data/churn/churn_bp_outsample.jsonl\"\n",
        "OUTPUT_URI = OUTPUT_GS_PATH\n",
        "INSTANCES_FORMAT = \"jsonl\"\n",
        "PREDICTIONS_FORMAT = \"jsonl\"\n",
        "JOB_NAME_PREFIX = \"bp_mm_demo\"\n",
        "MODEL_NAME = f\"projects/{PROJECT_ID}/locations/{REGION}/models/{MODEL_ID}\"\n",
        "MACHINE_TYPE = \"n1-standard-8\"\n",
        "BATCH_PREDICTION_JOB_NAME = JOB_NAME_PREFIX + \"_\" + now.strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "from google.cloud.aiplatform_v1beta1.types import (\n",
        "    BatchDedicatedResources, BatchPredictionJob, GcsDestination, GcsSource,\n",
        "    MachineSpec, ModelMonitoringAlertConfig, ModelMonitoringConfig,\n",
        "    ModelMonitoringObjectiveConfig, ThresholdConfig)\n",
        "\n",
        "batch_prediction_job = BatchPredictionJob(\n",
        "    display_name=BATCH_PREDICTION_JOB_NAME,\n",
        "    model=MODEL_NAME,\n",
        "    input_config=BatchPredictionJob.InputConfig(\n",
        "        instances_format=INSTANCES_FORMAT, gcs_source=GcsSource(uris=[INPUT_URI])\n",
        "    ),\n",
        "    output_config=BatchPredictionJob.OutputConfig(\n",
        "        predictions_format=PREDICTIONS_FORMAT,\n",
        "        gcs_destination=GcsDestination(output_uri_prefix=OUTPUT_URI),\n",
        "    ),\n",
        "    dedicated_resources=BatchDedicatedResources(\n",
        "        machine_spec=MachineSpec(machine_type=MACHINE_TYPE),\n",
        "        starting_replica_count=1,\n",
        "        max_replica_count=1,\n",
        "    ),\n",
        "    # Model monitoring service will be triggerred if provide following configs.\n",
        "    model_monitoring_config=ModelMonitoringConfig(\n",
        "        alert_config=ModelMonitoringAlertConfig(\n",
        "            email_alert_config=ModelMonitoringAlertConfig.EmailAlertConfig(\n",
        "                user_emails=[EMAIL_ADDRESS]\n",
        "            )\n",
        "        ),\n",
        "        objective_configs=[\n",
        "            ModelMonitoringObjectiveConfig(\n",
        "                training_dataset=ModelMonitoringObjectiveConfig.TrainingDataset(\n",
        "                    data_format=TRAINING_DATASET_FORMAT,\n",
        "                    gcs_source=GcsSource(uris=[TRAINING_DATASET]),\n",
        "                ),\n",
        "                training_prediction_skew_detection_config=ModelMonitoringObjectiveConfig.TrainingPredictionSkewDetectionConfig(\n",
        "                    skew_thresholds={\n",
        "                        \"cnt_user_engagement\": ThresholdConfig(value=0.001),\n",
        "                        \"julianday\": ThresholdConfig(value=0.001),\n",
        "                    }\n",
        "                ),\n",
        "            )\n",
        "        ],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae39778",
      "metadata": {
        "id": "cae39778"
      },
      "source": [
        "### Submit batch prediction job\n",
        "\n",
        "This step submits the batch prediction request created in the previous step. If successful, it returns a JSON document summarizing the request, which is displayed in the cell output below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcdd4a47",
      "metadata": {
        "id": "bcdd4a47"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform_v1beta1.services.job_service import \\\n",
        "    JobServiceClient\n",
        "\n",
        "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
        "client = JobServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
        "out = client.create_batch_prediction_job(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
        "    batch_prediction_job=batch_prediction_job,\n",
        ")\n",
        "BATCH_PREDICTION_JOB_ID = out.name.split(\"/\")[-1]\n",
        "print(\"BATCH_PREDICTION_JOB_ID:\", BATCH_PREDICTION_JOB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ec90a0",
      "metadata": {
        "id": "49ec90a0"
      },
      "source": [
        "## Verify prediction results\n",
        "\n",
        "The batch prediction request will be completed after about **17 mins**, and the model monitoring result will be available **10 mins** after that. The request below obtains the batch prediction job id, which is a unique number associated with asynchronous requests like this one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c30496b5",
      "metadata": {
        "id": "c30496b5"
      },
      "outputs": [],
      "source": [
        "# If auto-testing, wait for request completion\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    time.sleep(1800)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831651c2",
      "metadata": {
        "id": "831651c2"
      },
      "source": [
        "### Browse storage bucket\n",
        "\n",
        "Click on the link below, which opens the Cloud Storage object viewer on the output bucket you created above, to see the results of your batch prediction request.\n",
        "\n",
        "When everything is ready, you'll see two folders in this bucket (the precise names will vary):\n",
        "\n",
        "- `prediction-batch_prediction_monitoring_test_model_20220714100939-2022_07_14T03_10_10_069Z` - this folder contains the your batch prediction results, i.e. the predictions produced by your model for each input in the batch\n",
        "- `job-8794345073597743104` - this folder contains the model monitoring results, including the model schema, monitoring thresholds and other config settings, statistics, and anomalies\n",
        "\n",
        "*Note:* that until the request and the monitoring job are completed, you may see empty or partial results in this bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a705c10b",
      "metadata": {
        "id": "a705c10b"
      },
      "outputs": [],
      "source": [
        "print(f\"https://console.cloud.google.com/storage/browser/{OUTPUT_URI.lstrip('gs://')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbdddac",
      "metadata": {
        "id": "2bbdddac"
      },
      "source": [
        "### Visualize the batch prediction result\n",
        "\n",
        "Run the following cell to examine the batch prediction results with a tabular and visual analysis using the <a href=\"https://www.tensorflow.org/tfx/data_validation/get_started\" target=\"_blank\">TensorFlow Data Validation</a> package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c674e9",
      "metadata": {
        "id": "f6c674e9"
      },
      "outputs": [],
      "source": [
        "! rm -f ./training_stats.pb\n",
        "! rm -f ./prediction_stats.pb\n",
        "\n",
        "TRAINING_STATS_SUBPATH = \"stats_training/stats/training_stats\"\n",
        "PREDICTION_STATS_SUBPATH = \"stats_and_anomalies/stats/current_stats\"\n",
        "STATS_GCS_FOLDER = OUTPUT_URI = (\n",
        "    OUTPUT_GS_PATH + \"/job-\" + BATCH_PREDICTION_JOB_ID + \"/bp_monitoring/\"\n",
        ")\n",
        "TRAINING_STATS_GCS_PATH = STATS_GCS_FOLDER + TRAINING_STATS_SUBPATH\n",
        "print(\"Looking up statistics from: \" + TRAINING_STATS_GCS_PATH)\n",
        "PREDICTION_STATS_GCS_PATH = STATS_GCS_FOLDER + PREDICTION_STATS_SUBPATH\n",
        "print(\"Looking up statistics from: \" + PREDICTION_STATS_GCS_PATH)\n",
        "\n",
        "! gsutil cp $TRAINING_STATS_GCS_PATH ./training_stats.pb\n",
        "! gsutil cp $PREDICTION_STATS_GCS_PATH ./prediction_stats.pb\n",
        "\n",
        "\n",
        "# util function to load stats binary file from GCS\n",
        "def load_stats_binary(input_path):\n",
        "    stats_proto = statistics_pb2.DatasetFeatureStatisticsList()\n",
        "    stats_proto.ParseFromString(\n",
        "        io_util.read_file_to_string(input_path, binary_mode=True)\n",
        "    )\n",
        "    return stats_proto\n",
        "\n",
        "\n",
        "tfdv.visualize_statistics(load_stats_binary(\"./training_stats.pb\"))\n",
        "tfdv.visualize_statistics(load_stats_binary(\"./prediction_stats.pb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233b1266",
      "metadata": {
        "id": "233b1266"
      },
      "source": [
        "### Check skew results\n",
        "\n",
        "Finally, you can check the skew results by examining a file in the output bucket. The JSON file contains a report indicating how much the batch prediction data deviates from the training data, on a feature-by-feature basis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8c00a7",
      "metadata": {
        "id": "4e8c00a7"
      },
      "outputs": [],
      "source": [
        "SKEW_GS_PATH = (\n",
        "    STATS_GCS_FOLDER\n",
        "    + \"stats_and_anomalies/anomalies/training_prediction_skew_anomalies\"\n",
        ")\n",
        "! gsutil cat $SKEW_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497a0016",
      "metadata": {
        "id": "497a0016"
      },
      "source": [
        "## Clean up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabc3f81",
      "metadata": {
        "id": "eabc3f81"
      },
      "outputs": [],
      "source": [
        "# Delete model resource\n",
        "! gcloud ai models delete $MODEL_NAME --quiet\n",
        "\n",
        "# Delete Cloud Storage resources\n",
        "! gsutil -m rm -r $INPUT_GS_PATH\n",
        "! gsutil -m rm -r $OUTPUT_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa0219d",
      "metadata": {
        "id": "0aa0219d"
      },
      "source": [
        "## Learn more...\n",
        "\n",
        "**Congratulations!** You've now learned how to monitor batch predictions, and how to find and interpret the results. Check out the following resources to learn more about model monitoring and ML Ops.\n",
        "\n",
        "- [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv)\n",
        "- [Data Understanding, Validation, and Monitoring At Scale](https://blog.tensorflow.org/2018/09/introducing-tensorflow-data-validation.html)\n",
        "- [Vertex Product Documentation](https://cloud.google.com/vertex-ai)\n",
        "- [Vertex AI Model Monitoring Reference Docs](https://cloud.google.com/vertex-ai/docs/reference)\n",
        "- [Vertex AI Model Monitoring blog article](https://cloud.google.com/blog/topics/developers-practitioners/monitor-models-training-serving-skew-vertex-ai)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "batch_prediction_model_monitoring.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
