{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX2wUzd3gjTc"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Video Warehouse SDK Demo\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vision/video_warehouse_sdk.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vision/video_warehouse_sdk.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>                                                                                         \n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/vision/video_warehouse_sdk.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI8d5ytBhfuw"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENEut1m0h3Uo"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Learn how to build a [Video Warehouse](https://cloud.google.com/vision-ai/docs) step by step by using SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMF4pbEIuZS2"
      },
      "source": [
        "### Objective\n",
        "The objective is to demostrate how to use Warehouse SDK to process input videos, index and search.\n",
        "\n",
        "The steps to perform include:\n",
        "\n",
        "* Create corpus.\n",
        "\n",
        "* Create and upload assets using video files from Google Cloud Storage.\n",
        "\n",
        "* Create index, create index endpoint, and deploy index.\n",
        "  * This step can take an hour.\n",
        "\n",
        "* Run transformations to analyze the assets:\n",
        "  * Speech transformation\n",
        "    * Use Video intelligence API to run speech transcription and store into warehouse. By default, the speech result can be searched with criteria with \"speech\" field. You can specify the search criteria field by setting speech_transcript_search_criteria_key in SpeechTransformerInitConfig.\n",
        "  * OCR transformation\n",
        "    * Use Video intelligence API to run text detection and store into warehouse. By default, the text detection result can be searched with criteria with \"text\" field. Specify the search criteria field by setting ocr_search_criteria_key in OcrTransformerInitConfig.\n",
        "  * Embedding analysis\n",
        "\n",
        "* Index.\n",
        "\n",
        "* Search.\n",
        "\n",
        "* Clean up resources (assets, index, index endpoint, corpus).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzdLmFrajntF"
      },
      "source": [
        "### Dataset\n",
        "The dataset will use a collection of videos stored in a Google Cloud Storage bucket: [gs://cloud-samples-data/video](https://pantheon.corp.google.com/storage/browser/cloud-samples-data/video).\n",
        "\n",
        "This tutorial shows how to use warehouse SDK to run speech transcription, text detection, embedding analysis for the videos of this dataset, builds search index and provides search capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQV4SMLUqchE"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "Vertex AI Vision ([Pricing](https://cloud.google.com/vision-ai/pricing))\n",
        "\n",
        "Video Intelligence ([Pricing](https://cloud.google.com/video-intelligence/pricing))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ZDs2SUq0DN"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DWuFFA_wUtL"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://visionai-artifacts/visionai-0.0.6-py3-none-any.whl .\n",
        "!pip install visionai-0.0.6-py3-none-any.whl --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeRSrNTGZVBJ"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3i7BDALZqeQ"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOkFz5v6Z5mL"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXNewDH2wkV-"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixfp-_Ne09EK"
      },
      "source": [
        "### Set Up Other Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBCHXC3uhrQo"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER_STR = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
        "PROJECT_NUMBER = int(PROJECT_NUMBER_STR[0])\n",
        "\n",
        "# Only us-central1 is supported.\n",
        "# Please note that this region is for VisionAi services. For speech\n",
        "# transcription, we may not respect the region here.\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "CORPUS_DISPLAY_NAME = \"Demo corpus\"  # @param {type: \"string\"}\n",
        "CORPUS_DESCRIPTION = \"Demo corpus to demo warehouse transformations and search\"  # @param {type: \"string\"}\n",
        "\n",
        "# External users can only access PROD environment.\n",
        "ENV = \"PROD\"\n",
        "\n",
        "INDEX_DISPLAY_NAME = \"Demo Index\"  # @param {type: \"string\"}\n",
        "INDEX_ENDPOINT_DISPLAY_NAME = \"Demo Index Endpoint\"  # @param {type: \"string\"}\n",
        "\n",
        "CLEAN_UP_ASSETS = True  # @param {type: \"boolean\"}\n",
        "CLEAN_UP_INDEX = True  # @param {type: \"boolean\"}\n",
        "CLEAN_UP_CORPUS = True  # @param {type: \"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4aFiWRihds8"
      },
      "source": [
        "### Whether Using Existing Corpus and Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOhXWtfjhxuz"
      },
      "outputs": [],
      "source": [
        "# Because it takes ~1h to create and deploy index. A existing index can be\n",
        "# specified to save time.\n",
        "\n",
        "# If CORPUS_ID is specified, skip creating a new corpus.\n",
        "CORPUS_ID = None  # @param {type: \"string\"}\n",
        "# If DEPLOYED_INDEX_ID is specified, use existing index instead of creating and\n",
        "# deploying a new index.\n",
        "DEPLOYED_INDEX_ID = None  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUDxEpztitwN"
      },
      "source": [
        "### Input Video Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYgf32fogKHa"
      },
      "outputs": [],
      "source": [
        "GCS_FILES = [\n",
        "    \"gs://cloud-samples-data/video/animals.mp4\",\n",
        "    \"gs://cloud-samples-data/video/googlework_short.mp4\",\n",
        "    \"gs://cloud-samples-data/video/chicago.mp4\",\n",
        "    (\n",
        "        \"gs://cloud-samples-data/video/Machine Learning Solving Problems\"\n",
        "        \" Big, Small, and Prickly.mp4\"\n",
        "    ),\n",
        "    \"gs://cloud-samples-data/video/JaneGoodall.mp4\",\n",
        "    \"gs://cloud-samples-data/video/gbikes_dinosaur.mp4\",\n",
        "    \"gs://cloud-samples-data/video/pizza.mp4\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxXIz2fhpbe3"
      },
      "source": [
        "### Enable API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBV1hcV_spkd"
      },
      "outputs": [],
      "source": [
        "!gcloud services enable videointelligence.googleapis.com\n",
        "!gcloud services enable visionai.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAZP-f1LhLpY"
      },
      "source": [
        "### Config logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgumkNAeoBGg"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "_logger = logging.getLogger(\"colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtpK3kCfhRQ5"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b74iOAaMynQT"
      },
      "outputs": [],
      "source": [
        "import concurrent\n",
        "import logging\n",
        "\n",
        "from visionai.python.gapic.visionai import visionai_v1\n",
        "from visionai.python.net import channel\n",
        "from visionai.python.warehouse.transformer import \\\n",
        "    asset_indexing_transformer as ait\n",
        "from visionai.python.warehouse.transformer import (ocr_transformer,\n",
        "                                                   speech_transformer,\n",
        "                                                   transformer_factory)\n",
        "from visionai.python.warehouse.utils import (vod_asset, vod_corpus,\n",
        "                                             vod_index_endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D78bPt9wftNS"
      },
      "source": [
        "## Create Warehouse client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjBTqlAricqz"
      },
      "outputs": [],
      "source": [
        "warehouse_endpoint = channel.get_warehouse_service_endpoint(channel.Environment[ENV])\n",
        "warehouse_client = visionai_v1.WarehouseClient(\n",
        "    client_options={\"api_endpoint\": warehouse_endpoint}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsJVdL9if-cK"
      },
      "source": [
        "## Create a Corpus or use existing Corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEVMGRjuf5oJ"
      },
      "outputs": [],
      "source": [
        "if CORPUS_ID is None:\n",
        "    corpus_name = vod_corpus.create_corpus(\n",
        "        warehouse_client,\n",
        "        PROJECT_NUMBER,\n",
        "        REGION,\n",
        "        CORPUS_DISPLAY_NAME,\n",
        "        CORPUS_DESCRIPTION,\n",
        "    ).name\n",
        "else:\n",
        "    corpus_name = visionai_v1.WarehouseClient.corpus_path(\n",
        "        PROJECT_NUMBER, REGION, CORPUS_ID\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TuwJWZtiAXF"
      },
      "source": [
        "## Create an Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXh9TlJv9Ayz"
      },
      "outputs": [],
      "source": [
        "# Creates an executor to upload and transform assets in parallel.\n",
        "executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aifUauuriHMm"
      },
      "source": [
        "## Create and Upload Assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZWKPBR_yHIF"
      },
      "outputs": [],
      "source": [
        "new_asset_futures = []\n",
        "for gcs_file in GCS_FILES:\n",
        "    new_asset_futures.append(\n",
        "        executor.submit(\n",
        "            vod_asset.create_and_upload_asset,\n",
        "            warehouse_client,\n",
        "            gcs_file,\n",
        "            corpus_name,\n",
        "        )\n",
        "    )\n",
        "done_or_error, _ = concurrent.futures.wait(\n",
        "    new_asset_futures, return_when=\"ALL_COMPLETED\"\n",
        ")\n",
        "asset_names = []\n",
        "for done_future in done_or_error:\n",
        "    try:\n",
        "        asset_names.append(done_future.result())\n",
        "        _logger.info(\"Create and upload asset succeeded %s\", done_future.result())\n",
        "    except Exception as e:\n",
        "        _logger.exception(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICZAwBuyiMpM"
      },
      "source": [
        "## Prepare Index or use existing Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJpefxMzl4FM"
      },
      "outputs": [],
      "source": [
        "# Create index and index endpoint for the corpus, or use existing index\n",
        "# and index endpoint if specified.\n",
        "if DEPLOYED_INDEX_ID is None:\n",
        "    # Creates index for the corpus.\n",
        "    index_name = vod_corpus.index_corpus(\n",
        "        warehouse_client, corpus_name, INDEX_DISPLAY_NAME\n",
        "    )\n",
        "    # Creates index endpoint and deploys the created index above to the index\n",
        "    # endpoint.\n",
        "    index_endpoint_name = vod_index_endpoint.create_index_endpoint(\n",
        "        warehouse_client,\n",
        "        PROJECT_NUMBER,\n",
        "        REGION,\n",
        "        INDEX_ENDPOINT_DISPLAY_NAME,\n",
        "    ).name\n",
        "    deploy_operation = warehouse_client.deploy_index(\n",
        "        visionai_v1.DeployIndexRequest(\n",
        "            index_endpoint=index_endpoint_name,\n",
        "            deployed_index=visionai_v1.DeployedIndex(\n",
        "                index=index_name,\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    _logger.info(\"Wait for index to be deployed %s.\", deploy_operation.operation.name)\n",
        "    # Wait for the deploy index operation. Depends on the data size to be\n",
        "    # indexed, the timeout may need to be increased.\n",
        "    deploy_operation.result(timeout=7200)\n",
        "    _logger.info(\"Index is deployed.\")\n",
        "else:\n",
        "    index_name = \"{}/indexes/{}\".format(corpus_name, DEPLOYED_INDEX_ID)\n",
        "    index = warehouse_client.get_index(visionai_v1.GetIndexRequest(name=index_name))\n",
        "    _logger.info(\"Use existing index %s.\", index)\n",
        "    if index.state != visionai_v1.Index.State.CREATED:\n",
        "        _logger.critical(\"Invalid index. The index state must be Created.\")\n",
        "    if not index.deployed_indexes:\n",
        "        _logger.critical(\"Invalid index. The index must be deployed.\")\n",
        "    index_endpoint_name = index.deployed_indexes[0].index_endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw6l8UYiiYy3"
      },
      "source": [
        "## Run Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPp5LV0-x4ZS"
      },
      "outputs": [],
      "source": [
        "ocr_config = ocr_transformer.OcrTransformerInitConfig(\n",
        "    corpus_name=corpus_name,\n",
        "    env=channel.Environment[ENV],\n",
        ")\n",
        "\n",
        "ml_config = transformer_factory.MlTransformersCreationConfig(\n",
        "    run_embedding=True,\n",
        "    speech_transformer_init_config=speech_transformer.SpeechTransformerInitConfig(\n",
        "        corpus_name=corpus_name, language_code=\"en-US\"\n",
        "    ),\n",
        "    ocr_transformer_init_config=ocr_config,\n",
        ")\n",
        "ml_transformers = transformer_factory.create_ml_transformers(\n",
        "    warehouse_client, ml_config\n",
        ")\n",
        "# Creates indexing transformer to index assets.\n",
        "asset_indexing_transformer = ait.AssetIndexingTransformer(warehouse_client, index_name)\n",
        "# Runs the transformers for the assets.\n",
        "futures = []\n",
        "\n",
        "for asset_name in asset_names:\n",
        "    futures.append(\n",
        "        executor.submit(\n",
        "            vod_asset.transform_single_asset,\n",
        "            asset_name,\n",
        "            ml_transformers,\n",
        "            asset_indexing_transformer,\n",
        "        )\n",
        "    )\n",
        "done_or_error, _ = concurrent.futures.wait(futures, return_when=\"ALL_COMPLETED\")\n",
        "for future in done_or_error:\n",
        "    try:\n",
        "        future.result()\n",
        "    except Exception as e:\n",
        "        _logger.exception(e)\n",
        "\n",
        "all_transformers = ml_transformers + [asset_indexing_transformer]\n",
        "for transformer in all_transformers:\n",
        "    transformer.teardown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BstsgXbnij2I"
      },
      "source": [
        "## Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKlKYnA7hEPT"
      },
      "outputs": [],
      "source": [
        "search_response = warehouse_client.search_index_endpoint(\n",
        "    visionai_v1.SearchIndexEndpointRequest(\n",
        "        index_endpoint=index_endpoint_name,\n",
        "        text_query=\"dinosaur\",\n",
        "        page_size=10,\n",
        "    )\n",
        ")\n",
        "_logger.info(\"Search response: %s\", search_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0znp7rq8PvS"
      },
      "outputs": [],
      "source": [
        "cr = visionai_v1.Criteria(\n",
        "    field=\"speech\", text_array=visionai_v1.StringArray(txt_values=[\"kid\"])\n",
        ")\n",
        "search_response = warehouse_client.search_index_endpoint(\n",
        "    visionai_v1.SearchIndexEndpointRequest(\n",
        "        index_endpoint=index_endpoint_name,\n",
        "        text_query=\"river\",\n",
        "        criteria=[cr],\n",
        "        page_size=100,\n",
        "    )\n",
        ")\n",
        "_logger.info(\"Search response: %s\", search_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ypuAtP0E8y-"
      },
      "outputs": [],
      "source": [
        "cr = visionai_v1.Criteria(\n",
        "    field=\"text\", text_array=visionai_v1.StringArray(txt_values=[\"National Park\"])\n",
        ")\n",
        "search_response = warehouse_client.search_index_endpoint(\n",
        "    visionai_v1.SearchIndexEndpointRequest(\n",
        "        index_endpoint=index_endpoint_name,\n",
        "        text_query=\"trees\",\n",
        "        criteria=[cr],\n",
        "        page_size=100,\n",
        "    )\n",
        ")\n",
        "_logger.info(\"Search response: %s\", search_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NZsfKd2djB4"
      },
      "source": [
        "## Cleaning up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZt1pXWfsaAt"
      },
      "outputs": [],
      "source": [
        "if CLEAN_UP_ASSETS:\n",
        "    for asset_name in asset_names:\n",
        "        warehouse_client.delete_asset(visionai_v1.DeleteAssetRequest(name=asset_name))\n",
        "        _logger.info(\"Deleted asset %s\", asset_name)\n",
        "\n",
        "if CLEAN_UP_INDEX:\n",
        "    undeploy_operation = warehouse_client.undeploy_index(\n",
        "        visionai_v1.UndeployIndexRequest(index_endpoint=index_endpoint_name)\n",
        "    )\n",
        "    _logger.info(\n",
        "        \"Wait for index to be undeployed %s.\",\n",
        "        undeploy_operation.operation.name,\n",
        "    )\n",
        "    # Wait for the undeploy index operation.\n",
        "    undeploy_operation.result(timeout=1800)\n",
        "    _logger.info(\"Index is undeployed.\")\n",
        "    warehouse_client.delete_index(visionai_v1.DeleteIndexRequest(name=index_name))\n",
        "    _logger.info(\"Deleted index %s\", index_name)\n",
        "    warehouse_client.delete_index_endpoint(\n",
        "        visionai_v1.DeleteIndexEndpointRequest(name=index_endpoint_name)\n",
        "    )\n",
        "    _logger.info(\"Deleted index endpoint %s\", index_endpoint_name)\n",
        "\n",
        "if CLEAN_UP_CORPUS:\n",
        "    warehouse_client.delete_corpus(visionai_v1.DeleteCorpusRequest(name=corpus_name))\n",
        "    _logger.info(\"Deleted corpus %s\", corpus_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "video_warehouse_sdk.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
