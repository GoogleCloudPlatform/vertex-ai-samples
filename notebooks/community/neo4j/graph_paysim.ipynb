{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph_paysim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpj6twWatL1e"
      },
      "source": [
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/benofben/vertex-ai-samples/blob/master/notebooks/community/neo4j/graph_paysim.ipynb\" target=\"_blank\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/benofben/vertex-ai-samples/tree/master/notebooks/community/neo4j/graph_paysim.ipynb\" target=\"_blank\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YasYy1BqRHY8"
      },
      "source": [
        "# Overview\n",
        "This notebook is an example of using Neo4j with Vertex AI.  It takes PaySim data from a Neo4j database, then puts that into Vertex AI Feature Store.  It  also runs a classification on the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4-nDLfK4pw"
      },
      "source": [
        "## Dataset\n",
        "The notebook uses a version of the PaySim dataset that has been modified to work with Neo4j's graph database.  PaySim is a synthetic fraud dataset.  The goal is to identify whether or not a given transaction constitutes fraud.  The [original version of the dataset](https://github.com/EdgarLopezPhD/PaySim) has tabular data.\n",
        "\n",
        "Neo4j has worked on a modified version that generates a graph dataset [here](https://github.com/voutilad/PaySim).  We've pregenerated a copy of that dataset that you can grab [here](https://storage.googleapis.com/neo4j-datasets/paysim.dump).  You'll want to download that dataset and then upload it to Neo4j AuraDS.  AuraDS is a graph data science tool that is offered as a service on GCP.  Instructions on signing up and uploading the dataset are available [here](https://github.com/neo4j-partners/aurads-paysim)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhXY4QkGraog"
      },
      "source": [
        "##Objective\n",
        "In this notebook, you will learn how to use Neo4j AuraDS to create graph features.  You'll then use those new features to solve a classification problem with Vertex AI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD0fZLPdsAYf"
      },
      "source": [
        "##Costs\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Cloud Storage\n",
        "* Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbIYWyMksbpC"
      },
      "source": [
        "##Set up your development environment\n",
        "We suggest you use Colab for this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLocKiyCwtR7"
      },
      "source": [
        "## Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKipBL0kWY7w"
      },
      "source": [
        "## Install additional Packages\n",
        "We assume that you've already loaded the PaySim data into a Neo4j instance and have the credentials to connect to that.\n",
        "\n",
        "You'll also need to install a few packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwKogqD_He_e",
        "outputId": "ed31a367-2c5e-47ec-b97f-1f69f587d1de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install neo4j"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neo4j\n",
            "  Downloading neo4j-4.4.0.tar.gz (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from neo4j) (2018.9)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-4.4.0-py3-none-any.whl size=114860 sha256=e7cb25181483e669711142c351931aeb8ae22b47999aece36b479358125b6a0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/cb/e4/d34e10b40d33911c281a6e9aa038d54ca7435310529b3f6042\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix0KpBl-hnxF",
        "outputId": "a6b3cf24-dc25-4dbc-94a4-c1dc208f9716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade google-cloud-storage google.cloud.aiplatform"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-1.42.3-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting google.cloud.aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.7.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n",
            "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.2.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-api-core<3.0dev,>=1.29.0\n",
            "  Downloading google_api_core-2.2.2-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting google-resumable-media<3.0dev,>=1.3.0\n",
            "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.7.2)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n",
            "Collecting proto-plus>=1.10.1\n",
            "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google.cloud.aiplatform) (1.21.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google.cloud.aiplatform) (21.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google.cloud.aiplatform) (1.26.3)\n",
            "Collecting grpcio-status<2.0dev,>=1.33.2\n",
            "  Downloading grpcio_status-1.41.1-py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.41.1)\n",
            "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
            "  Downloading google_cloud_bigquery-2.30.1-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google.cloud.aiplatform) (2.8.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google.cloud.aiplatform) (2.4.7)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-3.19.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: protobuf, grpcio-status, google-crc32c, google-api-core, proto-plus, google-resumable-media, google-cloud-core, google-cloud-storage, google-cloud-bigquery, google.cloud.aiplatform\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.26.3\n",
            "    Uninstalling google-api-core-1.26.3:\n",
            "      Successfully uninstalled google-api-core-1.26.3\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 1.21.0\n",
            "    Uninstalling google-cloud-bigquery-1.21.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.30.1 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.2.2 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.2.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.2.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.2.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.2.2 which is incompatible.\n",
            "google-api-python-client 1.12.8 requires google-api-core<2dev,>=1.21.0, but you have google-api-core 2.2.2 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed google-api-core-2.2.2 google-cloud-bigquery-2.30.1 google-cloud-core-2.2.1 google-cloud-storage-1.42.3 google-crc32c-1.3.0 google-resumable-media-2.1.0 google.cloud.aiplatform-1.7.1 grpcio-status-1.41.1 proto-plus-1.19.8 protobuf-3.19.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXAh7fVt9Ou"
      },
      "source": [
        "##Restart the kernel\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpNk1MvcWY7x"
      },
      "source": [
        "## Working with Neo4j\n",
        "In this section we're going to connect to Neo4j and look around the database.  We're going to generate some new features in the dataset using Neo4j's Graph Data Science library.  Finally, we'll load the data into a Pandas dataframe so that it's all ready to put into GCP Feature Store.\n",
        "\n",
        "You'll need to enter the credentials for your Aura DS instance below.  Some example credentials are shown below.  You can get your credentials by following this [walkthrough](https://github.com/neo4j-partners/aurads-paysim).\n",
        "\n",
        "The \"DB_NAME\" is always neo4j for AuraDS.  It is different from the name you gave your database tenant in the AuraDS console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPePBuOA4pMx"
      },
      "source": [
        "DB_ULR = 'neo4j+s://df9cad2b.databases.neo4j.io'\n",
        "DB_USER = 'neo4j'\n",
        "DB_PASS = 'password'\n",
        "DB_NAME = 'neo4j'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiFDi4uLWY7x"
      },
      "source": [
        "import pandas as pd\n",
        "from neo4j import GraphDatabase"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgEy4q7iWY7y"
      },
      "source": [
        "driver = GraphDatabase.driver(DB_ULR, auth=(DB_USER, DB_PASS))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBpL6dY3HEMD"
      },
      "source": [
        "Now, let's explore the data in the database a bit to understand what we have to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4a0_CqVWY7y",
        "outputId": "3d066514-2a72-4355-d2d2-49c26e84eaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "# node labels\n",
        "with driver.session(database = DB_NAME) as session:\n",
        "  result = session.read_transaction( lambda tx: \n",
        "    tx.run(\n",
        "    \"\"\"\n",
        "    CALL db.labels() YIELD label\n",
        "    CALL apoc.cypher.run('MATCH (:`'+label+'`) RETURN count(*) as freq', {})\n",
        "    YIELD value\n",
        "    RETURN label, value.freq AS freq\n",
        "    \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  df = pd.DataFrame(result)\n",
        "  display(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Node</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Client</td>\n",
              "      <td>11270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bank</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Merchant</td>\n",
              "      <td>3465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mule</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CashIn</td>\n",
              "      <td>746751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CashOut</td>\n",
              "      <td>424574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Debit</td>\n",
              "      <td>130284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Payment</td>\n",
              "      <td>542443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Transfer</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transaction</td>\n",
              "      <td>1844052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Email</td>\n",
              "      <td>11299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SSN</td>\n",
              "      <td>11301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Phone</td>\n",
              "      <td>11299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>model_data</td>\n",
              "      <td>1662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          label     freq\n",
              "0          Node        0\n",
              "1        Client    11270\n",
              "2          Bank        5\n",
              "3      Merchant     3465\n",
              "4          Mule        0\n",
              "5        CashIn   746751\n",
              "6       CashOut   424574\n",
              "7         Debit   130284\n",
              "8       Payment   542443\n",
              "9      Transfer        0\n",
              "10  Transaction  1844052\n",
              "11        Email    11299\n",
              "12          SSN    11301\n",
              "13        Phone    11299\n",
              "14   model_data     1662"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrETUiWdFDoy",
        "outputId": "76225d29-ea3c-4ee9-a138-86a53678c1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# relationship types\n",
        "with driver.session(database = DB_NAME) as session:\n",
        "  result = session.read_transaction( lambda tx: \n",
        "    tx.run(\n",
        "      \"\"\"\n",
        "      CALL db.relationshipTypes() YIELD relationshipType as type\n",
        "      CALL apoc.cypher.run('MATCH ()-[:`'+type+'`]->() RETURN count(*) as freq', {})\n",
        "      YIELD value\n",
        "      RETURN type AS relationshipType, value.freq AS freq\n",
        "      ORDER by freq DESC\n",
        "      \"\"\"\n",
        "      ).data()\n",
        "    )\n",
        "df = pd.DataFrame(result)\n",
        "display(df)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relationshipType</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PERFORMED</td>\n",
              "      <td>1844052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TO</td>\n",
              "      <td>1844052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEXT</td>\n",
              "      <td>1833720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAS_SSN</td>\n",
              "      <td>11330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAS_EMAIL</td>\n",
              "      <td>11330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HAS_PHONE</td>\n",
              "      <td>11330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FIRST_TX</td>\n",
              "      <td>10332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LAST_TX</td>\n",
              "      <td>10332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  relationshipType     freq\n",
              "0        PERFORMED  1844052\n",
              "1               TO  1844052\n",
              "2             NEXT  1833720\n",
              "3          HAS_SSN    11330\n",
              "4        HAS_EMAIL    11330\n",
              "5        HAS_PHONE    11330\n",
              "6         FIRST_TX    10332\n",
              "7          LAST_TX    10332"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsfbg8rpJcXo",
        "outputId": "953a721b-5fff-484d-97e3-787515b0eb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# transaction types\n",
        "with driver.session(database = DB_NAME) as session:\n",
        "  result = session.read_transaction( lambda tx: \n",
        "    tx.run(\n",
        "    \"\"\"\n",
        "    MATCH (t:Transaction)\n",
        "    WITH sum(t.amount) AS globalSum, count(t) AS globalCnt\n",
        "    WITH *, 10^3 AS scaleFactor\n",
        "    UNWIND ['CashIn', 'CashOut', 'Payment', 'Debit', 'Transfer'] AS txType\n",
        "      CALL apoc.cypher.run('MATCH (t:' + txType + ')\n",
        "        RETURN sum(t.amount) as txAmount, count(t) AS txCnt', {})\n",
        "      YIELD value\n",
        "    RETURN txType,value.txAmount AS TotalMarketValue\n",
        "    \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  df = pd.DataFrame(result)\n",
        "  display(df)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txType</th>\n",
              "      <th>TotalMarketValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CashIn</td>\n",
              "      <td>1.040582e+11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CashOut</td>\n",
              "      <td>5.385410e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Payment</td>\n",
              "      <td>9.646814e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Debit</td>\n",
              "      <td>1.016829e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Transfer</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     txType  TotalMarketValue\n",
              "0    CashIn      1.040582e+11\n",
              "1   CashOut      5.385410e+10\n",
              "2   Payment      9.646814e+10\n",
              "3     Debit      1.016829e+09\n",
              "4  Transfer      0.000000e+00"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKo4m-A4J9F8"
      },
      "source": [
        "## Create a New Feature with a Graph Embedding using Neo4j\n",
        "First we're going to create an in memory graph represtation of the data in Neo4j Graph Data Science (GDS).\n",
        "\n",
        "Note, if you get an error saying the graph already exists, that's probably because you ran this code before.  You can destroy it using the command in the cleanup section of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdBkeDV7J8Ke",
        "outputId": "ec7e9594-b64e-4c04-e6b5-5501076a519e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "with driver.session(database = DB_NAME) as session:\n",
        "  result = session.read_transaction( lambda tx: \n",
        "    tx.run(\n",
        "    \"\"\"\n",
        "    CALL gds.graph.create.cypher('client_graph', \n",
        "      'MATCH (c:Client) RETURN id(c) as id, c.num_transactions as num_transactions, c.total_transaction_amnt as total_transaction_amnt, c.is_fraudster as is_fraudster',\n",
        "      'MATCH (c:Client)-[:PERFORMED]->(t:Transaction)-[:TO]->(c2:Client) return id(c) as source, id(c2) as target, sum(t.amount) as amount, \"TRANSACTED_WITH\" as type ')\n",
        "    \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  df = pd.DataFrame(result)\n",
        "  display(df)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodeQuery</th>\n",
              "      <th>relationshipQuery</th>\n",
              "      <th>graphName</th>\n",
              "      <th>nodeCount</th>\n",
              "      <th>relationshipCount</th>\n",
              "      <th>createMillis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MATCH (c:Client) RETURN id(c) as id, c.num_tra...</td>\n",
              "      <td>MATCH (c:Client)-[:PERFORMED]-&gt;(t:Transaction)...</td>\n",
              "      <td>client_graph</td>\n",
              "      <td>11270</td>\n",
              "      <td>26035</td>\n",
              "      <td>875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           nodeQuery  ... createMillis\n",
              "0  MATCH (c:Client) RETURN id(c) as id, c.num_tra...  ...          875\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WewKw5g4NKVo"
      },
      "source": [
        "Now we can generate an embedding from that graph.  This is a new feature we can use in our predictions.  We're using FastRP, which is a more full featured and higher performance of Node2Vec.  You can learn more about that [here](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBa8ofijEtHn",
        "outputId": "4ae16a9b-2dd3-4cbf-c868-2d40c0aca0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "with driver.session(database = DB_NAME) as session:\n",
        "  result = session.read_transaction( lambda tx: \n",
        "    tx.run(\n",
        "    \"\"\"\n",
        "    CALL gds.fastRP.mutate('client_graph',{\n",
        "      relationshipWeightProperty:'amount',\n",
        "      iterationWeights: [0.0, 1.00, 1.00, 0.80, 0.60],\n",
        "      featureProperties: ['num_transactions', 'total_transaction_amnt'],\n",
        "      propertyRatio: .25, \n",
        "      embeddingDimension: 16,\n",
        "      randomSeed: 1, \n",
        "      mutateProperty:'embedding'\n",
        "    })\n",
        "    \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  df = pd.DataFrame(result)\n",
        "  display(df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodePropertiesWritten</th>\n",
              "      <th>mutateMillis</th>\n",
              "      <th>nodeCount</th>\n",
              "      <th>createMillis</th>\n",
              "      <th>computeMillis</th>\n",
              "      <th>configuration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11270</td>\n",
              "      <td>1</td>\n",
              "      <td>11270</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>{'nodeSelfInfluence': 0, 'relationshipWeightPr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nodePropertiesWritten  ...                                      configuration\n",
              "0                  11270  ...  {'nodeSelfInfluence': 0, 'relationshipWeightPr...\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PCI0yiUNpLZ"
      },
      "source": [
        "Finally we dump that out to a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkALAMl5NtDg"
      },
      "source": [
        "with driver.session(database = DB_NAME) as session:\n",
        "  result = session.read_transaction( lambda tx: \n",
        "    tx.run(\n",
        "    \"\"\"\n",
        "    CALL gds.graph.streamNodeProperties\n",
        "    ('client_graph', ['embedding', 'num_transactions', 'total_transaction_amnt', 'is_fraudster'])\n",
        "    YIELD nodeId, nodeProperty, propertyValue\n",
        "    RETURN nodeId, nodeProperty, propertyValue\n",
        "    \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  df = pd.DataFrame(result)\n",
        "  df.head()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzDiV7Efv40X"
      },
      "source": [
        "Now we need to take that dataframe and shape it into something that better represents our classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkzFxCgdqeTt",
        "outputId": "075e342a-5eef-4c24-e564-527f27f0e18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "x = df.pivot(index='nodeId', columns='nodeProperty', values='propertyValue')\n",
        "x = x.reset_index()\n",
        "x.columns.name = None\n",
        "x.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodeId</th>\n",
              "      <th>embedding</th>\n",
              "      <th>is_fraudster</th>\n",
              "      <th>num_transactions</th>\n",
              "      <th>total_transaction_amnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>118919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>-9223372036854775808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>[-4.998395475297457e-09, 5.79870196304455e-09,...</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>7.48446e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>-9223372036854775808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>[0.02352502942085266, -0.023524967953562737, 2...</td>\n",
              "      <td>1</td>\n",
              "      <td>227</td>\n",
              "      <td>3.75806e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nodeId  ... total_transaction_amnt\n",
              "0       0  ...                 118919\n",
              "1       3  ...                      0\n",
              "2       5  ...            7.48446e+06\n",
              "3       8  ...                      0\n",
              "4      10  ...            3.75806e+07\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPim4AGB8w3Q"
      },
      "source": [
        "is_fraudster will have a value of 0 or 1 if populated.  If the value is 10000 then it's unlabled, so we're going to drop it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jZZg6ln8wW_",
        "outputId": "841cd2f2-c8c7-409b-da8f-27033c7aaf2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "x = x.loc[x['is_fraudster'] != 10000]\n",
        "x.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodeId</th>\n",
              "      <th>embedding</th>\n",
              "      <th>is_fraudster</th>\n",
              "      <th>num_transactions</th>\n",
              "      <th>total_transaction_amnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>118919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>-9223372036854775808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>[-4.998395475297457e-09, 5.79870196304455e-09,...</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>7.48446e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>-9223372036854775808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>[0.02352502942085266, -0.023524967953562737, 2...</td>\n",
              "      <td>1</td>\n",
              "      <td>227</td>\n",
              "      <td>3.75806e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nodeId  ... total_transaction_amnt\n",
              "0       0  ...                 118919\n",
              "1       3  ...                      0\n",
              "2       5  ...            7.48446e+06\n",
              "3       8  ...                      0\n",
              "4      10  ...            3.75806e+07\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOt_DjoPVirz"
      },
      "source": [
        "Note that the embedding row is an array.  To make this dataset more consumable, we should flatten that out into multiple individual features: embedding_0, embedding_1, ... embedding_n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9j0PPn9H4RD"
      },
      "source": [
        "embeddings = pd.DataFrame(x['embedding'].values.tolist()).add_prefix('embedding_')\n",
        "merged = x.drop(columns=['embedding']).merge(embeddings, left_index=True, right_index=True)\n",
        "features_df = merged.drop(columns=['is_fraudster', 'num_transactions', 'total_transaction_amnt'])\n",
        "train_df = merged.drop(columns=['nodeId'])\n",
        "\n",
        "FEATURES_FILENAME = 'features.csv'\n",
        "features_df.to_csv(FEATURES_FILENAME, index=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWBOxHrusEXk"
      },
      "source": [
        "This dataset is too small to use with Vertex AI AutoML Tables. For sake of demonstration, we're going to repeat it a few times. Don't do this in the real world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTvbcsvdVfb"
      },
      "source": [
        "TRAINING_FILENAME = 'train.csv'\n",
        "pd.concat([train_df for i in range(10)]).to_csv(TRAINING_FILENAME, index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpNFaHfKK6jK"
      },
      "source": [
        "And that's it!  The dataframe now has a nice dataset that we can use with GCP Vertex AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6tjQDbgf2S"
      },
      "source": [
        "## Authenticate your Google Cloud account\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HucMnpmVgfmX"
      },
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pguKxUv3gLSZ"
      },
      "source": [
        "## Setup GCP Environmental Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQjJqWal5APv"
      },
      "source": [
        "import os\n",
        "PROJECT_ID = 'neo4jbusinessdev'\n",
        "os.environ['GCLOUD_PROJECT'] = PROJECT_ID"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUU7z4FjJS90"
      },
      "source": [
        "##Upload to a GCP Cloud Storage Bucket\n",
        "\n",
        "To get the data into Vertex AI, we must first put it in a bucket as a CSV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3nbLg1cKJpJ"
      },
      "source": [
        "from google.cloud import storage\n",
        "client = storage.Client()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dAkAU5ALnUo",
        "outputId": "b361a90e-0006-4def-c317-781981b01d20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a bucket\n",
        "STORAGE_BUCKET = 'paysim'\n",
        "bucket = client.bucket(STORAGE_BUCKET)\n",
        "client.create_bucket(bucket)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Bucket: paysim>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTo7-_oJL_dZ"
      },
      "source": [
        "# Upload our files to that bucket\n",
        "for filename in [FEATURES_FILENAME, TRAINING_FILENAME]:\n",
        "  blob = bucket.blob(filename)\n",
        "  blob.upload_from_filename(filename)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArK3cfKsdT1x"
      },
      "source": [
        "## Create a Dataset with Vertex AI\n",
        "Now we're going to take the CSV in our bucket and turn that into a dataset in Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGjrD-k3dsCN",
        "outputId": "4accea57-febf-4347-9ffb-9ae470d78040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.cloud import aiplatform\n",
        "aiplatform.init()\n",
        "\n",
        "dataset = aiplatform.TabularDataset.create(display_name='paysim', gcs_source=os.path.join('gs://', STORAGE_BUCKET, TRAINING_FILENAME))\n",
        "dataset.wait()\n",
        "\n",
        "print(f'\\tDataset: \"{dataset.display_name}\"')\n",
        "print(f'\\tname: \"{dataset.resource_name}\"')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tDataset: \"paysim\"\n",
            "\tname: \"projects/803648085855/locations/us-central1/datasets/6086254256577314816\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaSPuk31N2xS"
      },
      "source": [
        "# TODO: don't hard code the dimension size\n",
        "EMBEDDING_DIMENSION = 16\n",
        "embedding_column_names = [ 'embedding_{}'.format(i) for i in range(EMBEDDING_DIMENSION) ]\n",
        "other_column_names = ['num_transactions', 'total_dollar_amnt']\n",
        "all_columns = other_column_names + embedding_column_names\n",
        "\n",
        "column_specs = [\n",
        "  {column: 'numeric'} for column in all_columns\n",
        "]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPdFiAn79DU-",
        "outputId": "c53f20dd-1d33-4317-f910-4699125811ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "job = aiplatform.AutoMLTabularTrainingJob(\n",
        "    display_name = 'train-paysim-automl-1',\n",
        "    optimization_prediction_type = 'classification',\n",
        "    column_specs = column_specs,\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-8a820146f1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdisplay_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train-paysim-automl-1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimization_prediction_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcolumn_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_specs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, display_name, optimization_prediction_type, optimization_objective, column_specs, column_transformations, optimization_objective_recall_value, optimization_objective_precision_value, project, location, credentials, labels, training_encryption_spec_key_name, model_encryption_spec_key_name)\u001b[0m\n\u001b[1;32m   3287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m         self._column_transformations = column_transformations_utils.validate_and_get_column_transformations(\n\u001b[0;32m-> 3289\u001b[0;31m             \u001b[0mcolumn_specs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3290\u001b[0m         )\n\u001b[1;32m   3291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/utils/column_transformations_utils.py\u001b[0m in \u001b[0;36mvalidate_and_get_column_transformations\u001b[0;34m(column_specs, column_transformations)\u001b[0m\n\u001b[1;32m    105\u001b[0m         return [\n\u001b[1;32m    106\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"column_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         ]\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqf44y_G8vi1"
      },
      "source": [
        "model = job.run(\n",
        "    dataset = dataset,\n",
        "    target_column = 'is_fraudster',\n",
        "    training_fraction_split = 0.8,\n",
        "    validation_fraction_split = 0.1,\n",
        "    test_fraction_split = 0.1,\n",
        "    model_display_name = 'paysim-prediction-model',\n",
        "    disable_early_stopping = False,\n",
        "    budget_milli_node_hours = int(1000 / 60 * 5) # Limit to 5 minute running time\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugQOvhv4WY7z"
      },
      "source": [
        "## Classification with Vertex AI\n",
        "In this section, we're going to run two classifiers and compare results.  The first will use the standard PaySim features.  The second will use our new graph features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NnDaATyWY7z"
      },
      "source": [
        "## Loading Data into GCP Feature Store\n",
        "In this section, we'll take our dataframe with newly engineered features and load that into GCP feature store."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3sXGnyD6YYu"
      },
      "source": [
        "REGION = 'us-central1'\n",
        "FEATURESTORE_ID = 'paysim'\n",
        "ENTITY_NAME = 'payer'"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0DcYzPkRrzj"
      },
      "source": [
        "from google.cloud.aiplatform_v1 import FeaturestoreServiceClient\n",
        "api_endpoint = '{}-aiplatform.googleapis.com'.format(REGION)\n",
        "fs_client = FeaturestoreServiceClient(client_options={'api_endpoint': api_endpoint})\n",
        "\n",
        "resource_path = fs_client.common_location_path(PROJECT_ID, REGION)\n",
        "fs_path = fs_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID)\n",
        "entity_path = fs_client.entity_type_path(PROJECT_ID, REGION, FEATURESTORE_ID, ENTITY_NAME)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMN4Ue2hjdL3"
      },
      "source": [
        "First, let's check if the Feature Store already exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYQknjQFsVNC"
      },
      "source": [
        "from grpc import StatusCode\n",
        "def check_has_resource(callable):\n",
        "  has_resource = False\n",
        "  try:\n",
        "    callable()\n",
        "    has_resource = True\n",
        "  except Exception as e:\n",
        "    if not hasattr(e, 'grpc_status_code') or e.grpc_status_code != StatusCode.NOT_FOUND:\n",
        "      raise e\n",
        "  return has_resource"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTVIsom6eejQ"
      },
      "source": [
        "feature_store_exists = check_has_resource(\n",
        "    lambda: fs_client.get_featurestore(\n",
        "      name= fs_path\n",
        "    )\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caTWbgeChd_x",
        "outputId": "b7c0f3f5-954b-4042-b855-7e3beddfa433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from google.cloud.aiplatform_v1.types import featurestore_service as featurestore_service_pb2\n",
        "from google.cloud.aiplatform_v1.types import featurestore as featurestore_pb2\n",
        "from google.cloud.aiplatform_v1.types import feature as feature_pb2\n",
        "from google.cloud.aiplatform_v1.types import entity_type as entity_type_pb2\n",
        "from google.cloud.aiplatform_v1.types import io as io_pb2\n",
        "\n",
        "if not feature_store_exists:\n",
        "  create_lro = admin_client.create_featurestore(\n",
        "      featurestore_service_pb2.CreateFeaturestoreRequest(\n",
        "          parent=resource_path,\n",
        "          featurestore_id=FEATURESTORE_ID,\n",
        "          featurestore=featurestore_pb2.Featurestore(\n",
        "              online_serving_config=featurestore_pb2.Featurestore.OnlineServingConfig(\n",
        "                  fixed_node_count=1\n",
        "              ),\n",
        "          ),\n",
        "      )\n",
        "  )\n",
        "\n",
        "  print(create_lro.result())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-c7e75dea754d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeature_store_exists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   create_lro = admin_client.create_featurestore(\n\u001b[0m\u001b[1;32m      9\u001b[0m       featurestore_service_pb2.CreateFeaturestoreRequest(\n\u001b[1;32m     10\u001b[0m           \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'admin_client' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1JRwvvYJMBy"
      },
      "source": [
        "entity_type_exists = check_has_resource(    \n",
        "    lambda: fs_client.get_entity_type(\n",
        "        name=entity_path\n",
        "    )\n",
        ")\n",
        "\n",
        "if not entity_type_exists:\n",
        "  users_entity_type_lro = fs_client.create_entity_type(\n",
        "    featurestore_service_pb2.CreateEntityTypeRequest(\n",
        "        parent=fs_path,\n",
        "        entity_type_id=ENTITY_NAME,\n",
        "        entity_type=entity_type_pb2.EntityType(\n",
        "            description=\"Main entity type\",\n",
        "        ),\n",
        "      )\n",
        "  )\n",
        "  print(users_entity_type_lro.result())\n",
        "\n",
        "  feature_requests = [\n",
        "    featurestore_service_pb2.CreateFeatureRequest(\n",
        "      feature=feature_pb2.Feature(\n",
        "          value_type=feature_pb2.Feature.ValueType.DOUBLE,\n",
        "          description=\"Embedding {} from Neo4j\".format(i),\n",
        "      ),\n",
        "      feature_id=\"embedding_{}\".format(i),\n",
        "    )\n",
        "    for i in range(EMBEDDING_DIMENSION)\n",
        "  ]\n",
        "  create_features_lro = fs_client.batch_create_features(\n",
        "      parent=entity_path,\n",
        "      requests=feature_requests,\n",
        "  )\n",
        "  print(create_features_lro.result())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz78rmNrwK0V"
      },
      "source": [
        "feature_specs = [\n",
        "  featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"embedding_{}\".format(i))\n",
        "  for i in range(EMBEDDING_DIMENSION)         \n",
        "]\n",
        "\n",
        "from google.protobuf.timestamp_pb2 import Timestamp\n",
        "\n",
        "import_request = fs_client.import_feature_values(\n",
        "    featurestore_service_pb2.ImportFeatureValuesRequest(\n",
        "      entity_type=entity_path,\n",
        "      csv_source=io_pb2.CsvSource(\n",
        "          gcs_source=io_pb2.GcsSource(\n",
        "              uris=[\n",
        "                  os.path.join('gs://', STORAGE_BUCKET, FEATURES_FILENAME)\n",
        "              ]\n",
        "          )\n",
        "      ),\n",
        "      entity_id_field=\"nodeId\",\n",
        "      feature_specs=feature_specs,\n",
        "      worker_count=1,\n",
        "      feature_time=Timestamp().GetCurrentTime()\n",
        "  )\n",
        ")\n",
        "\n",
        "print(import_request.result())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU79nGz2gv_M"
      },
      "source": [
        "##Cleanup\n",
        "\n",
        "To delete the Graph Data Science representation of the graph, run this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICSNRLM5YQ5N"
      },
      "source": [
        "with driver.session(database = DB_NAME) as session:\n",
        "    result = session.read_transaction( lambda tx: \n",
        "        tx.run(\n",
        "        \"\"\"\n",
        "        CALL gds.graph.drop('client_graph')\n",
        "        \"\"\"\n",
        "        ).data()\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
