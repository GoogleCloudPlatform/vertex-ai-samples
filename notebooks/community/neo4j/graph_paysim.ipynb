{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YasYy1BqRHY8"
      },
      "source": [
        "# Graph PaySim\n",
        "This notebook is an example of using Neo4j with Vertex AI.  It takes PaySim data from a Neo4j database, puts that into Feature Store and then runs two classifications on that.  One classification uses the standard PaySim features.  A second uses features engineered using Neo4j Graph Data Science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/benofben/vertex-ai-samples/blob/master/notebooks/community/neo4j/graph_paysim.ipynb\" target=\"_parent\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/benofben/vertex-ai-samples/tree/master/notebooks/community/neo4j/graph_paysim.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4-nDLfK4pw"
      },
      "source": [
        "## Data Set\n",
        "The notebook uses a version of the PaySim dataset that has been modified to work with Neo4j's graph database.  PaySim is a synthetic fraud dataset.  The goal is to identify whether or not a given transaction constitutes fraud.  The dataset is [here](https://github.com/voutilad/PaySim)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "We assume that you've already loaded the PaySim data into a Neo4j instance and have the credentials to connect to that.  You'll also need to install the Neo4j Python driver by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install neo4j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working with Neo4j\n",
        "In this section we're going to connect to Neo4j and look around the database.  We're going to generate some new features in the dataset using Neo4j's Graph Data Science library.  Finally, we'll load the data into a Pandas dataframe so that it's all ready to put into GCP Feature Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from neo4j import GraphDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DB_ULR = 'neo4j+s://6c443062.databases.neo4j.io:7687'\n",
        "DB_USER = 'neo4j'\n",
        "DB_PASS = 'some password'\n",
        "DB_NAME = 'neo4j'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "driver = GraphDatabase.driver(DB_ULR, auth=(DB_USER, DB_PASS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's have a closer look at transactions\n",
        "with driver.session(database = DB_NAME) as session:\n",
        "    result = session.read_transaction( lambda tx: \n",
        "        tx.run(\n",
        "        \"\"\"\n",
        "        MATCH (t:Transaction)\n",
        "        WITH sum(t.amount) AS globalSum, count(t) AS globalCnt\n",
        "        WITH *, 10^3 AS scaleFactor\n",
        "        UNWIND ['CashIn', 'CashOut', 'Payment', 'Debit', 'Transfer'] AS txType\n",
        "        CALL apoc.cypher.run('MATCH (t:' + txType + ')\n",
        "            RETURN sum(t.amount) as txAmount, count(t) AS txCnt', {})\n",
        "        YIELD value\n",
        "        RETURN txType,value.txAmount AS TotalMarketValue,\n",
        "        100*round(scaleFactor*(toFloat(value.txAmount)/toFloat(globalSum)))\n",
        "            /scaleFactor AS `%MarketValue`,\n",
        "        100*round(scaleFactor*(toFloat(value.txCnt)/toFloat(globalCnt)))\n",
        "            /scaleFactor AS `%MarketTransactions`,\n",
        "        toInteger(toFloat(value.txAmount)/toFloat(value.txCnt)) AS AvgTransactionValue,\n",
        "        value.txCnt AS NumberOfTransactions\n",
        "        ORDER BY `%MarketTransactions` DESC\n",
        "        \"\"\"\n",
        "        ).data()\n",
        "    )\n",
        "    df = pd.DataFrame(result)\n",
        "    display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Data into GCP Feature Store\n",
        "In this section, we'll take our dataframe with newly engineered features and load that into GCP feature store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification with Vertex AI\n",
        "In this section, we're going to run two classifiers and compare results.  The first will use the standard PaySim features.  The second will use our new graph features."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "graph_paysim.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
