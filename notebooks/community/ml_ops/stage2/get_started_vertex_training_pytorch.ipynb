{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "# E2E ML on GCP: MLOps stage 2 : experimentation: get started with Vertex Training for Pytorch\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_pytorch.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/ai/platform/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_pytorch.ipynb\">\n",
    "      Open in Google Cloud Notebooks\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "This tutorial demonstrates how to use Vertex AI for E2E MLOps on Google Cloud in production. This tutorial covers stage 2 : experimentation: get started with Vertex Training for Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:pytorch,cifar10,icn",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the [CIFAR10 dataset](https://pytorch.org/vision/stable/datasets.html#cifar) from [Pytorch Datasets](https://pytorch.org/vision/stable/datasets.html). The version of the dataset you will use is built into TensorFlow. The trained model predicts which type of class an image is from ten classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, or truck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_training_pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to use `Vertex AI Training` for training a Pytorch custom model.\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Model` resource\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Single node training using a Python package.\n",
    "- Report accuracy when hyperparameter tuning.\n",
    "- Create a `Vertex AI Model` resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "## Installations\n",
    "\n",
    "Install *one time* the packages for executing the MLOps notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops",
    "repo": "snippets_mlops.ipynb"
   },
   "outputs": [],
   "source": [
    "ONCE_ONLY = False\n",
    "if ONCE_ONLY:\n",
    "    ! pip3 install -U tensorflow==2.5 $USER_FLAG\n",
    "    ! pip3 install -U tensorflow-data-validation==1.2 $USER_FLAG\n",
    "    ! pip3 install -U tensorflow-transform==1.2 $USER_FLAG\n",
    "    ! pip3 install -U tensorflow-io==0.18 $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform[tensorboard] $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-pipeline-components $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-bigquery $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-logging $USER_FLAG\n",
    "    ! pip3 install --upgrade apache-beam[gcp] $USER_FLAG\n",
    "    ! pip3 install --upgrade pyarrow $USER_FLAG\n",
    "    ! pip3 install --upgrade cloudml-hypertune $USER_FLAG\n",
    "    ! pip3 install --upgrade kfp $USER_FLAG\n",
    "    ! pip3 install --upgrade torchvision $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
    "\n",
    "- Americas: `us-central1`\n",
    "- Europe: `europe-west4`\n",
    "- Asia Pacific: `asia-east1`\n",
    "\n",
    "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
    "\n",
    "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "#### Timestamp\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "When you initialize the Vertex SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "Finally, validate access to your Cloud Storage bucket by examining its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "Next, set up some variables used throughout the tutorial.\n",
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,mbsdk",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "#### Set hardware accelerators\n",
    "\n",
    "You can set hardware accelerators for training.\n",
    "\n",
    "Set the variable `TRAIN_GPU/TRAIN_NGPU` to use a container image supporting a GPU and the number of GPUs allocated to the virtual machine (VM) instance. For example, to use a GPU container image with 4 Nvidia Telsa K80 GPUs allocated to each VM, you would specify:\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "Otherwise specify `(None, None)` to use a container image to run on a CPU.\n",
    "\n",
    "Learn more [here](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators) hardware accelerator support for your region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,mbsdk",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, int(os.getenv(\"IS_TESTING_TRAIN_GPU\")))\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,pytorch",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "#### Set pre-built containers\n",
    "\n",
    "Set the pre-built Docker container image for training.\n",
    "\n",
    "- Set the variable `TF` to the TensorFlow version of the container image. For example, `2-1` would be version 2.1, and `1-15` would be version 1.15. The following list shows some of the pre-built images available:\n",
    "\n",
    "\n",
    "For the latest list, see [Pre-built containers for training](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,pytorch",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    TRAIN_VERSION = \"pytorch-gpu.1-9\"\n",
    "else:\n",
    "    TRAIN_VERSION = \"pytorch-xla.1-9\"\n",
    "\n",
    "TRAIN_IMAGE = \"{0}-docker.pkg.dev/vertex-ai/training/{1}:latest\".format(REGION.split('-')[0],TRAIN_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training",
    "repo": "snippets_housekeeping.ipynb"
   },
   "source": [
    "#### Set machine type\n",
    "\n",
    "Next, set the machine type to use for training.\n",
    "\n",
    "- Set the variable `TRAIN_COMPUTE` to configure  the compute resources for the VMs you will use for for training.\n",
    " - `machine type`\n",
    "     - `n1-standard`: 3.75GB of memory per vCPU.\n",
    "     - `n1-highmem`: 6.5GB of memory per vCPU\n",
    "     - `n1-highcpu`: 0.9 GB of memory per vCPU\n",
    " - `vCPUs`: number of \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "*Note: The following is not supported for training:*\n",
    "\n",
    " - `standard`: 2 vCPUs\n",
    " - `highcpu`: 2, 4 and 8 vCPUs\n",
    "\n",
    "*Note: You may also use n2 and e2 machine types for training and deployment, but they do not support GPUs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training",
    "repo": "snippets_housekeeping.ipynb"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = 'n1-standard'\n",
    "\n",
    "VCPU = '4'\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + '-' + VCPU\n",
    "print('Train machine type', TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pytorch_intro",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "## Introduction to Pytorch training\n",
    "\n",
    "The Pytorch package supports both single node and distributed model training.\n",
    "\n",
    "Once you have trained a Pytorch model, you will want to save it at a Cloud Storage location, so it can subsequently be uploaded to a `Vertex AI Model` resource.\n",
    "The Pytorch package does not have support to save the model to a Cloud Storage location. Instead, you will do the following steps to save to a Cloud Storage location.\n",
    "\n",
    "1. Save the in-memory model to the local filesystem (e.g., model.pth).\n",
    "2. Use gsutil to copy the local copy to the specified Cloud Storage location.\n",
    "\n",
    "*Note*: You can do hyperparameter tuning with a Pytorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package:pytorch",
    "repo": "snippets_custom.ipynb"
   },
   "source": [
    "### Examine the training package\n",
    "\n",
    "#### Package layout\n",
    "\n",
    "Before you start the training, you will look at how a Python package is assembled for a custom training job. When unarchived, the package contains the following directory/file layout.\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "The files `setup.cfg` and `setup.py` are the instructions for installing the package into the operating environment of the Docker image.\n",
    "\n",
    "The file `trainer/task.py` is the Python script for executing the custom training job. *Note*, when we referred to it in the worker pool specification, we replace the directory slash with a dot (`trainer.task`) and dropped the file suffix (`.py`).\n",
    "\n",
    "#### Package Assembly\n",
    "\n",
    "In the following cells, you will assemble the training package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package:pytorch",
    "repo": "snippets_custom.ipynb"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'cloudml-hypertune',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: CIFAR10 image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:cifar10,pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "### Create the task script for the Python training package\n",
    "\n",
    "Next, you create the `task.py` script for driving the training package. Some noteable steps include:\n",
    "\n",
    "- Command-line arguments:\n",
    "    - `model-dir`: The location to save the trained model. When using Vertex AI custom training, the location will be specified in the environment variable: `AIP_MODEL_DIR`,\n",
    "    - `batch_size`/`lr` : Hyperparameter tuning variables\n",
    "    - `distribute`: single node or distributed training.\n",
    "- Data preprocessing (`get_data()`):\n",
    "    - Download the dataset and split into training and test.\n",
    "- Model architecture (`getmodel()`):\n",
    "    - Get or build the model architecture.\n",
    "- Training (`train_model()`):\n",
    "    - Trains the model\n",
    "- Evaluation (`evaluate_model()`):\n",
    "    - Evaluates the model.\n",
    "    - If hyperparameter tuning, reports the metric for accuracy.\n",
    "- Model artifact saving\n",
    "    - Saves the model artifacts and evaluation metrics where the Cloud Storage location specified by `model-dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:cifar10,pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import subprocess\n",
    "import hypertune\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "#import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as distributed\n",
    "#import torch.optim\n",
    "#import torch.multiprocessing as mp\n",
    "import torch.utils.data as data\n",
    "#import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument('--batch_size', dest='batch_size',\n",
    "                    type=int, default=16, help='Batch size')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    type=int, default=20, help='Number of epochs')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    type=int, default=20, help='Learning rate')\n",
    "parser.add_argument('--distribute', default=\"single\",\n",
    "                    type=str, help='Distributed training strategy')\n",
    "parser.add_argument('--checkpoints', default=False,\n",
    "                    type=bool, help='Whether to save checkpoints')\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def distributed_is_initialized():\n",
    "    if args.distribute == \"mirror\":\n",
    "        if distributed.is_available() and distributed.is_initialized():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), normalize,]\n",
    "    )\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=\"./train\", transform=transform, train=True, download=True)\n",
    "    logging.info(train_dataset)\n",
    "    if distributed_is_initialized():\n",
    "        sampler = data.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        sampler = None\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=(sampler is None),\n",
    "        sampler=sampler,\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(root=\"./test\", transform=transform, train=False, download=True)\n",
    "    logging.info(test_dataset)\n",
    "    sampler = None\n",
    "    test_loader = data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_model():\n",
    "    class Cifar10Model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    logging.info(\"Get model architecture\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gpu_id = \"0\" if torch.cuda.is_available() else None\n",
    "    logging.info(f\"Device: {device}\")\n",
    "\n",
    "    model = Cifar10Model()\n",
    "    model.to(device)\n",
    "\n",
    "    if distributed_is_initialized():\n",
    "        model = DistributedDataParallel(model)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss().cuda(gpu_id)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    return model, loss, optimizer, device\n",
    "\n",
    "def train_model(model, loss_func, optimizer, train_loader, test_loader, is_chief, device):\n",
    "\n",
    "    class Average(object):\n",
    "        def __init__(self):\n",
    "            self.sum = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def __str__(self):\n",
    "            return '{:.6f}'.format(self.average)\n",
    "\n",
    "        @property\n",
    "        def average(self):\n",
    "            return self.sum / self.count\n",
    "\n",
    "        def update(self, value, number):\n",
    "            self.sum += value * number\n",
    "            self.count += number\n",
    "\n",
    "    class Accuracy(object):\n",
    "        def __init__(self):\n",
    "            self.correct = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def __str__(self):\n",
    "            return '{:.2f}%'.format(self.accuracy * 100)\n",
    "\n",
    "        @property\n",
    "        def accuracy(self):\n",
    "            return self.correct / self.count\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def update(self, output, target):\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "\n",
    "            self.correct += correct\n",
    "            self.count += output.size(0)\n",
    "\n",
    "    def train():\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = Average()\n",
    "        train_acc = Accuracy()\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.update(loss.item(), data.size(0))\n",
    "            train_acc.update(output, target)\n",
    "\n",
    "            return train_loss, train_acc\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(epoch):\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = Average()\n",
    "        test_acc = Accuracy()\n",
    "\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "\n",
    "        test_loss.update(loss.item(), data.size(0))\n",
    "        test_acc.update(output, target)\n",
    "\n",
    "        # report metric for hyperparameter tuning\n",
    "        hpt = hypertune.HyperTune()\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "            hyperparameter_metric_tag='accuracy',\n",
    "            metric_value=test_acc.accuracy,\n",
    "            global_step=epoch\n",
    "        )\n",
    "\n",
    "        return test_loss, test_acc\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "        logging.info('Epoch: {}, Training ...'.format(epoch))\n",
    "        train_loss, train_acc = train()\n",
    "\n",
    "        if is_chief:\n",
    "            test_loss, test_acc = evaluate(epoch)\n",
    "\n",
    "            if args.checkpoints:\n",
    "                torch.save(model.state_dict(), args.model_dir + f\"/{epoch}.chkpt\")\n",
    "\n",
    "            logging.info('Epoch: {}/{},'.format(epoch, args.epochs))\n",
    "            logging.info('train loss: {}, train acc: {},'.format(train_loss, train_acc))\n",
    "            logging.info('test loss: {}, test acc: {}.'.format(test_loss, test_acc))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = get_data()\n",
    "model, loss, optimizer, device = get_model()\n",
    "train_model(model, loss, optimizer, train_dataset, test_dataset, True, device)\n",
    "\n",
    "logging.info('start saving')\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "subprocess.check_call(['gsutil', 'cp', 'model.pth', os.path.join(args.model_dir, 'model.pth')], stderr=sys.stdout)\n",
    "logging.info(f'Model is saved to {args.model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_package_locally",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "### Test training package locally\n",
    "\n",
    "Next, test your completed training package locally with just a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_package_locally,pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "outputs": [],
   "source": [
    "! python3 custom/trainer/task.py --model-dir=custom --distribute=mirror --checkpoints=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script",
    "repo": "snippets_custom.ipynb"
   },
   "source": [
    "#### Store training script on your Cloud Storage bucket\n",
    "\n",
    "Next, you package the training folder into a compressed tar ball, and then store it in your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script",
    "repo": "snippets_custom.ipynb"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_NAME/trainer_cifar10.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "docker_write,prediction,pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "source": [
    "### Make Pytorch container for prediction\n",
    "\n",
    "Currently, Vertex AI does not have a prefined container for making predictions with a deployed Pytorch model. No problem, you can assemble your own custom container. Typically, one would base the container on the `Torch Server`. We demonstrations purpose, you build a placeholder container (not complete) that includes the latest `Torch Server` image, and push it to the `Container Registry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "docker_write,prediction,pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest-cpu\n",
    "\n",
    "\n",
    "# run Torchserve HTTP serve to respond to prediction requests\n",
    "CMD [\"torchserve\", \\n     \"--start\", \\n     \"--ts-config=/home/model-server/config.properties\", \\n     \"--models\", \\n     \"$APP_NAME=$APP_NAME.mar\", \\n     \"--model-store\", \\n     \"/home/model-server/model-store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "docker_push,prediction,pytorch",
    "repo": "snippets_mlops.ipynb"
   },
   "outputs": [],
   "source": [
    "APP_NAME='cifar10'\n",
    "DEPLOY_IMAGE = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(DEPLOY_IMAGE)\n",
    "\n",
    "! docker build --tag=$DEPLOY_IMAGE ./\n",
    "\n",
    "! docker push $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_pp_training_job:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "source": [
    "### Create and run custom training job\n",
    "\n",
    "\n",
    "To train a custom model, you perform two steps: 1) create a custom training job, and 2) run the job.\n",
    "\n",
    "#### Create custom training job\n",
    "\n",
    "A custom training job is created with the `CustomTrainingJob` class, with the following parameters:\n",
    "\n",
    "- `display_name`: The human readable name for the custom training job.\n",
    "- `container_uri`: The training container image.\n",
    "\n",
    "- `python_package_gcs_uri`: The location of the Python training package as a tarball.\n",
    "- `python_module_name`: The relative path to the training script in the Python package.\n",
    "- `model_serving_container_uri`: The container image for deploying the model.\n",
    "\n",
    "*Note:* There is no requirements parameter. You specify any requirements in the `setup.py` script in your Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_pp_training_job:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"cifar10_\" + TIMESTAMP\n",
    "\n",
    "job = aip.CustomPythonPackageTrainingJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    python_package_gcs_uri=f'{BUCKET_NAME}/trainer_cifar10.tar.gz',\n",
    "    python_module_name='trainer.task',\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    project=PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_custom_cmdargs:cifar10,pytorch",
    "repo": "snippets_custom.ipynb"
   },
   "source": [
    "### Prepare your command-line arguments\n",
    "\n",
    "Now define the command-line arguments for your custom training container:\n",
    "\n",
    "- `args`: The command-line arguments to pass to the executable that is set as the entry point into the container.\n",
    "  - `--model-dir` : For our demonstrations, we use this command-line argument to specify where to store the model artifacts.\n",
    "      - direct: You pass the Cloud Storage location as a command line argument to your training script (set variable `DIRECT = True`), or\n",
    "      - indirect: The service passes the Cloud Storage location as the environment variable `AIP_MODEL_DIR` to your training script (set variable `DIRECT = False`). In this case, you tell the service the model artifact location in the job specification.\n",
    "  - `--BLAH`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_custom_cmdargs:cifar10,pytorch",
    "repo": "snippets_custom.ipynb"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = '{}/{}'.format(BUCKET_NAME, TIMESTAMP)\n",
    "\n",
    "DIRECT = False\n",
    "if DIRECT:\n",
    "    CMDARGS = [ \"--model_dir=\" + MODEL_DIR\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = [\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "source": [
    "#### Run the custom training job\n",
    "\n",
    "Next, you run the custom job to start the training job by invoking the method `run`, with the following parameters:\n",
    "\n",
    "- `model_display_name`: The human readable name for the `Model` resource.\n",
    "- `args`: The command-line arguments to pass to the training script.\n",
    "- `replica_count`: The number of compute instances for training (replica_count = 1 is single node training).\n",
    "- `machine_type`: The machine type for the compute instances.\n",
    "- `accelerator_type`: The hardware accelerator type.\n",
    "- `accelerator_count`: The number of accelerators to attach to a worker replica.\n",
    "- `base_output_dir`: The Cloud Storage location to write the model artifacts to.\n",
    "- `sync`: Whether to block until completion of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom_job:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    model = job.run(\n",
    "        model_display_name=\"cifar10_\" + TIMESTAMP,\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=False\n",
    "    )\n",
    "else:\n",
    "    model = job.run(\n",
    "        model_display_name=\"cifar10_\" + TIMESTAMP,\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=False\n",
    "    )\n",
    "\n",
    "model_path_to_deploy = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "list_job",
    "repo": "snippets_mbsdk.ipynb"
   },
   "source": [
    "### List a custom training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "list_job",
    "repo": "snippets_mbsdk.ipynb"
   },
   "outputs": [],
   "source": [
    "_job = job.list(filter=f'display_name={DISPLAY_NAME}')\n",
    "print(_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_job_wait:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "source": [
    "### Wait for completion of custom training job\n",
    "\n",
    "Next, wait for the custom training job to complete. Alternatively, one can set the parameter `sync` to `True` in the `run()` method to block until the custom training job is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_job_wait:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "outputs": [],
   "source": [
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_job",
    "repo": "snippets_mbsdk.ipynb"
   },
   "source": [
    "### Delete a custom training job\n",
    "\n",
    "After a training job is completed, you can delete the training job with the method `delete()`.  Prior to completion, a training job can be canceled with the method `cancel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_job",
    "repo": "snippets_mbsdk.ipynb"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "source": [
    "# Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:\n",
    "\n",
    "- Dataset\n",
    "- Pipeline\n",
    "- Model\n",
    "- Endpoint\n",
    "- AutoML Training Job\n",
    "- Batch Job\n",
    "- Custom Job\n",
    "- Hyperparameter Tuning Job\n",
    "- Cloud Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk",
    "repo": "snippets_mbsdk.ipynb"
   },
   "outputs": [],
   "source": [
    "delete_all = True\n",
    "\n",
    "if delete_all:\n",
    "    # Delete the dataset using the Vertex dataset object\n",
    "    try:\n",
    "        if 'dataset' in globals():\n",
    "            dataset.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the model using the Vertex model object\n",
    "    try:\n",
    "        if 'model' in globals():\n",
    "            model.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the endpoint using the Vertex endpoint object\n",
    "    try:\n",
    "        if 'endpoint' in globals():\n",
    "            endpoint.undeploy_all()\n",
    "            endpoint.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the AutoML or Pipeline training job\n",
    "    try:\n",
    "        if 'dag' in globals():\n",
    "            dag.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the custom training job\n",
    "    try:\n",
    "        if 'job' in globals():\n",
    "            job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the batch prediction job using the Vertex batch prediction object\n",
    "    try:\n",
    "        if 'batch_predict_job' in globals():\n",
    "            batch_predict_job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the hyperparameter tuning job using the Vertex hyperparameter tuning object\n",
    "    try:\n",
    "        if 'hpt_job' in globals():\n",
    "            hpt_job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    if 'BUCKET_NAME' in globals():\n",
    "        ! gsutil rm -r $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vars": {
   "AIP": "AI Platform",
   "AUTOML": "AutoML",
   "AUTOML_URL": "https://cloud.google.com/vertex-ai/docs/start/automl-users",
   "BQ": "BigQuery",
   "COLAB": "Colab",
   "DATASET_ALIAS": "cifar10",
   "DATASET_NAME": "CIFAR10",
   "DOCKER": "Docker",
   "EDGE": "Edge",
   "EMAIL": "cdpe@gmail.com",
   "GAPIC": "client library",
   "GAPICP": "client library for Python",
   "GCONSOLE": "Cloud Console",
   "GCP": "Google Cloud",
   "GCS": "Cloud Storage",
   "GNOTEBOOK": "Google Cloud Notebook",
   "MODEL_TYPE": "image classification",
   "NOTEBOOK": "stage2/get_started_vertex_training_pytorch.ipynb",
   "REGION": "us-central1",
   "REPO": "vertex-ai-samples/blob/main/notebooks/community/ml_ops",
   "SDKP": "SDK for Python",
   "STAGE": "2 : experimentation: get started with Vertex Training for Pytorch",
   "TENSORFLOW": "TensorFlow",
   "TFLite": "TFLite",
   "TFServing": "TF Serving",
   "TITLE": "E2E ML on GCP: MLOps stage 2 : experimentation: get started with Vertex Training for Pytorch",
   "TRAINING": "training",
   "VERTEX": "Vertex AI",
   "VERTEX_AI": "Vertex AI",
   "YEAR": "2022",
   "null": "null",
   "uCAIP": "Vertex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
