{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "copyright"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title:generic,gcp"
      },
      "source": [
        "# E2E ML on GCP: MLOps stage 2 : experimentation: get started with Logging and Vertex Experiments\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/master/notebooks/official/automl/ml_ops_stage2/get_started_vertex_experiments.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/ai/platform/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/master/notebooks/official/automl/ml_ops_stage2/get_started_vertex_experiments.ipynb\">\n",
        "      Open in Google Cloud Notebooks\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview:mlops"
      },
      "source": [
        "## Overview\n",
        "\n",
        "\n",
        "This tutorial demonstrates how to use Vertex AI for E2E MLOps on Google Cloud in production. This tutorial covers stage 2 : experimentation: get started with Logging and Vertex Experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "objective:mlops,stage2,get_started_vertex_experiments"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to use Python logging and `Vertex Experiments` when training with `Vertex AI`.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex Experiments`\n",
        "- `Vertex ML Metadata`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Use Python logging to log training configuration/results locally.\n",
        "- Use Google Cloud Logging to log training configuration/results in cloud storage.\n",
        "- Create a Vertex `Experiment` resource.\n",
        "- Instantiate an experiment run.\n",
        "- Log parameters for the run.\n",
        "- Log metrics for the run.\n",
        "- Display the logged experiment run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "recommendation:mlops,stage2,logging"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "When doing E2E MLOps on Google Cloud, the following best practices for logging data when experimenting or formal training a model.\n",
        "\n",
        "#### Python Logging\n",
        "\n",
        "Use Python's logging package when doing ad-hoc training locally.\n",
        "\n",
        "#### Cloud Logging\n",
        "\n",
        "Use `Google Cloud Logging` when doing training on the cloud.\n",
        "\n",
        "#### Experiments\n",
        "\n",
        "Use Vertex Experiments in conjunction with logging when doing experiments to compare results for different experiment configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_mlops"
      },
      "source": [
        "## Installations\n",
        "\n",
        "Install *one time* the packages for executing the MLOps notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_mlops"
      },
      "outputs": [],
      "source": [
        "ONCE_ONLY = False\n",
        "if ONCE_ONLY:\n",
        "    ! pip3 install -U tensorflow==2.5 $USER_FLAG\n",
        "    ! pip3 install -U tensorflow-data-validation==1.2 $USER_FLAG\n",
        "    ! pip3 install -U tensorflow-transform==1.2 $USER_FLAG\n",
        "    ! pip3 install -U tensorflow-io==0.18 $USER_FLAG\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform[tensorboard] $USER_FLAG\n",
        "    ! pip3 install --upgrade google-cloud-bigquery $USER_FLAG\n",
        "    ! pip3 install --upgrade google-cloud-logging $USER_FLAG\n",
        "    ! pip3 install --upgrade apache-beam[gcp] $USER_FLAG\n",
        "    ! pip3 install --upgrade pyarrow $USER_FLAG\n",
        "    ! pip3 install --upgrade cloudml-hypertune $USER_FLAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "restart"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "restart"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_id"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autoset_project_id"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
        "    # Get your GCP project id from gcloud\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_gcloud_project_id"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "timestamp"
      },
      "source": [
        "#### Timestamp\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "timestamp"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_vars"
      },
      "source": [
        "### Set up variables\n",
        "\n",
        "Next, set up some variables used throughout the tutorial.\n",
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_aip:mbsdk"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "import_logging"
      },
      "source": [
        "#### Import logging\n",
        "\n",
        "Import the logging package into your Python environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_logging"
      },
      "outputs": [],
      "source": [
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,region"
      },
      "source": [
        "### Initialize Vertex SDK for Python\n",
        "\n",
        "Initialize the Vertex SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_aip:mbsdk,region"
      },
      "outputs": [],
      "source": [
        "aip.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "python_logging"
      },
      "source": [
        "## Python Logging\n",
        "\n",
        "The Python logging package is widely used for logging within Python scripts. Commonly used features:\n",
        "\n",
        "- Set logging levels.\n",
        "- Send log output to console.\n",
        "- Send log output to a file.\n",
        "\n",
        "### Logging Levels\n",
        "\n",
        "The logging levels in order (from least to highest) are, with each level inclusive of the previous level:\n",
        "\n",
        "1. Informational\n",
        "2. Warnings\n",
        "3. Errors\n",
        "4. Debugging\n",
        "\n",
        "By default, the logging level is set to error level.\n",
        "\n",
        "### Logging output to console\n",
        "\n",
        "By default, the Python logging package outputs to the console. Note, in the example the debug log message is not outputted since the default logging level is set to error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "python_logging"
      },
      "outputs": [],
      "source": [
        "def logging_examples():\n",
        "    logging.info(\"Model training started...\")\n",
        "    logging.warning(\"Using older version of package ...\")\n",
        "    logging.error(\"Training was terminated ...\")\n",
        "    logging.debug(\"Hyperparameters were ...\")\n",
        "\n",
        "\n",
        "logging_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "python_logging_level"
      },
      "source": [
        "### Setting logging level\n",
        "\n",
        "To set the logging level, you get the logging handler using `getLogger()`. You can have multiple logging handles. When `getLogger()` is called w/o arguments it gets the default handler, named ROOT. With the handler, you set the logging level with the method 'setLevel()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "python_logging_level"
      },
      "outputs": [],
      "source": [
        "logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "logging_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "python_logging_remove"
      },
      "source": [
        "### Clearing handlers\n",
        "\n",
        "At times, you may desire to reconfigure your logging. A common practice in this case is to first remove all existing logging handles for a fresh start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "python_logging_remove"
      },
      "outputs": [],
      "source": [
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "python_logging_file"
      },
      "source": [
        "### Output to a local file\n",
        "\n",
        "You can preserve your logging output to a file that is local to where the Python script is running with the method `BasicConfig()`, with the following paraneters:\n",
        "\n",
        "- `filename`: The file path to the local file to write the log output to.\n",
        "- `level`: Sets the level of logging that is written to the logging file.\n",
        "\n",
        "*Note:* You cannot use a Cloud Storage bucket as the output file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "python_logging_file"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(filename=\"mylog.log\", level=logging.DEBUG)\n",
        "\n",
        "logging_examples()\n",
        "\n",
        "! cat mylog.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloud_logging"
      },
      "source": [
        "## Logging with Google Cloud Logging\n",
        "\n",
        "You can preserve and retrieve your logging output to `Google Cloud Logging` service. Commonly used features:\n",
        "\n",
        "- Set logging levels.\n",
        "- Send log output to storage.\n",
        "- Retrieve log output from storage.\n",
        "\n",
        "### Logging Levels\n",
        "\n",
        "The logging levels in order (from least to highest) are, with each level inclusive of the previous level:\n",
        "\n",
        "1. Informational\n",
        "2. Warnings\n",
        "3. Errors\n",
        "4. Debugging\n",
        "\n",
        "By default, the logging level is set to warning level.\n",
        "\n",
        "### Configurable and storing log data.\n",
        "\n",
        "To use the `Google Cloud Logging` service, you do the following steps:\n",
        "\n",
        "1. Create a client to the service.\n",
        "2. Obtain a handler for the service.\n",
        "3. Create a logger instance and set logging level.\n",
        "4. Attach logger instance to the service.\n",
        "\n",
        "Learn more about [Logging client libraries](https://cloud.google.com/logging/docs/reference/libraries)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cloud_logging"
      },
      "outputs": [],
      "source": [
        "import google.cloud.logging\n",
        "from google.cloud.logging.handlers import CloudLoggingHandler\n",
        "\n",
        "# Connect to the Cloud Logging service\n",
        "cl_client = google.cloud.logging.Client()\n",
        "handler = CloudLoggingHandler(cl_client, name=\"mylog\")\n",
        "\n",
        "# Create a logger instance and logging level\n",
        "cloud_logger = logging.getLogger(\"cloudLogger\")\n",
        "cloud_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Attach the logger instance to the service.\n",
        "cloud_logger.addHandler(handler)\n",
        "\n",
        "# Log something\n",
        "cloud_logger.error(\"bad news\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloud_logging_write"
      },
      "source": [
        "### Logging output\n",
        "\n",
        "To log output at specific levels is identical in method, and method names, as in Python logging, except that you use your instance of the cloud logger in place of logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cloud_logging_write"
      },
      "outputs": [],
      "source": [
        "cloud_logger.info(\"Model training started...\")\n",
        "cloud_logger.warning(\"Using older version of package ...\")\n",
        "cloud_logger.error(\"Training was terminated ...\")\n",
        "cloud_logger.debug(\"Hyperparameters were ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloud_logging_list"
      },
      "source": [
        "### Get logging entries\n",
        "\n",
        "To get the logged output, you:\n",
        "\n",
        "1. Retrieve the log handle to the service.\n",
        "2. Using the handle call the method `list_entries()`\n",
        "3. Iterate through the entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cloud_logging_list"
      },
      "outputs": [],
      "source": [
        "logger = cl_client.logger(\"mylog\")\n",
        "\n",
        "for entry in logger.list_entries():\n",
        "    timestamp = entry.timestamp.isoformat()\n",
        "    print(\"* {}: {}: {}\".format(timestamp, entry.severity, entry.payload))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiments_logging"
      },
      "source": [
        "## Logging with Vertex Experiments and Vertex ML Metadata\n",
        "\n",
        "You can log results related to training experiments with `Vertex Experiments` and `ML Metadata`:\n",
        "\n",
        "- Preserve results of an experiment.\n",
        "- Track multiple runs -- i.e., training runs -- within an experiment.\n",
        "- Track parameters (configuration) and metrics (results).\n",
        "- Retrieve and display the logged output.\n",
        "\n",
        "Learn more about [Experiments](https://cloud.google.com/vertex-ai/docs/experiments/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "start_experiment"
      },
      "source": [
        "### Create experiment for tracking training related metadata\n",
        "\n",
        "Setup tracking the parameters (configuration) and metrics (results) for each experiment:\n",
        "\n",
        "- `aip.init()` - Create an experiment instance\n",
        "- `aip.start_run()` - Track a specific run within the experiment.\n",
        "\n",
        "Learn more about [Introduction to Vertex ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_experiment"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_NAME = \"example-\" + TIMESTAMP\n",
        "aip.init(experiment=EXPERIMENT_NAME)\n",
        "aip.start_run(\"run-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_log_params"
      },
      "source": [
        "### Log parameters for the experiment\n",
        "\n",
        "Typically, an experiment is associated with a specific dataset and model architecture. Within an experiment, you may have multiple training runs, where each run tries a different configuration. As examples:\n",
        "\n",
        "- Dataset split\n",
        "- Dataset sampling and boosting\n",
        "- Depth and width of layers\n",
        "- Hyperparameters\n",
        "\n",
        "These configuration settings are referred to as parameters, which you store their key/value pair using the method `log_params()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "experiment_log_params"
      },
      "outputs": [],
      "source": [
        "hyperparams = {}\n",
        "hyperparams[\"epochs\"] = 100\n",
        "hyperparams[\"batch_size\"] = 32\n",
        "hyperparams[\"learning_rate\"] = 0.01\n",
        "aip.log_params(hyperparams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_log_metrics"
      },
      "source": [
        "### Log metrics for the experiment\n",
        "\n",
        "At the completion, or termination, of a run within an experiment, you can log results that you use to compare runs. As examples:\n",
        "\n",
        "- Evaluation metrics\n",
        "- Hyperparameter search selection\n",
        "- Time to train the model\n",
        "- Early stop trigger\n",
        "\n",
        "These results settings are referred to as metrics, which you store their key/value pair using the method `log_metrics()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "experiment_log_metrics"
      },
      "outputs": [],
      "source": [
        "metrics = {}\n",
        "metrics[\"test_acc\"] = 98.7\n",
        "metrics[\"train_acc\"] = 99.3\n",
        "aip.log_metrics(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "get_experiment"
      },
      "source": [
        "### Get the experiment results\n",
        "\n",
        "Next, you use the experiment name as a parameter to the method `get_experiment_df()` to get the results of the experiment as a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "get_experiment"
      },
      "outputs": [],
      "source": [
        "experiment_df = aip.get_experiment_df()\n",
        "experiment_df = experiment_df[experiment_df.experiment_name == \"example\"]\n",
        "experiment_df.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup:mbsdk"
      },
      "source": [
        "# Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "- Dataset\n",
        "- Pipeline\n",
        "- Model\n",
        "- Endpoint\n",
        "- AutoML Training Job\n",
        "- Batch Job\n",
        "- Custom Job\n",
        "- Hyperparameter Tuning Job\n",
        "- Cloud Storage Bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cleanup:mbsdk"
      },
      "outputs": [],
      "source": [
        "delete_all = True\n",
        "\n",
        "if delete_all:\n",
        "    # Delete the dataset using the Vertex dataset object\n",
        "    try:\n",
        "        if \"dataset\" in globals():\n",
        "            dataset.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Delete the model using the Vertex model object\n",
        "    try:\n",
        "        if \"model\" in globals():\n",
        "            model.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Delete the endpoint using the Vertex endpoint object\n",
        "    try:\n",
        "        if \"endpoint\" in globals():\n",
        "            endpoint.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Delete the AutoML or Pipeline training job\n",
        "    try:\n",
        "        if \"dag\" in globals():\n",
        "            dag.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Delete the custom training job\n",
        "    try:\n",
        "        if \"job\" in globals():\n",
        "            job.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Delete the batch prediction job using the Vertex batch prediction object\n",
        "    try:\n",
        "        if \"batch_predict_job\" in globals():\n",
        "            batch_predict_job.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Delete the hyperparameter tuning job using the Vertex hyperparameter tuning object\n",
        "    try:\n",
        "        if \"hpt_job\" in globals():\n",
        "            hpt_job.delete()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    if \"BUCKET_NAME\" in globals():\n",
        "        ! gsutil rm -r $BUCKET_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "get_started_vertex_experiments.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
