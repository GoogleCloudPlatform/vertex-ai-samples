{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e4b7925f2ff"
      },
      "source": [
        "This notebook is a revised version of notebook from [Sara Robinson and Ivan Chueng](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/matching_engine/sdk_matching_engine_for_indexing.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# E2E ML on GCP: MLOps stage 6 : serving: get started with Vertex AI Matching Engine\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_matching_engine.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "    <td>\n",
        "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_matching_engine.ipynb\">\n",
        "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "        </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage6/get_started_with_matching_engine.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to use `Vertex AI Matching Engine` service. This Cloud AI service is a appropriamate nearest neighbor (ANN) index and matching service for vectors (i.e., embeddings), with high scaling and low latency.\n",
        "the GCP ANN Service.  The service is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
        "\n",
        "There are several levels of using this service.\n",
        "\n",
        "*no code*\n",
        "\n",
        "Demomstrated in this tutorial. The user brings their own embeddings for indexing and querying.\n",
        "\n",
        "*low code*\n",
        "\n",
        "The user constructs embeddings using a Vertex AI pre-built algorithm: Swivel and TwoTowers.\n",
        "\n",
        "*high code*\n",
        "\n",
        "The user configures the serving binary how to generate embeddings from the model, indexing and querying, using `Vertex AI Explanations by Examples`\n",
        "\n",
        "Learn more about [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)\n",
        "\n",
        "### Embeddings\n",
        "\n",
        "The prebuilt embeddings used for this tutorial is the [GloVe dataset](https://nlp.stanford.edu/projects/glove/).\n",
        "\n",
        "    \"GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\"\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this notebook, you will learn how to create Approximate Nearest Neighbor (ANN) Index, query against indexes. \n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Create ANN Index.\n",
        "- Create an IndexEndpoint with VPC Network\n",
        "- Deploy ANN Index\n",
        "- Perform online query\n",
        "- Deploy brute force Index.\n",
        "- Perform calibration between ANN and brute force index.\n",
        "\n",
        "\n",
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_aip:mbsdk"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the packages required for executing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_mlops"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "! pip3 install --upgrade google-cloud-aiplatform {USER_FLAG} -q\n",
        "! pip3 install -U grpcio-tools {USER_FLAG} -q\n",
        "! pip3 install -U h5py {USER_FLAG} -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "before_you_begin"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### GPU runtime\n",
        "\n",
        "*Make sure you're running this notebook in a GPU runtime if you have that option. In Colab, select* **Runtime > Change Runtime Type > GPU**\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project.](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
        "\n",
        "3. [Enable the following APIs: Vertex AI APIs, Compute Engine APIs, and Cloud Storage.](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com)\n",
        "\n",
        "4. [Enable the Service Networking API](https://console.cloud.google.com/flows/enableapi?apiid=servicenetworking.googleapis.com).\n",
        "\n",
        "5. [Enable the Cloud DNS API](https://console.cloud.google.com/flows/enableapi?apiid=dns.googleapis.com).\n",
        "\n",
        "6. If you are running this notebook locally, you will need to install the [Cloud SDK]((https://cloud.google.com/sdk)).\n",
        "\n",
        "7. Enter your project ID in the cell below. Then run the  cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_id"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autoset_project_id"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
        "    # Get your GCP project id from gcloud\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_gcloud_project_id"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23988890fef6"
      },
      "source": [
        "#### Get your project number\n",
        "\n",
        "Now that the project ID is set, you get your corresponding project number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d6950574e1d"
      },
      "outputs": [],
      "source": [
        "shell_output = ! gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "PROJECT_NUMBER = shell_output[0]\n",
        "print(\"Project Number:\", PROJECT_NUMBER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
        "\n",
        "if REGION == \"[your-region]\":\n",
        "    REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "timestamp"
      },
      "source": [
        "#### Timestamp\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "timestamp"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcp_authenticate"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Vertex AI Workbench Notebooks**, your environment is already authenticated. Skip this step.\n",
        "\n",
        "**If you are using Colab**, run the cell below and follow the instructions when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "In the Cloud Console, go to the [Create service account key](https://console.cloud.google.com/apis/credentials/serviceaccountkey) page.\n",
        "\n",
        "**Click Create service account**.\n",
        "\n",
        "In the **Service account name** field, enter a name, and click **Create**.\n",
        "\n",
        "In the **Grant this service account access to project** section, click the Role drop-down list. Type \"Vertex\" into the filter box, and select **Vertex Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "Click Create. A JSON file that contains your key downloads to your local environment.\n",
        "\n",
        "Enter the path to your service account key as the GOOGLE_APPLICATION_CREDENTIALS variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcp_authenticate"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "IS_COLAB = False\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
        "    \"DL_ANACONDA_HOME\"\n",
        "):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        IS_COLAB = True\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:mbsdk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "When you initialize the Vertex AI SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autoset_bucket"
      },
      "outputs": [],
      "source": [
        "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
        "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "validate_bucket"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validate_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_vars"
      },
      "source": [
        "### Set up variables\n",
        "\n",
        "Next, set up some variables used throughout the tutorial.\n",
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_aip:mbsdk"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR6Wwv-hCCN-"
      },
      "source": [
        "### Download and prepare the prebuilt GloVe embeddings\n",
        "\n",
        "The GloVe embeddings consists of a set of pre-trained embeddings. The embeddings are split into a \"train\" and \"test\" splits.\n",
        "You create a `Vertex AI Matching Engine` index from the \"train\" split, and use the embedding vectors in the \"test\" split as query vectors to test the index.\n",
        "\n",
        "*Note:* While the data split uses the term \"train\", these are pre-trained embeddings and thus are ready to be indexed for search. The terms \"train\" and \"test\" split are used just to be consistent with usual machine learning terminology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wzS85TeB9dG"
      },
      "outputs": [],
      "source": [
        "! gsutil cp gs://cloud-samples-data/vertex-ai/matching_engine/glove-100-angular.hdf5 ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fAO9CMoCNtq"
      },
      "source": [
        "#### Load the embeddings into memory\n",
        "\n",
        "Load the GloVe embeddings into memory from a HDF5 storage format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ3JQTS6CN-3"
      },
      "outputs": [],
      "source": [
        "h5 = h5py.File(\"glove-100-angular.hdf5\", \"r\")\n",
        "train = h5[\"train\"]\n",
        "test = h5[\"test\"]\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIQSyF9GtSv"
      },
      "source": [
        "#### Save the train split in JSONL format\n",
        "\n",
        "Next, you store the embeddings from the train split as a JSONL formatted file. Each embedding is stored as:\n",
        "\n",
        "    { 'id': .., 'embedding': [ ... ] }\n",
        "    \n",
        "The format of the embeddings for the index can be in either CSV, JSON, or Avro format.\n",
        "\n",
        "Learn more about [Embedding Formats for Indexing](https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18wCiTwfG40P"
      },
      "outputs": [],
      "source": [
        "with open(\"glove100.json\", \"w\") as f:\n",
        "    for i in range(len(train)):\n",
        "        f.write('{\"id\":\"' + str(i) + '\",')\n",
        "        f.write('\"embedding\":[' + \",\".join(str(x) for x in train[i]) + \"]}\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVl8DrWG8NS"
      },
      "source": [
        "#### Store the JSONL formatted embeddings in Cloud Storage\n",
        "\n",
        "Next, you upload the training data to your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PgsA_vbI8Vg"
      },
      "outputs": [],
      "source": [
        "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine/initial/\"\n",
        "! gsutil cp glove100.json {EMBEDDINGS_INITIAL_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIBCQ7dDSbW"
      },
      "source": [
        "### Create Matching Engine Index\n",
        "\n",
        "Next, you create the index for your embeddings. Currently, two indexing algorithms are supported:\n",
        "\n",
        "- `create_tree_ah_index()`:  Shallow tree + Asymmetric hashing.\n",
        "- `create_brute_force_index()`: Linear search.\n",
        "\n",
        "In this tutorial, you use the `create_tree_ah_index()`for production scale. The method is called with the following parameters:\n",
        "\n",
        "- `display_name`: A human readable name for the index.\n",
        "- `contents_delta_uri`: A Cloud Storage location for the embeddings, which are either to be inserted, updated or deleted.\n",
        "- `dimensions`: The number of dimensions of the input vector\n",
        "- `approximate_neighbors_count`: (for Tree AH) The default number of neighbors to find via approximate search before exact reordering is performed. Exact reordering is a procedure where results returned by an approximate search algorithm are reordered via a more expensive distance computation.\n",
        "- `distance_measure_type`: The distance measure used in nearest neighbor search.\n",
        "    - `SQUARED_L2_DISTANCE`: Euclidean (L2) Distance\n",
        "    - `L1_DISTANCE`: Manhattan (L1) Distance\n",
        "    - `COSINE_DISTANCE`: Cosine Distance. Defined as 1 - cosine similarity.\n",
        "    - `DOT_PRODUCT_DISTANCE`: Default value. Defined as a negative of the dot product.\n",
        "- `description`: A human readble description of the index.\n",
        "- `labels`: User metadata in the form of a dictionary.\n",
        "- `leaf_node_embedding_count`: Number of embeddings on each leaf node. The default value is 1000 if not set.\n",
        "- `leaf_nodes_to_search_percent`: The default percentage of leaf nodes that any query may be searched. Must be in range 1-100, inclusive. The default value is 10 (means 10%) if not set.\n",
        "\n",
        "This may take upto 30 minutes.\n",
        "\n",
        "Learn more about [Configuring Matching Engine Indexes](https://cloud.google.com/vertex-ai/docs/matching-engine/configuring-indexes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzY7TpUSJcTV"
      },
      "outputs": [],
      "source": [
        "DIMENSIONS = 100\n",
        "DISPLAY_NAME = \"glove_100_1\"\n",
        "\n",
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    description=\"Glove 100 ANN index\",\n",
        "    labels={\"label_name\": \"label_value\"},\n",
        "    # TreeAH specific parameters\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        ")\n",
        "\n",
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "print(INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omlgEZ-sGoM5"
      },
      "source": [
        "### Update the Index\n",
        "\n",
        "Next, you update the index with a new embedding -- i.e., insertion.\n",
        "\n",
        "#### Create update delta file\n",
        "\n",
        "First, you make a JSONL file with the embeddings to update. You use synthetic data -- in this case, all zeros -- for existing embedding with `id` of 0. You then upload the JSONL file to a Cloud Storage location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDAvm_mj_BVs"
      },
      "outputs": [],
      "source": [
        "with open(\"glove100_incremental.json\", \"w\") as f:\n",
        "    f.write(\n",
        "        '{\"id\":\"0\",\"embedding\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}\\n'\n",
        "    )\n",
        "\n",
        "EMBEDDINGS_UPDATE_URI = f\"{BUCKET_URI}/matching-engine/incremental/\"\n",
        "\n",
        "! gsutil cp glove100_incremental.json {EMBEDDINGS_UPDATE_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiXtF_x0GoM6"
      },
      "source": [
        "#### Update the index\n",
        "\n",
        "Next, you use the method `update_embeddings()` to incrementally update the index, with the following parameters:\n",
        "\n",
        "- `contents_delta_uri`: A Cloud Storage location for the embeddings, which are either to be inserted or updated.\n",
        "\n",
        "Optionally, the parameter `is_complete_overwrite` will replace the entire index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvedBONtGoM6"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = tree_ah_index.update_embeddings(\n",
        "    contents_delta_uri=EMBEDDINGS_UPDATE_URI,\n",
        ")\n",
        "\n",
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "print(INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4f0bc64ddb"
      },
      "source": [
        "## Setup VPC peering network\n",
        "\n",
        "To use a `Matching Engine Index`, you setup a VPC peering network between your project and the `Vertex AI Matching Engine` service project. This eliminates additional hops in network traffic and allows using efficient gRPC protocol.\n",
        "\n",
        "Learn more about [VPC peering](https://cloud.google.com/vertex-ai/docs/general/vpc-peering).\n",
        "\n",
        "**IMPORTANT: you can only setup one VPC peering to servicenetworking.googleapis.com per project.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d85e8f48291a"
      },
      "source": [
        "### Create VPC peering for default network\n",
        "\n",
        "For simplicity, we setup VPC peering to the default network. You can create a different network for your project.\n",
        "\n",
        "If you setup VPC peering with any other network, make sure that the network already exists and that your VM is running on that network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a107544fbabf"
      },
      "outputs": [],
      "source": [
        "# This is for display only; you can name the range anything.\n",
        "PEERING_RANGE_NAME = \"vertex-ai-prediction-peering-range\"\n",
        "NETWORK = \"default\"\n",
        "\n",
        "# NOTE: `prefix-length=16` means a CIDR block with mask /16 will be\n",
        "# reserved for use by Google services, such as Vertex AI.\n",
        "! gcloud compute addresses create $PEERING_RANGE_NAME \\\n",
        "  --global \\\n",
        "  --prefix-length=16 \\\n",
        "  --description=\"peering range for Google service\" \\\n",
        "  --network=$NETWORK \\\n",
        "  --purpose=VPC_PEERING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e29cad1a0be"
      },
      "source": [
        "### Create the VPC connection\n",
        "\n",
        "Next, create the connection for VPC peering.\n",
        "\n",
        "*Note:* If you get a PERMISSION DENIED, you may not have the neccessary role 'Compute Network Admin' set for your default service account. In the Cloud Console, do the following steps.\n",
        "\n",
        "1. Goto `IAM & Admin`\n",
        "2. Find your service account.\n",
        "3. Click edit icon.\n",
        "4. Select `Add Another Role`.\n",
        "5. Enter 'Compute Network Admin'.\n",
        "6. Select `Save`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3f6c85ffc63"
      },
      "outputs": [],
      "source": [
        "! gcloud services vpc-peerings connect \\\n",
        "  --service=servicenetworking.googleapis.com \\\n",
        "  --network=$NETWORK \\\n",
        "  --ranges=$PEERING_RANGE_NAME \\\n",
        "  --project=$PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "944d772b1397"
      },
      "source": [
        "Check the status of your peering connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b946ce37cc16"
      },
      "outputs": [],
      "source": [
        "! gcloud compute networks peerings list --network $NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a5e1b83ae61"
      },
      "source": [
        "#### Construct the full network name\n",
        "\n",
        "You need to have the full network resource name when you subsequently create an `Matching Engine Index Endpoint` resource for VPC peering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd58eb809f71"
      },
      "outputs": [],
      "source": [
        "full_network_name = f\"projects/{PROJECT_NUMBER}/global/networks/{NETWORK}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2xjAnDDObD"
      },
      "source": [
        "### Create an IndexEndpoint with VPC Network\n",
        "\n",
        "Next, you create a `Matching Engine Index Endpoint`, similar to the concept of creating a `Private Endpoint` for prediction with a peer-to-peer network.\n",
        "\n",
        "To create the `Index Endpoint` resource, you call the method `create()` with the following parameters:\n",
        "\n",
        "- `display_name`: A human readable name for the `Index Endpoint`.\n",
        "- `description`: A description for the `Index Endpoint`.\n",
        "- `network`: The VPC network resource name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuARXzJVGyQX"
      },
      "outputs": [],
      "source": [
        "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=\"index_endpoint_for_demo\",\n",
        "    description=\"index endpoint description\",\n",
        "    network=full_network_name,\n",
        ")\n",
        "\n",
        "INDEX_ENDPOINT_NAME = index_endpoint.resource_name\n",
        "print(INDEX_ENDPOINT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ew1UgcIIiJG"
      },
      "source": [
        "### Deploy the `Matching Engine Index` to the `Index Endpoint` resource\n",
        "\n",
        "Next, deploy your index to the `Index Endpoint` using the method `deploy_index()` with the following parameters:\n",
        "\n",
        "- `display_name`: A human readable name for the deployed index.\n",
        "- `index`: Your index.\n",
        "- `deployed_index_id`: A user assigned identifier for the deployed index.\n",
        "- `machine_type`: (optional) The VM instance type.\n",
        "- `min_replica_count`: (optional) Minimum number of VM instances for auto-scaling.\n",
        "- `max_replica_count`: (optional) Maximum number of VM instances for auto-scaling.\n",
        "\n",
        "Learn more about [Machine resources for Index Endpoint](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints#DeployedIndex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uK4WOgqN1NG"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = \"tree_ah_glove_deployed_\" + TIMESTAMP\n",
        "\n",
        "MIN_NODES = 1\n",
        "MAX_NODES = 2\n",
        "DEPLOY_COMPUTE = \"n1-standard-16\"\n",
        "\n",
        "index_endpoint.deploy_index(\n",
        "    display_name=\"deployed_index_for_demo\",\n",
        "    index=tree_ah_index,\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    # machine_type=DEPLOY_COMPUTE,\n",
        "    min_replica_count=MIN_NODES,\n",
        "    max_replica_count=MAX_NODES,\n",
        ")\n",
        "\n",
        "print(index_endpoint.deployed_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCGvBNvBd8D"
      },
      "source": [
        "### Create and execute an online query\n",
        "\n",
        "Now that your index is deployed, you can make queries.\n",
        "\n",
        "First, you construct a vector `query` using synthetic data, to use as the example to return matches for.\n",
        "\n",
        "Next, you make the matching request using the method `match()`, with the following parameters:\n",
        "\n",
        "- `deployed_index_id`:  The identifier of the deployed index.\n",
        "- `queries`: A list of queries (instances).\n",
        "- `num_neighbors`: The number of closest matches to return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3KYVw5HB-4v"
      },
      "outputs": [],
      "source": [
        "# The number of nearest neighbors to be retrieved from database for each query.\n",
        "NUM_NEIGHBOURS = 10\n",
        "\n",
        "# Test query\n",
        "queries = [\n",
        "    [\n",
        "        -0.11333,\n",
        "        0.48402,\n",
        "        0.090771,\n",
        "        -0.22439,\n",
        "        0.034206,\n",
        "        -0.55831,\n",
        "        0.041849,\n",
        "        -0.53573,\n",
        "        0.18809,\n",
        "        -0.58722,\n",
        "        0.015313,\n",
        "        -0.014555,\n",
        "        0.80842,\n",
        "        -0.038519,\n",
        "        0.75348,\n",
        "        0.70502,\n",
        "        -0.17863,\n",
        "        0.3222,\n",
        "        0.67575,\n",
        "        0.67198,\n",
        "        0.26044,\n",
        "        0.4187,\n",
        "        -0.34122,\n",
        "        0.2286,\n",
        "        -0.53529,\n",
        "        1.2582,\n",
        "        -0.091543,\n",
        "        0.19716,\n",
        "        -0.037454,\n",
        "        -0.3336,\n",
        "        0.31399,\n",
        "        0.36488,\n",
        "        0.71263,\n",
        "        0.1307,\n",
        "        -0.24654,\n",
        "        -0.52445,\n",
        "        -0.036091,\n",
        "        0.55068,\n",
        "        0.10017,\n",
        "        0.48095,\n",
        "        0.71104,\n",
        "        -0.053462,\n",
        "        0.22325,\n",
        "        0.30917,\n",
        "        -0.39926,\n",
        "        0.036634,\n",
        "        -0.35431,\n",
        "        -0.42795,\n",
        "        0.46444,\n",
        "        0.25586,\n",
        "        0.68257,\n",
        "        -0.20821,\n",
        "        0.38433,\n",
        "        0.055773,\n",
        "        -0.2539,\n",
        "        -0.20804,\n",
        "        0.52522,\n",
        "        -0.11399,\n",
        "        -0.3253,\n",
        "        -0.44104,\n",
        "        0.17528,\n",
        "        0.62255,\n",
        "        0.50237,\n",
        "        -0.7607,\n",
        "        -0.071786,\n",
        "        0.0080131,\n",
        "        -0.13286,\n",
        "        0.50097,\n",
        "        0.18824,\n",
        "        -0.54722,\n",
        "        -0.42664,\n",
        "        0.4292,\n",
        "        0.14877,\n",
        "        -0.0072514,\n",
        "        -0.16484,\n",
        "        -0.059798,\n",
        "        0.9895,\n",
        "        -0.61738,\n",
        "        0.054169,\n",
        "        0.48424,\n",
        "        -0.35084,\n",
        "        -0.27053,\n",
        "        0.37829,\n",
        "        0.11503,\n",
        "        -0.39613,\n",
        "        0.24266,\n",
        "        0.39147,\n",
        "        -0.075256,\n",
        "        0.65093,\n",
        "        -0.20822,\n",
        "        -0.17456,\n",
        "        0.53571,\n",
        "        -0.16537,\n",
        "        0.13582,\n",
        "        -0.56016,\n",
        "        0.016964,\n",
        "        0.1277,\n",
        "        0.94071,\n",
        "        -0.22608,\n",
        "        -0.021106,\n",
        "    ],\n",
        "    [\n",
        "        -0.99544,\n",
        "        -2.3651,\n",
        "        -0.24332,\n",
        "        -1.0321,\n",
        "        0.42052,\n",
        "        -1.1817,\n",
        "        -0.16451,\n",
        "        -1.683,\n",
        "        0.49673,\n",
        "        -0.27258,\n",
        "        -0.025397,\n",
        "        0.34188,\n",
        "        1.5523,\n",
        "        1.3532,\n",
        "        0.33297,\n",
        "        -0.0056677,\n",
        "        -0.76525,\n",
        "        0.49587,\n",
        "        1.2211,\n",
        "        0.83394,\n",
        "        -0.20031,\n",
        "        -0.59657,\n",
        "        0.38485,\n",
        "        -0.23487,\n",
        "        -1.0725,\n",
        "        0.95856,\n",
        "        0.16161,\n",
        "        -1.2496,\n",
        "        1.6751,\n",
        "        0.73899,\n",
        "        0.051347,\n",
        "        -0.42702,\n",
        "        0.16257,\n",
        "        -0.16772,\n",
        "        0.40146,\n",
        "        0.29837,\n",
        "        0.96204,\n",
        "        -0.36232,\n",
        "        -0.47848,\n",
        "        0.78278,\n",
        "        0.14834,\n",
        "        1.3407,\n",
        "        0.47834,\n",
        "        -0.39083,\n",
        "        -1.037,\n",
        "        -0.24643,\n",
        "        -0.75841,\n",
        "        0.7669,\n",
        "        -0.37363,\n",
        "        0.52741,\n",
        "        0.018563,\n",
        "        -0.51301,\n",
        "        0.97674,\n",
        "        0.55232,\n",
        "        1.1584,\n",
        "        0.73715,\n",
        "        1.3055,\n",
        "        -0.44743,\n",
        "        -0.15961,\n",
        "        0.85006,\n",
        "        -0.34092,\n",
        "        -0.67667,\n",
        "        0.2317,\n",
        "        1.5582,\n",
        "        1.2308,\n",
        "        -0.62213,\n",
        "        -0.032801,\n",
        "        0.1206,\n",
        "        -0.25899,\n",
        "        -0.02756,\n",
        "        -0.52814,\n",
        "        -0.93523,\n",
        "        0.58434,\n",
        "        -0.24799,\n",
        "        0.37692,\n",
        "        0.86527,\n",
        "        0.069626,\n",
        "        1.3096,\n",
        "        0.29975,\n",
        "        -1.3651,\n",
        "        -0.32048,\n",
        "        -0.13741,\n",
        "        0.33329,\n",
        "        -1.9113,\n",
        "        -0.60222,\n",
        "        -0.23921,\n",
        "        0.12664,\n",
        "        -0.47961,\n",
        "        -0.89531,\n",
        "        0.62054,\n",
        "        0.40869,\n",
        "        -0.08503,\n",
        "        0.6413,\n",
        "        -0.84044,\n",
        "        -0.74325,\n",
        "        -0.19426,\n",
        "        0.098722,\n",
        "        0.32648,\n",
        "        -0.67621,\n",
        "        -0.62692,\n",
        "    ],\n",
        "]\n",
        "\n",
        "matches = index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID, queries=queries, num_neighbors=NUM_NEIGHBOURS\n",
        ")\n",
        "\n",
        "for instance in matches:\n",
        "    print(\"INSTANCE\")\n",
        "    for match in instance:\n",
        "        print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e0d3dec8970"
      },
      "source": [
        "## Create brute force index for calibration\n",
        "\n",
        "The brute force index uses a naive brute force method to find the nearest neighbors. This method uses a linear search and thus not efficient for large scale indexes. We recommend using the brute force index for calibrating the approximate nearest neighbor (ANN) index for recall, or for mission critical matches.\n",
        "\n",
        "### Create the brute force index\n",
        "\n",
        "Now create the brute force index using the method `create_brute_force_index()`.\n",
        "\n",
        "To ensure an apples to apples comparison, the distanceMeasureType and featureNormType, dimensions of the brute force index should match those of the production indices being tuned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e7fff414fd5"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    description=\"Glove 100 index (brute force)\",\n",
        "    labels={\"label_name\": \"label_value\"},\n",
        ")\n",
        "\n",
        "INDEX_BRUTE_FORCE_RESOURCE_NAME = brute_force_index.resource_name\n",
        "print(INDEX_BRUTE_FORCE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec2756445d9c"
      },
      "source": [
        "### Update the index\n",
        "\n",
        "For apples to apples comparison, you perform the same incremental update to the brute force index as you did for the Tree AH index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "547f8aa9d7be"
      },
      "outputs": [],
      "source": [
        "brute_force_index = tree_ah_index.update_embeddings(\n",
        "    contents_delta_uri=EMBEDDINGS_UPDATE_URI\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1deaafa47163"
      },
      "source": [
        "### Deploy the brute force index to the `IndexEndpoint` resource\n",
        "\n",
        "Next, you deploy the brute force index to the same `IndexEndpoint`.\n",
        "\n",
        "*Note:* You can deploy multiple indexes to the same `Index Endpoint` resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a661c94a30e5"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"glove_brute_force_deployed_\" + TIMESTAMP\n",
        "\n",
        "index_endpoint.deploy_index(\n",
        "    index=brute_force_index, deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c315ab3ee761"
      },
      "source": [
        "## Calibration\n",
        "\n",
        "Now your ready to do calibration. The production version of the index uses an approxiamation method, which means it may have less than perfect recall when compared to the slower exact match (brute force) method.\n",
        "\n",
        "### Get test results for both indexes\n",
        "\n",
        "First, using the GloVe test embeddings, you make the identical request to both indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e05792c2823"
      },
      "outputs": [],
      "source": [
        "prod_matches = index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=list(test),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "\n",
        "exact_matches = index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
        "    queries=list(test),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeUZO3bAGoM-"
      },
      "source": [
        "### Compute Recall\n",
        "\n",
        "Finally, you determine from the results the percentage of exact matches are recalled from the production index. You can subsequently use this information to tune the deployment of the production index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-eMF05UGoM-"
      },
      "outputs": [],
      "source": [
        "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
        "correct_neighbors = 0\n",
        "for tree_ah_neighbors, brute_force_neighbors in zip(prod_matches, exact_matches):\n",
        "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
        "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
        "\n",
        "    correct_neighbors += len(\n",
        "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
        "    )\n",
        "\n",
        "recall = correct_neighbors / (len(test) * NUM_NEIGHBOURS)\n",
        "\n",
        "print(\"Recall: {}\".format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "You can also manually delete resources that you created by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Force undeployment of indexes and delete endpoint\n",
        "try:\n",
        "    index_endpoint.delete(force=True)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Delete indexes\n",
        "try:\n",
        "    tree_ah_index.delete()\n",
        "    brute_force_index.delete()\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "delete_bucket = False\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -rf {BUCKET_URI}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "get_started_with_matching_engine.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
