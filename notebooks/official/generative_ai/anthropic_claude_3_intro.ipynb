{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9A9NkTRTfo2I"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPprg6Oz0QDs"
      },
      "source": [
        "# Getting Started with Claude 3 Models\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/anthropic_claude_3_intro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fblob%2Fmain%2Fnotebooks%2Fofficial%2Fgenerative_ai%2Fanthropic_claude_3_intro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td> \n",
        "  <td style=\"text-align: center\">                                                                             \n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/generative_ai/anthropic_claude_3_intro.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/anthropic_claude_3_intro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fK_rdvvx1iZ"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Claude on Vertex AI\n",
        "\n",
        "Anthropic Claude 3 models on Vertex AI offer fully managed and serverless models are offered as managed APIs. To use a Claude model on Vertex AI, send a request directly to the Vertex AI API endpoint.\n",
        "\n",
        "You can stream your Claude responses to reduce the end-user latency perception. A streamed response uses server-sent events (SSE) to incrementally stream the response.\n",
        "\n",
        "### Available Anthropic Claude models\n",
        "\n",
        "#### Claude 3.5 Sonnet\n",
        "Anthropic's most powerful AI model. Claude 3.5 Sonnet outperforms competitor models and Claude 3 Opus at higher speeds and lower cost.\n",
        "\n",
        "#### Claude 3 Opus\n",
        "Claude 3 Opus is Anthropic's second-most intelligent AI model, with top-level performance on highly complex tasks.\n",
        "\n",
        "#### Claude 3 Haiku\n",
        "Anthropic Claude 3 Haiku is Anthropic's fastest, most compact vision and text model for near-instant responses to simple queries, meant for seamless AI experiences mimicking human interactions.\n",
        "\n",
        "#### Claude 3 Sonnet\n",
        "Anthropic Claude 3 Sonnet is engineered to be dependable for scaled AI deployments across a variety of use cases.\n",
        "\n",
        "All Claude 3 models can process images and return text outputs, and feature a 200K context window.\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook shows how to use **Vertex AI API** and **Anthropic’s Vertex SDK for Python** to call the Claude on Vertex AI API with the Claude 3 Sonnet and Claude 3 Haiku model.\n",
        "\n",
        "For more information, see the [Use Claude](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-claude) documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcJCV6Dw5usD"
      },
      "source": [
        "## Vertex AI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwYvaaW25jYS"
      },
      "source": [
        "## Get Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0660e339bf3f"
      },
      "source": [
        "### Install required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "754611260f53"
      },
      "outputs": [],
      "source": [
        "! pip3 install -U -q httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9f4c57a43f6"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b9119a60525"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e767418763cd"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5bea26f60f"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c97be6a73155"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fxZn4SAbxdl"
      },
      "source": [
        "#### Select Claude 3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8X70FTSbx7U"
      },
      "outputs": [],
      "source": [
        "MODEL = \"claude-3-5-sonnet@20240620\"  # @param [\"claude-3-5-sonnet@20240620\", \"claude-3-opus@20240229\", \"claude-3-haiku@20240307\", \"claude-3-sonnet@20240229\" ]\n",
        "if MODEL == \"claude-3-5-sonnet@20240620\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\"]\n",
        "elif MODEL == \"claude-3-opus@20240229\":\n",
        "    available_regions = [\"us-east5\"]\n",
        "elif MODEL == \"claude-3-haiku@20240307\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\"]\n",
        "elif MODEL == \"claude-3-sonnet@20240229\":\n",
        "    available_regions = [\"us-east5\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpuX3sKtexlK"
      },
      "source": [
        "#### Select a location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHl8xW45ex_O"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=available_regions,\n",
        "    description=\"Select a location:\",\n",
        "    font_weight=\"bold\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "\n",
        "def dropdown_eventhandler(change):\n",
        "    global LOCATION\n",
        "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "        LOCATION = change.new\n",
        "        print(\"Selected:\", change.new)\n",
        "\n",
        "\n",
        "LOCATION = dropdown.value\n",
        "dropdown.observe(dropdown_eventhandler, names=\"value\")\n",
        "display(dropdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q58icinBjoK"
      },
      "source": [
        "#### Set Google Cloud project and model information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltNx33t6cSZ"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "ENDPOINT = f\"https://{LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NAstKRFBt4N"
      },
      "source": [
        "#### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZEFLE6a6bqy"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "\n",
        "import httpx\n",
        "import requests\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ahw-uFjCAbo"
      },
      "source": [
        "### Text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61107099357a"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to get a response from the model for a banana bread recipe using the provided payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zFz260B50oi"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Send me a recipe for banana bread.\"}],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": False,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:rawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6f52fae9379"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to stream a response from the model for a banana bread recipe using the provided payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c99761dcd7da"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Send me a recipe for banana bread.\"}],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": True,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:streamRawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfTx9TIKCBHo"
      },
      "source": [
        "### Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d627efff784"
      },
      "source": [
        "#### Encode And Preview Image\n",
        "\n",
        "We fetch sample images from Wikipedia using the httpx library, but you can use whatever image sources work for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f1954211edf"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Camponotus_flavomarginatus_ant.jpg/300px-Camponotus_flavomarginatus_ant.jpg\"\n",
        "image_b64 = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "\n",
        "response = requests.get(image_url)\n",
        "image = Image(response.content, width=300, height=200)\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9771877508aa"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to get a response from the model analyzing the content of an image, provided as base64-encoded data, along with the text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjrE75TF8Nsn"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": \"image/jpeg\",\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": False,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:rawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ecd941bf6cc"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to stream a response from the model analyzing the content of an image, provided as base64-encoded data, along with the text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59ca7a4e6426"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": \"image/jpeg\",\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": True,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:streamRawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI3KlxQQ_F_T"
      },
      "source": [
        "## Using Anthropic's Vertex SDK for *Python*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0x3GO6M_O3_"
      },
      "source": [
        "## Get Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJrqUvqAfR7"
      },
      "source": [
        "### Install Anthropic's Vertex SDK for Python and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi_HLdat_Pce"
      },
      "outputs": [],
      "source": [
        "! pip3 install -U -q 'anthropic[vertex]'\n",
        "! pip3 install -U -q httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUiAYUFbBCpR"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcqgcj_DBFgt"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa9169957a89"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bffc70d3e8be"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1baa068f48a"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcmJpKPBMVC"
      },
      "source": [
        "#### Select Claude 3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6SJn92__jpy"
      },
      "outputs": [],
      "source": [
        "MODEL = \"claude-3-5-sonnet@20240620\"  # @param [\"claude-3-5-sonnet@20240620\", \"claude-3-opus@20240229\", \"claude-3-haiku@20240307\", \"claude-3-sonnet@20240229\" ]\n",
        "if MODEL == \"claude-3-5-sonnet@20240620\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\"]\n",
        "elif MODEL == \"claude-3-opus@20240229\":\n",
        "    available_regions = [\"us-east5\"]\n",
        "elif MODEL == \"claude-3-haiku@20240307\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\"]\n",
        "elif MODEL == \"claude-3-sonnet@20240229\":\n",
        "    available_regions = [\"us-east5\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-z0epNze9k8"
      },
      "source": [
        "#### Select a region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ciYLdLe-D-"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=available_regions,\n",
        "    description=\"Select a location:\",\n",
        "    font_weight=\"bold\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "\n",
        "def dropdown_eventhandler(change):\n",
        "    global LOCATION\n",
        "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "        LOCATION = change.new\n",
        "        print(\"Selected:\", change.new)\n",
        "\n",
        "\n",
        "LOCATION = dropdown.value\n",
        "dropdown.observe(dropdown_eventhandler, names=\"value\")\n",
        "display(dropdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shZgRl6qbZYP"
      },
      "source": [
        "#### Set Google Cloud project and model information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZLqMJ6va9fc"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "ENDPOINT = f\"https://{LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6a543c2cd07"
      },
      "source": [
        "#### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4a553b6a5c2"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "import httpx\n",
        "import requests\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gijJ2vr5B5nV"
      },
      "source": [
        "### Text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f7ee8ceb620"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a request to generate the content, and prints the response in a formatted JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2c03d3da1b0"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Send me a recipe for banana bread.\",\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "print(message.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e56a2fb209"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a streaming request to generate the content, and continuously prints the received text as it is streamed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KedVqBW9_2m_"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "\n",
        "with client.messages.stream(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Send me a recipe for banana bread.\",\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ") as stream:\n",
        "    for text in stream.text_stream:\n",
        "        print(text, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CysN0InWCKN4"
      },
      "source": [
        "### Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fe57432a56d"
      },
      "source": [
        "#### Encode And Preview Image\n",
        "\n",
        "We fetch sample images from Wikipedia using the httpx library, but you can use whatever image sources work for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8437abc38965"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Camponotus_flavomarginatus_ant.jpg/300px-Camponotus_flavomarginatus_ant.jpg\"\n",
        "image_media_type = \"image/jpeg\"\n",
        "image_b64 = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "\n",
        "response = requests.get(image_url)\n",
        "image = Image(response.content, width=300, height=200)\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fd5937f839b"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a request to describe an image (provided as base64-encoded data) along with a text prompt, and prints the response in a formatted JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hTk6_Ju_3rj"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "\n",
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": image_media_type,\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "print(message.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb4855047e3"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a streaming request to describe an image (provided as base64-encoded data) along with a text prompt, and continuously prints the received text as it is streamed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6df4d0e6d95b"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "\n",
        "with client.messages.stream(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": image_media_type,\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ") as stream:\n",
        "    for text in stream.text_stream:\n",
        "        print(text, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "anthropic_claude_3_intro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
