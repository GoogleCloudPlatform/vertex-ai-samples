{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9A9NkTRTfo2I"
      },
      "outputs": [],
      "source": [
        "# Copyright 2026 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPprg6Oz0QDs"
      },
      "source": [
        "# Getting Started with Claude Models\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/anthropic_claude_intro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fgenerative_ai%2Fanthropic_claude_intro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">                                                                             \n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/generative_ai/anthropic_claude_intro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/anthropic_claude_intro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://raw.githubusercontent.com/primer/octicons/refs/heads/main/icons/mark-github-24.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fK_rdvvx1iZ"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Claude on Vertex AI\n",
        "\n",
        "Anthropic Claude models on Vertex AI offer fully managed and serverless models are offered as managed APIs. To use a Claude model on Vertex AI, send a request directly to the Vertex AI API endpoint.\n",
        "\n",
        "You can stream your Claude responses to reduce the end-user latency perception. A streamed response uses server-sent events (SSE) to incrementally stream the response.\n",
        "\n",
        "### Available Anthropic Claude models\n",
        "\n",
        "#### Claude Sonnet 4.6\n",
        "Claude Sonnet 4.6 delivers frontier intelligence at scale—built for coding, agents, and enterprise workflows.\n",
        "\n",
        "#### Claude Opus 4.6\n",
        "Claude Opus 4.6 is the next generation of Anthropic’s most intelligent model, and the world’s best model for coding, enterprise agents, and professional work.\n",
        "\n",
        "#### Claude Opus 4.5\n",
        "The next generation of Anthropic's most intelligent model, Claude Opus 4.5 is an industry leader across coding, agents, computer use, and enterprise workflows.\n",
        "\n",
        "#### Claude Haiku 4.5\n",
        "Anthropic's mid-size model with superior intelligence for high-volume uses in coding, in-depth research, agents, & more.\n",
        "\n",
        "#### Claude Sonnet 4.5\n",
        "Anthropic's most powerful model for powering real-world agents, with industry leading capabilities around coding, computer use, cybersecurity, and working with office files like spreadsheets.\n",
        "\n",
        "#### Claude Opus 4.1\n",
        "\n",
        "The next generation of Anthropic’s most powerful model yet, Claude Opus 4.1 is an industry leader for coding. It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve. Claude Opus 4.1 is ideal for powering frontier agent products and features.\n",
        "\n",
        "#### Claude Sonnet 4\n",
        "Anthropic's mid-size model with superior intelligence for high-volume uses in coding, in-depth research, agents, & more.\n",
        "\n",
        "#### Claude Opus 4\n",
        "Anthropic’s most powerful model yet and the state-of-the-art coding model. It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve. Claude Opus 4 is ideal for powering frontier agent products and features.\n",
        "\n",
        "#### Claude 3.7 Sonnet\n",
        "Industry-leading model for coding and powering AI agents—and the first Claude model to offer extended thinking.\n",
        "\n",
        "#### Claude 3.5 Sonnet v2 (Deprecated)\n",
        "The upgraded Claude 3.5 Sonnet is now state-of-the-art for a variety of tasks including real-world software engineering, enhanced agentic capabilities, and computer use.\n",
        "\n",
        "#### Claude 3.5 Haiku (Deprecated)\n",
        "Claude 3.5 Haiku, Anthropic’s fastest and most cost-effective model, excels at use cases like code and test case generation, sub-agents, and user-facing chatbots.\n",
        "\n",
        "#### Claude 3.5 Sonnet (Deprecated)\n",
        "Anthropic's most powerful AI model. Claude 3.5 Sonnet outperforms competitor models and Claude 3 Opus at higher speeds and lower cost.\n",
        "\n",
        "#### Claude 3 Opus (Deprecated)\n",
        "Claude 3 Opus is Anthropic's second-most intelligent AI model, with top-level performance on highly complex tasks.\n",
        "\n",
        "#### Claude 3 Haiku\n",
        "Anthropic Claude 3 Haiku is Anthropic's fastest, most compact vision and text model for near-instant responses to simple queries, meant for seamless AI experiences mimicking human interactions.\n",
        "\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook shows how to use **Vertex AI API** and **Anthropic’s Vertex SDK for Python** to call the Claude models on Vertex AI API.\n",
        "\n",
        "For more information and list of supported regions, see the [Use Claude](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-claude) documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcJCV6Dw5usD"
      },
      "source": [
        "## Vertex AI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwYvaaW25jYS"
      },
      "source": [
        "## Get Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0660e339bf3f"
      },
      "source": [
        "### Install required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "754611260f53"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5bea26f60f"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c97be6a73155"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fxZn4SAbxdl"
      },
      "source": [
        "#### Select Claude model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8X70FTSbx7U"
      },
      "outputs": [],
      "source": [
        "MODEL = \"claude-sonnet-4-6\"  # @param [\"claude-sonnet-4-6\",\"claude-opus-4-6\",\"claude-opus-4-5\",\"claude-haiku-4-5\",\"claude-sonnet-4-5\",\"claude-opus-4-1\",\"claude-sonnet-4\",\"claude-opus-4\",\"claude-3-7-sonnet\",\"claude-3-5-sonnet-v2\",\"claude-3-5-haiku\",\"claude-3-5-sonnet\",\"claude-3-opus\",\"claude-3-haiku\"]\n",
        "if MODEL == \"claude-sonnet-4-6\":\n",
        "    available_regions = [\n",
        "        \"us-east5\",\n",
        "        \"europe-west1\",\n",
        "        \"asia-southeast1\",\n",
        "        \"global\",\n",
        "    ]\n",
        "elif MODEL == \"claude-opus-4-6\":\n",
        "    available_regions = [\n",
        "        \"us-east5\",\n",
        "        \"us-west4\",\n",
        "        \"us-east1\",\n",
        "        \"us-south1\",\n",
        "        \"europe-west1\",\n",
        "        \"europe-west4\",\n",
        "        \"europe-north1\",\n",
        "        \"asia-southeast1\",\n",
        "        \"global\",\n",
        "    ]\n",
        "elif MODEL == \"claude-opus-4-5\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\", \"global\"]\n",
        "elif MODEL == \"claude-haiku-4-5\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-east1\", \"global\"]\n",
        "elif MODEL == \"claude-sonnet-4-5\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\", \"global\"]\n",
        "elif MODEL == \"claude-opus-4-1\":\n",
        "    available_regions = [\"us-east5\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-sonnet-4\":\n",
        "    available_regions = [\"us-east5\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-opus-4\":\n",
        "    available_regions = [\"us-east5\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-3-7-sonnet\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-3-5-sonnet-v2\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"global\"]\n",
        "elif MODEL == \"claude-3-5-haiku\":\n",
        "    available_regions = [\"us-east5\"]\n",
        "elif MODEL == \"claude-3-5-sonnet\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\"]\n",
        "elif MODEL == \"claude-3-opus\":\n",
        "    available_regions = [\"us-east5\"]\n",
        "elif MODEL == \"claude-3-haiku\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpuX3sKtexlK"
      },
      "source": [
        "#### Select a location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHl8xW45ex_O"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=available_regions,\n",
        "    description=\"Select a location:\",\n",
        "    font_weight=\"bold\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "\n",
        "def dropdown_eventhandler(change):\n",
        "    global LOCATION\n",
        "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "        LOCATION = change.new\n",
        "        print(\"Selected:\", change.new)\n",
        "\n",
        "\n",
        "LOCATION = dropdown.value\n",
        "dropdown.observe(dropdown_eventhandler, names=\"value\")\n",
        "display(dropdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q58icinBjoK"
      },
      "source": [
        "#### Set Google Cloud project and model information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltNx33t6cSZ"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "if LOCATION == \"global\":\n",
        "    ENDPOINT = \"https://aiplatform.googleapis.com\"\n",
        "else:\n",
        "    ENDPOINT = f\"https://{LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NAstKRFBt4N"
      },
      "source": [
        "#### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZEFLE6a6bqy"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "\n",
        "import httpx\n",
        "import requests\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ahw-uFjCAbo"
      },
      "source": [
        "### Text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61107099357a"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to get a response from the model for a banana bread recipe using the provided payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zFz260B50oi"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Send me a recipe for banana bread.\"}],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": False,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:rawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6f52fae9379"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to stream a response from the model for a banana bread recipe using the provided payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c99761dcd7da"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Send me a recipe for banana bread.\"}],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": True,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:streamRawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfTx9TIKCBHo"
      },
      "source": [
        "### Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d627efff784"
      },
      "source": [
        "#### Encode And Preview Image\n",
        "\n",
        "We fetch sample images from Wikipedia using the httpx library, but you can use whatever image sources work for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f1954211edf"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Camponotus_flavomarginatus_ant.jpg/300px-Camponotus_flavomarginatus_ant.jpg\"\n",
        "image_b64 = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "\n",
        "response = requests.get(image_url)\n",
        "image = Image(response.content, width=300, height=200)\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9771877508aa"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to get a response from the model analyzing the content of an image, provided as base64-encoded data, along with the text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjrE75TF8Nsn"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": \"image/jpeg\",\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": False,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:rawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ecd941bf6cc"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to stream a response from the model analyzing the content of an image, provided as base64-encoded data, along with the text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59ca7a4e6426"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"anthropic_version\": \"vertex-2023-10-16\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": \"image/jpeg\",\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": True,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/anthropic/models/{MODEL}:streamRawPredict -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI3KlxQQ_F_T"
      },
      "source": [
        "## Using Anthropic's Vertex SDK for *Python*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0x3GO6M_O3_"
      },
      "source": [
        "## Get Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJrqUvqAfR7"
      },
      "source": [
        "### Install Anthropic's Vertex SDK for Python and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi_HLdat_Pce"
      },
      "outputs": [],
      "source": [
        "! pip3 install -U -q 'anthropic[vertex]'\n",
        "! pip3 install -U -q httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUiAYUFbBCpR"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcqgcj_DBFgt"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa9169957a89"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bffc70d3e8be"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1baa068f48a"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcmJpKPBMVC"
      },
      "source": [
        "#### Select Claude model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6SJn92__jpy"
      },
      "outputs": [],
      "source": [
        "MODEL = \"claude-sonnet-4-6\"  # @param [\"claude-sonnet-4-6\",\"claude-opus-4-6\",\"claude-opus-4-5\",\"claude-haiku-4-5\",\"claude-sonnet-4-5\",\"claude-opus-4-1\",\"claude-sonnet-4\",\"claude-opus-4\",\"claude-3-7-sonnet\",\"claude-3-5-sonnet-v2\",\"claude-3-5-haiku\",\"claude-3-5-sonnet\",\"claude-3-opus\",\"claude-3-haiku\"]\n",
        "if MODEL == \"claude-sonnet-4-6\":\n",
        "    available_regions = [\n",
        "        \"us-east5\",\n",
        "        \"europe-west1\",\n",
        "        \"asia-southeast1\",\n",
        "        \"global\",\n",
        "    ]\n",
        "elif MODEL == \"claude-opus-4-6\":\n",
        "    available_regions = [\n",
        "        \"us-east5\",\n",
        "        \"us-west4\",\n",
        "        \"us-east1\",\n",
        "        \"us-south1\",\n",
        "        \"europe-west1\",\n",
        "        \"europe-west4\",\n",
        "        \"europe-north1\",\n",
        "        \"asia-southeast1\",\n",
        "        \"global\",\n",
        "    ]\n",
        "elif MODEL == \"claude-opus-4-5\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\", \"global\"]\n",
        "elif MODEL == \"claude-haiku-4-5\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-east1\", \"global\"]\n",
        "elif MODEL == \"claude-sonnet-4-5\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\", \"global\"]\n",
        "elif MODEL == \"claude-opus-4-1\":\n",
        "    available_regions = [\"us-east5\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-sonnet-4\":\n",
        "    available_regions = [\"us-east5\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-opus-4\":\n",
        "    available_regions = [\"us-east5\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-3-7-sonnet\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"europe-west4\", \"global\"]\n",
        "elif MODEL == \"claude-3-5-sonnet-v2\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"global\"]\n",
        "elif MODEL == \"claude-3-5-haiku\":\n",
        "    available_regions = [\"us-east5\"]\n",
        "elif MODEL == \"claude-3-5-sonnet\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\"]\n",
        "elif MODEL == \"claude-3-opus\":\n",
        "    available_regions = [\"us-east5\"]\n",
        "elif MODEL == \"claude-3-haiku\":\n",
        "    available_regions = [\"us-east5\", \"europe-west1\", \"asia-southeast1\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-z0epNze9k8"
      },
      "source": [
        "#### Select a region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ciYLdLe-D-"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=available_regions,\n",
        "    description=\"Select a location:\",\n",
        "    font_weight=\"bold\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "\n",
        "def dropdown_eventhandler(change):\n",
        "    global LOCATION\n",
        "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "        LOCATION = change.new\n",
        "        print(\"Selected:\", change.new)\n",
        "\n",
        "\n",
        "LOCATION = dropdown.value\n",
        "dropdown.observe(dropdown_eventhandler, names=\"value\")\n",
        "display(dropdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shZgRl6qbZYP"
      },
      "source": [
        "#### Set Google Cloud project and model information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZLqMJ6va9fc"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6a543c2cd07"
      },
      "source": [
        "#### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4a553b6a5c2"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "import httpx\n",
        "import requests\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gijJ2vr5B5nV"
      },
      "source": [
        "### Text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f7ee8ceb620"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a request to generate the content, and prints the response in a formatted JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2c03d3da1b0"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Send me a recipe for banana bread.\",\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "print(message.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e56a2fb209"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a streaming request to generate the content, and continuously prints the received text as it is streamed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KedVqBW9_2m_"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "\n",
        "with client.messages.stream(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Send me a recipe for banana bread.\",\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ") as stream:\n",
        "    for text in stream.text_stream:\n",
        "        print(text, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CysN0InWCKN4"
      },
      "source": [
        "### Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fe57432a56d"
      },
      "source": [
        "#### Encode And Preview Image\n",
        "\n",
        "We fetch sample images from Wikipedia using the httpx library, but you can use whatever image sources work for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8437abc38965"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Camponotus_flavomarginatus_ant.jpg/300px-Camponotus_flavomarginatus_ant.jpg\"\n",
        "image_media_type = \"image/jpeg\"\n",
        "image_b64 = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "\n",
        "response = requests.get(image_url)\n",
        "image = Image(response.content, width=300, height=200)\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fd5937f839b"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a request to describe an image (provided as base64-encoded data) along with a text prompt, and prints the response in a formatted JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hTk6_Ju_3rj"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "\n",
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": image_media_type,\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "print(message.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb4855047e3"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Initializes a client for Anthropic's Vertex AI, sends a streaming request to describe an image (provided as base64-encoded data) along with a text prompt, and continuously prints the received text as it is streamed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6df4d0e6d95b"
      },
      "outputs": [],
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
        "\n",
        "with client.messages.stream(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": image_media_type,\n",
        "                        \"data\": image_b64,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ") as stream:\n",
        "    for text in stream.text_stream:\n",
        "        print(text, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "anthropic_claude_intro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
