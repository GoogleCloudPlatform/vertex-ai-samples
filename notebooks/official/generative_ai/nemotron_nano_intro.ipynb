{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9A9NkTRTfo2I"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d49913ade4d1"
      },
      "source": [
        "# Getting Started with `Nemotron Nano` Models\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/nemotron_nano_intro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fgenerative_ai%2Fnemotron_nano_intro.ipynb\\\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/generative_ai/nemotron_nano_intro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/generative_ai/nemotron_nano_intro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fK_rdvvx1iZ"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to deploy `Nemotron Nano` NVIDIA Inference Microservices (NIM) to Google Cloud Platform (GCP) Vertex AI.\n",
        "\n",
        "You’ll learn how to run an NVIDIA NIM container on a Vertex AI compute instance, register it as a model in the Vertex AI Model Registry, deploy it to an Endpoint, and perform real-time predictions — all within a managed and scalable GCP environment.\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Set up Vertex AI environment and authentication.\n",
        "- Upload the NVIDIA NIM model to the Vertex AI Model Registry.\n",
        "- Create a Vertex AI Endpoint.\n",
        "- Deploy the Model to the Endpoint.\n",
        "- Send a prediction request via API and Python SDK.\n",
        "\n",
        "### `Nemotron Nano` on Vertex AI\n",
        "\n",
        "You can deploy the `Nemotron Nano` models in your own endpoint.\n",
        "\n",
        "### Available `Nemotron Nano` models\n",
        "\n",
        "#### `Nemotron Nano 12B V2 VL`\n",
        "**NVIDIA Nemotron Nano 12B v2 VL** model enables multi-image reasoning and video understanding, along with strong document intelligence, visual Q&A and summarization capabilities.\n",
        "\n",
        "Nemotron Nano 12B V2 VL is a model for multi-modal document intelligence. It would be used by individuals or businesses that need to process documents such as invoices, receipts, and manuals. The model is capable of handling multiple images of documents, up to four images at a resolution of 1k x 2k each, along with a long text prompt. The expected use is for tasks like summarization and Visual Question Answering (VQA). The model is also expected to have a significant advantage in throughput.\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook shows how to use **Vertex AI API** to deploy the `Nemotron Nano` models.\n",
        "\n",
        "For more information, see the [NIM documentation](https://build.nvidia.com/nvidia/nemotron-nano-12b-v2-vl/modelcard).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwYvaaW25jYS"
      },
      "source": [
        "## Get Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d10e8895d2d4"
      },
      "source": [
        "### Install Vertex AI SDK for Python or other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08dd6d2ac629"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9f4c57a43f6"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b9119a60525"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e767418763cd"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5bea26f60f"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c97be6a73155"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fxZn4SAbxdl"
      },
      "source": [
        "### Select one of `publisher name` models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8X70FTSbx7U"
      },
      "outputs": [],
      "source": [
        "PUBLISHER_NAME = \"nvidia\"  # @param {type:\"string\"}\n",
        "PUBLISHER_MODEL_NAME = (\n",
        "    \"nemotron-nano-12b-v2-vl@1.5.0\"  # @param [\"nemotron-nano-12b-v2-vl@1.5.0\"]\n",
        ")\n",
        "\n",
        "if PUBLISHER_MODEL_NAME == \"nemotron-nano-12b-v2-vl@1.5.0\":\n",
        "    available_regions = [\n",
        "        \"asia-northeast1\",\n",
        "        \"asia-northeast3\",\n",
        "        \"asia-south1\",\n",
        "        \"asia-south2\",\n",
        "        \"asia-southeast1\",\n",
        "        \"australia-southeast1\",\n",
        "        \"europe-north1\",\n",
        "        \"europe-west1\",\n",
        "        \"europe-west2\",\n",
        "        \"europe-west3\",\n",
        "        \"europe-west4\",\n",
        "        \"me-west1\",\n",
        "        \"northamerica-northeast2\",\n",
        "        \"us-central1\",\n",
        "        \"us-east1\",\n",
        "        \"us-east4\",\n",
        "        \"us-east5\",\n",
        "        \"us-south1\",\n",
        "        \"us-west1\",\n",
        "        \"us-west2\",\n",
        "        \"us-west3\",\n",
        "        \"us-west4\",\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpuX3sKtexlK"
      },
      "source": [
        "### Select a location and a version from the dropdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHl8xW45ex_O"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "dropdown_loc = widgets.Dropdown(\n",
        "    options=available_regions,\n",
        "    description=\"Select a location:\",\n",
        "    font_weight=\"bold\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "\n",
        "def dropdown_loc_eventhandler(change):\n",
        "    global LOCATION\n",
        "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "        LOCATION = change.new\n",
        "        print(\"Selected:\", change.new)\n",
        "\n",
        "\n",
        "LOCATION = dropdown_loc.value\n",
        "dropdown_loc.observe(dropdown_loc_eventhandler, names=\"value\")\n",
        "display(dropdown_loc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2fc3d7b6bfa"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c1a467db2f4"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "ENDPOINT = f\"https://{LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NAstKRFBt4N"
      },
      "source": [
        "### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZEFLE6a6bqy"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82e27b61e4c6"
      },
      "source": [
        "## Using Vertex AI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjsDpa8jlTRu"
      },
      "source": [
        "### Upload Model\n",
        "\n",
        "When uploading model for the first time, it will take more time to provision. Please wait a few minutes until model shows up in the Model Registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1R2BRsBlu-k"
      },
      "outputs": [],
      "source": [
        "UPLOAD_MODEL_PAYLOAD = {\n",
        "    \"model\": {\n",
        "        \"displayName\": \"ModelGarden_LaunchPad_Model_\" + time.strftime(\"%Y%m%d-%H%M%S\"),\n",
        "        \"baseModelSource\": {\n",
        "            \"modelGardenSource\": {\n",
        "                \"publicModelName\": f\"publishers/{PUBLISHER_NAME}/models/{PUBLISHER_MODEL_NAME}\",\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "request = json.dumps(UPLOAD_MODEL_PAYLOAD)\n",
        "\n",
        "! curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/models:upload -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2j0nVGwlf9b"
      },
      "source": [
        "### Get Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f80351b014d"
      },
      "source": [
        "After uploading the model to the Vertex AI Model Registry, extract its Model ID by specifying the target region and matching the display name pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebad591b782"
      },
      "outputs": [],
      "source": [
        "# Adjust filter to include exact timestamp if needed\n",
        "MODEL_ID = !gcloud ai models list --region=$LOCATION --filter=\"display_name~'.*ModelGarden_LaunchPad_Model.*'\" --format=\"value(name)\" | head -n 1\n",
        "MODEL_ID = MODEL_ID[1]\n",
        "print(MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxwM0GXTmQhh"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"YOUR_MODEL_ID\"  # @param {type: \"string\"}\n",
        "\n",
        "! curl -X GET -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/models/{MODEL_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q3ygq8VlZAp"
      },
      "source": [
        "### Create Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ChDOt7mPBQ"
      },
      "outputs": [],
      "source": [
        "CREATE_ENDPOINT_PAYLOAD = {\n",
        "    \"displayName\": \"ModelGarden_LaunchPad_Endpoint_\" + time.strftime(\"%Y%m%d-%H%M%S\"),\n",
        "}\n",
        "\n",
        "request = json.dumps(CREATE_ENDPOINT_PAYLOAD)\n",
        "\n",
        "! curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuMZCdhmlpCE"
      },
      "source": [
        "### Get Endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b754e1c66d40"
      },
      "source": [
        "After creating the Endpoint, extract its Endpoint ID by specifying the target region and matching the display name pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d0eae891cb5"
      },
      "outputs": [],
      "source": [
        "ENDPOINT_ID = !gcloud ai endpoints list --region=$LOCATION --filter=\"DISPLAY_NAME ~ .*ModelGarden_LaunchPad_Endpoint.*\" --format=\"value(name)\" | head -n 1\n",
        "ENDPOINT_ID = ENDPOINT_ID[1]\n",
        "print(ENDPOINT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHq_cLT6mPp_"
      },
      "outputs": [],
      "source": [
        "ENDPOINT_ID = \"YOUR_ENDPOINT_ID\"  # @param {type: \"string\"}\n",
        "\n",
        "! curl -X GET -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0amEPXolbP7"
      },
      "source": [
        "### Deploy Model\n",
        "\n",
        "Deploy the model to the endpoint. The deployment process will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55ee4053dd94"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Configure machine types (please change if needed)\n",
        "\n",
        "MACHINE_CONFIG = {\n",
        "    \"a2-highgpu-8g\": {\"type\": \"NVIDIA_TESLA_A100\", \"count\": 8},\n",
        "    \"a2-ultragpu-8g\": {\"type\": \"NVIDIA_A100_80GB\", \"count\": 8},\n",
        "    \"a3-highgpu-8g\": {\"type\": \"NVIDIA_H100_80GB\", \"count\": 8},\n",
        "    \"a3-megagpu-8g\": {\"type\": \"NVIDIA_H100_MEGA_80GB\", \"count\": 8},\n",
        "    \"a4-highgpu-8g\": {\"type\": \"NVIDIA_B200\", \"count\": 8},\n",
        "    \"g4-standard-96\": {\"type\": \"NVIDIA_RTX_PRO_6000\", \"count\": 2},\n",
        "}\n",
        "\n",
        "COMPATIBLE_MACHINES = list(MACHINE_CONFIG.keys())\n",
        "\n",
        "# Setup Widgets\n",
        "\n",
        "dropdown_machine = widgets.Dropdown(\n",
        "    options=COMPATIBLE_MACHINES,\n",
        "    description=\"Machine type:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "label_accelerator_type = widgets.HTML()\n",
        "label_accelerator_count = widgets.HTML()\n",
        "\n",
        "\n",
        "def update_labels(machine_type: str):\n",
        "    \"\"\"Update accelerator labels based on the selected machine.\"\"\"\n",
        "    info = MACHINE_CONFIG.get(machine_type, {\"type\": \"Unknown\", \"count\": 0})\n",
        "    label_accelerator_type.value = f\"<b>Accelerator type:</b> {info['type']}\"\n",
        "    label_accelerator_count.value = f\"<b>Accelerator count:</b> {info['count']}\"\n",
        "    return info\n",
        "\n",
        "\n",
        "# Event Handling\n",
        "\n",
        "\n",
        "def on_machine_change(change):\n",
        "    \"\"\"Handle machine selection change.\"\"\"\n",
        "    if change[\"name\"] == \"value\" and change[\"type\"] == \"change\":\n",
        "        global MACHINE_TYPE, ACCELERATOR_TYPE, ACCELERATOR_COUNT\n",
        "        MACHINE_TYPE = change.new\n",
        "        info = update_labels(MACHINE_TYPE)\n",
        "        ACCELERATOR_TYPE = info[\"type\"]\n",
        "        ACCELERATOR_COUNT = info[\"count\"]\n",
        "\n",
        "\n",
        "# Initiate Global Variables\n",
        "\n",
        "MACHINE_TYPE = dropdown_machine.value\n",
        "initial_info = update_labels(MACHINE_TYPE)\n",
        "ACCELERATOR_TYPE = initial_info[\"type\"]\n",
        "ACCELERATOR_COUNT = initial_info[\"count\"]\n",
        "\n",
        "dropdown_machine.observe(on_machine_change, names=\"value\")\n",
        "\n",
        "display(\n",
        "    widgets.VBox(\n",
        "        [\n",
        "            dropdown_machine,\n",
        "            label_accelerator_type,\n",
        "            label_accelerator_count,\n",
        "        ]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGTyCQQhlrAR"
      },
      "outputs": [],
      "source": [
        "DEPLOY_PAYLOAD = {\n",
        "    \"deployedModel\": {\n",
        "        \"model\": f\"projects/{PROJECT_ID}/locations/{LOCATION}/models/{MODEL_ID}\",\n",
        "        \"displayName\": \"ModelGarden_LaunchPad_DeployedModel_\"\n",
        "        + time.strftime(\"%Y%m%d-%H%M%S\"),\n",
        "        \"dedicatedResources\": {\n",
        "            \"machineSpec\": {\n",
        "                \"machineType\": MACHINE_TYPE,\n",
        "                \"acceleratorType\": ACCELERATOR_TYPE,\n",
        "                \"acceleratorCount\": ACCELERATOR_COUNT,\n",
        "            },\n",
        "            \"minReplicaCount\": 1,\n",
        "            \"maxReplicaCount\": 1,\n",
        "        },\n",
        "    },\n",
        "    \"trafficSplit\": {\"0\": 100},\n",
        "}\n",
        "\n",
        "request = json.dumps(DEPLOY_PAYLOAD)\n",
        "print(\"Request payload to Deploy Model:\")\n",
        "print(json.dumps(DEPLOY_PAYLOAD, indent=2))\n",
        "print(\"\\nResult:\")\n",
        "! curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}:deployModel -d '{request}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ahw-uFjCAbo"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "`Nemotron Nano 12B V2 VL` supports reasoning for text, image and multi-images inputs. Reasoning behavior is controlled via the system prompt. By default, reasoning is OFF. For video inputs, reasoning is not supported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61107099357a"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to get a response from the model to analyze an image using the provided payload. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18e080f556fe"
      },
      "outputs": [],
      "source": [
        "IMAGE_URL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "!curl -L \"$IMAGE_URL\" -o image.jpg\n",
        "\n",
        "with open(\"image.jpg\", \"rb\") as f:\n",
        "    image_base64 = base64.b64encode(f.read()).decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5d8f498addb"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"model\": \"nvidia/nemotron-nano-12b-v2-vl\",\n",
        "    \"messages\": [\n",
        "            # Enable reasoning (text and images only)\n",
        "            {   \"role\": \"system\", \"content\": \"/think\"}, \n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"What is in this image?\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\":\n",
        "                            {\n",
        "                               \"url\": \"data:image/jpeg;base64,\"+image_base64 \n",
        "                            }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "    \"max_tokens\": 1024,\n",
        "    \"stream\": False\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "\n",
        "with open(\"payload.json\", \"w\") as f:\n",
        "    json.dump(PAYLOAD, f)\n",
        "    \n",
        "!curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}:rawPredict \\\n",
        "  -d @payload.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6f52fae9379"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to stream a response from the model to analyze an image using the provided payload. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c99761dcd7da"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"model\": \"nvidia/nemotron-nano-12b-v2-vl\",\n",
        "    \"messages\": [\n",
        "            # Enable reasoning (text and images only)\n",
        "            {   \"role\": \"system\", \"content\": \"/think\"}, \n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"What is in this image?\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\":\n",
        "                            {\n",
        "                               \"url\": \"data:image/jpeg;base64,\"+image_base64 \n",
        "                            }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "    \"max_tokens\": 1024,\n",
        "    \"stream\": True\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "\n",
        "with open(\"payload.json\", \"w\") as f:\n",
        "    json.dump(PAYLOAD, f)\n",
        "    \n",
        "!curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" {ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}:rawPredict \\\n",
        "  -d @payload.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d3f1e80d7bf"
      },
      "source": [
        "## Using Vertex AI SDK for *Python*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "483260c9f355"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f12fbc8611b1"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bcd31111743"
      },
      "source": [
        "### Upload Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46caaf8daa50"
      },
      "outputs": [],
      "source": [
        "model = aiplatform.Model.upload(\n",
        "    display_name=\"ModelGarden_LaunchPad_Endpoint_\" + time.strftime(\"%Y%m%d-%H%M%S\"),\n",
        "    model_garden_source_model_name=f\"publishers/{PUBLISHER_NAME}/models/{PUBLISHER_MODEL_NAME}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67b0d512503"
      },
      "source": [
        "### Create Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "634f7565b954"
      },
      "outputs": [],
      "source": [
        "my_endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=\"ModelGarden_LaunchPad_Endpoint_\" + time.strftime(\"%Y%m%d-%H%M%S\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1183d066f72"
      },
      "source": [
        "### Deploy Model\n",
        "\n",
        "Deploy the model to the endpoint. The deployment process will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7f0e6cd2112"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Configure machine types (please change if needed)\n",
        "\n",
        "MACHINE_CONFIG = {\n",
        "    \"a2-highgpu-8g\": {\"type\": \"NVIDIA_TESLA_A100\", \"count\": 8},\n",
        "    \"a2-ultragpu-8g\": {\"type\": \"NVIDIA_A100_80GB\", \"count\": 8},\n",
        "    \"a3-highgpu-8g\": {\"type\": \"NVIDIA_H100_80GB\", \"count\": 8},\n",
        "    \"a3-megagpu-8g\": {\"type\": \"NVIDIA_H100_MEGA_80GB\", \"count\": 8},\n",
        "    \"a4-highgpu-8g\": {\"type\": \"NVIDIA_B200\", \"count\": 8},\n",
        "    \"g4-standard-96\": {\"type\": \"NVIDIA_RTX_PRO_6000\", \"count\": 2},\n",
        "}\n",
        "\n",
        "COMPATIBLE_MACHINES = list(MACHINE_CONFIG.keys())\n",
        "\n",
        "# Setup Widgets\n",
        "\n",
        "dropdown_machine = widgets.Dropdown(\n",
        "    options=COMPATIBLE_MACHINES,\n",
        "    description=\"Machine type:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "label_accelerator_type = widgets.HTML()\n",
        "label_accelerator_count = widgets.HTML()\n",
        "\n",
        "\n",
        "def update_labels(machine_type: str):\n",
        "    \"\"\"Update accelerator labels based on the selected machine.\"\"\"\n",
        "    info = MACHINE_CONFIG.get(machine_type, {\"type\": \"Unknown\", \"count\": 0})\n",
        "    label_accelerator_type.value = f\"<b>Accelerator type:</b> {info['type']}\"\n",
        "    label_accelerator_count.value = f\"<b>Accelerator count:</b> {info['count']}\"\n",
        "    return info\n",
        "\n",
        "\n",
        "# Event Handling\n",
        "\n",
        "\n",
        "def on_machine_change(change):\n",
        "    \"\"\"Handle machine selection change.\"\"\"\n",
        "    if change[\"name\"] == \"value\" and change[\"type\"] == \"change\":\n",
        "        global MACHINE_TYPE, ACCELERATOR_TYPE, ACCELERATOR_COUNT\n",
        "        MACHINE_TYPE = change.new\n",
        "        info = update_labels(MACHINE_TYPE)\n",
        "        ACCELERATOR_TYPE = info[\"type\"]\n",
        "        ACCELERATOR_COUNT = info[\"count\"]\n",
        "\n",
        "\n",
        "# Initiate Global Variables\n",
        "\n",
        "MACHINE_TYPE = dropdown_machine.value\n",
        "initial_info = update_labels(MACHINE_TYPE)\n",
        "ACCELERATOR_TYPE = initial_info[\"type\"]\n",
        "ACCELERATOR_COUNT = initial_info[\"count\"]\n",
        "\n",
        "dropdown_machine.observe(on_machine_change, names=\"value\")\n",
        "\n",
        "display(\n",
        "    widgets.VBox(\n",
        "        [\n",
        "            dropdown_machine,\n",
        "            label_accelerator_type,\n",
        "            label_accelerator_count,\n",
        "        ]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db9415fda5d8"
      },
      "outputs": [],
      "source": [
        "model.deploy(\n",
        "    endpoint=my_endpoint,\n",
        "    deployed_model_display_name=\"ModelGarden_LaunchPad_DeployedModel_\"\n",
        "    + time.strftime(\"%Y%m%d-%H%M%S\"),\n",
        "    traffic_split={\"0\": 100},\n",
        "    machine_type=MACHINE_TYPE,\n",
        "    accelerator_type=ACCELERATOR_TYPE,\n",
        "    accelerator_count=ACCELERATOR_COUNT,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07adf27204e1"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "`Nemotron Nano 12B V2 VL` supports reasoning for text, image and multi-images inputs. Reasoning behavior is controlled via the system prompt. By default, reasoning is OFF. For video inputs, reasoning is not supported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d61129a3e195"
      },
      "source": [
        "#### Unary call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to get a response from the model to analyze an image using the provided payload. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7d11e422b7d"
      },
      "outputs": [],
      "source": [
        "IMAGE_URL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "!curl -L \"$IMAGE_URL\" -o image.jpg\n",
        "\n",
        "with open(\"image.jpg\", \"rb\") as f:\n",
        "    image_base64 = base64.b64encode(f.read()).decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "736db4b012ca"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"model\": \"nvidia/nemotron-nano-12b-v2-vl\",\n",
        "    \"messages\": [\n",
        "        # Enable reasoning (text and images only)\n",
        "        {\"role\": \"system\", \"content\": \"/think\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": \"data:image/jpeg;base64,\" + image_base64},\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        "    \"max_tokens\": 1024,\n",
        "    \"stream\": False,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "\n",
        "response = my_endpoint.raw_predict(\n",
        "    body=request, headers={\"Content-Type\": \"application/json\"}\n",
        ")\n",
        "\n",
        "result = json.loads(response.text)\n",
        "\n",
        "print(json.dumps(result[\"choices\"][0][\"message\"][\"content\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdc767b8876d"
      },
      "source": [
        "#### Streaming call\n",
        "\n",
        "Sends a POST request to the specified API endpoint to stream a response from the model to analyze an image using the provided payload. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "939a2a0f07f8"
      },
      "outputs": [],
      "source": [
        "PAYLOAD = {\n",
        "    \"model\": \"nvidia/nemotron-nano-12b-v2-vl\",\n",
        "    \"messages\": [\n",
        "        # Enable reasoning (text and images only)\n",
        "        {\"role\": \"system\", \"content\": \"/think\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": \"data:image/jpeg;base64,\" + image_base64},\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        "    \"max_tokens\": 1024,\n",
        "    \"stream\": True,\n",
        "}\n",
        "\n",
        "request = json.dumps(PAYLOAD)\n",
        "\n",
        "for stream_response in my_endpoint.stream_raw_predict(\n",
        "    body=request, headers={\"Content-Type\": \"application/json\"}\n",
        "):\n",
        "    print(stream_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "nemotron_nano_intro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
