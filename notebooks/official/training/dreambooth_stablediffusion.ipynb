{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "219f1b1fe8fe"
   },
   "source": [
    "# Tune and deploy DreamBooth Stable Diffusion model using your own images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/stable_diffusion/dreambooth_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/stable_diffusion/dreambooth_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    " <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/stable_diffusion/dreambooth_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fce05a8186d6"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to train and host a [Stable Diffusion 1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5) model on Vertex AI. The notebook uses [PyTorch](https://pytorch.org/) to train the model; the PyTorch 3 container built for Vertex AI is used for hosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c76216b03fec"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to fine tune a Stable Diffusion 1.5 model using your own images and serve that model on Vertex AI.\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "+ Vertex AI `Model` resource\n",
    "+ Vertex AI `Endpoint` resource\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "+ Fine tune a Stable Diffusion 1.5 model locally using the DreamBooth approach.\n",
    "+ Save the model as a PyTorch checkpoint (.ckpt) artifact.\n",
    "+ Create a `torchserve` handler for responding to prediction requests.\n",
    "+ Upload a Stable Diffusion 1.5 model on a prebuilt PyTorch container in Vertex AI.\n",
    "+ Deploy a custom model to a Vertex AI Endpoint.\n",
    "+ Send requests to the endpoint and parse the responses using Vertex AI Prediction service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6deba5a8557"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This notebook uses a dataset of 5 dog images that you can download from Google Cloud Storage. These are the same images used in the original [DreamBooth paper](https://dreambooth.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "911dc651ea9c"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI models\n",
    "* Vertex AI endpoints\n",
    "* Vertex AI prediction\n",
    "* Google Cloud Storage\n",
    "* (Optionally) Vertex AI Workbench\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bb4201cc99a"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook.\n",
    "\n",
    "**Note**: You might need to change the version of PyTorch (`torch`) installed by `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c769df171a6"
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "bitsandbytes==0.37.0\n",
    "ftfy\n",
    "google-cloud-aiplatform\n",
    "gradio\n",
    "natsort\n",
    "ninja\n",
    "tensorboard==1.15.0\n",
    "torch\n",
    "torchaudio\n",
    "torchvision\n",
    "torchserve\n",
    "torch-model-archiver\n",
    "torch-workflow-archiver\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e46804ac90d8"
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22431ea2f6cb"
   },
   "source": [
    "**Note**: The `bitsandbytes` library v0.37.0, which was used for testing, has a minor bug that we need to fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca6e65cb641e"
   },
   "outputs": [],
   "source": [
    "!sed -i '153 i\\            cuda_setup = CUDASetup.get_instance()' /opt/conda/lib/python3.7/site-packages/bitsandbytes/cuda_setup/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1671f3ba3803"
   },
   "source": [
    "Some additional pre-release, forked, and specialized libraries are required for running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f4f08a041f4"
   },
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/ShivamShrirao/diffusers\n",
    "%pip install -U --pre triton\n",
    "%pip install -U --pre xformers\n",
    "%pip install accelerate==0.15.0\n",
    "%pip install nvidia-pyindex\n",
    "%pip install nvidia-cuda-runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "341bcba4d3b3"
   },
   "source": [
    "Due to an issue with newer versions of PyTorch, older versions of the NVIDIA CUDA drivers needs to be manually removed. \n",
    "\n",
    "To remove these drivers, open up a new terminal instance and run the following from the command line. When prompted, type \"Y\" to proceed.\n",
    "\n",
    "```bash\n",
    "pip uninstall nvidia_cublas_cu11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9f86ba5d6fe"
   },
   "source": [
    "Finally, this notebook uses two additional files available on GitHub. Run the following cell to download these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e76b1ae0aeca"
   },
   "outputs": [],
   "source": [
    "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
    "!wget -q https://gist.github.com/jachiam/8a5c0b607e38fcc585168b90c686eb05/raw/2af0a9c0237ed98b863a75e1db21d7ed5541094f/convert_diffusers_to_sd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### Colab only: Uncomment the following cell to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77c11549298a"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "294df346a918"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d36bd3d53fa"
   },
   "source": [
    "### Hardware requirements\n",
    "\n",
    "This notebook requires that you use a GPU with a sufficient amount of VRAM available. It was tested on a `Tesla P100-PCIE-16GB` with 16 MiB of VRAM. Run the following cell to ensure that you have the correct hardware configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dd4022552e5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=\"csv,noheader\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a782627e5f73"
   },
   "source": [
    "### Create a user-managed notebook on Vertex AI\n",
    "\n",
    "If you are using Vertex AI Workbench, you can create a notebook with the correct configuration by doing the following:\n",
    "\n",
    "+ Go to [Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/user-managed) in the Google Cloud Console.\n",
    "+ Click **New Notebook** and then click **Python 3 (CUDA Toolkit 11.0)** > **With 1 NVIDIA T4**.\n",
    "+ In the **New notebook** dialog box, click **Advanced Options**. The **Create a user-managed notebook** page opens up.\n",
    "+ In the **Create a user-managed notebook** page, do the following:\n",
    "  * In the **Notebook name** box, type a name for your notebook, for example \"my-stablediffusion-nb\".\n",
    "  * In the **Machine type** drop-down, select **N1-standard** > **n1-standard-16**.\n",
    "  * In the **GPU type** drop-down, select **NVIDIA Tesla P100**.\n",
    "  * Check the box next to **Install NVIDIA GPU driver automatically for me**\n",
    "  * Expand **Disk(s)** and do the following:\n",
    "    - Under **Boot disk type**, select **SSD Persistent Disk**.\n",
    "    - Under **Data disk type**, select **SSD Persistent Disk**.\n",
    "  * Click **Create**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAPoU8Sm5E6e"
   },
   "source": [
    "<div style=\"background:#feefe3; padding:5px; color:#aa0000\">\n",
    "<strong>Caution:</strong> Using a Vertex AI Workbench notebook with the above configuration can increase your costs significantly.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ccc9e52986"
   },
   "source": [
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6b2ccc891ed"
   },
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb5c4ca3e851"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7348591eda51"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from google.cloud import aiplatform\n",
    "from IPython.display import display\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "from torch import autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f2ac67caf69"
   },
   "source": [
    "## Fine tune the Stable Diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2820915e9942"
   },
   "source": [
    "### Set paths for inputs and outputs\n",
    "\n",
    "To train the Stable Diffusion 2.0 model, you must provide a local folder for storing artifacts. You need to create a directory to store your input images (the images you use to fine tune the model). Your inputs should all show the same \"class\" of thing. In this example, we are going to fine-tune our model to create new images of a dog, so the name of our class is `dog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42f6506a0610"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"\n",
    "INSTANCE_DIR = \"/home/jupyter/examplePup\"\n",
    "CLASS_DIR = \"/home/jupyter/dog\"\n",
    "OUTPUT_DIR = \"stable_diffusion_weights/output\"\n",
    "\n",
    "save_to_gdrive = False\n",
    "if save_to_gdrive:\n",
    "    from google.colab import drive\n",
    "\n",
    "    # make sure google drive is unmounted before remount\n",
    "    drive.mount(\"/content/drive\")\n",
    "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
    "\n",
    "else:\n",
    "    OUTPUT_DIR = \"/home/jupyter/\" + OUTPUT_DIR\n",
    "\n",
    "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
    "\n",
    "!mkdir -p $INSTANCE_DIR\n",
    "!mkdir -p $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e659f0ec0047"
   },
   "source": [
    "You can use a set of 5 images available on Google Cloud Storage to fine-tune the `dog` class for your Stable Diffusion model. The images are available at the URI `gs://cloud-samples-data/vertex-ai/dataset-management/datasets/dogs/`.\n",
    "\n",
    "Be sure that you download the images to the same location that you provided for `INSTANCE_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d63df8d91215"
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://cloud-samples-data/vertex-ai/dataset-management/datasets/dogs/*.jpg \\\n",
    "   $INSTANCE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9989fa92987e"
   },
   "source": [
    "### Start model training\n",
    "\n",
    "This notebook uses the `accelerate` library from [HuggingFace](https://github.com/huggingface/accelerate) to speed up model training. This library is invoked directly from the CLI. Training hyperparameters, input and output folders, class and instance prompts are passed into the CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caf3994cd7c3"
   },
   "source": [
    "This notebook uses [mixed precision training](https://keras.io/api/mixed_precision/), which allows it to run faster and use less memory.\n",
    "\n",
    "You might need to adjust the following command based upon your hardware (memory and speed) configuration. Use the following table to determine which settings are best for your hardware.\n",
    "\n",
    "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
    "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
    "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
    "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
    "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
    "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
    "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
    "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
    "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
    "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
    "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c2be654869c"
   },
   "outputs": [],
   "source": [
    "# Update this value for your own fine-tuning dataset\n",
    "NUM_CLASS_IMAGES = 5\n",
    "INSTANCE_PROMPT = \"examplePup\"  # @markdown `INSTANCE_PROMPT` is a prompt that should contain a good description of what your object or style is\n",
    "CLASS_PROMPT = \"dog\"  # @markdown `CLASS_PROMPT` is a prompt that should contain a good description of what the class your object belongs to\n",
    "\n",
    "# Change these constants to match your hardware constraints\n",
    "RESOLUTION = 512\n",
    "LEARNING_RATE = 5e-06\n",
    "MAX_TRAIN_STEPS = 1000\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "MIXED_PRECISION = \"fp16\"\n",
    "PRIOR_LOSS_WEIGHT = 1.0\n",
    "SAMPLE_BATCH_SIZE = 4\n",
    "LR_SCHEDULER = \"constant\"\n",
    "LR_WARMUP_STEPS = 0\n",
    "SEED = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "329571e59aa2"
   },
   "source": [
    "To learn more about the arguments passed to `accelerate launch`, see the [reference documentation](https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-launch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b2b9bec0032"
   },
   "outputs": [],
   "source": [
    "%%capture tuning_output\n",
    "\n",
    "!accelerate launch train_dreambooth.py \\\n",
    "--pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "--instance_data_dir=$INSTANCE_DIR \\\n",
    "--class_data_dir=$CLASS_DIR \\\n",
    "--output_dir=$OUTPUT_DIR \\\n",
    "--with_prior_preservation \\\n",
    "--prior_loss_weight=$PRIOR_LOSS_WEIGHT \\\n",
    "--instance_prompt=$INSTANCE_PROMPT \\\n",
    "--class_prompt=$CLASS_PROMPT \\\n",
    "--seed=$SEED \\\n",
    "--resolution=$RESOLUTION \\\n",
    "--center_crop \\\n",
    "--train_batch_size=$TRAIN_BATCH_SIZE \\\n",
    "--mixed_precision=$MIXED_PRECISION \\\n",
    "--use_8bit_adam \\\n",
    "--gradient_accumulation_steps=$GRADIENT_ACCUMULATION_STEPS \\\n",
    "--learning_rate=$LEARNING_RATE  \\\n",
    "--lr_scheduler=$LR_SCHEDULER\\\n",
    "--lr_warmup_steps=$LR_WARMUP_STEPS \\\n",
    "--num_class_images=$NUM_CLASS_IMAGES \\\n",
    "--sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
    "--max_train_steps=$MAX_TRAIN_STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19bd71735408"
   },
   "source": [
    "Fine-tuning a Stable Diffusion model can take a while to finish, depending on the amount of input images that you provide to it. To see the output from training, run the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3128db457c4c"
   },
   "outputs": [],
   "source": [
    "tuning_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "697566b5f660"
   },
   "source": [
    "## View training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31361bb3366b"
   },
   "source": [
    "### Consolidate model artifacts\n",
    "\n",
    "Once your Stable Diffusion model is done training / fine tuning, you can look at the results! In the next step, you'll need to move the most recent directory of weights for you model into directory with the rest of your model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72920300e016"
   },
   "outputs": [],
   "source": [
    "# @markdown Specify the weights directory to use (leave blank for latest)\n",
    "WEIGHTS_DIR = \"\"  # @param {type:\"string\"}\n",
    "if WEIGHTS_DIR == \"\":\n",
    "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
    "\n",
    "    print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34deceab56f1"
   },
   "outputs": [],
   "source": [
    "!mv {WEIGHTS_DIR}/* {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b23a297295e"
   },
   "source": [
    "Now that you have all of the model artifacts in the same directory, we can create a model checkpoint (.ckpt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f1227778f8a"
   },
   "outputs": [],
   "source": [
    "# @markdown Run conversion.\n",
    "model_name = \"model-dog\"  # @param {type: \"string\"}\n",
    "ckpt_path = OUTPUT_DIR + f\"/{model_name}.ckpt\"\n",
    "\n",
    "half_arg = \"\"\n",
    "# @markdown  Whether to convert to fp16, takes half the space (2GB), might lose some quality.\n",
    "fp16 = True  # @param {type: \"boolean\"}\n",
    "if fp16:\n",
    "    half_arg = \"--half\"\n",
    "!python convert_diffusers_to_sd.py --model_path $OUTPUT_DIR  --checkpoint_path $ckpt_path $half_arg\n",
    "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9192ea4f3b57"
   },
   "source": [
    "### Create new images\n",
    "\n",
    "With everying in place, you can now generate new images from the Stable Diffusion model. First you must load your model into a `StableDiffusionPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd1f30223b79"
   },
   "outputs": [],
   "source": [
    "model_path = \"\"\n",
    "if model_path == \"\":\n",
    "    model_path = OUTPUT_DIR\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_path, torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "g_cuda = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd91520f58cf"
   },
   "outputs": [],
   "source": [
    "g_cuda = torch.Generator(device=\"cuda\")\n",
    "seed = 52362\n",
    "g_cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e9c5d734b9f"
   },
   "source": [
    "With the model loaded into a `StableDiffusionPipeline`, you can now generate results (inferences) from the model. Each set of inference requires an input (called a [prompt](https://learnprompting.org/)) that specifies what the model should create.\n",
    "\n",
    "You can also vary other inputs into the model, as shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a28b73de55ce"
   },
   "outputs": [],
   "source": [
    "prompt = \"photo of examplePup dog with snow mountain background.\"\n",
    "\n",
    "num_samples = 4\n",
    "num_batches = 1\n",
    "num_columns = 2\n",
    "guidance_scale = 10\n",
    "num_inference_steps = 50\n",
    "height = 512\n",
    "width = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11a7bb79de59"
   },
   "outputs": [],
   "source": [
    "def image_grid(imgs, cols):\n",
    "    total = len(imgs)\n",
    "    rows = math.ceil(total / cols)\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "all_images = []\n",
    "for _ in range(num_batches):\n",
    "    with autocast(\"cuda\"):\n",
    "        images = pipe(\n",
    "            [prompt] * num_samples,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "        ).images\n",
    "        all_images.extend(images)\n",
    "\n",
    "\n",
    "grid = image_grid(all_images, num_columns)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf8d545a135b"
   },
   "source": [
    "### Re-training the model\n",
    "\n",
    "If you aren't satisfied with the inference outputs from the model, you can retrain it. Before you can do that, you might need to release the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5621b7a927f8"
   },
   "outputs": [],
   "source": [
    "# Run this cell _only_ if you want to release the GPU memory.\n",
    "pipe = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbc72963ff88"
   },
   "source": [
    "## Deploy the model to Vertex AI\n",
    "\n",
    "You can host your Stable Diffusion 2.0 model on a Vertex AI endpoint where you can get inferences from it online. Uploading your model is a three step process: \n",
    "\n",
    "1. Create a custom TorchServe handler.\n",
    "1. Upload the model artifacts onto Google Cloud Storage.\n",
    "2. Create a Vertex AI model with the model artifacts and a prebuilt PyTorch container image.\n",
    "3. Deploy the Vertex AI model onto an endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67b163c48525"
   },
   "source": [
    "Before we can do that, though, we need to collect all of the model artifacts into a single place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d450d60edf4"
   },
   "outputs": [],
   "source": [
    "!mkdir model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eafbb0e0-40e6-43a0-a38e-edc54323da51"
   },
   "source": [
    "### Create the custom TorchServe handler\n",
    "\n",
    "The model deployed to Vertex AI uses [TorchServe](https://pytorch.org/serve/) to handle requests and return responses from the model. You must create a custom TorchServe handler to include in with the model artifacts uploaded to Vertex AI.\n",
    "\n",
    "The handler file should be included in the directory with the other model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94567a87-9d74-4c87-a749-306ddaf01b61"
   },
   "outputs": [],
   "source": [
    "%%writefile model_artifacts/handler.py\n",
    "\n",
    "\"\"\"Customized handler for Stable Diffusion 2.\"\"\"\n",
    "import base64\n",
    "import logging\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "model_id = 'stabilityai/stable-diffusion-2'\n",
    "\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.initialized = False\n",
    "    self.map_location = None\n",
    "    self.device = None\n",
    "    self.use_gpu = True\n",
    "    self.store_avg = True\n",
    "    self.pipe = None\n",
    "\n",
    "  def initialize(self, context):\n",
    "    \"\"\"Initializes the pipe.\"\"\"\n",
    "    properties = context.system_properties\n",
    "    gpu_id = properties.get('gpu_id')\n",
    "\n",
    "    self.map_location, self.device, self.use_gpu = \\\n",
    "      ('cuda', torch.device('cuda:' + str(gpu_id)),\n",
    "       True) if torch.cuda.is_available() else \\\n",
    "        ('cpu', torch.device('cpu'), False)\n",
    "\n",
    "    # Use the Euler scheduler here instead\n",
    "    scheduler = EulerDiscreteScheduler.from_pretrained(model_id,\n",
    "                                                       subfolder='scheduler')\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id,\n",
    "                                                   scheduler=scheduler,\n",
    "                                                   torch_dtype=torch.float16)\n",
    "    pipe = pipe.to('cuda')\n",
    "    # Uncomment the following line to reduce the GPU memory usage.\n",
    "    # pipe.enable_attention_slicing()\n",
    "    self.pipe = pipe\n",
    "\n",
    "    self.initialized = True\n",
    "\n",
    "  def preprocess(self, requests):\n",
    "    \"\"\"Noting to do here.\"\"\"\n",
    "    logger.info('requests: %s', requests)\n",
    "    return requests\n",
    "\n",
    "  def inference(self, preprocessed_data, *args, **kwargs):\n",
    "    \"\"\"Run the inference.\"\"\"\n",
    "    images = []\n",
    "    for pd in preprocessed_data:\n",
    "      prompt = pd['prompt']\n",
    "      images.extend(self.pipe(prompt).images)\n",
    "    return images\n",
    "\n",
    "  def postprocess(self, output_batch):\n",
    "    \"\"\"Converts the images to base64 string.\"\"\"\n",
    "    postprocessed_data = []\n",
    "    for op in output_batch:\n",
    "      fp = BytesIO()\n",
    "      op.save(fp, format='JPEG')\n",
    "      postprocessed_data.append(base64.b64encode(fp.getvalue()).decode('utf-8'))\n",
    "      fp.close()\n",
    "    return postprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ace1dac0af0"
   },
   "source": [
    "After creating the handler file, you must package the handler as a model archiver (MAR) file. The output file must be named 'model.mar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67707f95d440"
   },
   "outputs": [],
   "source": [
    "!torch-model-archiver \\\n",
    "  -f \\\n",
    "  --model-name model \\\n",
    "  --version 1.0 \\\n",
    "  --handler model_artifacts/handler.py \\\n",
    "  --export-path model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffab030f4bc8"
   },
   "source": [
    "### Upload the model artifacts to Google Cloud Storage\n",
    "\n",
    "Create a new folder in your Google Cloud Storage bucket to hold the model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://your-bucket-name-unique\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}/\"\n",
    "FULL_GCS_PATH = f\"{BUCKET_URI}model_artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "971232e28657"
   },
   "source": [
    "Next, upload the model archive file and your trained Stable Diffusion 2.0 model to the folder on Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef6baf44c808"
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r model_artifacts $BUCKET_URI\n",
    "!gsutil cp -r $OUTPUT_DIR $FULL_GCS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "402370ca9396"
   },
   "source": [
    "### Create the Vertex AI model\n",
    "\n",
    "Once you've uploaded the model artifacts into a Cloud Storage bucket, you can create a new Vertex AI model. This notebook uses the [Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk) to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6c58a74a0fd"
   },
   "outputs": [],
   "source": [
    "PYTORCH_PREDICTION_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.1-12:latest\"\n",
    ")\n",
    "APP_NAME = \"my-stable-diffusion\"\n",
    "VERSION = 1\n",
    "MODEL_DISPLAY_NAME = \"stable_diffusion_1_4-unique\"\n",
    "MODEL_DESCRIPTION = \"stable_diffusion_1_4 container\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"{APP_NAME}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07c3503a1a2e"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a776324dd16f"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    description=MODEL_DESCRIPTION,\n",
    "    serving_container_image_uri=PYTORCH_PREDICTION_IMAGE_URI,\n",
    "    artifact_uri=FULL_GCS_PATH,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fbc3d371574"
   },
   "source": [
    "### Deploy the model to an endpoint\n",
    "\n",
    "To get online preductions from your Stable Diffusion 2.0 model, you must [deploy it to a Vertex AI endpoint](https://cloud.google.com/vertex-ai/docs/predictions/overview). You can again use the Vertex AI SDK to create the endpoint and deploy your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab29f0a770cb"
   },
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25f703df88c7"
   },
   "outputs": [],
   "source": [
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_P100\",\n",
    "    accelerator_count=1,\n",
    "    traffic_percentage=100,\n",
    "    deploy_request_timeout=1200,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9fc560df0a9"
   },
   "source": [
    "If the previous cell times out before returning, your endpoint might still be successfully deployed ot an end point. Check the [Cloud Console](https://console.cloud.google.com/vertex-ai/endpoints) to verify the results.\n",
    "\n",
    "You can also extend the time to wait for deployment by changing the `deploy_request_timeout` argument passed to `model.deploy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88a5304dfdc9"
   },
   "source": [
    "## Get online predictions\n",
    "\n",
    "Finally, with your Stable Diffusion 2.0 model deployed to a Vertex AI endpoint, you can now get online predictions from it. Using the Vertex AI SDK, you only need a few lines of code to get an inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d6bc4aa34d6"
   },
   "outputs": [],
   "source": [
    "instances = [{\"prompt\": \"An examplePup dog with a baseball jersey.\"}]\n",
    "response = endpoint.predict(instances=instances)\n",
    "\n",
    "with open(\"img5.jpg\", \"wb\") as g:\n",
    "    g.write(base64.b64decode(response.predictions[0]))\n",
    "\n",
    "display.Image(\"img5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Delete endpoint resource\n",
    "endpoint.undeploy_all()\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete model resource\n",
    "\n",
    "model.delete()\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dreambooth_stablediffusion.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
