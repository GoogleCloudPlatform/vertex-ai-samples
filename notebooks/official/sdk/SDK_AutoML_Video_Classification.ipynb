{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "modular-concentration"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pregnant-going"
   },
   "source": [
    "# Vertex SDK for Python: AutoML Video Classification Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/sdk/SDK_AutoML_Video_Classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/sdk/SDK_AutoML_Video_Classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/sdk/SDK_AutoML_Video_Classification.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrate how to create an AutoML Video Classification Model, with a Vertex AI video dataset, and how to serve the model for batch prediction. It will require you provide a bucket where the dataset will be stored.\n",
    "\n",
    "Note: you may incur charges for training, prediction, storage or usage of other GCP products in connection with testing this SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "##### HMDB: a large human motion database\n",
    "We prepared some training data and prediction data for the demo using the [HMDB Dataset](https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database).\n",
    "\n",
    "The HMDB Dataset is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit https://creativecommons.org/licenses/by/4.0/\n",
    "\n",
    "For more information about this dataset please visit: https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The objective of this notebook is to build a AutoML Video Classification Model. The following steps have been followed:  \n",
    "\n",
    "- Create a Dataset on Vertex AI.\n",
    "- Launch a Training Job and Create a Model on Vertex AI\n",
    "- Perform batch Prediction Job on the Model\n",
    "- Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs\n",
    "\n",
    "This tutorial uses the following billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "- Cloud Storage\n",
    "\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [BigQuery pricing](https://cloud.google.com/bigquery/pricing) and [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your local development environment\n",
    "\n",
    "**If you are using Colab or Vertex AI Workbench Notebooks**, your environment already meets\n",
    "all the requirements to run this notebook. You can skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
    "You need the following:\n",
    "\n",
    "* The Google Cloud SDK\n",
    "* Git\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* Jupyter notebook running in a virtual environment with Python 3\n",
    "\n",
    "The Google Cloud guide to [Setting up a Python development\n",
    "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
    "installation guide](https://jupyter.org/install) provide detailed instructions\n",
    "for meeting these requirements. The following steps provide a condensed set of\n",
    "instructions:\n",
    "\n",
    "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "1. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "1. [Install\n",
    "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
    "   and create a virtual environment that uses Python 3. Activate the virtual environment.\n",
    "\n",
    "1. To install Jupyter, run `pip3 install jupyter` on the\n",
    "command-line in a terminal shell.\n",
    "\n",
    "1. To launch Jupyter, run `jupyter notebook` on the command-line in a terminal shell.\n",
    "\n",
    "1. Open this notebook in the Jupyter Notebook Dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install additional packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "coated-remark",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.9/site-packages (1.11.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.16.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4.0.0dev,>=3.19.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-aiplatform) (3.20.0rc2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-aiplatform) (1.20.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-aiplatform) (2.2.1)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.6.0-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 54.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 54.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.9/site-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-aiplatform) (2.34.2)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 63.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.6.2)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.9/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.9/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.2.3)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos[grpc]<2.0.0dev,>=1.56.0 in /usr/local/lib/python3.9/site-packages (from grpc-google-iam-v1<1.0.0dev,>=0.12.4->google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (1.56.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.12)\n",
      "Installing collected packages: googleapis-common-protos, google-api-core, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-aiplatform\n",
      "  Attempting uninstall: googleapis-common-protos\n",
      "    Found existing installation: googleapis-common-protos 1.56.0\n",
      "    Uninstalling googleapis-common-protos-1.56.0:\n",
      "      Successfully uninstalled googleapis-common-protos-1.56.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 2.7.1\n",
      "    Uninstalling google-api-core-2.7.1:\n",
      "      Successfully uninstalled google-api-core-2.7.1\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.11.0\n",
      "    Uninstalling google-cloud-aiplatform-1.11.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.11.0\n",
      "Successfully installed google-api-core-2.8.2 google-cloud-aiplatform-1.16.1 google-cloud-resource-manager-1.6.0 googleapis-common-protos-1.56.4 grpc-google-iam-v1-0.12.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install {USER_FLAG} --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the kernel\n",
    "\n",
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "1. [Enable the Vertex AI, Cloud Storage, and Compute Engine APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com). \n",
    "\n",
    "1. [Configure your Google Cloud project for Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/configure-project).\n",
    "\n",
    "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
    "\n",
    "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
    "Cloud SDK uses the right project for all the commands in this notebook.\n",
    "\n",
    "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands.\n",
    "\n",
    "### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  vertex-ai-dev\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, set your project ID here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UUID\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "**If you are using Vertex AI Workbench Notebooks**, your environment is already\n",
    "authenticated. Skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are using Colab**, run the cell below and follow the instructions\n",
    "when prompted to authenticate your account via oAuth.\n",
    "\n",
    "**Otherwise**, follow these steps:\n",
    "\n",
    "1. In the Cloud Console, go to the [**Create service account key**\n",
    "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
    "\n",
    "2. Click **Create service account**.\n",
    "\n",
    "3. In the **Service account name** field, enter a name, and\n",
    "   click **Create**.\n",
    "\n",
    "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"Vertex AI\"\n",
    "into the filter box, and select\n",
    "   **Vertex AI Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
    "\n",
    "5. Click *Create*. A JSON file that contains your key downloads to your\n",
    "local environment.\n",
    "\n",
    "6. Enter the path to your service account key as the\n",
    "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
    "Cloud Storage buckets.\n",
    "\n",
    "You may also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook. Make sure to [choose a region where Vertex AI services are\n",
    "available](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions). You may\n",
    "not use a Multi-Regional Storage bucket for training with Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "REGION = \"[your-region]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_URI = \"gs://\" + PROJECT_ID + \"aip-\" + UUID\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://vertex-ai-devaip-l0fpag0g/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally**, validate access to your Cloud Storage bucket by examining its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://vertex-ai-devaip-l0fpag0g/mbsdk_automl-video-training_classification/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "incorporated-edgar"
   },
   "source": [
    "### Import libraries and define constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hispanic-macedonia"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "MY_PROJECT = PROJECT_ID\n",
    "MY_STAGING_BUCKET = BUCKET_URI  # bucket should be in same region as ucaip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "historical-consciousness"
   },
   "source": [
    "### Set Your Task Name, and GCS Prefix\n",
    "\n",
    "If you want to centeralize all input and output files under the gcs location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "organizational-salad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Name:    vertex-ai-devaip-l0fpag0g\n",
      "Task Name:      mbsdk_automl-video-training_classification\n"
     ]
    }
   ],
   "source": [
    "TASK_TYPE = \"mbsdk_automl-video-training\"\n",
    "PREDICTION_TYPE = \"classification\"\n",
    "MODEL_TYPE = \"CLOUD\"\n",
    "\n",
    "TASK_NAME = f\"{TASK_TYPE}_{PREDICTION_TYPE}\"\n",
    "BUCKET_NAME = MY_STAGING_BUCKET.split(\"gs://\")[1]\n",
    "GCS_PREFIX = TASK_NAME\n",
    "\n",
    "print(f\"Bucket Name:    {BUCKET_NAME}\")\n",
    "print(f\"Task Name:      {TASK_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compact-engagement"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SPDHQoFRD-vM"
   },
   "outputs": [],
   "source": [
    "automl_video_demo_train_data = (\n",
    "    \"gs://automl-video-demo-data/hmdb_split1_5classes_all.csv\"\n",
    ")\n",
    "automl_video_demo_batch_prediction_data = (\n",
    "    \"gs://automl-video-demo-data/hmdb_split1_predict.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "professional-bulletin"
   },
   "source": [
    "### Copy AutoML Video Demo Train Data for Creating Managed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "accurate-producer"
   },
   "outputs": [],
   "source": [
    "gcs_source_train = f\"gs://{BUCKET_NAME}/{TASK_NAME}/data/video_classification.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sticky-casino"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://automl-video-demo-data/hmdb_split1_5classes_all.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 52.8 KiB/ 52.8 KiB]                                                \n",
      "Operation completed over 1 objects/52.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $automl_video_demo_train_data $gcs_source_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rough-alert"
   },
   "source": [
    "# Run AutoML Video Training with Managed Video Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adaptive-slovakia"
   },
   "source": [
    "## Initialize Vertex SDK for Python\n",
    "\n",
    "Initialize the *client* for Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "figured-fellow"
   },
   "outputs": [],
   "source": [
    "\n",
    "aiplatform.init(project=MY_PROJECT, staging_bucket=MY_STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pleasant-holmes"
   },
   "source": [
    "## Create a Dataset on Vertex AI\n",
    "We will now create a Vertex AI video dataset using the previously prepared csv files. Choose one of the options below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln-8NdHjTfbH"
   },
   "source": [
    "Option 1: Using MBSDK VideoDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "id": "uVBfL-0TTjNS",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating VideoDataset\n",
      "Create VideoDataset backing LRO: projects/931647533046/locations/us-central1/datasets/6222780615398260736/operations/2821241627354333184\n",
      "VideoDataset created. Resource name: projects/931647533046/locations/us-central1/datasets/6222780615398260736\n",
      "To use this VideoDataset in another session:\n",
      "ds = aiplatform.VideoDataset('projects/931647533046/locations/us-central1/datasets/6222780615398260736')\n",
      "Importing VideoDataset data: projects/931647533046/locations/us-central1/datasets/6222780615398260736\n",
      "Import VideoDataset data backing LRO: projects/931647533046/locations/us-central1/datasets/6222780615398260736/operations/5605592096976142336\n"
     ]
    }
   ],
   "source": [
    "dataset = aiplatform.VideoDataset.create(\n",
    "    display_name=f\"temp-{TASK_NAME}\",\n",
    "    gcs_source=gcs_source_train,\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.video.classification,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXCA_nvHTp_I"
   },
   "source": [
    "Option 2: Using MBSDK Dataset class\n",
    "```\n",
    "dataset = aiplatform.Dataset.create(\n",
    "    display_name=f'temp-{TASK_NAME}',\n",
    "    metadata_schema_uri=aiplatform.schema.dataset.metadata.video,\n",
    "    gcs_source=gcs_source_train, \n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.video.classification,\n",
    "    sync=False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3x4xuyIbVR_N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoDataset data imported. Resource name: projects/931647533046/locations/us-central1/datasets/6222780615398260736\n"
     ]
    }
   ],
   "source": [
    "dataset.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mexican-spending"
   },
   "source": [
    "## Launch a Training Job and Create a Model on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dynamic-piece"
   },
   "source": [
    "### Config a Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "continuous-circular"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLVideoTrainingJob(\n",
    "    display_name=f\"temp-{TASK_NAME}\",\n",
    "    prediction_type=PREDICTION_TYPE,\n",
    "    model_type=MODEL_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juvenile-parameter"
   },
   "source": [
    "### Run the Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "human-carrier"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6896921156079583232?project=931647533046\n"
     ]
    }
   ],
   "source": [
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    training_fraction_split=0.1,\n",
    "    test_fraction_split=0.9,\n",
    "    model_display_name=f\"temp-{TASK_NAME}\",\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "abstract-textbook",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLVideoTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/6896921156079583232 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noted-usage"
   },
   "source": [
    "# Batch Prediction Job on the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruled-smith"
   },
   "source": [
    "### Copy AutoML Video Demo Prediction Data for Creating Batch Prediction Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "polished-dispatch"
   },
   "outputs": [],
   "source": [
    "gcs_source_batch_prediction = (\n",
    "    f\"gs://{BUCKET_NAME}/{TASK_NAME}/data/video_classification_batch_prediction.jsonl\"\n",
    ")\n",
    "gcs_destination_prefix_batch_prediction = (\n",
    "    f\"gs://{BUCKET_NAME}/{TASK_NAME}/batch_prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "objective-soldier"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://automl-video-demo-data/hmdb_split1_predict.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  887.0 B/  887.0 B]                                                \n",
      "Operation completed over 1 objects/887.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $automl_video_demo_batch_prediction_data $gcs_source_batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "piano-middle"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/931647533046/locations/us-central1/batchPredictionJobs/2836081667074949120\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/931647533046/locations/us-central1/batchPredictionJobs/2836081667074949120')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/2836081667074949120?project=931647533046\n"
     ]
    }
   ],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=f\"temp-{TASK_NAME}\",\n",
    "    gcs_source=gcs_source_batch_prediction,\n",
    "    gcs_destination_prefix=gcs_destination_prefix_batch_prediction,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "visible-scientist"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instance': {'content': 'gs://automl-video-demo-data/hmdb51/35_pull_ups_pullup_f_nm_np1_fr_goo_1.mp4', 'mimeType': 'mp4', 'timeSegmentStart': '0.0s', 'timeSegmentEnd': '2.633333s'}, 'prediction': [{'id': '2649711422509940736', 'displayName': 'pullup', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.8607105}, {'id': '6108475936330481664', 'displayName': 'ride_horse', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.03772395}, {'id': '4955554431723634688', 'displayName': 'golf', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.03616389}, {'id': '1496789917903093760', 'displayName': 'kick_ball', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.033297308}, {'id': '7261397440937328640', 'displayName': 'cartwheel', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.032104395}]}\n",
      "{'instance': {'content': 'gs://automl-video-demo-data/hmdb51/CrossCountry_ride_horse_f_cm_np1_le_med_2.mp4', 'mimeType': 'mp4', 'timeSegmentStart': '0.0s', 'timeSegmentEnd': '2.366667s'}, 'prediction': [{'id': '6108475936330481664', 'displayName': 'ride_horse', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.366667s', 'confidence': 0.8481315}, {'id': '4955554431723634688', 'displayName': 'golf', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.366667s', 'confidence': 0.045736562}, {'id': '2649711422509940736', 'displayName': 'pullup', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.366667s', 'confidence': 0.03725655}, {'id': '1496789917903093760', 'displayName': 'kick_ball', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.366667s', 'confidence': 0.035912223}, {'id': '7261397440937328640', 'displayName': 'cartwheel', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.366667s', 'confidence': 0.03296317}]}\n",
      "{'instance': {'content': 'gs://automl-video-demo-data/hmdb51/How_to_Shoot_Penalty_Kicks_kick_ball_f_cm_np1_ba_bad_4.mp4', 'mimeType': 'mp4', 'timeSegmentStart': '0.0s', 'timeSegmentEnd': '1.366667s'}, 'prediction': [{'id': '1496789917903093760', 'displayName': 'kick_ball', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '1.366667s', 'confidence': 0.80414367}, {'id': '6108475936330481664', 'displayName': 'ride_horse', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '1.366667s', 'confidence': 0.05305075}, {'id': '2649711422509940736', 'displayName': 'pullup', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '1.366667s', 'confidence': 0.049748775}, {'id': '7261397440937328640', 'displayName': 'cartwheel', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '1.366667s', 'confidence': 0.04655124}, {'id': '4955554431723634688', 'displayName': 'golf', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '1.366667s', 'confidence': 0.046505567}]}\n",
      "{'instance': {'content': 'gs://automl-video-demo-data/hmdb51/Michelle_Wie__Golf_Swing_golf_f_cm_np1_fr_med_0.mp4', 'mimeType': 'mp4', 'timeSegmentStart': '0.0s', 'timeSegmentEnd': '2.633333s'}, 'prediction': [{'id': '4955554431723634688', 'displayName': 'golf', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.8585761}, {'id': '6108475936330481664', 'displayName': 'ride_horse', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.04235302}, {'id': '2649711422509940736', 'displayName': 'pullup', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.0352593}, {'id': '7261397440937328640', 'displayName': 'cartwheel', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.03227132}, {'id': '1496789917903093760', 'displayName': 'kick_ball', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '2.633333s', 'confidence': 0.031540245}]}\n",
      "{'instance': {'content': 'gs://automl-video-demo-data/hmdb51/how_to_do_a_cartwheel_cartwheel_f_cm_np1_ri_med_0.mp4', 'mimeType': 'mp4', 'timeSegmentStart': '0.0s', 'timeSegmentEnd': '3.0s'}, 'prediction': [{'id': '7261397440937328640', 'displayName': 'cartwheel', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '3s', 'confidence': 0.82382154}, {'id': '6108475936330481664', 'displayName': 'ride_horse', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '3s', 'confidence': 0.046743527}, {'id': '4955554431723634688', 'displayName': 'golf', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '3s', 'confidence': 0.045543123}, {'id': '2649711422509940736', 'displayName': 'pullup', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '3s', 'confidence': 0.044500094}, {'id': '1496789917903093760', 'displayName': 'kick_ball', 'type': 'segment-classification', 'timeSegmentStart': '0s', 'timeSegmentEnd': '3s', 'confidence': 0.039391775}]}\n"
     ]
    }
   ],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(BUCKET_URI.replace(\"gs://\", \"\"))\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"{prediction_result}\"\n",
    "    data = bucket.blob(gfile_name).download_as_string()\n",
    "    data = json.loads(data)\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "<a name=\"section-13\"></a>\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete the dataset using the Vertex dataset object\n",
    "dataset.delete()\n",
    "\n",
    "# Delete the model using the Vertex model object\n",
    "model.delete()\n",
    "\n",
    "# Delete the AutoML or Pipeline training job\n",
    "job.delete()\n",
    "\n",
    "# Delete the batch prediction job using the Vertex batch prediction object\n",
    "batch_predict_job.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_Platform_(Unified)_SDK_AutoML_Video_Classification.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
