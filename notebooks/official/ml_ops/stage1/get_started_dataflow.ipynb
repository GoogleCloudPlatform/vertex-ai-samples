{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# E2E ML on GCP: MLOps stage 1 : data management: get started with Dataflow\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage1/get_started_dataflow.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/ai/platform/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage1/get_started_dataflow.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "This tutorial demonstrates how to use Vertex AI for E2E MLOps on Google Cloud in production. This tutorial covers stage 1 : data management: get started with Dataflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:gsod,lrg"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the GSOD dataset from [BigQuery public datasets](https://cloud.google.com/bigquery/public-data). The version of the dataset you use here will only use the fields year, month and day to predict the value of mean daily temperature (mean_temp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage1,get_started_dataflow"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to use `Dataflow` for training with `Vertex AI`.\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "- `Dataflow`\n",
    "- `BigQuery Datasets`\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Offline preprocessing of data:\n",
    "    - Serially - w/o dataflow\n",
    "    - Parallel - with dataflow\n",
    "- Upstream preprocessing of data:\n",
    "    - tabular data\n",
    "    - image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommendation:mlops,stage1,dataflow"
   },
   "source": [
    "### Recommendations\n",
    "\n",
    "When doing E2E MLOps on Google Cloud, the following best practices for preprocessing and feeding data during training of custom models:\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "Data is preprocessed either:\n",
    "\n",
    "- Offline: The data is preprocessed and stored prior to training.\n",
    "    - Small datasets: reprocessed and stored when new data.\n",
    "- Upstream: The data is preprocessed upstream from the model while the data is feed for training.\n",
    "    - Training on a CPU.\n",
    "- Downstream: The data is preprocessed downstream in the model while the data is feed for training.\n",
    "    - Training on a HW accelerator (e.g., GPU/TPU).\n",
    "\n",
    "#### Model Feeding\n",
    "\n",
    "Data is feed for model feeding either:\n",
    "\n",
    "- In-memory: small dataset.\n",
    "- From disk: large dataset, quick training.\n",
    "- `Dataflow` from disk: massive dataset, extended training.\n",
    "\n",
    "#### AutoML\n",
    "\n",
    "For AutoML training, preprocessing and model feeding are automatically handled.\n",
    "\n",
    "Alternately for AutoML tabular model training, you can reconfigure the otherwise default preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## Installations\n",
    "\n",
    "Install *one time* the packages for executing the MLOps notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow==2.5\n",
      "  Using cached tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (3.7.4.3)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Using cached grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (2.8.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.15.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (3.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (3.19.4)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (0.37.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (0.12.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.5) (1.6.3)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow==2.5) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (2.27.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (59.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5) (1.35.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (4.11.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (3.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: grpcio, tensorflow\n",
      "  Attempting uninstall: grpcio\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: grpcio 1.44.0\n",
      "    Uninstalling grpcio-1.44.0:\n",
      "      Successfully uninstalled grpcio-1.44.0\n",
      "  Attempting uninstall: tensorflow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tensorflow 2.5.3\n",
      "    Uninstalling tensorflow-2.5.3:\n",
      "      Successfully uninstalled tensorflow-2.5.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tfx-bsl 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "tensorflow-serving-api 2.5.4 requires tensorflow<3,>=2.5.3, but you have tensorflow 2.5.0 which is incompatible.\n",
      "tensorflow-data-validation 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tensorflow-data-validation 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "google-cloud-bigquery 2.34.2 requires grpcio<2.0dev,>=1.38.1, but you have grpcio 1.34.1 which is incompatible.\n",
      "apache-beam 2.37.0 requires pyarrow<7.0.0,>=0.15.1, but you have pyarrow 7.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed grpcio-1.34.1 tensorflow-2.5.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-data-validation==1.2 in /opt/conda/lib/python3.7/site-packages (1.2.0)\n",
      "Collecting pyarrow<3,>=1\n",
      "  Using cached pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7 MB)\n",
      "Requirement already satisfied: absl-py<0.13,>=0.9 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-metadata<1.3,>=1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (1.2.0)\n",
      "Requirement already satisfied: joblib<0.15,>=0.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (0.14.1)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (1.19.5)\n",
      "Requirement already satisfied: six<2,>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (1.15.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.13 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (3.19.4)\n",
      "Requirement already satisfied: tfx-bsl<1.3,>=1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (1.2.0)\n",
      "Collecting google-cloud-bigquery<2.21,>=1.28.0\n",
      "  Using cached google_cloud_bigquery-2.20.0-py2.py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (2.5.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.31 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (2.37.0)\n",
      "Requirement already satisfied: pandas<2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation==1.2) (1.3.5)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.7)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.4.2)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.27.1)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2021.3)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.34.1)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (3.6.7)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.8.2)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (3.12.3)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.19.1)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (4.1.3)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.4.10)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.20.3)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.15.3)\n",
      "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.0.0)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (4.2.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.35.0)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (3.6.2)\n",
      "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.6.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage>=2.6.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.12.0)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.7.2)\n",
      "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.5.31)\n",
      "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.7.0)\n",
      "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.19.1)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.16.1)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.4.1)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<=0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.2.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (1.31.5)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (1.3.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (21.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.1.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (0.37.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.6.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (0.4.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata<1.3,>=1.2->tensorflow-data-validation==1.2) (1.54.0)\n",
      "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<1.3,>=1.2->tensorflow-data-validation==1.2) (2.5.4)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<1.3,>=1.2->tensorflow-data-validation==1.2) (1.12.10)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (59.8.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.3,>=1.2->tensorflow-data-validation==1.2) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.3,>=1.2->tensorflow-data-validation==1.2) (0.1.0)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.17.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.2.7)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.12.3)\n",
      "Requirement already satisfied: libcst>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.4.1)\n",
      "Requirement already satisfied: grpcio-status>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.34.1)\n",
      "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (6.1.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (1.1.2)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.5.2)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<0.20.0,>=0.8->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.4.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (2021.10.8)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (2.0.3)\n",
      "Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2\n",
      "  Using cached tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2\n",
      "  Using cached tensorflow-2.7.1-cp37-cp37m-manylinux2010_x86_64.whl (495.0 MB)\n",
      "  Using cached tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
      "  Using cached tensorflow-2.6.3-cp37-cp37m-manylinux2010_x86_64.whl (463.8 MB)\n",
      "  Using cached tensorflow-2.6.2-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "  Using cached tensorflow-2.6.1-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "  Using cached tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "  Using cached tensorflow-2.5.3-cp37-cp37m-manylinux2010_x86_64.whl (460.3 MB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (1.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (4.11.1)\n",
      "Requirement already satisfied: typing-utils>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from overrides<7.0.0,>=6.0.1->google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.1.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-data-validation==1.2) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15.2->tensorflow-data-validation==1.2) (3.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from typing-inspect>=0.4.0->libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-data-validation==1.2) (0.4.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyarrow, tensorflow, google-cloud-bigquery\n",
      "  Attempting uninstall: pyarrow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pyarrow 7.0.0\n",
      "    Uninstalling pyarrow-7.0.0:\n",
      "      Successfully uninstalled pyarrow-7.0.0\n",
      "  Attempting uninstall: tensorflow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: google-cloud-bigquery 2.34.2\n",
      "    Uninstalling google-cloud-bigquery-2.34.2:\n",
      "      Successfully uninstalled google-cloud-bigquery-2.34.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-bigquery-2.20.0 pyarrow-2.0.0 tensorflow-2.5.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-transform==1.2 in /opt/conda/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.31 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (2.37.0)\n",
      "Requirement already satisfied: pyarrow<3,>=1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (2.0.0)\n",
      "Requirement already satisfied: tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (2.5.3)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (1.19.5)\n",
      "Requirement already satisfied: tfx-bsl<1.3.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (1.2.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (1.4.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<2.21,>=1.28.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (2.20.0)\n",
      "Requirement already satisfied: absl-py<0.13,>=0.9 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (0.12.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.13 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-metadata<1.3.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==1.2) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<0.13,>=0.9->tensorflow-transform==1.2) (1.15.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (3.7.4.3)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (3.12.3)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.34.1)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (4.1.3)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.3.1.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.8.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.7)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (3.6.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.27.1)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.19.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.4.10)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.0.0)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.6.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2021.3)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.4.1)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.6.0)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<=0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.2.0)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.7.2)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.16.1)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage>=2.6.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.12.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.35.0)\n",
      "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.19.1)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (3.6.2)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (4.2.4)\n",
      "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.5.31)\n",
      "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.15.3)\n",
      "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.7.0)\n",
      "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.0.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (1.3.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (21.3)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (1.31.5)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot<2,>=1.2->tensorflow-transform==1.2) (2.4.7)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (0.4.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (0.37.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (2.8.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (0.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata<1.3.0,>=1.2.0->tensorflow-transform==1.2) (1.54.0)\n",
      "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<1.3.0,>=1.2.0->tensorflow-transform==1.2) (2.5.4)\n",
      "Requirement already satisfied: pandas<2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<1.3.0,>=1.2.0->tensorflow-transform==1.2) (1.3.5)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<1.3.0,>=1.2.0->tensorflow-transform==1.2) (1.12.10)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (59.8.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.3.0,>=1.2.0->tensorflow-transform==1.2) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.3.0,>=1.2.0->tensorflow-transform==1.2) (3.0.1)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.17.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (4.8)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.12.3)\n",
      "Requirement already satisfied: libcst>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.4.1)\n",
      "Requirement already satisfied: grpcio-status>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.34.1)\n",
      "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (6.1.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (1.1.2)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.5.2)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.6.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (3.3.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (1.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (4.11.1)\n",
      "Requirement already satisfied: typing-utils>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from overrides<7.0.0,>=6.0.1->google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.1.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2.21,>=1.28.0->tensorflow-transform==1.2) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform==1.2) (3.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from typing-inspect>=0.4.0->libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.31->tensorflow-transform==1.2) (0.4.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-io==0.18 in /opt/conda/lib/python3.7/site-packages (0.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.18.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-io==0.18) (0.18.0)\n",
      "Requirement already satisfied: tensorflow<2.6.0,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-io==0.18) (2.5.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2.8.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.12.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.34.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.3.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.19.4)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.6.3)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.37.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.7.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2.5.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.1.0)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (59.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (4.11.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io==0.18) (3.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-aiplatform[tensorboard] in /opt/conda/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform[tensorboard]) (21.3)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform[tensorboard]) (1.20.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform[tensorboard]) (2.20.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform[tensorboard]) (1.31.5)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform[tensorboard]) (1.44.0)\n",
      "Requirement already satisfied: tensorflow<=2.7.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform[tensorboard]) (2.5.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (1.54.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (59.8.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (1.35.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (1.15.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (2.27.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (3.19.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (2021.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (1.34.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform[tensorboard]) (1.7.2)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform[tensorboard]) (1.3.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform[tensorboard]) (2.4.7)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (3.7.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (3.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (0.12.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.19.5)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (0.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (0.37.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (2.8.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (2.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (4.2.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform[tensorboard]) (1.1.2)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.5.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (2021.10.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (2.0.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform[tensorboard]) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (4.11.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform[tensorboard]) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform[tensorboard]) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<=2.7.0,>=2.3.0->google-cloud-aiplatform[tensorboard]) (3.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-pipeline-components in /opt/conda/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.31.5)\n",
      "Requirement already satisfied: google-cloud-notebooks>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.2.1)\n",
      "Requirement already satisfied: kfp<2.0.0,>=1.8.9 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.8.11)\n",
      "Requirement already satisfied: google-cloud-aiplatform>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.11.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (21.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (59.8.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (1.54.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2021.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (1.35.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (3.19.4)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (1.20.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (2.20.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (1.44.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.4.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.8.9)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.9.1)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (3.7.4.3)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.8.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.9.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.13)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.1.10)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.12.10)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.12.0)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (2.0.0)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (3.2.0)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.4.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (8.0.4)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (5.4.1)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.2.13)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.13 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.1.13)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (18.20.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (4.11.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.12.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (1.34.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.19.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (0.2.7)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (1.3.3)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.18.1)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.26.8)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.3.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2.0.12)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (0.37.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (1.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components) (2.21)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-bigquery in /opt/conda/lib/python3.7/site-packages (2.20.0)\n",
      "Collecting google-cloud-bigquery\n",
      "  Using cached google_cloud_bigquery-2.34.2-py2.py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (21.3)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (3.19.4)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.3.3)\n",
      "Collecting grpcio<2.0dev,>=1.38.1\n",
      "  Using cached grpcio-1.44.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (2.27.1)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.31.5)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2021.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (59.8.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.35.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.15.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.54.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-bigquery) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.4.8)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: grpcio, google-cloud-bigquery\n",
      "  Attempting uninstall: grpcio\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: google-cloud-bigquery 2.20.0\n",
      "    Uninstalling google-cloud-bigquery-2.20.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-2.20.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tensorflow 2.5.3 requires grpcio~=1.34.0, but you have grpcio 1.44.0 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tensorflow-data-validation 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-bigquery-2.34.2 grpcio-1.44.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-logging in /opt/conda/lib/python3.7/site-packages (3.0.0)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0dev,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging) (0.2.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging) (0.12.3)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging) (1.20.3)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging) (1.31.5)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0dev,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging) (1.1.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging) (1.7.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (3.19.4)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (59.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (1.54.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (21.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (2021.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (2.27.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (1.44.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (4.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (2.0.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-logging) (0.4.8)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: apache-beam[gcp] in /opt/conda/lib/python3.7/site-packages (2.37.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.44.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (3.7.4.3)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (0.3.1.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.6.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (3.12.3)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.8.2)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.4.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (3.19.4)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.7)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (0.19.1)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2021.3)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.20.3)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.4.10)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.27.1)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (4.1.3)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.0.0)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (3.6.7)\n",
      "Requirement already satisfied: numpy<1.22.0,>=1.14.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.19.5)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.35.0)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<=0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (0.2.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage>=2.6.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.12.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.34.2)\n",
      "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.19.1)\n",
      "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.4.1)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (4.2.4)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (2.6.0)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.15.3)\n",
      "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (0.5.31)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.7.2)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.16.1)\n",
      "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (1.7.0)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (3.6.2)\n",
      "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (1.15.0)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (0.17.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (59.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (4.8)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (1.3.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (21.3)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (1.31.5)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]) (0.12.3)\n",
      "Requirement already satisfied: libcst>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (0.4.1)\n",
      "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]) (6.1.0)\n",
      "Requirement already satisfied: grpcio-status>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]) (1.34.1)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<0.20.0,>=0.8->apache-beam[gcp]) (2.4.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (3.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (1.54.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (1.1.2)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (0.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (5.4.1)\n",
      "Requirement already satisfied: typing-utils>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from overrides<7.0.0,>=6.0.1->google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]) (0.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (1.15.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from typing-inspect>=0.4.0->libcst>=0.3.10->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (0.4.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]) (2.21)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.19.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pyarrow 2.0.0\n",
      "    Uninstalling pyarrow-2.0.0:\n",
      "      Successfully uninstalled pyarrow-2.0.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tfx-bsl 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "tensorflow-data-validation 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
      "tensorflow-data-validation 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "apache-beam 2.37.0 requires pyarrow<7.0.0,>=0.15.1, but you have pyarrow 7.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyarrow-7.0.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: cloudml-hypertune in /opt/conda/lib/python3.7/site-packages (0.1.0.dev6)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: kfp in /opt/conda/lib/python3.7/site-packages (1.8.11)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.13 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.13)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.19.4)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.12.10)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.9.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.1)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.7.4.3)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.13)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.12.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.44.0)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.0.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2,>=0.9->kfp) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.11.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.19.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (1.31.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (59.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (1.7.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (1.3.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.27.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.8)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2021.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (21.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.54.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (2.21)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (0.18.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "ONCE_ONLY = False\n",
    "if ONCE_ONLY:\n",
    "    ! pip3 install -U tensorflow==2.5 $USER_FLAG\n",
    "    ! pip3 install -U tensorflow-data-validation==1.2 $USER_FLAG\n",
    "    ! pip3 install -U tensorflow-transform==1.2 $USER_FLAG\n",
    "    ! pip3 install -U tensorflow-io==0.18 $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform[tensorboard] $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-pipeline-components $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-bigquery $USER_FLAG\n",
    "    ! pip3 install --upgrade google-cloud-logging $USER_FLAG\n",
    "    ! pip3 install --upgrade apache-beam[gcp] $USER_FLAG\n",
    "    ! pip3 install --upgrade pyarrow $USER_FLAG\n",
    "    ! pip3 install --upgrade cloudml-hypertune $USER_FLAG\n",
    "    ! pip3 install --upgrade kfp $USER_FLAG\n",
    "    ! pip3 install future $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: vertex-ai-dev\n"
     ]
    }
   ],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
    "\n",
    "- Americas: `us-central1`\n",
    "- Europe: `europe-west4`\n",
    "- Asia Pacific: `asia-east1`\n",
    "\n",
    "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
    "\n",
    "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "#### Timestamp\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:custom"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "When you submit a custom training job using the Vertex SDK, you upload a Python package\n",
    "containing your training code to a Cloud Storage bucket. Vertex AI runs\n",
    "the code from this package. In this tutorial, Vertex AI also saves the\n",
    "trained model that results from your job in the same bucket. You can then\n",
    "create an `Endpoint` resource based on this output in order to serve\n",
    "online predictions.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://vertex-ai-devaip-20220308120540/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "Finally, validate access to your Cloud Storage bucket by examining its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "Next, set up some variables used throughout the tutorial.\n",
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_beam"
   },
   "source": [
    "#### Import Apache Beam\n",
    "\n",
    "Import the Apache Beam package into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "import_beam"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.Sequence[~T]\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_bq"
   },
   "source": [
    "#### Import BigQuery\n",
    "\n",
    "Import the BigQuery package into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "import_bq"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_pandas"
   },
   "source": [
    "#### Import pandas\n",
    "\n",
    "Import the pandas package into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "import_pandas"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_numpy"
   },
   "source": [
    "#### Import numpy\n",
    "\n",
    "Import the numpy package into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "import_numpy"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_tfdv"
   },
   "source": [
    "#### Import TensorFlow Data Validation\n",
    "\n",
    "Import the TensorFlow Data Validation (TFDV) package into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "import_tfdv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:05:47.126988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-08 12:05:47.127040: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_tft"
   },
   "source": [
    "#### Import TensorFlow Transform\n",
    "\n",
    "Import the TensorFlow Transform (TFT) package into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "import_tft"
   },
   "outputs": [],
   "source": [
    "import tensorflow_transform as tft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,region"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "init_aip:mbsdk,region"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_bq"
   },
   "source": [
    "### Create BigQuery client\n",
    "\n",
    "Create the BigQuery client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "init_bq"
   },
   "outputs": [],
   "source": [
    "bqclient = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "offline_preprocess:bq"
   },
   "source": [
    "## Offline preprocessing data with BigQuery table using pandas dataframe\n",
    "\n",
    "- Offline: The BigQuery table is preprocessed in-memory and stored prior to training.\n",
    "\n",
    "    - Extract the tabular data into a pandas dataframe.\n",
    "    - Preprocess the data, per column, within the dataframe.\n",
    "    - Write the preprocessed dataframe to a new BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "import_file:gsod,bq,lrg"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"bq://bigquery-public-data.samples.gsod\"\n",
    "BQ_TABLE = \"bigquery-public-data.samples.gsod\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq_to_dataframe:gsod"
   },
   "source": [
    "### Read the BigQuery dataset into a pandas dataframe\n",
    "\n",
    "Next, you read a sample of the dataset into a pandas dataframe using BigQuery `list_rows()` and `to_dataframe()` method, as follows:\n",
    "\n",
    "- `list_rows()`: Performs a query on the specified table and returns a row iterator to the query results. Optionally specify:\n",
    " - `selected_fields`: Subset of fields (columns) to return.\n",
    " - `max_results`: The maximum number of rows to return. Same as SQL LIMIT command.\n",
    "\n",
    "\n",
    "- `rows.to_dataframe()`: Invokes the row iterator and reads in the data into a pandas dataframe.\n",
    "\n",
    "Learn more about [Loading BigQuery table into a dataframe](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bq_to_dataframe:gsod"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_number  year  month  day  mean_temp\n",
      "0          39730  1929     10   20  52.799999\n",
      "1          33110  1929     12   18  47.500000\n",
      "2          37770  1931      4   24  50.200001\n",
      "3         726810  1931      6   23  65.099998\n",
      "4         726810  1931      3    2  42.799999\n"
     ]
    }
   ],
   "source": [
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\"bigquery-public-data.samples.gsod\")\n",
    "\n",
    "rows = bqclient.list_rows(\n",
    "    table,\n",
    "    max_results=500,\n",
    "    selected_fields=[\n",
    "        bigquery.SchemaField(\"station_number\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"month\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"day\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mean_temp\", \"FLOAT\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "dataframe = rows.to_dataframe()\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataframe_transform:gsod"
   },
   "source": [
    "### Transform data within pandas dataframe.\n",
    "\n",
    "Next, you preprocess the data within the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dataframe_transform:gsod"
   },
   "outputs": [],
   "source": [
    "dataframe[\"station_number\"] = pd.to_numeric(dataframe[\"station_number\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqml_create_dataset"
   },
   "source": [
    "### Create BQ dataset resource\n",
    "\n",
    "First, you create an empty dataset resource in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bqml_create_dataset"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'vertex-ai-dev:samples' already exists.\n"
     ]
    }
   ],
   "source": [
    "BQ_MY_DATASET = 'samples'\n",
    "BQ_MY_TABLE = 'gsod'\n",
    "! bq --location=US mk -d \\\n",
    "$PROJECT_ID:$BQ_MY_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dataframe_to_bq:transformed,gsod"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 rows and 5 columns to vertex-ai-dev.samples.gsod_transformed\n"
     ]
    }
   ],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"station_number\", \"FLOAT\"),  # <-- after one hot encoding\n",
    "        bigquery.SchemaField(\"year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"month\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"day\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mean_temp\", \"FLOAT\"),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n",
    "NEW_BQ_TABLE = f\"{PROJECT_ID}.samples.gsod_transformed\"\n",
    "\n",
    "job = bqclient.load_table_from_dataframe(\n",
    "    dataframe, NEW_BQ_TABLE, job_config=job_config\n",
    ")  # Make an API request.\n",
    "job.result()  # Wait for the job to complete.\n",
    "\n",
    "table = bqclient.get_table(NEW_BQ_TABLE)  # Make an API request.\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), NEW_BQ_TABLE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upstream_preprocess:image"
   },
   "source": [
    "## Upstream preprocessing data with tf.data.Dataset generator\n",
    "\n",
    "### Image data\n",
    "\n",
    "- Upstream: The data is preprocessed upstream from the model while the data is feed for training.\n",
    "\n",
    "    - Define preprocessing function:\n",
    "        - Input: unprocessed batch of tensors\n",
    "        - Output: preprocessed batch of tensors\n",
    "    - Use tf.data.Dataset `map()` method to map the preprocessing function to the generator output.\n",
    "\n",
    "In this example:\n",
    "\n",
    "- Load CIFAR10 dataset into memory as numpy arrays.\n",
    "- Create a tf.data.Dataset generator for the in-memory CIFAR10 dataset. *Note*: The pixel data is casted to FLOAT32 to be compatiable with the preprocessing function which outputs the pixel data as FLOAT32.\n",
    "- Define a preprocessing function to rescale the pixel data by 1/255.0\n",
    "- Map the preprocessing function to the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "upstream_preprocess:image"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:06:45.931376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-08 12:06:45.931423: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-08 12:06:45.931445: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vertex-ai-sdk-manuel-2): /proc/driver/nvidia/version does not exist\n",
      "2022-03-08 12:06:45.931907: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-08 12:06:46.434283: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2022-03-08 12:06:46.677837: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing\n",
      "(<tf.Tensor: shape=(32, 32, 3), dtype=float32, numpy=\n",
      "array([[[ 59.,  62.,  63.],\n",
      "        [ 43.,  46.,  45.],\n",
      "        [ 50.,  48.,  43.],\n",
      "        ...,\n",
      "        [158., 132., 108.],\n",
      "        [152., 125., 102.],\n",
      "        [148., 124., 103.]],\n",
      "\n",
      "       [[ 16.,  20.,  20.],\n",
      "        [  0.,   0.,   0.],\n",
      "        [ 18.,   8.,   0.],\n",
      "        ...,\n",
      "        [123.,  88.,  55.],\n",
      "        [119.,  83.,  50.],\n",
      "        [122.,  87.,  57.]],\n",
      "\n",
      "       [[ 25.,  24.,  21.],\n",
      "        [ 16.,   7.,   0.],\n",
      "        [ 49.,  27.,   8.],\n",
      "        ...,\n",
      "        [118.,  84.,  50.],\n",
      "        [120.,  84.,  50.],\n",
      "        [109.,  73.,  42.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[208., 170.,  96.],\n",
      "        [201., 153.,  34.],\n",
      "        [198., 161.,  26.],\n",
      "        ...,\n",
      "        [160., 133.,  70.],\n",
      "        [ 56.,  31.,   7.],\n",
      "        [ 53.,  34.,  20.]],\n",
      "\n",
      "       [[180., 139.,  96.],\n",
      "        [173., 123.,  42.],\n",
      "        [186., 144.,  30.],\n",
      "        ...,\n",
      "        [184., 148.,  94.],\n",
      "        [ 97.,  62.,  34.],\n",
      "        [ 83.,  53.,  34.]],\n",
      "\n",
      "       [[177., 144., 116.],\n",
      "        [168., 129.,  94.],\n",
      "        [179., 142.,  87.],\n",
      "        ...,\n",
      "        [216., 184., 140.],\n",
      "        [151., 118.,  84.],\n",
      "        [123.,  92.,  72.]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([6], dtype=uint8)>)\n",
      "After preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:06:47.184534: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 32, 3), dtype=float32, numpy=\n",
      "array([[[0.23137255, 0.24313726, 0.24705882],\n",
      "        [0.16862746, 0.18039216, 0.1764706 ],\n",
      "        [0.19607843, 0.1882353 , 0.16862746],\n",
      "        ...,\n",
      "        [0.61960787, 0.5176471 , 0.42352942],\n",
      "        [0.59607846, 0.49019608, 0.4       ],\n",
      "        [0.5803922 , 0.4862745 , 0.40392157]],\n",
      "\n",
      "       [[0.0627451 , 0.07843138, 0.07843138],\n",
      "        [0.        , 0.        , 0.        ],\n",
      "        [0.07058824, 0.03137255, 0.        ],\n",
      "        ...,\n",
      "        [0.48235294, 0.34509805, 0.21568628],\n",
      "        [0.46666667, 0.3254902 , 0.19607843],\n",
      "        [0.47843137, 0.34117648, 0.22352941]],\n",
      "\n",
      "       [[0.09803922, 0.09411765, 0.08235294],\n",
      "        [0.0627451 , 0.02745098, 0.        ],\n",
      "        [0.19215687, 0.10588235, 0.03137255],\n",
      "        ...,\n",
      "        [0.4627451 , 0.32941177, 0.19607843],\n",
      "        [0.47058824, 0.32941177, 0.19607843],\n",
      "        [0.42745098, 0.28627452, 0.16470589]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
      "        [0.7882353 , 0.6       , 0.13333334],\n",
      "        [0.7764706 , 0.6313726 , 0.10196079],\n",
      "        ...,\n",
      "        [0.627451  , 0.52156866, 0.27450982],\n",
      "        [0.21960784, 0.12156863, 0.02745098],\n",
      "        [0.20784314, 0.13333334, 0.07843138]],\n",
      "\n",
      "       [[0.7058824 , 0.54509807, 0.3764706 ],\n",
      "        [0.6784314 , 0.48235294, 0.16470589],\n",
      "        [0.7294118 , 0.5647059 , 0.11764706],\n",
      "        ...,\n",
      "        [0.72156864, 0.5803922 , 0.36862746],\n",
      "        [0.38039216, 0.24313726, 0.13333334],\n",
      "        [0.3254902 , 0.20784314, 0.13333334]],\n",
      "\n",
      "       [[0.69411767, 0.5647059 , 0.45490196],\n",
      "        [0.65882355, 0.5058824 , 0.36862746],\n",
      "        [0.7019608 , 0.5568628 , 0.34117648],\n",
      "        ...,\n",
      "        [0.84705883, 0.72156864, 0.54901963],\n",
      "        [0.5921569 , 0.4627451 , 0.32941177],\n",
      "        [0.48235294, 0.36078432, 0.28235295]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([6], dtype=uint8)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:06:47.614202: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-08 12:06:47.615015: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((x_train.astype(np.float32), y_train))\n",
    "\n",
    "print(\"Before preprocessing\")\n",
    "for batch in tf_dataset:\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "\n",
    "def preprocess_fn(inputs, labels):\n",
    "    inputs /= 255.0\n",
    "    return tf.cast(inputs, tf.float32), labels\n",
    "\n",
    "\n",
    "tf_dataset = tf_dataset.map(preprocess_fn)\n",
    "\n",
    "print(\"After preprocessing\")\n",
    "for batch in tf_dataset:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upstream_preprocess:tabular"
   },
   "source": [
    "## Upstream preprocessing data with tf.data.Dataset generator\n",
    "\n",
    "### Tabular data\n",
    "\n",
    "- Upstream: The data is preprocessed upstream from the model while the data is feed for training.\n",
    "\n",
    "    - Define preprocessing function:\n",
    "        - Input: unprocessed batch of tensors\n",
    "        - Output: preprocessed batch of tensors\n",
    "    - Use tf.data.Dataset `map()` method to map the preprocessing function to the generator output.\n",
    "\n",
    "In this example:\n",
    "\n",
    "- Create tf.data.Dataset generator for Boston Housing data.\n",
    "- Iterate a single batch before preprocessing.\n",
    "- Define preprocessing function to scale all the features between 0 and 1.\n",
    "- Map the preprocessing function to the dataset.\n",
    "- Iterate once through the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "upstream_preprocess:tabular"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing\n",
      "(<tf.Tensor: shape=(13,), dtype=float32, numpy=\n",
      "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
      "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
      "        18.72   ], dtype=float32)>, <tf.Tensor: shape=(), dtype=float64, numpy=15.2>)\n",
      "After preprocessing\n",
      "(<tf.Tensor: shape=(13,), dtype=float32, numpy=\n",
      "array([0.7742506 , 0.5       , 0.9997084 , 0.5       , 0.63134706,\n",
      "       0.997854  , 1.        , 0.98160124, 0.98201376, 1.        ,\n",
      "       1.        , 1.        , 1.        ], dtype=float32)>, <tf.Tensor: shape=(), dtype=float64, numpy=15.2>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((x_train.astype(np.float32), y_train))\n",
    "\n",
    "print(\"Before preprocessing\")\n",
    "for batch in tf_dataset:\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs, labels):\n",
    "    inputs = tft.scale_to_0_1(inputs)\n",
    "    return tf.cast(inputs, tf.float32), labels\n",
    "\n",
    "\n",
    "tf_dataset = tf_dataset.map(preprocessing_fn)\n",
    "\n",
    "print(\"After preprocessing\")\n",
    "for batch in tf_dataset:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "offline_preprocess:dataflow"
   },
   "source": [
    "## Offline preprocessing with Dataflow\n",
    "\n",
    "- Generate data chema from BigQuery table.\n",
    "- Define Beam pipeline to:\n",
    "    - Split data from BigQuery table into train and eval datasets.\n",
    "    - Encode datasets as TFRecords, using the data schema.\n",
    "    - Save the TFRecords as compressed files to Cloud Storage\n",
    "- Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq_to_dataframe:gsod"
   },
   "source": [
    "### Read the BigQuery dataset into a pandas dataframe\n",
    "\n",
    "Next, you read a sample of the dataset into a pandas dataframe using BigQuery `list_rows()` and `to_dataframe()` method, as follows:\n",
    "\n",
    "- `list_rows()`: Performs a query on the specified table and returns a row iterator to the query results. Optionally specify:\n",
    " - `selected_fields`: Subset of fields (columns) to return.\n",
    " - `max_results`: The maximum number of rows to return. Same as SQL LIMIT command.\n",
    "\n",
    "\n",
    "- `rows.to_dataframe()`: Invokes the row iterator and reads in the data into a pandas dataframe.\n",
    "\n",
    "Learn more about [Loading BigQuery table into a dataframe](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bq_to_dataframe:gsod"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_number  year  month  day  mean_temp\n",
      "0          39730  1929     10   20  52.799999\n",
      "1          33110  1929     12   18  47.500000\n",
      "2          37770  1931      4   24  50.200001\n",
      "3         726810  1931      6   23  65.099998\n",
      "4         726810  1931      3    2  42.799999\n"
     ]
    }
   ],
   "source": [
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\"bigquery-public-data.samples.gsod\")\n",
    "\n",
    "rows = bqclient.list_rows(\n",
    "    table,\n",
    "    max_results=500,\n",
    "    selected_fields=[\n",
    "        bigquery.SchemaField(\"station_number\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"month\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"day\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mean_temp\", \"FLOAT\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "dataframe = rows.to_dataframe()\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfdv_stats:dataframe"
   },
   "source": [
    "###  Generate dataset statistics\n",
    "\n",
    "#### Dataframe input data\n",
    "\n",
    "Generate statistics on the dataset with the TensorFlow Data Validation (TFDV) package. Use the `generate_statistics_from_dataframe()` method, with the following parameters:\n",
    "\n",
    "- `dataframe`: The dataset in an in-memory pandas dataframe.\n",
    "- `stats_options`: The selected statistics options:\n",
    "  - `label_feature`: The column which is the label to predict.\n",
    "  - `sample_rate`: The sampling rate. If specified, statistics is computed over the sample.\n",
    "  - `num_top_values`: number of most frequent feature values to keep for string features.\n",
    "\n",
    "Learn about [TensorFlow Data Validation (TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tfdv_stats:dataframe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets {\n",
      "  num_examples: 500\n",
      "  features {\n",
      "    type: STRING\n",
      "    string_stats {\n",
      "      common_stats {\n",
      "        num_non_missing: 500\n",
      "        min_num_values: 1\n",
      "        max_num_values: 1\n",
      "        avg_num_values: 1.0\n",
      "        num_values_histogram {\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "        tot_num_values: 500\n",
      "      }\n",
      "      unique: 165\n",
      "      top_values {\n",
      "        value: \"949999\"\n",
      "        frequency: 49.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"726810\"\n",
      "        frequency: 22.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"949680\"\n",
      "        frequency: 18.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"949260\"\n",
      "        frequency: 14.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"726980\"\n",
      "        frequency: 14.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"956770\"\n",
      "        frequency: 13.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"727640\"\n",
      "        frequency: 13.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"726770\"\n",
      "        frequency: 13.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"944760\"\n",
      "        frequency: 11.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"958660\"\n",
      "        frequency: 10.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"943740\"\n",
      "        frequency: 10.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"107110\"\n",
      "        frequency: 10.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"943265\"\n",
      "        frequency: 8.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"377890\"\n",
      "        frequency: 7.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"370310\"\n",
      "        frequency: 7.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"349290\"\n",
      "        frequency: 7.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"949100\"\n",
      "        frequency: 6.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"943350\"\n",
      "        frequency: 6.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"941200\"\n",
      "        frequency: 6.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"121000\"\n",
      "        frequency: 6.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"108580\"\n",
      "        frequency: 6.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"107280\"\n",
      "        frequency: 6.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"947675\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"947530\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"724050\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"60300\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"292310\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"107260\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"10520\"\n",
      "        frequency: 5.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"946530\"\n",
      "        frequency: 4.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"722977\"\n",
      "        frequency: 4.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"722860\"\n",
      "        frequency: 4.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"70580\"\n",
      "        frequency: 4.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"702615\"\n",
      "        frequency: 4.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"379070\"\n",
      "        frequency: 4.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"948210\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"722265\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"375150\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"370990\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"368700\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"295740\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"109530\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"105590\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"104910\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"103390\"\n",
      "        frequency: 3.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"946120\"\n",
      "        frequency: 2.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"944030\"\n",
      "        frequency: 2.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"943120\"\n",
      "        frequency: 2.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"942945\"\n",
      "        frequency: 2.0\n",
      "      }\n",
      "      top_values {\n",
      "        value: \"942875\"\n",
      "        frequency: 2.0\n",
      "      }\n",
      "      avg_length: 5.943999767303467\n",
      "      rank_histogram {\n",
      "        buckets {\n",
      "          label: \"949999\"\n",
      "          sample_count: 49.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 1\n",
      "          high_rank: 1\n",
      "          label: \"726810\"\n",
      "          sample_count: 22.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 2\n",
      "          high_rank: 2\n",
      "          label: \"949680\"\n",
      "          sample_count: 18.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 3\n",
      "          high_rank: 3\n",
      "          label: \"949260\"\n",
      "          sample_count: 14.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 4\n",
      "          high_rank: 4\n",
      "          label: \"726980\"\n",
      "          sample_count: 14.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 5\n",
      "          high_rank: 5\n",
      "          label: \"956770\"\n",
      "          sample_count: 13.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 6\n",
      "          high_rank: 6\n",
      "          label: \"727640\"\n",
      "          sample_count: 13.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 7\n",
      "          high_rank: 7\n",
      "          label: \"726770\"\n",
      "          sample_count: 13.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 8\n",
      "          high_rank: 8\n",
      "          label: \"944760\"\n",
      "          sample_count: 11.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 9\n",
      "          high_rank: 9\n",
      "          label: \"958660\"\n",
      "          sample_count: 10.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 10\n",
      "          high_rank: 10\n",
      "          label: \"943740\"\n",
      "          sample_count: 10.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 11\n",
      "          high_rank: 11\n",
      "          label: \"107110\"\n",
      "          sample_count: 10.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 12\n",
      "          high_rank: 12\n",
      "          label: \"943265\"\n",
      "          sample_count: 8.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 13\n",
      "          high_rank: 13\n",
      "          label: \"377890\"\n",
      "          sample_count: 7.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 14\n",
      "          high_rank: 14\n",
      "          label: \"370310\"\n",
      "          sample_count: 7.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 15\n",
      "          high_rank: 15\n",
      "          label: \"349290\"\n",
      "          sample_count: 7.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 16\n",
      "          high_rank: 16\n",
      "          label: \"949100\"\n",
      "          sample_count: 6.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 17\n",
      "          high_rank: 17\n",
      "          label: \"943350\"\n",
      "          sample_count: 6.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 18\n",
      "          high_rank: 18\n",
      "          label: \"941200\"\n",
      "          sample_count: 6.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 19\n",
      "          high_rank: 19\n",
      "          label: \"121000\"\n",
      "          sample_count: 6.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 20\n",
      "          high_rank: 20\n",
      "          label: \"108580\"\n",
      "          sample_count: 6.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 21\n",
      "          high_rank: 21\n",
      "          label: \"107280\"\n",
      "          sample_count: 6.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 22\n",
      "          high_rank: 22\n",
      "          label: \"947675\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 23\n",
      "          high_rank: 23\n",
      "          label: \"947530\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 24\n",
      "          high_rank: 24\n",
      "          label: \"724050\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 25\n",
      "          high_rank: 25\n",
      "          label: \"60300\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 26\n",
      "          high_rank: 26\n",
      "          label: \"292310\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 27\n",
      "          high_rank: 27\n",
      "          label: \"107260\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 28\n",
      "          high_rank: 28\n",
      "          label: \"10520\"\n",
      "          sample_count: 5.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 29\n",
      "          high_rank: 29\n",
      "          label: \"946530\"\n",
      "          sample_count: 4.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 30\n",
      "          high_rank: 30\n",
      "          label: \"722977\"\n",
      "          sample_count: 4.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 31\n",
      "          high_rank: 31\n",
      "          label: \"722860\"\n",
      "          sample_count: 4.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 32\n",
      "          high_rank: 32\n",
      "          label: \"70580\"\n",
      "          sample_count: 4.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 33\n",
      "          high_rank: 33\n",
      "          label: \"702615\"\n",
      "          sample_count: 4.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 34\n",
      "          high_rank: 34\n",
      "          label: \"379070\"\n",
      "          sample_count: 4.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 35\n",
      "          high_rank: 35\n",
      "          label: \"948210\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 36\n",
      "          high_rank: 36\n",
      "          label: \"722265\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 37\n",
      "          high_rank: 37\n",
      "          label: \"375150\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 38\n",
      "          high_rank: 38\n",
      "          label: \"370990\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 39\n",
      "          high_rank: 39\n",
      "          label: \"368700\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 40\n",
      "          high_rank: 40\n",
      "          label: \"295740\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 41\n",
      "          high_rank: 41\n",
      "          label: \"109530\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 42\n",
      "          high_rank: 42\n",
      "          label: \"105590\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 43\n",
      "          high_rank: 43\n",
      "          label: \"104910\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 44\n",
      "          high_rank: 44\n",
      "          label: \"103390\"\n",
      "          sample_count: 3.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 45\n",
      "          high_rank: 45\n",
      "          label: \"946120\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 46\n",
      "          high_rank: 46\n",
      "          label: \"944030\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 47\n",
      "          high_rank: 47\n",
      "          label: \"943120\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 48\n",
      "          high_rank: 48\n",
      "          label: \"942945\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 49\n",
      "          high_rank: 49\n",
      "          label: \"942875\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 50\n",
      "          high_rank: 50\n",
      "          label: \"802220\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 51\n",
      "          high_rank: 51\n",
      "          label: \"70700\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 52\n",
      "          high_rank: 52\n",
      "          label: \"70130\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 53\n",
      "          high_rank: 53\n",
      "          label: \"388360\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 54\n",
      "          high_rank: 54\n",
      "          label: \"374720\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 55\n",
      "          high_rank: 55\n",
      "          label: \"372280\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 56\n",
      "          high_rank: 56\n",
      "          label: \"357000\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 57\n",
      "          high_rank: 57\n",
      "          label: \"353580\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 58\n",
      "          high_rank: 58\n",
      "          label: \"351880\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 59\n",
      "          high_rank: 59\n",
      "          label: \"351210\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 60\n",
      "          high_rank: 60\n",
      "          label: \"307580\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 61\n",
      "          high_rank: 61\n",
      "          label: \"299740\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 62\n",
      "          high_rank: 62\n",
      "          label: \"296340\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 63\n",
      "          high_rank: 63\n",
      "          label: \"289520\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 64\n",
      "          high_rank: 64\n",
      "          label: \"282750\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 65\n",
      "          high_rank: 65\n",
      "          label: \"278150\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 66\n",
      "          high_rank: 66\n",
      "          label: \"249440\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 67\n",
      "          high_rank: 67\n",
      "          label: \"239330\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 68\n",
      "          high_rank: 68\n",
      "          label: \"124170\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 69\n",
      "          high_rank: 69\n",
      "          label: \"108390\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 70\n",
      "          high_rank: 70\n",
      "          label: \"107460\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 71\n",
      "          high_rank: 71\n",
      "          label: \"106870\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 72\n",
      "          high_rank: 72\n",
      "          label: \"106570\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 73\n",
      "          high_rank: 73\n",
      "          label: \"103590\"\n",
      "          sample_count: 2.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 74\n",
      "          high_rank: 74\n",
      "          label: \"946370\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 75\n",
      "          high_rank: 75\n",
      "          label: \"810010\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 76\n",
      "          high_rank: 76\n",
      "          label: \"749067\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 77\n",
      "          high_rank: 77\n",
      "          label: \"727855\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 78\n",
      "          high_rank: 78\n",
      "          label: \"727846\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 79\n",
      "          high_rank: 79\n",
      "          label: \"726815\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 80\n",
      "          high_rank: 80\n",
      "          label: \"725720\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 81\n",
      "          high_rank: 81\n",
      "          label: \"724835\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 82\n",
      "          high_rank: 82\n",
      "          label: \"724338\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 83\n",
      "          high_rank: 83\n",
      "          label: \"722785\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 84\n",
      "          high_rank: 84\n",
      "          label: \"722165\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 85\n",
      "          high_rank: 85\n",
      "          label: \"722110\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 86\n",
      "          high_rank: 86\n",
      "          label: \"71950\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 87\n",
      "          high_rank: 87\n",
      "          label: \"719340\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 88\n",
      "          high_rank: 88\n",
      "          label: \"719181\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 89\n",
      "          high_rank: 89\n",
      "          label: \"60630\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 90\n",
      "          high_rank: 90\n",
      "          label: \"39730\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 91\n",
      "          high_rank: 91\n",
      "          label: \"389110\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 92\n",
      "          high_rank: 92\n",
      "          label: \"388800\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 93\n",
      "          high_rank: 93\n",
      "          label: \"387630\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 94\n",
      "          high_rank: 94\n",
      "          label: \"386830\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 95\n",
      "          high_rank: 95\n",
      "          label: \"385990\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 96\n",
      "          high_rank: 96\n",
      "          label: \"384570\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 97\n",
      "          high_rank: 97\n",
      "          label: \"382620\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 98\n",
      "          high_rank: 98\n",
      "          label: \"381980\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 99\n",
      "          high_rank: 99\n",
      "          label: \"380620\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 100\n",
      "          high_rank: 100\n",
      "          label: \"38040\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 101\n",
      "          high_rank: 101\n",
      "          label: \"37970\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 102\n",
      "          high_rank: 102\n",
      "          label: \"37950\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 103\n",
      "          high_rank: 103\n",
      "          label: \"378500\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 104\n",
      "          high_rank: 104\n",
      "          label: \"37770\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 105\n",
      "          high_rank: 105\n",
      "          label: \"374320\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 106\n",
      "          high_rank: 106\n",
      "          label: \"372600\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 107\n",
      "          high_rank: 107\n",
      "          label: \"371930\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 108\n",
      "          high_rank: 108\n",
      "          label: \"370500\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 109\n",
      "          high_rank: 109\n",
      "          label: \"363350\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 110\n",
      "          high_rank: 110\n",
      "          label: \"361770\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 111\n",
      "          high_rank: 111\n",
      "          label: \"354060\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 112\n",
      "          high_rank: 112\n",
      "          label: \"351080\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 113\n",
      "          high_rank: 113\n",
      "          label: \"349540\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 114\n",
      "          high_rank: 114\n",
      "          label: \"346550\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 115\n",
      "          high_rank: 115\n",
      "          label: \"345600\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 116\n",
      "          high_rank: 116\n",
      "          label: \"335870\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 117\n",
      "          high_rank: 117\n",
      "          label: \"33110\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 118\n",
      "          high_rank: 118\n",
      "          label: \"323790\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 119\n",
      "          high_rank: 119\n",
      "          label: \"309650\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 120\n",
      "          high_rank: 120\n",
      "          label: \"308790\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 121\n",
      "          high_rank: 121\n",
      "          label: \"307770\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 122\n",
      "          high_rank: 122\n",
      "          label: \"30750\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 123\n",
      "          high_rank: 123\n",
      "          label: \"307100\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 124\n",
      "          high_rank: 124\n",
      "          label: \"306830\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 125\n",
      "          high_rank: 125\n",
      "          label: \"306360\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 126\n",
      "          high_rank: 126\n",
      "          label: \"304930\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 127\n",
      "          high_rank: 127\n",
      "          label: \"302300\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 128\n",
      "          high_rank: 128\n",
      "          label: \"301020\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 129\n",
      "          high_rank: 129\n",
      "          label: \"299390\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 130\n",
      "          high_rank: 130\n",
      "          label: \"298650\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 131\n",
      "          high_rank: 131\n",
      "          label: \"296980\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 132\n",
      "          high_rank: 132\n",
      "          label: \"295810\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 133\n",
      "          high_rank: 133\n",
      "          label: \"292630\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 134\n",
      "          high_rank: 134\n",
      "          label: \"287220\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 135\n",
      "          high_rank: 135\n",
      "          label: \"286610\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 136\n",
      "          high_rank: 136\n",
      "          label: \"286420\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 137\n",
      "          high_rank: 137\n",
      "          label: \"282250\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 138\n",
      "          high_rank: 138\n",
      "          label: \"278570\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 139\n",
      "          high_rank: 139\n",
      "          label: \"270370\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 140\n",
      "          high_rank: 140\n",
      "          label: \"266970\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 141\n",
      "          high_rank: 141\n",
      "          label: \"255630\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 142\n",
      "          high_rank: 142\n",
      "          label: \"249590\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 143\n",
      "          high_rank: 143\n",
      "          label: \"236780\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 144\n",
      "          high_rank: 144\n",
      "          label: \"233300\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 145\n",
      "          high_rank: 145\n",
      "          label: \"225500\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 146\n",
      "          high_rank: 146\n",
      "          label: \"221490\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 147\n",
      "          high_rank: 147\n",
      "          label: \"206490\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 148\n",
      "          high_rank: 148\n",
      "          label: \"124040\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 149\n",
      "          high_rank: 149\n",
      "          label: \"121620\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 150\n",
      "          high_rank: 150\n",
      "          label: \"121590\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 151\n",
      "          high_rank: 151\n",
      "          label: \"121330\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 152\n",
      "          high_rank: 152\n",
      "          label: \"116030\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 153\n",
      "          high_rank: 153\n",
      "          label: \"110110\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 154\n",
      "          high_rank: 154\n",
      "          label: \"109620\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 155\n",
      "          high_rank: 155\n",
      "          label: \"109610\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 156\n",
      "          high_rank: 156\n",
      "          label: \"109080\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 157\n",
      "          high_rank: 157\n",
      "          label: \"10890\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 158\n",
      "          high_rank: 158\n",
      "          label: \"108690\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 159\n",
      "          high_rank: 159\n",
      "          label: \"107520\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 160\n",
      "          high_rank: 160\n",
      "          label: \"107450\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 161\n",
      "          high_rank: 161\n",
      "          label: \"105350\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 162\n",
      "          high_rank: 162\n",
      "          label: \"104750\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 163\n",
      "          high_rank: 163\n",
      "          label: \"103120\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_rank: 164\n",
      "          high_rank: 164\n",
      "          label: \"101510\"\n",
      "          sample_count: 1.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    path {\n",
      "      step: \"station_number\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    num_stats {\n",
      "      common_stats {\n",
      "        num_non_missing: 500\n",
      "        min_num_values: 1\n",
      "        max_num_values: 1\n",
      "        avg_num_values: 1.0\n",
      "        num_values_histogram {\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "        tot_num_values: 500\n",
      "      }\n",
      "      mean: 1938.49\n",
      "      std_dev: 2.754977313884973\n",
      "      min: 1929.0\n",
      "      median: 1939.0\n",
      "      max: 1942.0\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: 1929.0\n",
      "          high_value: 1930.3\n",
      "          sample_count: 1.8249999999999886\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1930.3\n",
      "          high_value: 1931.6\n",
      "          sample_count: 4.974999999999966\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1931.6\n",
      "          high_value: 1932.9\n",
      "          sample_count: 6.150000000000091\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1932.9\n",
      "          high_value: 1934.2\n",
      "          sample_count: 30.649999999999977\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1934.2\n",
      "          high_value: 1935.5\n",
      "          sample_count: 27.149999999999977\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1935.5\n",
      "          high_value: 1936.8\n",
      "          sample_count: 41.14999999999998\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1936.8\n",
      "          high_value: 1938.1\n",
      "          sample_count: 113.64999999999998\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1938.1\n",
      "          high_value: 1939.4\n",
      "          sample_count: 53.15000000000009\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1939.4\n",
      "          high_value: 1940.7\n",
      "          sample_count: 54.14999999999998\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1940.7\n",
      "          high_value: 1942.0\n",
      "          sample_count: 167.14999999999998\n",
      "        }\n",
      "      }\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: 1929.0\n",
      "          high_value: 1935.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1935.0\n",
      "          high_value: 1936.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1936.0\n",
      "          high_value: 1937.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1937.0\n",
      "          high_value: 1938.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1938.0\n",
      "          high_value: 1939.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1939.0\n",
      "          high_value: 1940.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1940.0\n",
      "          high_value: 1941.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1941.0\n",
      "          high_value: 1941.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1941.0\n",
      "          high_value: 1942.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 1942.0\n",
      "          high_value: 1942.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        type: QUANTILES\n",
      "      }\n",
      "    }\n",
      "    path {\n",
      "      step: \"year\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    num_stats {\n",
      "      common_stats {\n",
      "        num_non_missing: 500\n",
      "        min_num_values: 1\n",
      "        max_num_values: 1\n",
      "        avg_num_values: 1.0\n",
      "        num_values_histogram {\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "        tot_num_values: 500\n",
      "      }\n",
      "      mean: 6.764\n",
      "      std_dev: 3.511738031231829\n",
      "      min: 1.0\n",
      "      median: 7.0\n",
      "      max: 12.0\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: 1.0\n",
      "          high_value: 2.1\n",
      "          sample_count: 76.55\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 2.1\n",
      "          high_value: 3.2\n",
      "          sample_count: 39.050000000000004\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 3.2\n",
      "          high_value: 4.300000000000001\n",
      "          sample_count: 48.05\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 4.300000000000001\n",
      "          high_value: 5.4\n",
      "          sample_count: 34.050000000000004\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 5.4\n",
      "          high_value: 6.5\n",
      "          sample_count: 33.05\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 6.5\n",
      "          high_value: 7.6000000000000005\n",
      "          sample_count: 34.05\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 7.6000000000000005\n",
      "          high_value: 8.700000000000001\n",
      "          sample_count: 42.050000000000004\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 8.700000000000001\n",
      "          high_value: 9.8\n",
      "          sample_count: 49.05\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 9.8\n",
      "          high_value: 10.9\n",
      "          sample_count: 47.050000000000004\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 10.9\n",
      "          high_value: 12.0\n",
      "          sample_count: 97.05\n",
      "        }\n",
      "      }\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: 1.0\n",
      "          high_value: 2.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 2.0\n",
      "          high_value: 3.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 3.0\n",
      "          high_value: 4.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 4.0\n",
      "          high_value: 6.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 6.0\n",
      "          high_value: 7.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 7.0\n",
      "          high_value: 8.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 8.0\n",
      "          high_value: 9.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 9.0\n",
      "          high_value: 10.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 10.0\n",
      "          high_value: 11.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 11.0\n",
      "          high_value: 12.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        type: QUANTILES\n",
      "      }\n",
      "    }\n",
      "    path {\n",
      "      step: \"month\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    num_stats {\n",
      "      common_stats {\n",
      "        num_non_missing: 500\n",
      "        min_num_values: 1\n",
      "        max_num_values: 1\n",
      "        avg_num_values: 1.0\n",
      "        num_values_histogram {\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "        tot_num_values: 500\n",
      "      }\n",
      "      mean: 15.472\n",
      "      std_dev: 8.650850594016754\n",
      "      min: 1.0\n",
      "      median: 16.0\n",
      "      max: 31.0\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: 1.0\n",
      "          high_value: 4.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 4.0\n",
      "          high_value: 7.0\n",
      "          sample_count: 48.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 7.0\n",
      "          high_value: 10.0\n",
      "          sample_count: 60.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 10.0\n",
      "          high_value: 13.0\n",
      "          sample_count: 37.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 13.0\n",
      "          high_value: 16.0\n",
      "          sample_count: 48.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 16.0\n",
      "          high_value: 19.0\n",
      "          sample_count: 61.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 19.0\n",
      "          high_value: 22.0\n",
      "          sample_count: 45.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 22.0\n",
      "          high_value: 25.0\n",
      "          sample_count: 49.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 25.0\n",
      "          high_value: 28.0\n",
      "          sample_count: 58.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 28.0\n",
      "          high_value: 31.0\n",
      "          sample_count: 44.0\n",
      "        }\n",
      "      }\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: 1.0\n",
      "          high_value: 4.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 4.0\n",
      "          high_value: 7.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 7.0\n",
      "          high_value: 9.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 9.0\n",
      "          high_value: 13.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 13.0\n",
      "          high_value: 16.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 16.0\n",
      "          high_value: 18.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 18.0\n",
      "          high_value: 22.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 22.0\n",
      "          high_value: 25.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 25.0\n",
      "          high_value: 27.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 27.0\n",
      "          high_value: 31.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        type: QUANTILES\n",
      "      }\n",
      "    }\n",
      "    path {\n",
      "      step: \"day\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    type: FLOAT\n",
      "    num_stats {\n",
      "      common_stats {\n",
      "        num_non_missing: 500\n",
      "        min_num_values: 1\n",
      "        max_num_values: 1\n",
      "        avg_num_values: 1.0\n",
      "        num_values_histogram {\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 1.0\n",
      "            high_value: 1.0\n",
      "            sample_count: 50.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "        tot_num_values: 500\n",
      "      }\n",
      "      mean: 51.34719995290041\n",
      "      std_dev: 22.925435917261645\n",
      "      min: -34.5\n",
      "      median: 54.400001525878906\n",
      "      max: 97.19999694824219\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: -34.5\n",
      "          high_value: -21.33000030517578\n",
      "          sample_count: 3.975000073359606\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: -21.33000030517578\n",
      "          high_value: -8.160000610351563\n",
      "          sample_count: 8.638333056523207\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: -8.160000610351563\n",
      "          high_value: 5.009999084472653\n",
      "          sample_count: 11.933257684998278\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 5.009999084472653\n",
      "          high_value: 18.179998779296874\n",
      "          sample_count: 21.25340791354992\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 18.179998779296874\n",
      "          high_value: 31.349998474121094\n",
      "          sample_count: 32.8249988873923\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 31.349998474121094\n",
      "          high_value: 44.51999816894531\n",
      "          sample_count: 71.90833275051571\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 44.51999816894531\n",
      "          high_value: 57.689997863769534\n",
      "          sample_count: 133.4416624811309\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 57.689997863769534\n",
      "          high_value: 70.85999755859375\n",
      "          sample_count: 125.82498426399722\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 70.85999755859375\n",
      "          high_value: 84.02999725341796\n",
      "          sample_count: 70.02501716639962\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 84.02999725341796\n",
      "          high_value: 97.19999694824219\n",
      "          sample_count: 20.175005722133232\n",
      "        }\n",
      "      }\n",
      "      histograms {\n",
      "        buckets {\n",
      "          low_value: -34.5\n",
      "          high_value: 20.299999237060547\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 20.299999237060547\n",
      "          high_value: 35.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 35.0\n",
      "          high_value: 44.5\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 44.5\n",
      "          high_value: 51.0\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 51.0\n",
      "          high_value: 54.400001525878906\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 54.400001525878906\n",
      "          high_value: 58.79999923706055\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 58.79999923706055\n",
      "          high_value: 63.900001525878906\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 63.900001525878906\n",
      "          high_value: 69.9000015258789\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 69.9000015258789\n",
      "          high_value: 78.5999984741211\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        buckets {\n",
      "          low_value: 78.5999984741211\n",
      "          high_value: 97.19999694824219\n",
      "          sample_count: 50.0\n",
      "        }\n",
      "        type: QUANTILES\n",
      "      }\n",
      "    }\n",
      "    path {\n",
      "      step: \"mean_temp\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = tfdv.generate_statistics_from_dataframe(\n",
    "    dataframe=dataframe,\n",
    "    stats_options=tfdv.StatsOptions(\n",
    "        label_feature=\"mean_temp\", sample_rate=1, num_top_values=50\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfdv_schema"
   },
   "source": [
    "###  Generate the raw data schema\n",
    "\n",
    "Generate the data schema on the dataset with the TensorFlow Data Validation (TFDV) package. Use the `infer_schema()` method, with the following parameters:\n",
    "\n",
    "- `statistics`: The statistics generated by TFDV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tfdv_schema"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  name: \"station_number\"\n",
      "  type: BYTES\n",
      "  int_domain {\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"year\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"month\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"day\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mean_temp\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = tfdv.infer_schema(statistics=stats)\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfdv_schema:save"
   },
   "source": [
    "#### Save schema for the dataset to Cloud Storage\n",
    "\n",
    "Next, you write the schema for the dataset to the dataset's Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tfdv_schema:save"
   },
   "outputs": [],
   "source": [
    "SCHEMA_LOCATION = BUCKET_NAME + \"/schema.txt\"\n",
    "\n",
    "# When running Apache Beam directly (file is directly accessed)\n",
    "tfdv.write_schema_text(output_path=SCHEMA_LOCATION, schema=schema)\n",
    "# When running with Dataflow (file is uploaded to worker pool)\n",
    "tfdv.write_schema_text(output_path=\"schema.txt\", schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataflow_setup:transform"
   },
   "source": [
    "#### Prepare package requirements for Dataflow job.\n",
    "\n",
    "Before you can run a Dataflow job, you need to specify the package requirements for the worker pool that will execute the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dataflow_setup:transform"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "import setuptools\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    \"google-cloud-aiplatform==1.4.2\",\n",
    "    \"tensorflow-transform==1.2.0\",\n",
    "    \"tensorflow-data-validation==1.2.0\",\n",
    "]\n",
    "\n",
    "setuptools.setup(\n",
    "    name=\"executor\",\n",
    "    version=\"0.0.1\",\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=setuptools.find_packages(),\n",
    "    include_package_data=True,\n",
    "    package_data={\"./\": [\"schema.txt\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataflow:split,bq,gsod"
   },
   "source": [
    "### Preprocess data with Dataflow\n",
    "\n",
    "#### Dataset splitting\n",
    "\n",
    "Next, you preprocess the data using Dataflow. In this example, you query the BigQuery table and split the examples into training and evaluation datasets. For expendiency, the number of examples from the dataset is limited to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dataflow:split,bq,gsod"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing started...\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2437: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/testing bucket/myenv/bin/python', 'setup.py', 'sdist', '--dist-dir', '/tmp/tmpnlcbw83i']\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/testing bucket/myenv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpnlcbw83i', 'apache-beam==2.37.0', '--no-deps', '--no-binary', ':all:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI: dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/testing bucket/myenv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpnlcbw83i', 'apache-beam==2.37.0', '--no-deps', '--only-binary', ':all:', '--python-version', '37', '--implementation', 'cp', '--abi', 'cp37m', '--platform', 'manylinux1_x86_64']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/jupyter/testing bucket/myenv/bin/python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI: apache_beam-2.37.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.37.0\n",
      "INFO:root:Using provided Python SDK container image: gcr.io/cloud-dataflow/v1beta3/python37:2.37.0\n",
      "INFO:root:Python SDK container image set to \"gcr.io/cloud-dataflow/v1beta3/python37:2.37.0\" for Docker environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/jupyter/testing bucket/myenv/bin/python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function pack_combiners at 0x7fe535061290> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sort_stages at 0x7fe535061a70> ====================\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Defaulting to the temp_location as staging_location: gs://vertex-ai-devaip-20220308120540/temp\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Started BigQuery job: <JobReference\n",
      " location: 'US'\n",
      " projectId: 'vertex-ai-dev'>\n",
      " bq show -j --format=prettyjson --project_id=vertex-ai-dev None\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/workflow.tar.gz...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/workflow.tar.gz in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/apache_beam-2.37.0-cp37-cp37m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/apache_beam-2.37.0-cp37-cp37m-manylinux1_x86_64.whl in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/pipeline.pb in 0 seconds.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'raw_data_query': 'SELECT CAST(station_number as STRING) AS station_number,year,month,day,mean_temp FROM bigquery-public-data.samples.gsod LIMIT 500', 'exported_data_prefix': 'gs://vertex-ai-devaip-20220308120540/exported_data'}\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'raw_data_query': 'SELECT CAST(station_number as STRING) AS station_number,year,month,day,mean_temp FROM bigquery-public-data.samples.gsod LIMIT 500', 'exported_data_prefix': 'gs://vertex-ai-devaip-20220308120540/exported_data'}\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " clientRequestId: '20220308120657329029-5691'\n",
      " createTime: '2022-03-08T12:07:00.507181Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2022-03-08_04_06_59-9644980445081832882'\n",
      " location: 'us-central1'\n",
      " name: 'beamapp-jupyter-0308120657-326426-8j271gsl'\n",
      " projectId: 'vertex-ai-dev'\n",
      " stageStates: []\n",
      " startTime: '2022-03-08T12:07:00.507181Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2022-03-08_04_06_59-9644980445081832882]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Submitted job: 2022-03-08_04_06_59-9644980445081832882\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobs/us-central1/2022-03-08_04_06_59-9644980445081832882?project=vertex-ai-dev\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2022-03-08_04_06_59-9644980445081832882 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:01.229Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2022-03-08_04_06_59-9644980445081832882. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:01.431Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2022-03-08_04_06_59-9644980445081832882.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:04.859Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.481Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.504Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write Raw Eval Data/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.543Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write Raw Train Data/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.617Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.646Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.741Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.804Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.839Z: JOB_MESSAGE_DETAILED: Fusing consumer Read Raw Data/_PassThroughThenCleanup/ParDo(PassThrough)/ParDo(PassThrough) into Read Raw Data/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.881Z: JOB_MESSAGE_DETAILED: Fusing consumer Parse Data into Read Raw Data/_PassThroughThenCleanup/ParDo(PassThrough)/ParDo(PassThrough)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.953Z: JOB_MESSAGE_DETAILED: Fusing consumer Split/ParDo(ApplyPartitionFnFn)/ParDo(ApplyPartitionFnFn) into Parse Data\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:05.987Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/WindowInto(WindowIntoFn) into Split/ParDo(ApplyPartitionFnFn)/ParDo(ApplyPartitionFnFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:06.019Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/WriteBundles/WriteBundles into Write Raw Train Data/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:06.052Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/Pair into Write Raw Train Data/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:06.073Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/GroupByKey/Reify into Write Raw Train Data/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.180Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/GroupByKey/Write into Write Raw Train Data/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.201Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/GroupByKey/GroupByWindow into Write Raw Train Data/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.222Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/Extract into Write Raw Train Data/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.243Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/WindowInto(WindowIntoFn) into Split/ParDo(ApplyPartitionFnFn)/ParDo(ApplyPartitionFnFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.275Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/WriteBundles/WriteBundles into Write Raw Eval Data/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.296Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/Pair into Write Raw Eval Data/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.328Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/GroupByKey/Reify into Write Raw Eval Data/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.348Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/GroupByKey/Write into Write Raw Eval Data/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.379Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/GroupByKey/GroupByWindow into Write Raw Eval Data/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.422Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/Extract into Write Raw Eval Data/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.455Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Train Data/Write/WriteImpl/InitializeWrite into Write Raw Train Data/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.486Z: JOB_MESSAGE_DETAILED: Fusing consumer Write Raw Eval Data/Write/WriteImpl/InitializeWrite into Write Raw Eval Data/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.519Z: JOB_MESSAGE_DETAILED: Fusing consumer Read Raw Data/MapFilesToRemove into Read Raw Data/FilesToRemoveImpulse/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.551Z: JOB_MESSAGE_DETAILED: Fusing consumer Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/ParDo(RemoveExtractedFiles) into Read Raw Data/_PassThroughThenCleanup/Create/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.595Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.629Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.661Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.694Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.877Z: JOB_MESSAGE_DEBUG: Executing wait step start31\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.948Z: JOB_MESSAGE_BASIC: Executing operation Read Raw Data/FilesToRemoveImpulse/Read+Read Raw Data/MapFilesToRemove\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:07.998Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/DoOnce/Read+Write Raw Eval Data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:08.010Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:08.030Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/DoOnce/Read+Write Raw Train Data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:08.040Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2022-03-08_04_06_59-9644980445081832882 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:07:55.733Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:08:17.715Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:08:17.747Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:10.864Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/DoOnce/Read+Write Raw Eval Data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:10.995Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.025Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.100Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.137Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/WriteBundles/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.147Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.159Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.198Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/WriteBundles/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.218Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.230Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.262Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/WriteBundles/_UnpickledSideInput(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:11.302Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:14.274Z: JOB_MESSAGE_BASIC: Finished operation Read Raw Data/FilesToRemoveImpulse/Read+Read Raw Data/MapFilesToRemove\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:14.338Z: JOB_MESSAGE_DEBUG: Value \"Read Raw Data/MapFilesToRemove.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:14.387Z: JOB_MESSAGE_BASIC: Executing operation Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/_UnpickledSideInput(MapFilesToRemove.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:14.436Z: JOB_MESSAGE_BASIC: Finished operation Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/_UnpickledSideInput(MapFilesToRemove.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:14.485Z: JOB_MESSAGE_DEBUG: Value \"Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/_UnpickledSideInput(MapFilesToRemove.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:17.822Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/DoOnce/Read+Write Raw Train Data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:17.992Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.100Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.218Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.271Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/WriteBundles/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.305Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.326Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.360Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/WriteBundles/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.421Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.437Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.500Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/WriteBundles/_UnpickledSideInput(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.547Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.576Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.601Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.826Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.849Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.952Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:18.996Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:19.063Z: JOB_MESSAGE_BASIC: Executing operation Read Raw Data/Read+Read Raw Data/_PassThroughThenCleanup/ParDo(PassThrough)/ParDo(PassThrough)+Parse Data+Split/ParDo(ApplyPartitionFnFn)/ParDo(ApplyPartitionFnFn)+Write Raw Train Data/Write/WriteImpl/WindowInto(WindowIntoFn)+Write Raw Train Data/Write/WriteImpl/WriteBundles/WriteBundles+Write Raw Train Data/Write/WriteImpl/Pair+Write Raw Train Data/Write/WriteImpl/GroupByKey/Reify+Write Raw Train Data/Write/WriteImpl/GroupByKey/Write+Write Raw Eval Data/Write/WriteImpl/WindowInto(WindowIntoFn)+Write Raw Eval Data/Write/WriteImpl/WriteBundles/WriteBundles+Write Raw Eval Data/Write/WriteImpl/Pair+Write Raw Eval Data/Write/WriteImpl/GroupByKey/Reify+Write Raw Eval Data/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.683Z: JOB_MESSAGE_BASIC: Finished operation Read Raw Data/Read+Read Raw Data/_PassThroughThenCleanup/ParDo(PassThrough)/ParDo(PassThrough)+Parse Data+Split/ParDo(ApplyPartitionFnFn)/ParDo(ApplyPartitionFnFn)+Write Raw Train Data/Write/WriteImpl/WindowInto(WindowIntoFn)+Write Raw Train Data/Write/WriteImpl/WriteBundles/WriteBundles+Write Raw Train Data/Write/WriteImpl/Pair+Write Raw Train Data/Write/WriteImpl/GroupByKey/Reify+Write Raw Train Data/Write/WriteImpl/GroupByKey/Write+Write Raw Eval Data/Write/WriteImpl/WindowInto(WindowIntoFn)+Write Raw Eval Data/Write/WriteImpl/WriteBundles/WriteBundles+Write Raw Eval Data/Write/WriteImpl/Pair+Write Raw Eval Data/Write/WriteImpl/GroupByKey/Reify+Write Raw Eval Data/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.784Z: JOB_MESSAGE_DEBUG: Value \"Read Raw Data/_PassThroughThenCleanup/ParDo(PassThrough)/ParDo(PassThrough).cleanup_signal\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.820Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.853Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.876Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.911Z: JOB_MESSAGE_BASIC: Executing operation Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/_UnpickledSideInput(ParDo(PassThrough).cleanup_signal.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.935Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:39.994Z: JOB_MESSAGE_BASIC: Finished operation Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/_UnpickledSideInput(ParDo(PassThrough).cleanup_signal.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:40.005Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/GroupByKey/Read+Write Raw Eval Data/Write/WriteImpl/GroupByKey/GroupByWindow+Write Raw Eval Data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:40.040Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/GroupByKey/Read+Write Raw Train Data/Write/WriteImpl/GroupByKey/GroupByWindow+Write Raw Train Data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:40.064Z: JOB_MESSAGE_DEBUG: Value \"Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/_UnpickledSideInput(ParDo(PassThrough).cleanup_signal.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:40.144Z: JOB_MESSAGE_BASIC: Executing operation Read Raw Data/_PassThroughThenCleanup/Create/Read+Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/ParDo(RemoveExtractedFiles)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:14:59.496Z: JOB_MESSAGE_BASIC: Finished operation Read Raw Data/_PassThroughThenCleanup/Create/Read+Read Raw Data/_PassThroughThenCleanup/ParDo(RemoveExtractedFiles)/ParDo(RemoveExtractedFiles)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:03.747Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/GroupByKey/Read+Write Raw Eval Data/Write/WriteImpl/GroupByKey/GroupByWindow+Write Raw Eval Data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:03.808Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:03.872Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:03.920Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:03.940Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:03.990Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.033Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.065Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.131Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.626Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/GroupByKey/Read+Write Raw Train Data/Write/WriteImpl/GroupByKey/GroupByWindow+Write Raw Train Data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.694Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.760Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.793Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.806Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.871Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.875Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:04.991Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/PreFinalize/_UnpickledSideInput(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:05.044Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:07.391Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:07.477Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:07.547Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:07.623Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:07.686Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:07.754Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:08.225Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:08.287Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:08.354Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:08.424Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:08.490Z: JOB_MESSAGE_DEBUG: Value \"Write Raw Train Data/Write/WriteImpl/FinalizeWrite/_UnpickledSideInput(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:08.559Z: JOB_MESSAGE_BASIC: Executing operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:11.062Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Eval Data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:13.325Z: JOB_MESSAGE_BASIC: Finished operation Write Raw Train Data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:13.406Z: JOB_MESSAGE_DEBUG: Executing success step success29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:13.511Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:13.573Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:15:13.601Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:17:36.348Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:17:36.406Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2022-03-08T12:17:36.445Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2022-03-08_04_06_59-9644980445081832882 is in state JOB_STATE_DONE\n",
      "Data preprocessing completed.\n",
      "gs://vertex-ai-devaip-20220308120540/exported_data/train/-00000-of-00001.gz\n",
      "gs://vertex-ai-devaip-20220308120540/exported_data/eval/-00000-of-00001.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "\n",
    "RUNNER = \"DataflowRunner\"  # DirectRunner for local running w/o Dataflow\n",
    "\n",
    "\n",
    "def parse_bq_record(bq_record):\n",
    "    \"\"\"Parses a bq_record to a dictionary.\"\"\"\n",
    "    output = {}\n",
    "    for key in bq_record:\n",
    "        output[key] = [bq_record[key]]\n",
    "    return output\n",
    "\n",
    "\n",
    "def split_dataset(bq_row, num_partitions, ratio):\n",
    "    \"\"\"Returns a partition number for a given bq_row.\"\"\"\n",
    "    import json\n",
    "\n",
    "    assert num_partitions == len(ratio)\n",
    "    bucket = sum(map(ord, json.dumps(bq_row))) % sum(ratio)\n",
    "    total = 0\n",
    "    for i, part in enumerate(ratio):\n",
    "        total += part\n",
    "        if bucket < total:\n",
    "            return i\n",
    "    return len(ratio) - 1\n",
    "\n",
    "\n",
    "def run_pipeline(args):\n",
    "    \"\"\"Runs a Beam pipeline to split the dataset\"\"\"\n",
    "\n",
    "    pipeline_options = beam.pipeline.PipelineOptions(flags=[], **args)\n",
    "\n",
    "    raw_data_query = args[\"raw_data_query\"]\n",
    "    exported_data_prefix = args[\"exported_data_prefix\"]\n",
    "    temp_location = args[\"temp_location\"]\n",
    "    project = args[\"project\"]\n",
    "\n",
    "    schema = tfdv.load_schema_text(SCHEMA_LOCATION)\n",
    "\n",
    "    with beam.Pipeline(options=pipeline_options) as pipeline:\n",
    "        with tft_beam.Context(temp_location):\n",
    "\n",
    "            # Read raw BigQuery data.\n",
    "            raw_train_data, raw_eval_data = (\n",
    "                pipeline\n",
    "                | \"Read Raw Data\"\n",
    "                >> beam.io.ReadFromBigQuery(\n",
    "                    query=raw_data_query,\n",
    "                    project=project,\n",
    "                    use_standard_sql=True,\n",
    "                )\n",
    "                | \"Parse Data\" >> beam.Map(parse_bq_record)\n",
    "                | \"Split\" >> beam.Partition(split_dataset, 2, ratio=[8, 2])\n",
    "            )\n",
    "\n",
    "            _ = (\n",
    "                raw_train_data\n",
    "                | \"Write Raw Train Data\"\n",
    "                >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "                    file_path_prefix=os.path.join(exported_data_prefix, \"train/\"),\n",
    "                    file_name_suffix=\".gz\",\n",
    "                    coder=tft.coders.ExampleProtoCoder(schema),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            _ = (\n",
    "                raw_eval_data\n",
    "                | \"Write Raw Eval Data\"\n",
    "                >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "                    file_path_prefix=os.path.join(exported_data_prefix, \"eval/\"),\n",
    "                    file_name_suffix=\".gz\",\n",
    "                    coder=tft.coders.ExampleProtoCoder(schema),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "EXPORTED_DATA_PREFIX = os.path.join(BUCKET_NAME, \"exported_data\")\n",
    "\n",
    "QUERY_STRING = \"SELECT {},{} FROM {} LIMIT 500\".format(\n",
    "    \"CAST(station_number as STRING) AS station_number,year,month,day\",\n",
    "    \"mean_temp\",\n",
    "    IMPORT_FILE[5:],\n",
    ")\n",
    "JOB_NAME = \"gsod\" + TIMESTAMP\n",
    "\n",
    "args = {\n",
    "    \"runner\": RUNNER,\n",
    "    \"raw_data_query\": QUERY_STRING,\n",
    "    \"exported_data_prefix\": EXPORTED_DATA_PREFIX,\n",
    "    \"temp_location\": os.path.join(BUCKET_NAME, \"temp\"),\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"region\": REGION,\n",
    "    \"setup_file\": \"./setup.py\",\n",
    "}\n",
    "\n",
    "print(\"Data preprocessing started...\")\n",
    "run_pipeline(args)\n",
    "print(\"Data preprocessing completed.\")\n",
    "\n",
    "! gsutil ls $EXPORTED_DATA_PREFIX/train\n",
    "! gsutil ls $EXPORTED_DATA_PREFIX/eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "# Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:\n",
    "\n",
    "- Cloud Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://vertex-ai-devaip-20220308120540/schema.txt#1646741209649207...\n",
      "Removing gs://vertex-ai-devaip-20220308120540/exported_data/eval/-00000-of-00001.gz#1646741709567696...\n",
      "Removing gs://vertex-ai-devaip-20220308120540/exported_data/train/-00000-of-00001.gz#1646741711927311...\n",
      "Removing gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/apache_beam-2.37.0-cp37-cp37m-manylinux1_x86_64.whl#1646741219271257...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/dataflow_python_sdk.tar#1646741218292952...\n",
      "Removing gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/pipeline.pb#1646741219488394...\n",
      "Removing gs://vertex-ai-devaip-20220308120540/temp/beamapp-jupyter-0308120657-326426-8j271gsl.1646741217.327548/workflow.tar.gz#1646741217987119...\n",
      "/ [7 objects]                                                                   \n",
      "Operation completed over 7 objects.                                              \n",
      "Removing gs://vertex-ai-devaip-20220308120540/...\n"
     ]
    }
   ],
   "source": [
    "if \"BUCKET_NAME\" in globals():\n",
    "    ! gsutil rm -r $BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_dataflow.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "myenv",
   "name": "common-cpu.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m89"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
