{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Using Vertex AI Feature Store with Pandas Dataframe\n",
        "\n",
        "<table align=\"left\">\n",
        "    <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> \n",
        "        Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "    \n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "962e636b5cee"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook introduces Pandas support for Feature Store using Vertex AI SDK. For pre-requisites and introduction on Vertex AI SDK and Feature Store native support, please go through this [Colab notebook](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/feature_store/sdk-feature-store.ipynb). \n",
        "\n",
        "Learn more about [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxF5JWRVT5PP"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to use `Vertex AI Feature Store` with pandas Dataframe.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- Vertex AI Feature Store\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Create Featurestore, entity types and features.\n",
        "- Ingest feature values from Pandas DataFrame into Feature Store's Entity types.\n",
        "- Read Entity feature values from Online Feature Store into Pandas DataFrame.\n",
        "- Batch serve feature values from your Feature Store into Pandas DataFrame.\n",
        "\n",
        "You also learn how Vertex AI Feature Store can be useful in the below scenarios:\n",
        "\n",
        "- Online serving with updated feature values.\n",
        "- Point-in-time correctness to fetch feature values for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ZNLaf6T0lN"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial is a part of the Feature Store tutorial notebooks. It uses a movie recommendation dataset as an example for demonstrating various functionalities of Feature Store. The original task is to train a model to predict if a user is going to watch a movie, and serve the model online."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2Bj_QpT2Ud"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet --upgrade google-cloud-aiplatform \\\n",
        "                                google-cloud-bigquery \\\n",
        "                                google-cloud-bigquery-storage \\\n",
        "                                avro \\\n",
        "                                pyarrow \\\n",
        "                                pandas \\\n",
        "                                fsspec \\\n",
        "                                gcsfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "restart"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-ZBOjErv5mM"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfEglUHQk9S3"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21e3cac35e75"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcp_authenticate"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n",
        "\n",
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated.\n",
        "\n",
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce6043da7b33"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0367eac06a10"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ad4dbb4a61"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13224697bfb"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:mbsdk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to serve as a staging bucket for Vertex AI and to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdct_Lm7x2I_"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from avro.datafile import DataFileReader\n",
        "from avro.io import DatumReader\n",
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "138407556b22"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2077ffee78"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQBIv3ZL3A0"
      },
      "source": [
        "## Create a Feature Store\n",
        "\n",
        "Vertex AI Feature Store serves you as a centralised and organised repository for your ML features. You can store, serve and monitor certain aspects of your features like their distributions and drift. Learn more about [Vertex AI Feature Store data model](https://cloud.google.com/vertex-ai/docs/featurestore/concepts), and [benefits of Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore/overview#benefits).\n",
        "\n",
        "To begin this tutorial, you create a feature store using the Vertex AI SDK for Python. A feature store is a top-level container for your features and their values. For this, you use the [`Featurestore.create()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Featurestore) method which returns a LRO ([long-running operation](https://google.aip.dev/151)). A LRO starts an asynchronous job. LROs are returned for other API methods too, such as updating or deleting a featurestore. \n",
        "\n",
        "You pass the below parameters while creating the featurestore:\n",
        "\n",
        "- `featurestore_id`: A unique name or id for your featurestore\n",
        "- `online_store_fixed_node_count`: Config for online serving resources. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6uIWQeoBSr8"
      },
      "outputs": [],
      "source": [
        "# set the id or name for the feature store\n",
        "featurestore_id = \"movie_predictions_unique\"  # @param {type:\"string\"}\n",
        "\n",
        "# Create featurestore\n",
        "movie_predictions_feature_store = aiplatform.Featurestore.create(\n",
        "    featurestore_id=featurestore_id, online_store_fixed_node_count=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmJq75zXjmT"
      },
      "source": [
        "## Create Entity types\n",
        "\n",
        "Using Vertex AI Feature Store, you can create and manage feature stores, entity types, and features. An entity type is a collection of semantically related features. You define your own entity types, based on the concepts that are relevant to your use case. For example, a movie service might have the entity types movie and user, which group related features that correspond to movies or customers.\n",
        "\n",
        "Learn more about [Entity types](https://cloud.google.com/vertex-ai/docs/featurestore/concepts#entity_type).\n",
        "\n",
        "Entity types are created within the Featurestore class. Below, you create the following entity types `users` and `movies` for the movie recommendation dataset.\n",
        "\n",
        "You pass the following parameters while creating the entity types:\n",
        "\n",
        "- `entity_type_id`: A unique name or id for your entity type.\n",
        "- `description`: (Optional) Description for your entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU0oXvINBgPV"
      },
      "outputs": [],
      "source": [
        "# Create users entity type\n",
        "users_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"users\",\n",
        "    description=\"Users entity\",\n",
        ")\n",
        "\n",
        "# Create movies entity type\n",
        "movies_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"movies\",\n",
        "    description=\"Movies entity\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJW4q-0jO2Xf"
      },
      "source": [
        "## Create Features\n",
        "\n",
        "A feature is a measurable property or attribute of an entity type. For example, the movie entity type has features such as average_rating and title that track various properties of movies. Features are associated with entity types. \n",
        "\n",
        "Learn more about [Features](https://cloud.google.com/vertex-ai/docs/featurestore/concepts#feature).\n",
        "\n",
        "Add the defined features to the entity types `users` and `movies` using the following methods.\n",
        "\n",
        "### Add features using *`create_feature`* method\n",
        "\n",
        "You provide the following parameters for creating features:\n",
        "\n",
        "- `feature_id`: Resource name or an id for the Feature.\n",
        "- `value_type`: Type of Feature value. One of BOOL, BOOL_ARRAY, DOUBLE, DOUBLE_ARRAY, INT64, INT64_ARRAY, STRING, STRING_ARRAY, BYTES.\n",
        "- `description`: Description of the Feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvjwT84iVSps"
      },
      "outputs": [],
      "source": [
        "# Create age feature\n",
        "users_feature_age = users_entity_type.create_feature(\n",
        "    feature_id=\"age\",\n",
        "    value_type=\"INT64\",\n",
        "    description=\"User age\",\n",
        ")\n",
        "\n",
        "# Create gender feature\n",
        "users_feature_gender = users_entity_type.create_feature(\n",
        "    feature_id=\"gender\",\n",
        "    value_type=\"STRING\",\n",
        "    description=\"User gender\",\n",
        ")\n",
        "\n",
        "# Create liked_genres feature\n",
        "users_feature_liked_genres = users_entity_type.create_feature(\n",
        "    feature_id=\"liked_genres\",\n",
        "    value_type=\"STRING_ARRAY\",\n",
        "    description=\"An array of genres this user liked\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecb141839033"
      },
      "source": [
        "### Add features using *`batch_create_features`* method\n",
        "\n",
        "You can also add multiple features at a time using a config map in a dictionary format. For this, you use the `batch_create_features` method. \n",
        "\n",
        "Below, you define create `title`, `genres` and `average_rating` features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llTT9_Dgbac2"
      },
      "outputs": [],
      "source": [
        "# define the features\n",
        "movies_feature_configs = {\n",
        "    \"title\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The title of the movie\",\n",
        "    },\n",
        "    \"genres\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The genre of the movie\",\n",
        "    },\n",
        "    \"average_rating\": {\n",
        "        \"value_type\": \"DOUBLE\",\n",
        "        \"description\": \"The average rating for the movie, range is [1.0-5.0]\",\n",
        "    },\n",
        "}\n",
        "# create the features\n",
        "movie_features = movies_entity_type.batch_create_features(\n",
        "    feature_configs=movies_feature_configs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3n5XdK8Xjmw"
      },
      "source": [
        "## Ingest Feature values into Entity types from dataframes\n",
        "\n",
        "A Feature Store captures feature values for a feature belonging to an entity type at a specific point in time. After ingesting your feature values to feature store, you can later `read` (online) or `batch serve` (offline) the feature values from the entity type. \n",
        "\n",
        "In this section, you learn how to ingest feature values from a [Pandas dataframe](https://pandas.pydata.org/) into an entity type. \n",
        "\n",
        "Learn more about [Feature values](https://cloud.google.com/vertex-ai/docs/featurestore/concepts#feature_value).\n",
        "\n",
        "Note: You can also import feature values from BigQuery or Google Cloud Storage.\n",
        "\n",
        "### Get movie recommendation data from source\n",
        "\n",
        "Define the data sources for users and movies and copy them locally into **.avro** files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uNrHqiGXrff"
      },
      "outputs": [],
      "source": [
        "# set the users file source\n",
        "GCS_USERS_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
        ")\n",
        "# set the movies file source\n",
        "GCS_MOVIES_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
        ")\n",
        "# set the local file names\n",
        "USERS_AVRO_FN = \"users.avro\"\n",
        "MOVIES_AVRO_FN = \"movies.avro\"\n",
        "# copy the files using gsutil\n",
        "! gsutil cp $GCS_USERS_AVRO_URI $USERS_AVRO_FN\n",
        "! gsutil cp $GCS_MOVIES_AVRO_URI $MOVIES_AVRO_FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6Z0jfR5OW5"
      },
      "source": [
        "### Load data from avro files \n",
        "\n",
        "Load users and movies data from the downloaded avro files into Pandas dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrB7bnqbZYaC"
      },
      "outputs": [],
      "source": [
        "# Define a class for reading the avro data\n",
        "\n",
        "\n",
        "class AvroReader:\n",
        "    def __init__(self, data_file):\n",
        "        self.avro_reader = DataFileReader(open(data_file, \"rb\"), DatumReader())\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        records = [record for record in self.avro_reader]\n",
        "        return pd.DataFrame.from_records(data=records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdlWJhUt5OW5"
      },
      "outputs": [],
      "source": [
        "# Load users data from avro file\n",
        "users_avro_reader = AvroReader(data_file=USERS_AVRO_FN)\n",
        "users_source_df = users_avro_reader.to_dataframe()\n",
        "users_source_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ49cPS35OW5"
      },
      "outputs": [],
      "source": [
        "# Load movies data from avro file\n",
        "movies_avro_reader = AvroReader(data_file=MOVIES_AVRO_FN)\n",
        "movies_source_df = movies_avro_reader.to_dataframe()\n",
        "movies_source_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb0WGwX5OW6"
      },
      "source": [
        "### Ingest Feature values into Entity types\n",
        "\n",
        "Load the feature values into `users` entity type from the dataframe.\n",
        "\n",
        "You provide the following parameters for ingesting the data:\n",
        "\n",
        "- `feature_ids`: List of ids of the Feature to import values of. The Features must exist in the target EntityType, or the request will fail.\n",
        "- `feature_time`: The source column that holds the Feature timestamp for all Feature values in each entity. It can also be a single Feature timestamp for all entities being imported.\n",
        "- `df_source`: Pandas DataFrame containing the source data for ingestion.\n",
        "- `entity_id_field`: Source column that holds entity IDs.\n",
        "\n",
        "Learn more about the [`EntityType.ingest_from_df()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.EntityType#google_cloud_aiplatform_EntityType_ingest_from_df) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b813uj5OW6"
      },
      "outputs": [],
      "source": [
        "# ingest the data for users\n",
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=users_source_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCAdQ3cF5OW6"
      },
      "source": [
        "Similarly, load the feature values for `movies` entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DYlKe4e5OW6"
      },
      "outputs": [],
      "source": [
        "# ingest the data for movies\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=movies_source_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYLZwao5OW6"
      },
      "source": [
        "## Read Entity's feature values online from Feature Store\n",
        "\n",
        "Feature Store allows online serving which lets you read feature values for small batches of entities. It is beneficial when you want to read values of selected features from an entity or multiple entities in an entity type.\n",
        "\n",
        "Note: An entity is an instance of an entity type. For example, movie_01 and movie_02 are entities of the entity type movie.\n",
        "\n",
        "Learn more about [Feature Store online serving](https://cloud.google.com/vertex-ai/docs/featurestore/serving-online).\n",
        "\n",
        "### Read feature values for users\n",
        "\n",
        "Call the [`EntityType.read()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.EntityType#google_cloud_aiplatform_EntityType_read) method with the required entity ids from the entity type `users`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrR-SY3i58rh"
      },
      "outputs": [],
      "source": [
        "# read the data to a dataframe\n",
        "users_read_df = users_entity_type.read(\n",
        "    entity_ids=[\"dave\", \"alice\", \"charlie\", \"bob\", \"eve\"],\n",
        ")\n",
        "# dispaly the dataframe\n",
        "users_read_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2cfa09ef11d"
      },
      "source": [
        "### Read feature values for movies\n",
        "\n",
        "Call the [`EntityType.read()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.EntityType#google_cloud_aiplatform_EntityType_read) method with the required entity ids from the entity type `movies`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTW6kBxN5OW7"
      },
      "outputs": [],
      "source": [
        "# read the data to a dataframe\n",
        "movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "# display the dataframe\n",
        "movies_read_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK2Glzkq5OW7"
      },
      "source": [
        "## Batch serve feature values from Feature Store\n",
        "\n",
        "Feature Store can also serve the feature values in large batches for high-throughput. Batch serving is typically used for training a model or batch prediction. \n",
        "\n",
        "Learn more about [Feature Store batch serving](https://cloud.google.com/vertex-ai/docs/featurestore/serving-batch#batch_serving_inputs).\n",
        "\n",
        "In this section, you learn how to prepare training examples by using the Feature Store's batch serve function.\n",
        "\n",
        "### Load read instances from source file\n",
        "\n",
        "Define the source file path that consists of some samples with feature values. Here, you load some feature values from the `movie_prediction.csv` file in the dataset using Pandas. This data serves as read instances while calling the batch serve function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4k2QVN-5OW7"
      },
      "outputs": [],
      "source": [
        "# set the gcs source for samples\n",
        "GCS_READ_INSTANCES_CSV_URI = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d9fdcbc90fc"
      },
      "source": [
        "While loading the data, parse the `timestamp` column as datetime field. This is because the feature store expects a timestamp field in the read instances when batch serving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqQVfRnC5OW7"
      },
      "outputs": [],
      "source": [
        "# load the data using pandas\n",
        "read_instances_df = pd.read_csv(GCS_READ_INSTANCES_CSV_URI, parse_dates=[\"timestamp\"])\n",
        "# display the dataframe\n",
        "read_instances_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1dC5Pc5OW8"
      },
      "source": [
        "### Batch serve feature values from Feature Store\n",
        "\n",
        "Serve the batch response to a dataframe using the `batch_serve_to_df` method by providing the following parameters:\n",
        "\n",
        "- `serving_feature_ids`: A user defined dictionary to define the entity_types and their features for batch serve/read. The keys of the dictionary are the serving entity_type ids and the values are lists of serving feature ids in each entity_type.\n",
        "        \n",
        "- `read_instances_df`: A pandas DataFrame containing the read instances. Each read instance should consist of exactly one read timestamp and one or more entity IDs identifying entities of the corresponding EntityTypes whose Features are requested. Each output instance contains Feature values of requested entities concatenated together as of the read time. \n",
        "\n",
        "    An example read_instances_df may be:\n",
        "\n",
        "    ```\n",
        "    pd.DataFrame( data=[ { \n",
        "            \"my_entity_type_id_1\": \"my_entity_type_id_1_entity_1\", \n",
        "            \"my_entity_type_id_2\": \"my_entity_type_id_2_entity_1\", \n",
        "            \"timestamp\": \"2020-01-01T10:00:00.123Z\" ], ) \n",
        "    ```\n",
        "    An example batch_serve_output_df may be \n",
        "    \n",
        "    ```\n",
        "    pd.DataFrame( data=[ { \n",
        "            \"my_entity_type_id_1\": \"my_entity_type_id_1_entity_1\", \n",
        "            \"my_entity_type_id_2\": \"my_entity_type_id_2_entity_1\", \n",
        "            \"foo\": \"feature_id_1_1_feature_value\", \n",
        "            \"feature_id_1_2\": \"feature_id_1_2_feature_value\", \n",
        "            \"feature_id_2_1\": \"feature_id_2_1_feature_value\", \n",
        "            \"bar\": \"feature_id_2_2_feature_value\", \n",
        "            \"timestamp\": \"2020-01-01T10:00:00.123Z\" ], ) \n",
        "    ``` \n",
        "        \n",
        "\n",
        "Note: Calling the `batch_serve_to_df` method automatically creates and deletes a temporary bigquery dataset in the same GCP project, which is used as the intermediary storage for batch serve feature values from featurestore to dataframe.\n",
        "\n",
        "Learn more about [Feature Store batch serving to a dataframe](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Featurestore#google_cloud_aiplatform_Featurestore_batch_serve_to_df). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZSJ-Sbl5OW8"
      },
      "outputs": [],
      "source": [
        "# call the batch serve method\n",
        "movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "# display the dataframe\n",
        "movie_predictions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN84znoI5OW8"
      },
      "source": [
        "## Read the latest feature values\n",
        "\n",
        "In Feature Store, you access the latest or the last available feature values unless a specific time is provided. \n",
        "\n",
        "Now, you test this feature by ingesting new data to the entity types and reading it from the Feature Store.\n",
        "\n",
        "### Ingest updated feature values\n",
        "\n",
        "Now, you update the feature values by running the following cell. \n",
        "\n",
        "**Note:** For comparison, you can try printing the feature values read from the entity types earlier (those in `movies_read_df` variable). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y-iMUFH5OW9"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe for the new data\n",
        "update_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_03\", 4.3], [\"movie_04\", 4.8]],\n",
        "    columns=[\"movie_id\", \"average_rating\"],\n",
        ")\n",
        "\n",
        "# Ingest the new data from the dataframe\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\"],\n",
        "    feature_time=datetime.datetime.now(),  # provide the current timestamp\n",
        "    df_source=update_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s47WCIvL5OW9"
      },
      "source": [
        "### Fetch the latest feature values\n",
        "\n",
        "Reading from the entity type gives you the updated feature values from the latest ingestion.\n",
        "\n",
        "Running the below cell should fetch the latest values for all the requested entities including `movie_03` and `movie_04` which you added in the last cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2IPEY7S5OW9"
      },
      "outputs": [],
      "source": [
        "# read the feature values from the entity type\n",
        "update_movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "# display the dataframe\n",
        "update_movies_read_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1YGRNsW5OW9"
      },
      "source": [
        "## Point-in-time correctness\n",
        "\n",
        "Vertex AI Feature Store captures feature values for a feature at a [specific point in time](https://cloud.google.com/vertex-ai/docs/featurestore/serving-batch#example_point-in-time_lookup). In case there are missing values in your past data, you can backfill them using batch serving.\n",
        "\n",
        "### Check missing data\n",
        "Recall that response from the batch serve from last ingestion has some missing data in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueXYomBr5OW-"
      },
      "outputs": [],
      "source": [
        "# check the missing data\n",
        "movie_predictions_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abQRF6mx5OW-"
      },
      "source": [
        "### Backfill / correct point-in-time data\n",
        "\n",
        "Impute the missing data based on thetimestamps.\n",
        "\n",
        "Note: The timestamp field should must use the RFC 3339 format(e.g. 2012-07-30T10:43:17.123Z) or should be compatible with the Timestamp datatype when loaded to BigQuery. This is because Feature Stores loads to a temporary BigQuery table as an intermediate step when batch serving. Learn more about [loading data to BigQuery from dataframe](https://cloud.google.com/bigquery/docs/samples/bigquery-load-table-dataframe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehZhc4ZP5OW-"
      },
      "outputs": [],
      "source": [
        "# Impute the users data\n",
        "backfill_users_df = pd.DataFrame(\n",
        "    data=[[\"bob\", 34, \"Male\", [\"Drama\"], \"2020-02-13 09:35:15+00:00\"]],\n",
        "    columns=[\"user_id\", \"age\", \"gender\", \"liked_genres\", \"update_time\"],\n",
        ")\n",
        "# convert the timefield to datetime64[ns] (with timezone info)\n",
        "backfill_users_df[\"update_time\"] = pd.to_datetime(backfill_users_df[\"update_time\"])\n",
        "# display the dataframe\n",
        "backfill_users_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhdTzl5k5OW-"
      },
      "outputs": [],
      "source": [
        "# Impute the movies data\n",
        "backfill_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_04\", 4.2, \"The Dark Knight\", \"Action\", \"2020-02-13 09:35:15+00:00\"]],\n",
        "    columns=[\"movie_id\", \"average_rating\", \"title\", \"genres\", \"update_time\"],\n",
        ")\n",
        "# convert the timefield to datetime64[ns] (with timezone info)\n",
        "backfill_movies_df[\"update_time\"] = pd.to_datetime(backfill_movies_df[\"update_time\"])\n",
        "# display the dataframe\n",
        "backfill_movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXb4JUhu5OW-"
      },
      "source": [
        "### Ingest the backfilled / corrected data\n",
        "\n",
        "Ingest the imputed point-in-time data from dataframe to the entity types in feature store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM1ejZMa5OW-"
      },
      "outputs": [],
      "source": [
        "# Ingest the users data\n",
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_users_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnrNbv75OW-"
      },
      "outputs": [],
      "source": [
        "# Ingest the users data\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e62Ku6W5OW_"
      },
      "source": [
        "### Fetch the latest data\n",
        "Batch serve the ingested backfilled data to a dataframe to ensure the feature store is updated. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3njvLv2wbZok"
      },
      "outputs": [],
      "source": [
        "# batch serve the latest data to a dataframe\n",
        "backfill_movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "# display the dataframe\n",
        "backfill_movie_predictions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "- Vertex AI Feature Store\n",
        "- Cloud Storage bucket (set `delete_bucket` to True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBTNfN8vxz4x"
      },
      "outputs": [],
      "source": [
        "# Delete the feature store\n",
        "movie_predictions_feature_store.delete(force=True)\n",
        "\n",
        "# remove the local users and movies avro files\n",
        "! rm {USERS_AVRO_FN} {MOVIES_AVRO_FN}\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "delete_bucket = True\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk-feature-store-pandas.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
