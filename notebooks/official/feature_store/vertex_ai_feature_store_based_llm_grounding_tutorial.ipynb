{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EcdxqUnftBL"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awoLZ5dc5bcG"
      },
      "source": [
        "# Vertex AI Feature Store Based LLM Grounding tutorial\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/vertex_ai_feature_store_based_llm_grounding_tutorial.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ffeature_store%2Fvertex_ai_feature_store_based_llm_grounding_tutorial.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td> \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/feature_store/vertex_ai_feature_store_based_llm_grounding_tutorial.ipynb.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br>\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>                                                                                               \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/vertex_ai_feature_store_based_llm_grounding_tutorial.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br>\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWNCLbZZ6MLi"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this tutorial, you learn how to chunk user-provided data, and then generate embedding vectors for each chunk using a Vertex LLM (Large Language Model) having embedding generation capabilities. The resulting embedding vector dataset can then be loaded into Vertex AI Feature Store, enabling fast feature retrieval and efficient online serving.\n",
        "\n",
        "Learn more about [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBeo3dIqJVDd"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to create and use an online feature store instance to host and serve data in BigQuery with Vertex AI Feature Store in an end to end workflow of features serving and vector retrieval user journey.\n",
        "\n",
        "This tutorial uses the following Google Vertex AI services and resources:\n",
        "\n",
        "- Vertex AI Feature Store\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Provision an online feature store instance to host and serve data.\n",
        "- Create an online feature store instance to serve a BigQuery table.\n",
        "- Use the online server to search nearest neighbors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1t0xA5XB_3n"
      },
      "source": [
        "### Note\n",
        "This is a Preview release. By using the feature, you acknowledge that you're aware of the open issues and that this preview is provided “as is” under the pre-GA terms of service.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbCa7Pcpqgaz"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial uses the [Google Patents Public Data](https://console.cloud.google.com/marketplace/product/google_patents_public_datasets/google-patents-public-data) dataset from the BigQuery public datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrggkyCUrhZM"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* BigQuery\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "[BigQuery pricing](https://cloud.google.com/bigquery/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ea81ac77f0"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTJiDCrYsOmT"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAqbE5Z2sTVM"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade --quiet google-cloud-aiplatform\\\n",
        "                                 google-cloud-bigquery\\\n",
        "                                 db-dtypes\n",
        "\n",
        "! pip3 install --upgrade kfp -q --no-warn-conflicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np60_uuCs7X5"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u0aEgaSs-3v"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01e1cc61b578"
      },
      "source": [
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff666ce4051c"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc7251520a07"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60763ee24ce0"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5cutPRQtQ7m"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "API_ENDPOINT = f\"{LOCATION}-aiplatform.googleapis.com\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMCl0avIusKl"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifbIQuN1uz2r"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.aiplatform_v1 import (FeatureOnlineStoreAdminServiceClient,\n",
        "                                        FeatureOnlineStoreServiceClient)\n",
        "from google.cloud.aiplatform_v1.types import NearestNeighborQuery\n",
        "from google.cloud.aiplatform_v1.types import \\\n",
        "    feature_online_store as feature_online_store_pb2\n",
        "from google.cloud.aiplatform_v1.types import \\\n",
        "    feature_online_store_admin_service as \\\n",
        "    feature_online_store_admin_service_pb2\n",
        "from google.cloud.aiplatform_v1.types import \\\n",
        "    feature_online_store_service as feature_online_store_service_pb2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYzwb095DJTl"
      },
      "source": [
        "## Set up and start online serving\n",
        "\n",
        "To serve embedding data in Vertex AI Feature Store, do the following:\n",
        "\n",
        "1. Prepare the data source in BigQuery.\n",
        "2. Create an FeatureOnlineStore instance to host the data.\n",
        "3. Define the data (`FeatureView`) to be served by the newly-created instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNv9jdEhV0u6"
      },
      "source": [
        "### Prepare BigQuery data source for feature view creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PBDNyHnY_OB"
      },
      "outputs": [],
      "source": [
        "GCS_BUCKET = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OV9dADJb63o"
      },
      "source": [
        "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-9B3v7kcOAF"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {GCS_BUCKET}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTykneRCbDOU"
      },
      "source": [
        "#### Prepare data in Google Cloud Storage (GCS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmL7Z66xb9Sx"
      },
      "outputs": [],
      "source": [
        "INPUT_TEXT_GCS_DIR = f\"{GCS_BUCKET}/fs_grounding/data\"\n",
        "\n",
        "import tarfile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "\n",
        "def untar(file_name):\n",
        "    output_folder_name = file_name[:-7]\n",
        "    file = tarfile.open(file_name)\n",
        "    file.extractall(output_folder_name)\n",
        "    return output_folder_name\n",
        "\n",
        "\n",
        "# Download data from https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz\n",
        "url = \"https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz\"\n",
        "filename = \"nfcorpus.tar.gz\"\n",
        "path, _ = urlretrieve(url, filename)\n",
        "print(f\"Downloaded {path}\")\n",
        "\n",
        "# Copy text files to GCS.\n",
        "output_folder_name = f\"{untar(path)}/nfcorpus\"\n",
        "dev_all_queries = f\"{output_folder_name}/dev.all.queries\"\n",
        "dev_docs = f\"{output_folder_name}/dev.docs\"\n",
        "! gsutil cp {dev_all_queries} {INPUT_TEXT_GCS_DIR}/queries\n",
        "! gsutil cp {dev_docs} {INPUT_TEXT_GCS_DIR}/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4rxyUV4XU7q"
      },
      "source": [
        "#### Create BigQuery dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdIPzLkoW5mc"
      },
      "outputs": [],
      "source": [
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "BQ_DATASET_ID = \"fs_grounding\"  # @param {type:\"string\"}\n",
        "dataset = bigquery.Dataset(f\"{PROJECT_ID}.{BQ_DATASET_ID}\")\n",
        "dataset.location = LOCATION\n",
        "dataset = bq_client.create_dataset(\n",
        "    dataset, exists_ok=True, timeout=30\n",
        ")  # Make an API request.\n",
        "\n",
        "# Confirm dataset created.\n",
        "print(f\"Created dataset {dataset}.{BQ_DATASET_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlKyrvIAXf5O"
      },
      "source": [
        "#### Launch pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knz8N5iIXpl9"
      },
      "outputs": [],
      "source": [
        "run_id = str(uuid.uuid4())\n",
        "\n",
        "PIPELINE_TEMPLATE_URI = \"gs://vertex-evaluation-pipeline-templates/20240117_0005/feature_store_grounding_pipeline_pipeline.yaml\"\n",
        "BIGQUERY_BP_INPUT_URI = f\"bq://{PROJECT_ID}.{BQ_DATASET_ID}.batch_predict_input\"\n",
        "BIGQUERY_BP_OUTPUT_URI = f\"bq://{PROJECT_ID}.{BQ_DATASET_ID}.batch_predict_output\"\n",
        "\n",
        "PARAMS = {\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"location\": LOCATION,\n",
        "    \"bigquery_bp_input_uri\": BIGQUERY_BP_INPUT_URI,\n",
        "    \"bigquery_bp_output_uri\": BIGQUERY_BP_OUTPUT_URI,\n",
        "    \"input_text_gcs_dir\": INPUT_TEXT_GCS_DIR,\n",
        "    \"output_text_gcs_dir\": f\"{GCS_BUCKET}/fs_grounding_{run_id}/chunking_output\",\n",
        "    \"output_error_file_path\": f\"{GCS_BUCKET}/fs_grounding_{run_id}/chunking_error_output\",\n",
        "    \"model_name\": \"publishers/google/models/textembedding-gecko@latest\",\n",
        "    \"generation_threshold_microseconds\": \"0\",\n",
        "}\n",
        "\n",
        "\n",
        "def run_pipeline(\n",
        "    parameters: dict,\n",
        "    project: str,\n",
        "    pipeline_root: str,\n",
        "    location: str = \"us-central1\",\n",
        ") -> aiplatform.PipelineJob:\n",
        "    aiplatform.init(\n",
        "        project=project,\n",
        "        location=location,\n",
        "    )\n",
        "\n",
        "    test_prefix = \"your-test-prefix\"  # @param {type:\"string\"}\n",
        "    pipeline_name = \"feature-store-grounding-pipeline\"  # @param {type:\"string\"}\n",
        "\n",
        "    test_name = f\"{test_prefix}-{pipeline_name}-{run_id}\"\n",
        "    job = aiplatform.PipelineJob(\n",
        "        display_name=test_name,\n",
        "        template_path=PIPELINE_TEMPLATE_URI,\n",
        "        job_id=test_name,\n",
        "        pipeline_root=pipeline_root,\n",
        "        parameter_values=parameters,\n",
        "        enable_caching=False,\n",
        "    )\n",
        "\n",
        "    job.submit()\n",
        "\n",
        "    return job\n",
        "\n",
        "\n",
        "job = run_pipeline(\n",
        "    parameters=PARAMS,\n",
        "    project=PROJECT_ID,\n",
        "    pipeline_root=f\"{GCS_BUCKET}/fs_based/pipeline_root\",\n",
        "    location=LOCATION,\n",
        ")\n",
        "job.wait()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7v96efXpBxf"
      },
      "source": [
        "#### BQ format conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv27Q9AanTCO"
      },
      "outputs": [],
      "source": [
        "def compose_bq_query_format_conversion(\n",
        "    bigquery_bp_input_uri: str, bigquery_bp_output_uri: str\n",
        ") -> str:\n",
        "    \"\"\"Compose the BQ query for format conversion.\n",
        "\n",
        "    Args:\n",
        "      bigquery_bp_input_uri: The URI to a bigquery table as the input for the\n",
        "        batch prediction component. The chunking component populates data to\n",
        "        this uri first before batch prediction.\n",
        "      bigquery_bp_output_uri: The URI to a bigquery table as the output for the\n",
        "        batch prediction component.\n",
        "\n",
        "    Returns:\n",
        "      The composed query for BigQuery format conversion.\n",
        "    \"\"\"\n",
        "\n",
        "    if bigquery_bp_input_uri.startswith(\"bq://\"):\n",
        "        bigquery_bp_input_uri = bigquery_bp_input_uri.replace(\"bq://\", \"\")\n",
        "\n",
        "    if bigquery_bp_output_uri.startswith(\"bq://\"):\n",
        "        bigquery_bp_output_uri = bigquery_bp_output_uri.replace(\"bq://\", \"\")\n",
        "\n",
        "    inseration_query = (\n",
        "        f\"UPDATE `{bigquery_bp_input_uri}` destTable\"\n",
        "        \" SET embedding=ARRAY( select cast (str_element as float64) from\"\n",
        "        \" unnest(JSON_VALUE_ARRAY(prediction, '$.embeddings.values')) as\"\n",
        "        \" str_element)\"\n",
        "    )\n",
        "    fetch_data_query = (\n",
        "        \"FROM (SELECT vertex_generated_chunk_id, prediction FROM\"\n",
        "        f\" `{bigquery_bp_output_uri}` cross join\"\n",
        "        \" unnest(JSON_EXTRACT_ARRAY(predictions)) as prediction) sourceTable\"\n",
        "        \" WHERE\"\n",
        "        \" destTable.vertex_generated_chunk_id=sourceTable.vertex_generated_chunk_id\"\n",
        "    )\n",
        "    return f\"{inseration_query} {fetch_data_query};\"\n",
        "\n",
        "\n",
        "bq_query = compose_bq_query_format_conversion(\n",
        "    bigquery_bp_input_uri=BIGQUERY_BP_INPUT_URI,\n",
        "    bigquery_bp_output_uri=BIGQUERY_BP_OUTPUT_URI,\n",
        ")\n",
        "\n",
        "bq_job = bq_client.query(bq_query)\n",
        "bq_job.result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMdXOJB7EM47"
      },
      "source": [
        "### Initialize Admin Service Client\n",
        "\n",
        "Load the Feature Store SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNJF37XGEOi6"
      },
      "outputs": [],
      "source": [
        "admin_client = FeatureOnlineStoreAdminServiceClient(\n",
        "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43CSdWFTTn-_"
      },
      "source": [
        "### Create Feature Online Store\n",
        "\n",
        "Create a feature online store with embedding management enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoCExlfzfjNE"
      },
      "outputs": [],
      "source": [
        "FEATURE_ONLINE_STORE_ID = \"my_feature_online_store_unique\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4cS3i3zfld6"
      },
      "outputs": [],
      "source": [
        "online_store_config = feature_online_store_pb2.FeatureOnlineStore(\n",
        "    optimized=feature_online_store_pb2.FeatureOnlineStore.Optimized(),\n",
        ")\n",
        "\n",
        "create_store_lro = admin_client.create_feature_online_store(\n",
        "    feature_online_store_admin_service_pb2.CreateFeatureOnlineStoreRequest(\n",
        "        parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}\",\n",
        "        feature_online_store_id=FEATURE_ONLINE_STORE_ID,\n",
        "        feature_online_store=online_store_config,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzExizycIaHH"
      },
      "source": [
        "### Verify online store instance creation\n",
        "\n",
        "After the long-running operation (LRO) is complete, show the result.\n",
        "\n",
        "> **Note:** This operation might take up to 10 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ql5LrIUO0kJ"
      },
      "outputs": [],
      "source": [
        "# Wait for the LRO to finish and get the LRO result.\n",
        "print(create_store_lro.result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldCMH-IOOx-G"
      },
      "source": [
        "#### Verify `FeatureOnlineStore` instance creation by retrieving the online store instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3dZEtXKIqXT"
      },
      "outputs": [],
      "source": [
        "# Use get to verify the store is created.\n",
        "admin_client.get_feature_online_store(\n",
        "    name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vIjCzCwIGMF"
      },
      "source": [
        "#### List all online stores for the location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk8JseF4ICur"
      },
      "outputs": [],
      "source": [
        "# Use list to verify the store is created.\n",
        "admin_client.list_feature_online_stores(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QZnKMo41ud5"
      },
      "source": [
        "### Create feature view instance\n",
        "\n",
        "After creating a `FeatureOnlineStore` instance, you can define the features to serve with it. To do this, create a `FeatureView` instance, which specifies the following:\n",
        "\n",
        "* A data source (BigQuery table or view URI or `FeatureGroup/features`) synced to the `FeatureOnlineStore` instance for serving.\n",
        "* The [cron](https://en.wikipedia.org/wiki/Cron) schedule to run the sync pipeline.\n",
        "\n",
        "During feature view creation, a sync job is scheduled, and either started immediately or following the cron schedule. In the sync job, data is exported, an index is built and deployed to GKE cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9EfVmeu5KBu"
      },
      "outputs": [],
      "source": [
        "FEATURE_VIEW_ID = \"fs_grounding_test_new\"  # @param {type: \"string\"}\n",
        "# A schedule is created based on cron setting.\n",
        "# If cron is unspecified, a sync job is started immediately.\n",
        "CRON_SCHEDULE = \"TZ=America/Los_Angeles 00 13 11 8 *\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VQ4P2om6SNQ"
      },
      "outputs": [],
      "source": [
        "# Index building configs\n",
        "DIMENSIONS = 768  # @param {type: \"number\"}\n",
        "EMBEDDING_COLUMN = \"embedding\"  # @param {type: \"string\"}\n",
        "# Optional\n",
        "LEAF_NODE_EMBEDDING_COUNT = 10000  # @param {type: \"number\"}\n",
        "# Optional\n",
        "# CROWDING_COLUMN = \"cited_by_filing_date\"  # @param {type: \"string\"}\n",
        "# # Optional\n",
        "# FILTER_COLUMNS = [\"country\"]  # @param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWKPVw-wH5cH"
      },
      "outputs": [],
      "source": [
        "DATA_SOURCE = BIGQUERY_BP_INPUT_URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKdSax3N1ypm"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform_v1.types import feature_view as feature_view_pb2\n",
        "\n",
        "big_query_source = feature_view_pb2.FeatureView.BigQuerySource(\n",
        "    uri=DATA_SOURCE, entity_id_columns=[\"vertex_generated_chunk_id\"]\n",
        ")\n",
        "\n",
        "sync_config = feature_view_pb2.FeatureView.SyncConfig(cron=CRON_SCHEDULE)\n",
        "\n",
        "index_config = feature_view_pb2.FeatureView.IndexConfig(\n",
        "    embedding_column=EMBEDDING_COLUMN,\n",
        "    # filter_columns=FILTER_COLUMNS,\n",
        "    # crowding_column=CROWDING_COLUMN,\n",
        "    embedding_dimension=DIMENSIONS,\n",
        "    tree_ah_config=feature_view_pb2.FeatureView.IndexConfig.TreeAHConfig(),\n",
        ")\n",
        "\n",
        "print(f\"index_config: {index_config}\")\n",
        "\n",
        "create_view_lro = admin_client.create_feature_view(\n",
        "    feature_online_store_admin_service_pb2.CreateFeatureViewRequest(\n",
        "        parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}\",\n",
        "        feature_view_id=FEATURE_VIEW_ID,\n",
        "        feature_view=feature_view_pb2.FeatureView(\n",
        "            big_query_source=big_query_source,\n",
        "            sync_config=sync_config,\n",
        "            index_config=index_config,\n",
        "        ),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDhR7WOTOthp"
      },
      "source": [
        " Wait for LRO to complete and show result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV5rT5UKOqzv"
      },
      "outputs": [],
      "source": [
        "print(create_view_lro.result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmYQZroEO7dp"
      },
      "source": [
        "### Verify feature view creation\n",
        "\n",
        "Verify `FeatureView` instance creation by retrieving the feature view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaqTIYuwPFC7"
      },
      "outputs": [],
      "source": [
        "admin_client.get_feature_view(\n",
        "    name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqpu4nHAO4pW"
      },
      "source": [
        "Verify that the `FeatureView` instance is created by listing all the feature views within the online store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_tv0Z3BPHW4"
      },
      "outputs": [],
      "source": [
        "admin_client.list_feature_views(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es8z0YC4zd33"
      },
      "outputs": [],
      "source": [
        "# Optional: Delete feature views to avoid exceeding the deployed index nodes quota.\n",
        "# views = admin_client.list_feature_views(\n",
        "#     parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}\"\n",
        "# )\n",
        "# for view in views:\n",
        "#     admin_client.delete_feature_view(name=view.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZglLt0iuVs0"
      },
      "source": [
        "### Feature view syncs\n",
        "\n",
        "The sync pipeline executes according to the schedule specified in the `FeatureView` instance.\n",
        "\n",
        "To skip the wait and execute the sync pipeline immediately, start the sync manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-j5B6InuNfW"
      },
      "outputs": [],
      "source": [
        "sync_response = admin_client.sync_feature_view(\n",
        "    feature_view=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqyYqYplMUjZ"
      },
      "source": [
        "The `sync_response` contains the ID of the sync job.\n",
        "\n",
        "#### Use `get_feature_view_sync` to check the status of the job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kl8ZBAR2o0b"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "while True:\n",
        "    feature_view_sync = admin_client.get_feature_view_sync(\n",
        "        name=sync_response.feature_view_sync\n",
        "    )\n",
        "    if feature_view_sync.run_time.end_time.seconds > 0:\n",
        "        status = \"Succeed\" if feature_view_sync.final_status.code == 0 else \"Failed\"\n",
        "        print(f\"Sync {status} for {feature_view_sync.name}.\")\n",
        "        # wait a little more for the job to properly shutdown\n",
        "        time.sleep(30)\n",
        "        break\n",
        "    else:\n",
        "        print(\"Sync ongoing, waiting for 30 seconds.\")\n",
        "    time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3XHiHnAIJGj"
      },
      "source": [
        "#### Use `list_feature_view_syncs` to view all your syncs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CU67MyLIOAk"
      },
      "outputs": [],
      "source": [
        "admin_client.list_feature_view_syncs(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUBuFxXBbYOV"
      },
      "source": [
        "### Start online serving\n",
        "\n",
        "After the data sync is complete, use the `FetchFeatureValuesRequest` and `SearchNearestEntities` APIs to retrieve the public endpoint domain name.\n",
        "\n",
        "Get public endpoint domain name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssz79-yvgc1P"
      },
      "outputs": [],
      "source": [
        "# Verify online store creation.\n",
        "featore_online_store_instance = admin_client.get_feature_online_store(\n",
        "    name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}\"\n",
        ")\n",
        "PUBLIC_ENDPOINT = (\n",
        "    featore_online_store_instance.dedicated_serving_endpoint.public_endpoint_domain_name\n",
        ")\n",
        "\n",
        "print(f\"PUBLIC_ENDPOINT for online serving: {PUBLIC_ENDPOINT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpyAVYIkUX0N"
      },
      "source": [
        "#### Initialize the data client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKJKZx36TT8d"
      },
      "outputs": [],
      "source": [
        "# It will take some time for the DNS to be fully ready\n",
        "time.sleep(300)\n",
        "\n",
        "data_client = FeatureOnlineStoreServiceClient(\n",
        "    client_options={\"api_endpoint\": PUBLIC_ENDPOINT}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5gYpORiBW1n"
      },
      "source": [
        "#### Search with `ENTITY_ID`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ae4eR9LyoFn"
      },
      "outputs": [],
      "source": [
        "bq_query = f'SELECT * FROM `{BIGQUERY_BP_INPUT_URI.replace(\"bq://\", \"\")}` LIMIT 1'\n",
        "\n",
        "bq_query_job = bq_client.query(bq_query)\n",
        "result = bq_query_job.result().to_dataframe()\n",
        "\n",
        "print(result)\n",
        "\n",
        "ENTITY_ID = result[\"vertex_generated_chunk_id\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWhrk3pqSU6h"
      },
      "outputs": [],
      "source": [
        "# A vertex_generated_chunk_id for testing\n",
        "data_client.search_nearest_entities(\n",
        "    request=feature_online_store_service_pb2.SearchNearestEntitiesRequest(\n",
        "        feature_view=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\",\n",
        "        query=NearestNeighborQuery(\n",
        "            entity_id=ENTITY_ID,\n",
        "            neighbor_count=5,\n",
        "        ),\n",
        "        return_full_entity=True,  # returning entities with metadata\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQEpt08GBX-b"
      },
      "source": [
        "#### Search with `Embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWcOT26krxuj"
      },
      "outputs": [],
      "source": [
        "EMBEDDINGS = [1] * DIMENSIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3DZl0xRAusK"
      },
      "outputs": [],
      "source": [
        "data_client.search_nearest_entities(\n",
        "    request=feature_online_store_service_pb2.SearchNearestEntitiesRequest(\n",
        "        feature_view=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\",\n",
        "        query=NearestNeighborQuery(\n",
        "            embedding=NearestNeighborQuery.Embedding(value=EMBEDDINGS),\n",
        "            neighbor_count=10,\n",
        "        ),\n",
        "        return_full_entity=True,  # returning entities with metadata\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKALOxbsZfce"
      },
      "source": [
        "#### Use the `FetchFeatureValues` API to retrieve the full data without search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7op0efLdDFs"
      },
      "outputs": [],
      "source": [
        "data_client.fetch_feature_values(\n",
        "    request=feature_online_store_service_pb2.FetchFeatureValuesRequest(\n",
        "        feature_view=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\",\n",
        "        data_key=feature_online_store_service_pb2.FeatureViewDataKey(key=ENTITY_ID),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR1ve2OyyiKq"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, delete the individual resources you created in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um27J_vvvzGc"
      },
      "outputs": [],
      "source": [
        "# Delete Feature View\n",
        "admin_client.delete_feature_view(\n",
        "    name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\"\n",
        ")\n",
        "\n",
        "# Delete Feature Online Store\n",
        "admin_client.delete_feature_online_store(\n",
        "    name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}\",\n",
        "    force=True,\n",
        ")\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "delete_bucket = True\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $GCS_BUCKET"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vertex_ai_feature_store_based_llm_grounding_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
