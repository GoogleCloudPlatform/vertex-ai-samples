{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Train and deploy PyTorch models with prebuilt containers on Vertex AI\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/pytorch_train_deploy_models_with_prebuilt_containers.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/pytorch_train_deploy_models_with_prebuilt_containers.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/prediction/pytorch_train_deploy_models_with_prebuilt_containers.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Vertex AI provides Docker container images that you run as prebuilt containers for custom training and prediction. These containers, which are organized by machine learning (ML) framework and framework version, include common dependencies that you might want to use in training code and serving predictions. Using pre-built containers is generally simpler than creating your own custom containers.\n",
        "\n",
        "This tutorial demonstrates how to train and deploy a PyTorch image model with prebuilt containers on Vertex AI.\n",
        "\n",
        "- Learn more about [Prebuilt containers for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
        "- Learn more about [Prebuilt containers for prediction and explanation](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to build, train and deploy a PyTorch image classification model using prebuilt containers for custom training and prediction.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- `Vertex AI Training` service\n",
        "- `Vertex AI Prediction` service\n",
        "- `Vertex AI Model Registry`\n",
        "- `Vertex AI Model` resources\n",
        "- `Vertex AI Endpoint` resources\n",
        "\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Package training application into a Python source distribution\n",
        "- Configure and run training job in a prebuilt container\n",
        "- Package model artifacts in a model archive file\n",
        "- Upload model for deployment\n",
        "- Deploy model using a prebuilt container for prediction\n",
        "- Make online predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset/Model\n",
        "\n",
        "In this tutorial, you use the [MNIST](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) handwritten digit recognition dataset from PyTorch torchvision dataset. You train a simple Convolutional Neural Network on the MNIST dataset to identify handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
        "                                 torch \\\n",
        "                                 torchvision \\\n",
        "                                 torch-model-archiver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"vertex-training-356201\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gkaCh23Pg2h8"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6b2ccc891ed"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://edong-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating gs://edong-bucket-name-vertex-training-356201-unique/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'edong-bucket-name-vertex-training-356201-unique' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4KyAr2MHg2h9"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99DcIE4H54HA"
      },
      "source": [
        "## Train a PyTorch model with a prebuilt container\n",
        "\n",
        "To train a PyTorch model using your custom training code, choose one of the following options:\n",
        "\n",
        "- **Prebuilt container**: Load your custom training code as a Python package to a prebuilt container image from Vertex AI.\n",
        "\n",
        "- **Custom container**: Create your own container image that contains your custom training code.\n",
        "\n",
        "In this tutorial, you train a custom model using a prebuilt container for PyTorch models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOSGkpmJ6r7v"
      },
      "source": [
        "### Package a training application\n",
        "\n",
        "#### Package layout\n",
        "\n",
        "Before you start the training, let's take a look at how a Python package is assembled for a custom training job. When extracted, the package contains the following:\n",
        "\n",
        "- PKG-INFO\n",
        "- README.md\n",
        "- setup.cfg\n",
        "- setup.py\n",
        "- trainer\n",
        "  - \\_\\_init\\_\\_.py\n",
        "  - task.py\n",
        "\n",
        "The files `setup.cfg` and `setup.py` are the instructions for installing the package into the operating environment of the Docker image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KIWLwZe3q1uu"
      },
      "outputs": [],
      "source": [
        "APP_NAME = \"pytorch-101-trainer\"\n",
        "PYTHON_PACKAGE_APPLICATION_DIR = \"python_package\"\n",
        "\n",
        "source_package_file_name = (\n",
        "    f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/{APP_NAME}-0.1.tar.gz\"\n",
        ")\n",
        "python_package_gcs_uri = f\"{BUCKET_URI}/pytorch/training/{APP_NAME}-0.1.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KRy-N9edq2OM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘python_package’: File exists\n",
            "mkdir: cannot create directory ‘python_package/trainer’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir {PYTHON_PACKAGE_APPLICATION_DIR}\n",
        "! mkdir {PYTHON_PACKAGE_APPLICATION_DIR}/trainer\n",
        "\n",
        "! touch {PYTHON_PACKAGE_APPLICATION_DIR}/README.md\n",
        "! touch {PYTHON_PACKAGE_APPLICATION_DIR}/trainer/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1fi56Stvq2SG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./python_package/setup.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/setup.py\n",
        "\n",
        "import os\n",
        "from setuptools import find_packages\n",
        "from setuptools import setup\n",
        "import setuptools\n",
        "\n",
        "from distutils.command.build import build as _build\n",
        "import subprocess\n",
        "\n",
        "\n",
        "REQUIRED_PACKAGES = [\n",
        "]\n",
        "\n",
        "setup(\n",
        "    name='pytorch-101-trainer',\n",
        "    version='0.1',\n",
        "    install_requires=REQUIRED_PACKAGES,\n",
        "    packages=find_packages(),\n",
        "    include_package_data=True,\n",
        "    description='Vertex AI | Training | PyTorch | Image Classification | Python Package'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVz8V3b57R0M"
      },
      "source": [
        "#### Prepare the training script\n",
        "\n",
        "The file `trainer/task.py` is the Python script for executing the custom training job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cVgqlhM9q2Vo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./python_package/trainer/task.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/trainer/task.py\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "def load_data(batch_size):\n",
        "  # Download training data from open datasets\n",
        "  training_data = datasets.MNIST(\n",
        "      root=\"data\",\n",
        "      train=True,\n",
        "      download=True,\n",
        "      transform=ToTensor(),\n",
        "  )\n",
        "\n",
        "  # Download test data from open datasets\n",
        "  test_data = datasets.MNIST(\n",
        "      root=\"data\",\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=ToTensor(),\n",
        "  )\n",
        "\n",
        "  # Create data loaders\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "  test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader, test_dataloader\n",
        "\n",
        "def create_model(device):\n",
        "  # Define model\n",
        "  class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "  model = NeuralNetwork().to(device)\n",
        "\n",
        "  return model\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "\n",
        "def main():\n",
        "  parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "  parser.add_argument(\"--epochs\", type=int, help=\"Number of training epochs.\", default=2)\n",
        "  parser.add_argument(\"--batch_size\", type=int, help=\"Training batch size for one process.\", default=32)\n",
        "  parser.add_argument(\"--model_dir\", type=str, help=\"Directory for saving models.\", default=os.environ['AIP_MODEL_DIR'] if 'AIP_MODEL_DIR' in os.environ else \"\")\n",
        "  argv = parser.parse_args()\n",
        "\n",
        "  train_dataloader, test_dataloader = load_data(argv.batch_size)\n",
        "\n",
        "  # Get cpu or gpu device for training\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "  print(f\"Using {device} device\")\n",
        "\n",
        "  model = create_model(device)\n",
        "\n",
        "  # Define a loss function and an optimizer.\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "  for t in range(argv.epochs):\n",
        "      print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "      train(train_dataloader, model, loss_fn, optimizer, device)\n",
        "      test(test_dataloader, model, loss_fn, device)\n",
        "  print(\"Done!\")\n",
        "\n",
        "  # Export the model to TorchScript\n",
        "  model_filename = \"pytorch-mnist.pt\"\n",
        "  local_path = os.path.join(\"/tmp\", model_filename)\n",
        "  model_scripted = torch.jit.script(model)\n",
        "  model_scripted.save(local_path)\n",
        "\n",
        "  if (os.path.exists(local_path)):\n",
        "    # Upload the trained model to Cloud storage\n",
        "    storage_path = os.path.join(argv.model_dir, model_filename)\n",
        "    blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
        "    blob.upload_from_filename(local_path)\n",
        "    print(f\"Saved model files in {argv.model_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WRTlkEw7ugt"
      },
      "source": [
        "#### Create a Python source distribution\n",
        "\n",
        "You create a Python source distribution with your training application and upload the source distribution to your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WUS6ap2W1JeI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running sdist\n",
            "running egg_info\n",
            "writing pytorch_101_trainer.egg-info/PKG-INFO\n",
            "writing dependency_links to pytorch_101_trainer.egg-info/dependency_links.txt\n",
            "writing top-level names to pytorch_101_trainer.egg-info/top_level.txt\n",
            "reading manifest file 'pytorch_101_trainer.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pytorch_101_trainer.egg-info/SOURCES.txt'\n",
            "running check\n",
            "creating pytorch-101-trainer-0.1\n",
            "creating pytorch-101-trainer-0.1/pytorch_101_trainer.egg-info\n",
            "creating pytorch-101-trainer-0.1/trainer\n",
            "copying files to pytorch-101-trainer-0.1...\n",
            "copying README.md -> pytorch-101-trainer-0.1\n",
            "copying setup.py -> pytorch-101-trainer-0.1\n",
            "copying pytorch_101_trainer.egg-info/PKG-INFO -> pytorch-101-trainer-0.1/pytorch_101_trainer.egg-info\n",
            "copying pytorch_101_trainer.egg-info/SOURCES.txt -> pytorch-101-trainer-0.1/pytorch_101_trainer.egg-info\n",
            "copying pytorch_101_trainer.egg-info/dependency_links.txt -> pytorch-101-trainer-0.1/pytorch_101_trainer.egg-info\n",
            "copying pytorch_101_trainer.egg-info/top_level.txt -> pytorch-101-trainer-0.1/pytorch_101_trainer.egg-info\n",
            "copying trainer/__init__.py -> pytorch-101-trainer-0.1/trainer\n",
            "copying trainer/task.py -> pytorch-101-trainer-0.1/trainer\n",
            "Writing pytorch-101-trainer-0.1/setup.cfg\n",
            "Creating tar archive\n",
            "removing 'pytorch-101-trainer-0.1' (and everything under it)\n",
            "Copying file://python_package/dist/pytorch-101-trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
            "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
            "Operation completed over 1 objects/2.3 KiB.                                      \n",
            "Python source distribution package location: gs://edong-bucket-name-vertex-training-356201-unique/pytorch/training/pytorch-101-trainer-0.1.tar.gz\n"
          ]
        }
      ],
      "source": [
        "! cd {PYTHON_PACKAGE_APPLICATION_DIR} && python3 setup.py sdist --formats=gztar\n",
        "\n",
        "! gsutil cp {source_package_file_name} {python_package_gcs_uri}\n",
        "\n",
        "print(f\"Python source distribution package location: {python_package_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOyihOMh8Q3B"
      },
      "source": [
        "### Configure custom training job\n",
        "\n",
        "Configure a [custom job](https://cloud.google.com/vertex-ai/docs/training/create-custom-job) with the [prebuilt container](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) image for training code packaged as Python source distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x6ehn8V_1Prx"
      },
      "outputs": [],
      "source": [
        "JOB_DISPLAY_NAME = \"pytorch-custom-job\"\n",
        "python_module_name = \"trainer.task\"\n",
        "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI = (\n",
        "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-13:latest\"\n",
        ")\n",
        "\n",
        "job = aiplatform.CustomPythonPackageTrainingJob(\n",
        "    display_name=JOB_DISPLAY_NAME,\n",
        "    python_package_gcs_uri=python_package_gcs_uri,\n",
        "    python_module_name=python_module_name,\n",
        "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un0gwmrv80Ya"
      },
      "source": [
        "### Run custom training job\n",
        "\n",
        "Next, you run the custom job to start the training job by invoking the method `run`.\n",
        "\n",
        "**NOTE:** When using Vertex AI SDK for Python for submitting a training job, it creates a [training pipeline](https://cloud.google.com/vertex-ai/docs/training/create-training-pipeline) which launches the custom job on `Vertex AI Training` service.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VXdr0et51h-H"
      },
      "outputs": [],
      "source": [
        "MACHINE_TYPE = \"n1-standard-4\"\n",
        "ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
        "ACCELERATOR_COUNT = 1\n",
        "\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 32\n",
        "MODEL_DIR = f\"{BUCKET_URI}/{JOB_DISPLAY_NAME}\"\n",
        "\n",
        "training_args = [\n",
        "    \"--epochs\",\n",
        "    str(EPOCHS),\n",
        "    \"--batch_size\",\n",
        "    str(BATCH_SIZE),\n",
        "    \"--model_dir\",\n",
        "    MODEL_DIR,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vl4cDy9r1nnX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Output directory:\n",
            "gs://edong-bucket-name-vertex-training-356201-unique/pytorch-custom-job \n",
            "View Training:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2260748051628949504?project=818359284681\n",
            "CustomPythonPackageTrainingJob projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "View backing custom job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7367099953346248704?project=818359284681\n",
            "CustomPythonPackageTrainingJob projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomPythonPackageTrainingJob projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomPythonPackageTrainingJob projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomPythonPackageTrainingJob projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomPythonPackageTrainingJob projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomPythonPackageTrainingJob run completed. Resource name: projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504\n",
            "Training did not produce a Managed Model returning None. Training Pipeline projects/818359284681/locations/us-central1/trainingPipelines/2260748051628949504 is not configured to upload a Model. Create the Training Pipeline with model_serving_container_image_uri and model_display_name passed in. Ensure that your training script saves to model to os.environ['AIP_MODEL_DIR'].\n"
          ]
        }
      ],
      "source": [
        "model = job.run(\n",
        "    machine_type=MACHINE_TYPE,\n",
        "    accelerator_type=ACCELERATOR_TYPE,\n",
        "    accelerator_count=ACCELERATOR_COUNT,\n",
        "    base_output_dir=MODEL_DIR,\n",
        "    replica_count=1,\n",
        "    args=training_args,\n",
        "    sync=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abjl3sgM-sOt"
      },
      "source": [
        "#### Check model artifacts\n",
        "\n",
        "When the custom training job has completed, you check the model artifacts in the Cloud Storage location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ch36B6ju16z9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model artifacts are available at gs://edong-bucket-name-vertex-training-356201-unique/pytorch-custom-job\n",
            "   2690128  2023-04-13T16:37:18Z  gs://edong-bucket-name-vertex-training-356201-unique/pytorch-custom-job/pytorch-mnist.pt\n",
            "TOTAL: 1 objects, 2690128 bytes (2.57 MiB)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model artifacts are available at {MODEL_DIR}\")\n",
        "! gsutil ls -l {MODEL_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATeuG5I12BO9"
      },
      "source": [
        "## Deploy the PyTorch model to a prebuilt container for prediction\n",
        "\n",
        "\n",
        "You create a local directory and copy the model artifacts from the Cloud Storage to this local directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "awSZOd1i2EtZ"
      },
      "outputs": [],
      "source": [
        "# Create a local directory for model artifacts\n",
        "model_path = \"model\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    ! mkdir {model_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9raKhhpt3epG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://edong-bucket-name-vertex-training-356201-unique/pytorch-custom-job/pytorch-mnist.pt...\n",
            "/ [1 files][  2.6 MiB/  2.6 MiB]                                                \n",
            "Operation completed over 1 objects/2.6 MiB.                                      \n"
          ]
        }
      ],
      "source": [
        "model_name = \"pytorch-mnist.pt\"\n",
        "model_file = f\"{model_path}/{model_name}\"\n",
        "\n",
        "! gsutil cp {MODEL_DIR}/{model_name} {model_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6W-18UUCBMn"
      },
      "source": [
        "#### Create a custom model handler\n",
        "\n",
        "A custom model handler is a Python script that you package with the model when you use the model archiver. The script typically defines how to pre-process input data, invoke the model and post-process the output. TorchServe has [default handlers](https://pytorch.org/serve/default_handlers.html) for `image_classifier`, `image_segmenter`, `object_detector` and `text_classifier`. In this tutorial, you create a custom handler extending the default [`image_classifier`](https://github.com/pytorch/serve/blob/master/ts/torch_handler/image_classifier.py) handler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nW67E74lCDwA"
      },
      "outputs": [],
      "source": [
        "hander_file = f\"{model_path}/custom_handler.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YYUOBdvq3Z8G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting model/custom_handler.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {hander_file}\n",
        "\n",
        "from torchvision import transforms\n",
        "from ts.torch_handler.image_classifier import ImageClassifier\n",
        "from torch.profiler import ProfilerActivity\n",
        "\n",
        "\n",
        "class MNISTDigitClassifier(ImageClassifier):\n",
        "    \"\"\"\n",
        "    MNISTDigitClassifier handler class. This handler extends class ImageClassifier from image_classifier.py, a\n",
        "    default handler. This handler takes an image and returns the number in that image.\n",
        "    Here method postprocess() has been overridden while others are reused from parent class.\n",
        "    \"\"\"\n",
        "\n",
        "    image_processing = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MNISTDigitClassifier, self).__init__()\n",
        "        self.profiler_args = {\n",
        "            \"activities\" : [ProfilerActivity.CPU],\n",
        "            \"record_shapes\": True,\n",
        "        }\n",
        "\n",
        "\n",
        "    def postprocess(self, data):\n",
        "        \"\"\"The post process of MNIST converts the predicted output response to a label.\n",
        "        Args:\n",
        "            data (list): The predicted output from the Inference with probabilities is passed\n",
        "            to the post-process function\n",
        "        Returns:\n",
        "            list : A list of dictionaries with predictions and explanations is returned\n",
        "        \"\"\"\n",
        "        return data.argmax(1).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY-yZ9xzCSSe"
      },
      "source": [
        "#### Package the model artifacts in a model archive file\n",
        "\n",
        "You package all the model artifacts in a model archive file using the [`Torch model archiver`](https://github.com/pytorch/serve/tree/master/model-archiver).\n",
        "\n",
        "Note that the prebuilt PyTorch serving containers require the model archive file named as `model.mar` so you need to set the model-name as `model` in the `torch-model-archiver` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gMuQRwOB2oa3"
      },
      "outputs": [],
      "source": [
        "# Add torch-model-archiver to the PATH\n",
        "os.environ[\"PATH\"] = f'{os.environ.get(\"PATH\")}:~/.local/bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "t1mhQeX43jMP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING - Overwriting model/model.mar ...\n"
          ]
        }
      ],
      "source": [
        "! torch-model-archiver -f \\\n",
        "  --model-name model \\\n",
        "  --version 1.0  \\\n",
        "  --serialized-file $model_file \\\n",
        "  --handler $hander_file \\\n",
        "  --export-path $model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyx95vSPDJ3C"
      },
      "source": [
        "#### Copy the model artifacts to Cloud Storage\n",
        "\n",
        "Next, use `gsutil` to copy the model artifacts to your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "i9ltOguF322J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing gs://edong-bucket-name-vertex-training-356201-unique/model/custom_handler.py#1681401153459307...\n",
            "Removing gs://edong-bucket-name-vertex-training-356201-unique/model/model.mar#1681401153658658...\n",
            "Removing gs://edong-bucket-name-vertex-training-356201-unique/model/pytorch-mnist.pt#1681401153905710...\n",
            "/ [3 objects]                                                                   \n",
            "Operation completed over 3 objects.                                              \n",
            "Copying file://model/custom_handler.py [Content-Type=text/x-python]...\n",
            "Copying file://model/model.mar [Content-Type=application/octet-stream]...       \n",
            "Copying file://model/pytorch-mnist.pt [Content-Type=application/octet-stream]...\n",
            "/ [3 files][  4.9 MiB/  4.9 MiB]                                                \n",
            "Operation completed over 3 objects/4.9 MiB.                                      \n",
            "gs://edong-bucket-name-vertex-training-356201-unique/model/custom_handler.py\n",
            "gs://edong-bucket-name-vertex-training-356201-unique/model/model.mar\n",
            "gs://edong-bucket-name-vertex-training-356201-unique/model/pytorch-mnist.pt\n"
          ]
        }
      ],
      "source": [
        "MODEL_URI = f\"{BUCKET_URI}/model\"\n",
        "\n",
        "! gsutil rm -r $MODEL_URI\n",
        "! gsutil cp -r $model_path $MODEL_URI\n",
        "! gsutil ls $MODEL_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi3I6JotDw3k"
      },
      "source": [
        "### Upload model for deployment\n",
        "\n",
        "Next, you upload the model artifacts to `Vertex AI Model Registry`, which will create a `Vertex AI Model` resource for your model. This tutorial uses the PyTorch v1.11 container, but for your own use case, you can choose from the list of [PyTorch prebuilt containers](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9kyOITop38H7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Model\n",
            "Create Model backing LRO: projects/818359284681/locations/us-central1/models/436437946506149888/operations/6661505339931754496\n",
            "Model created. Resource name: projects/818359284681/locations/us-central1/models/436437946506149888@1\n",
            "To use this Model in another session:\n",
            "model = aiplatform.Model('projects/818359284681/locations/us-central1/models/436437946506149888@1')\n"
          ]
        }
      ],
      "source": [
        "DEPLOY_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.1-11:latest\"\n",
        "\n",
        "uploaded_model = aiplatform.Model.upload(\n",
        "    display_name=model_name,\n",
        "    serving_container_image_uri=DEPLOY_IMAGE_URI,\n",
        "    artifact_uri=MODEL_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko3IfZgbEG1J"
      },
      "source": [
        "### Deploy model for prediction\n",
        "\n",
        "Next, deploy your model for online prediction. You set the variable `DEPLOY_COMPUTE` to configure the machine type for the [compute resources](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute) you will use for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MSukFOf04IMv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Endpoint\n",
            "Create Endpoint backing LRO: projects/818359284681/locations/us-central1/endpoints/4324911395670851584/operations/5997787344848027648\n",
            "Endpoint created. Resource name: projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n",
            "To use this Endpoint in another session:\n",
            "endpoint = aiplatform.Endpoint('projects/818359284681/locations/us-central1/endpoints/4324911395670851584')\n",
            "Deploying model to Endpoint : projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n",
            "Deploy Endpoint model backing LRO: projects/818359284681/locations/us-central1/endpoints/4324911395670851584/operations/4355662330718060544\n",
            "Endpoint model deployed. Resource name: projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n"
          ]
        }
      ],
      "source": [
        "DEPLOY_COMPUTE = \"n1-standard-4\"\n",
        "\n",
        "endpoint = uploaded_model.deploy(\n",
        "    deployed_model_display_name=model_name,\n",
        "    machine_type=DEPLOY_COMPUTE,\n",
        "    accelerator_type=None,\n",
        "    accelerator_count=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzHtXzv0E2sg"
      },
      "source": [
        "## Make online predictions\n",
        "\n",
        "You use the MNIST dataset for the input for online predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kdRjvCOX4hVn"
      },
      "outputs": [],
      "source": [
        "# Download test data from PyTorch torchvision dataset\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fDWLHAuPWo_7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Take one image as example for prediction\n",
        "image, _ = test_data[0]\n",
        "pil_image = transforms.ToPILImage()(image)\n",
        "plt.imshow(pil_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOV_iS-jFcTK"
      },
      "source": [
        "### Get online predictions\n",
        "\n",
        "You send a `predict` request with encoded input image data to the `endpoint` and get prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kPqDTh184fM0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7.0]\n"
          ]
        }
      ],
      "source": [
        "buffered_image = io.BytesIO()\n",
        "pil_image.save(buffered_image, format=\"JPEG\")\n",
        "\n",
        "data = {\"data\": base64.b64encode(buffered_image.getvalue()).decode(\"utf-8\")}\n",
        "prediction = endpoint.predict(instances=[data])\n",
        "\n",
        "print(prediction.predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_pV0fq5FxgE"
      },
      "source": [
        "### Make batch predictions (optional)\n",
        "\n",
        "Learn more about [making batch predictions](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/pytorch_image_classification_with_prebuilt_serving_containers.ipynb) from your PyTorch model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Undeploying Endpoint model: projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n",
            "Undeploy Endpoint model backing LRO: projects/818359284681/locations/us-central1/endpoints/4324911395670851584/operations/8120671619199795200\n",
            "Endpoint model undeployed. Resource name: projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n",
            "Deleting Endpoint : projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n",
            "Delete Endpoint  backing LRO: projects/818359284681/locations/us-central1/operations/7992319029819736064\n",
            "Endpoint deleted. . Resource name: projects/818359284681/locations/us-central1/endpoints/4324911395670851584\n",
            "Deleting Model : projects/818359284681/locations/us-central1/models/436437946506149888\n",
            "Delete Model  backing LRO: projects/818359284681/locations/us-central1/operations/6458843356700082176\n",
            "Model deleted. . Resource name: projects/818359284681/locations/us-central1/models/436437946506149888\n"
          ]
        }
      ],
      "source": [
        "# Delete the deployment endpoint\n",
        "endpoint.undeploy_all()\n",
        "endpoint.delete()\n",
        "\n",
        "# Delete the model from Model Registry\n",
        "uploaded_model.delete()\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "delete_bucket = False\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch_train_deploy_models_with_prebuilt_containers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
