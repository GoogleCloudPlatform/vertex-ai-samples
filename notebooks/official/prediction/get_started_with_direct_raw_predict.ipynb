{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Get Started with Direct Raw Predict\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/get_started_with_direct_raw_predict.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fprediction%2Fget_started_with_direct_raw_predict.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/prediction/get_started_with_direct_raw_predict.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/get_started_with_direct_raw_predict.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use `Vertex AI Direct Raw Prediction` and `Vertex AI Streaming Direct Raw Prediction` to send gRPC content to a model deployed to a `Vertex AI Endpoint`.\n",
        "\n",
        "Learn more about [Direct Predict(https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/directPredict).\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to use `Vertex AI Direct Raw Prediction` and `Vertex AI Streaming Direct Raw Prediction` on a `Vertex AI Endpoint` resource.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "* `Vertex AI Direct Raw Prediction`\n",
        "* `Vertex AI Streaming Direct Raw Prediction`\n",
        "* `Vertex AI Models`\n",
        "* `Vertex AI Endpoints`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Create a `Vertex AI Model` resource that supports Direct Raw Prediction and Stream Direct Raw Predict.\n",
        "* Create an `Endpoint` resource.\n",
        "* Deploy the `Model` resource to an `Endpoint` resource.\n",
        "* Make an online direct prediction to the `Model` resource instance deployed to the `Endpoint` resource.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage Pricing](https://cloud.google.com/storage/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/?hl=en) to generate a cost entimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ab1905236c3"
      },
      "source": [
        "## Upload a `Vertex AI Model`\n",
        "Upload the model artifacts.\n",
        "\n",
        "Note: When you upload the model artifacts to a Vertex AI Model resource, you specify the corresponding deployment container image.\n",
        "\n",
        "Note: For more details about construction of model artifacts and container images, look at [this colab](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/get_started_with_raw_predict.ipynb) or others within this repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dbb252163137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Model\n",
            "Create Model backing LRO: projects/885162849955/locations/us-central1/models/4190926008221696000/operations/214007603200524288\n",
            "Model created. Resource name: projects/885162849955/locations/us-central1/models/4190926008221696000@1\n",
            "To use this Model in another session:\n",
            "model = aiplatform.Model('projects/885162849955/locations/us-central1/models/4190926008221696000@1')\n"
          ]
        }
      ],
      "source": [
        "ARTIFACT_URI = \"gs://grpc-predict-data\"  # param {type:\"string\"}\n",
        "SERVING_CONTAINER_IMAGE_URI = (\n",
        "    \"us-docker.pkg.dev/mmoynihan-test/test/grpc-test:latest\"  # param {type:\"string'}\n",
        ")\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=\"My grpc test model for Direct Raw Predict and Stream Direct Raw Predict.\",\n",
        "    artifact_uri=ARTIFACT_URI,\n",
        "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
        "    serving_container_grpc_ports=[8081],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89be3f591624"
      },
      "source": [
        "## Creating an `Endpoint` resource\n",
        "\n",
        "You create an `Endpoint` resource using the `Endpoint.create()` method. At a minimum, you specify the display name for the endpoint. Optionally, you can specify the `project` and `location`; otherwise the settings are inherited by the values you set when you initialized the Vertex AI SDK with the `init()` method.\n",
        "\n",
        "In this example, the following parameters are specified:\n",
        "\n",
        "* `display_name`: A human readable name for the `Endpoint` resource.\n",
        "* `project`: Your project ID.\n",
        "* `location`: Your location.\n",
        "* `labels`: (optional) User defined metadata for the `Endpoint` in the form of key/value pairs.\n",
        "\n",
        "This method returns an `Endpoint` object.\n",
        "\n",
        "Learn more about [Vertex AI Endpoints](https://cloud.google.com/vertex-ai/docs/predictions/overview#model_deployment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9bd14d566160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Endpoint\n",
            "Create Endpoint backing LRO: projects/885162849955/locations/us-central1/endpoints/1427269446946258944/operations/9173145005668171776\n",
            "Endpoint created. Resource name: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "To use this Endpoint in another session:\n",
            "endpoint = aiplatform.Endpoint('projects/885162849955/locations/us-central1/endpoints/1427269446946258944')\n",
            "<google.cloud.aiplatform.models.Endpoint object at 0x7ff9b1298fd0> \n",
            "resource name: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n"
          ]
        }
      ],
      "source": [
        "endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=\"grpc direct predict example\",\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    labels={\"your_key\": \"your_value\"},\n",
        ")\n",
        "\n",
        "print(endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62cb852cb086"
      },
      "source": [
        "## Deploying `Model` resources to an `Endpoint` resource.\n",
        "\n",
        "You can deploy one of more `Vertex AI Model` resource instances to the same endpoint. Each `Vertex AI Model` resource that is deployed will have its own deployment container for the serving binary.\n",
        "\n",
        "In the next example, you deploy the `Vertex AI Model` resource to a `Vertex AI Endpoint` resource. The `Vertex AI Model` resource already has defined the deployment container image. To deploy, you specify the following additional configuration settings:\n",
        "\n",
        "* The machine type.\n",
        "* The (if any) type and number of GPUs.\n",
        "* Static, manual or auto-scaling of VM instances.\n",
        "\n",
        "In this example, you deploy the model with the minimal amount of specified parameters, as follows:\n",
        "\n",
        "* `model`: The `Model` resource.\n",
        "* `deployed_model_displayed_name`: The human readable name for the deployed model instance.\n",
        "* `machine_type`: The machine type for each VM instance.\n",
        "\n",
        "Do to the requirements to provision the resource, this may take upto a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1f7f87f71237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deploying Model projects/885162849955/locations/us-central1/models/4190926008221696000 to Endpoint : projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "Deploy Endpoint model backing LRO: projects/885162849955/locations/us-central1/endpoints/1427269446946258944/operations/2262371377468145664\n",
            "Endpoint model deployed. Resource name: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n"
          ]
        }
      ],
      "source": [
        "MACHINE_TYPE = \"n1-standard\"\n",
        "\n",
        "VCPU = \"4\"\n",
        "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
        "\n",
        "endpoint.deploy(\n",
        "    model=model,\n",
        "    deployed_model_display_name=\"example\",\n",
        "    machine_type=DEPLOY_COMPUTE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb1a7dba3e3"
      },
      "source": [
        "## Make prediction instances\n",
        "\n",
        "Next, you prepare a prediction request using a synthetic example.\n",
        "\n",
        "For this model format, you use the `direct_raw_predict()` sdk method to pass raw bytes directly to your container in the `request` field. Since your custom container can expose any gRPC method name, you must specify `method_name` in addition to `request`.\n",
        "\n",
        "If you use the `stream_direct_raw_predict()` sdk method, you can pass in any number of requests in `requests` and stream the results as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bbeaef941acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Direct Predict Result:  b'\\n\\x04test'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n",
            "Stream Direct Predict Subresult:  b'\\n\\x05test0'\n"
          ]
        }
      ],
      "source": [
        "result = endpoint.direct_raw_predict(\n",
        "    method_name=\"/cloud.ml.tests.tools.tools.prediction_test_server.TestPredictionService/Predict\",\n",
        "    # Serialized proto message converted to base64.\n",
        "    request=\"CgR0ZXN0EAE=\",\n",
        ")\n",
        "print(\"Direct Predict Result: \", result.predictions)\n",
        "\n",
        "for subresult in endpoint.stream_direct_raw_predict(\n",
        "    method_name=\"/cloud.ml.tests.tools.tools.prediction_test_server.TestPredictionService/StreamingPredict\",\n",
        "    # Serialized proto message converted to base64.\n",
        "    requests=[\"CgV0ZXN0MBAB\"] * 10,\n",
        "):\n",
        "    print(\"Stream Direct Predict Subresult: \", subresult.predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e000fc0a9499"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3ba845adade3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Undeploying Endpoint model: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "Undeploy Endpoint model backing LRO: projects/885162849955/locations/us-central1/endpoints/1427269446946258944/operations/4591506441004646400\n",
            "Endpoint model undeployed. Resource name: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "Deleting Endpoint : projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "Endpoint deleted. . Resource name: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "Deleting Endpoint resource: projects/885162849955/locations/us-central1/endpoints/1427269446946258944\n",
            "Delete Endpoint backing LRO: projects/885162849955/locations/us-central1/operations/9203192459432034304\n",
            "Endpoint resource projects/885162849955/locations/us-central1/endpoints/1427269446946258944 deleted.\n",
            "Deleting Model : projects/885162849955/locations/us-central1/models/4190926008221696000\n",
            "Model deleted. . Resource name: projects/885162849955/locations/us-central1/models/4190926008221696000\n",
            "Deleting Model resource: projects/885162849955/locations/us-central1/models/4190926008221696000\n",
            "Delete Model backing LRO: projects/885162849955/locations/us-central1/models/4190926008221696000/operations/2919545079343349760\n",
            "Model resource projects/885162849955/locations/us-central1/models/4190926008221696000 deleted.\n"
          ]
        }
      ],
      "source": [
        "endpoint.undeploy_all()\n",
        "endpoint.delete()\n",
        "model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "get_started_with_direct_raw_predict.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
