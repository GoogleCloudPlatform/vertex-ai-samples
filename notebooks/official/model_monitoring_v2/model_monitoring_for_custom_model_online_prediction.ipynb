{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QgSVkLcRUOD"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndfGn8c4bI_G"
      },
      "source": [
        "# Model Monitoring for Vertex AI Custom Model Online Prediction\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring_v2/model_monitoring_for_custom_model_online_prediction.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2model_monitoring_v2%2model_monitoring_for_custom_model_online_prediction.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring_v2/model_monitoring_for_custom_model_online_prediction.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring_v2/model_monitoring_for_custom_model_online_prediction.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1owVk_lTGqE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to use the Vertex AI SDK for Python to set up Vertex AI Model Monitoring V2 for your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FokOJ8IHTJEJ"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you'll complete the following steps:\n",
        "\n",
        "- Upload a custom model to Vertex AI Model Registry.\n",
        "- Deploy the model to Vertex AI Endpoint with Request-Response Logging enabled.\n",
        "- Generate some online prediction traffic.\n",
        "- Create a model monitor.\n",
        "- Run an on-demand model monitoring job to analyze data drift between the Online prediction traffic and the training dataset.\n",
        "- Run an on-demand model monitoring job to analyze feature attribution drift between the Online prediction traffic and a GCS baseline dataset.\n",
        "- Create a schedule to continuously run model monitoring jobs to analyze data drift between the Online prediction traffic and the training dataset.\n",
        "\n",
        "\n",
        "### Costs\n",
        "\n",
        "Vertex AI Model Monitoring v2 is free during the public preview period, but you will still be billed for the following Google Cloud services:\n",
        "\n",
        "* [BigQuery](https://cloud.google.com/bigquery/pricing)\n",
        "* [Cloud Storage](https://cloud.google.com/storage/pricing)\n",
        "* [Vertex AI Online Prediction](https://cloud.google.com/vertex-ai/pricing#prediction-prices)\n",
        "* [Vertex AI Batch Explanation Job](https://cloud.google.com/vertex-ai/pricing#prediction-prices) (if you run the feature attribution drift example)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eUWh8W2654v"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nisFtSUFT29-"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrZ6qs-h68mf"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet \\\n",
        "    google-cloud-bigquery \\\n",
        "    pandas \\\n",
        "    pandas_gbq \\\n",
        "    pyarrow \\\n",
        "    tensorflow_data_validation[visualization] \\\n",
        "    google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8ol0OhLT8SQ"
      },
      "source": [
        "Check that the version of google-cloud-aiplatform is 1.51.0 or later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0seyjP7sT95U"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZLfsvsf7FV9"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDQUWZ7E7Fx3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH7RQ-Q8UDII"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgkRNiLHUExQ"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMn32IkDUGRn"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63oA1v7UUJBA"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-qYfaAsUKux"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import vertexai\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "! gcloud config set ai/region $LOCATION\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNiB5LfBaft-"
      },
      "source": [
        "## Start Model Monitoring tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_BdNCfk7Hjz"
      },
      "source": [
        "### Step 1: Create a Cloud Storage bucket\n",
        "\n",
        "Create a Cloud Storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_CZRJ5L60Mi"
      },
      "outputs": [],
      "source": [
        "# Create a Cloud Storage bucket\n",
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvHsyHsi7Dg8"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrHlJi-e7AyX"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZLxDjB6lYXx"
      },
      "source": [
        "### Step 2: Prepare a model in Vertex AI Model Registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q26J5e-D7p8e"
      },
      "source": [
        "You can register a model in Vertex AI Model Registry with its artifacts, enabling you to perform online serving or batch prediction. Alternatively, you can register a referenced/placeholder model that includes only the model's name.\n",
        "In this notebook, you register a model with artifacts because you'll run a batch prediction job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwrD1CnmmJsk"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "\n",
        "MODEL_PATH = \"gs://cloud-samples-data/vertex-ai/model-deployment/models/churn\"\n",
        "MODEL_NAME = \"churn\"\n",
        "IMAGE = \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-5:latest\"\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=MODEL_NAME,\n",
        "    artifact_uri=MODEL_PATH,\n",
        "    serving_container_image_uri=IMAGE,\n",
        "    sync=True,\n",
        ")\n",
        "\n",
        "MODEL_ID = model.resource_name.split(\"/\")[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p3buU6pC5B6"
      },
      "source": [
        "### Step 3: Deploy Model to Vertex AI Endpoint with Request-Respponse Logging Enabled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h-EOsirC8dY"
      },
      "source": [
        "#### Create an endpoint with logging enabled and deploy the model to this endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjKJ4yE3C-p4"
      },
      "outputs": [],
      "source": [
        "# Create an endpoint with logging enabled. Specify the logging sampling rate and BigQuery destination.\n",
        "import pandas as pd\n",
        "\n",
        "TIMESTAMP = pd.Timestamp.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "ENDPOINT_DISPLAY_NAME = f\"churn_endpoint_{TIMESTAMP}\"\n",
        "BQ_LOGGING_DATASET = f\"churn_production_{TIMESTAMP}\"\n",
        "BQ_LOGGING_TABLE = f\"bq://{PROJECT_ID}.{BQ_LOGGING_DATASET}.req_resp\"\n",
        "\n",
        "endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=ENDPOINT_DISPLAY_NAME,\n",
        "    enable_request_response_logging=True,\n",
        "    request_response_logging_sampling_rate=1.0,\n",
        "    request_response_logging_bq_destination_table=BQ_LOGGING_TABLE,\n",
        ")\n",
        "\n",
        "# Deploy model to this endpoint\n",
        "endpoint.deploy(\n",
        "    model=model,\n",
        "    traffic_percentage=100,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=1,\n",
        "    machine_type=\"n1-standard-4\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRCZNbtuDJPV"
      },
      "source": [
        "#### Run a prediction test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-3Wp4TcDJ51"
      },
      "outputs": [],
      "source": [
        "DEFAULT_INPUT = {\n",
        "    \"cnt_ad_reward\": 0,\n",
        "    \"cnt_challenge_a_friend\": 0,\n",
        "    \"cnt_completed_5_levels\": 1,\n",
        "    \"cnt_level_complete_quickplay\": 3,\n",
        "    \"cnt_level_end_quickplay\": 5,\n",
        "    \"cnt_level_reset_quickplay\": 2,\n",
        "    \"cnt_level_start_quickplay\": 6,\n",
        "    \"cnt_post_score\": 34,\n",
        "    \"cnt_spend_virtual_currency\": 0,\n",
        "    \"cnt_use_extra_steps\": 0,\n",
        "    \"cnt_user_engagement\": 120,\n",
        "    \"country\": \"Denmark\",\n",
        "    \"dayofweek\": 3,\n",
        "    \"julianday\": 254,\n",
        "    \"language\": \"da-dk\",\n",
        "    \"month\": 9,\n",
        "    \"operating_system\": \"IOS\",\n",
        "    \"user_pseudo_id\": \"104B0770BAE16E8B53DF330C95881893\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGZ1s6JODM_O"
      },
      "outputs": [],
      "source": [
        "import pprint as pp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    resp = endpoint.predict([DEFAULT_INPUT])\n",
        "    for i in resp.predictions:\n",
        "        vals = i[\"churned_values\"]\n",
        "        probs = i[\"churned_probs\"]\n",
        "    for i in range(len(vals)):\n",
        "        print(vals[i], probs[i])\n",
        "    plt.pie(probs, labels=vals)\n",
        "    pp.pprint(resp)\n",
        "except Exception as ex:\n",
        "    print(\"prediction request failed\", ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXxAxs5oDQf0"
      },
      "source": [
        "#### Send some online prediction requests to the endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCezq-GFDRAH"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Here we just use subset of the training dataset as prediction data\n",
        "DATASET_BQ_URI = \"bq://storage-samples.bqmlga4.train\"\n",
        "GROUND_TRUTH = \"churned\"\n",
        "\n",
        "bqclient = bigquery.Client(project=PROJECT_ID)\n",
        "table = bigquery.TableReference.from_string(DATASET_BQ_URI[5:])\n",
        "\n",
        "rows = bqclient.list_rows(table, max_results=1000)\n",
        "count = 0\n",
        "for row in rows:\n",
        "    instance = {}\n",
        "    for key, value in row.items():\n",
        "        if key == GROUND_TRUTH:\n",
        "            continue\n",
        "        if value is None:\n",
        "            value = \"\"\n",
        "        instance[key] = value\n",
        "    endpoint.predict(instances=[instance])\n",
        "    # Print progress\n",
        "    if count % 100 == 0:\n",
        "        print(f\"Sent: {count} requests\")\n",
        "    count = count + 1\n",
        "    time.sleep(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw-VWGwcDVLg"
      },
      "source": [
        "#### Check the endpoint logging table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwJ1YEZkDZTH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "query_string = (\n",
        "    f\"SELECT * FROM `{BQ_LOGGING_TABLE[5:]}` ORDER BY logging_time DESC LIMIT 10\"\n",
        ")\n",
        "pd.read_gbq(query_string, project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuwAoHTilv1j"
      },
      "source": [
        "### Step 4: Create a Model Monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hH4wSCXfgoE"
      },
      "source": [
        "#### Define Model Monitoring Schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyg0cMAdfrAa"
      },
      "source": [
        "The monitoring schema is a required configuration for a model monitor. The schema consists of input features names, prediction outputs, and ground truth (if available), along with their respective data types.\n",
        "\n",
        "**Note: The schema is optional only for AutoML tables (Regression/Classification), as it will be automatically fetched when available (if Model Monitoring is unable to retrieve the schema, you will need to provide your own).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR-4eTn3fkHk"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "MODEL_MONITORING_SCHEMA = ml_monitoring.spec.ModelMonitoringSchema(\n",
        "    feature_fields=[\n",
        "        ml_monitoring.spec.FieldSchema(name=\"user_pseudo_id\", data_type=\"string\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"country\", data_type=\"string\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"operating_system\", data_type=\"string\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"cnt_user_engagement\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_level_start_quickplay\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_level_end_quickplay\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_level_complete_quickplay\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_level_reset_quickplay\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"cnt_post_score\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_spend_virtual_currency\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"cnt_ad_reward\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_challenge_a_friend\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"cnt_completed_5_levels\", data_type=\"integer\"\n",
        "        ),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"cnt_use_extra_steps\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"month\", data_type=\"categorical\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"julianday\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"dayofweek\", data_type=\"integer\"),\n",
        "    ],\n",
        "    ground_truth_fields=[\n",
        "        ml_monitoring.spec.FieldSchema(name=\"churned\", data_type=\"categorical\")\n",
        "    ],\n",
        "    prediction_fields=[\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"predicted_churned\", data_type=\"categorical\"\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8KuANNbiiEV"
      },
      "source": [
        "#### (Optional) Define training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvFZRodti3qN"
      },
      "source": [
        "The training dataset can serve as the baseline dataset to analysis the data drift in production. You can register the training dataset in the model monitor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSqE4_roiw-q"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "# Copy files to your projects gs bucket to avoid permission issues.\n",
        "# Ignore any error(s) for bucket already exists.\n",
        "PUBLIC_TRAINING_DATASET = (\n",
        "    \"gs://cloud-samples-data/vertex-ai/model-monitoring/churn/churn_training.csv\"\n",
        ")\n",
        "TRAINING_URI = f\"{BUCKET_URI}/model-monitoring/churn/churn_training.csv\"\n",
        "\n",
        "! gsutil copy $PUBLIC_TRAINING_DATASET $TRAINING_URI\n",
        "\n",
        "TRAINING_DATASET = ml_monitoring.spec.MonitoringInput(\n",
        "    gcs_uri=TRAINING_URI, data_format=\"csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZnBZUEMjtDD"
      },
      "source": [
        "#### Create a model monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPBdgqz6jv9_"
      },
      "source": [
        "A model monitor is a top-level resource to manage your metrics and model monitoring jobs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_d917Ory595"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "my_model_monitor = ml_monitoring.ModelMonitor.create(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    display_name=\"churn_model_monitor\",\n",
        "    model_name=model.resource_name,\n",
        "    model_version_id=\"1\",\n",
        "    training_dataset=TRAINING_DATASET,\n",
        "    model_monitoring_schema=MODEL_MONITORING_SCHEMA,\n",
        ")\n",
        "MODEL_MONITOR_ID = my_model_monitor.name\n",
        "print(f\"MODEL MONITOR {MODEL_MONITOR_ID} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkHlwQuVli_2"
      },
      "source": [
        "### Step 5: Run an on-demand model monitoring job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpVp3fh3rkov"
      },
      "source": [
        "#### Define the monitoring objective configs\n",
        "\n",
        "For tabular models, Model Monitoring supports the following objectives:\n",
        "\n",
        "*   **Input feature drift detection**\n",
        "\n",
        "    Model Monitoring offers drift analysis for both categorical and numeric feature types, with the following supported metrics:\n",
        "\n",
        "    *    Categorical Feature: `Jensen Shannon Divergence`, `L Infinity`\n",
        "    *    Numeric Feature: `Jensen Shannon Divergence`\n",
        "\n",
        "    You can choose to analyze only the features of interest by specifying them in the `features` fields of the `ml_monitoring.spec.DataDriftSpec` specification. If not specified, all input features in the model schema are analyzed. Additionally, you have the option to set default thresholds for categorical or numeric features, or you can specify thresholds for individual features. If the detected drift surpasses a threshold, an alert is sent through email or another notification channel.\n",
        "\n",
        "*  **Prediction output drift detection**\n",
        "\n",
        "    Similar to input feature drift detection, prediction output drift detection identifies data drift in the prediction outputs.\n",
        "\n",
        "*   **Feature attribution drift detection**\n",
        "\n",
        "    Model Monitoring leverages Vertex Explainable AI to monitor feature attributions. Explainable AI enables you to understand the relative contribution of each feature to a resulting prediction. In essence, it assesses the magnitude of each feature's influence.\n",
        "    You must configure the `Explanation` specification with the feature attribution objectives configuration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZgrufEwzuFC"
      },
      "source": [
        "Input feature drift specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPkSsCZSzu50"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "FEATURE_THRESHOLDS = {\n",
        "    \"country\": 0.003,\n",
        "    \"cnt_user_engagement\": 0.004,\n",
        "}\n",
        "\n",
        "FEATURE_DRIFT_SPEC = ml_monitoring.spec.DataDriftSpec(\n",
        "    categorical_metric_type=\"l_infinity\",\n",
        "    numeric_metric_type=\"jensen_shannon_divergence\",\n",
        "    default_categorical_alert_threshold=0.2,\n",
        "    default_numeric_alert_threshold=0.3,\n",
        "    feature_alert_thresholds=FEATURE_THRESHOLDS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6rqFXXWzxuQ"
      },
      "source": [
        "Prediction output drift specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEQnbNlYgQ8y"
      },
      "outputs": [],
      "source": [
        "PREDICTION_OUTPUT_DRIFT_SPEC = ml_monitoring.spec.DataDriftSpec(\n",
        "    categorical_metric_type=\"l_infinity\",\n",
        "    numeric_metric_type=\"jensen_shannon_divergence\",\n",
        "    default_categorical_alert_threshold=0.1,\n",
        "    default_numeric_alert_threshold=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzdHn15az3pg"
      },
      "source": [
        "Feature attribution specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwGi882Fz5KA"
      },
      "outputs": [],
      "source": [
        "FEATURE_ATTRIBUTION_SPEC = ml_monitoring.spec.FeatureAttributionSpec(\n",
        "    default_alert_threshold=0.0003,\n",
        "    feature_alert_thresholds={\"cnt_ad_reward\": 0.0001},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avV5qcCUr9IT"
      },
      "source": [
        "#### Define the alert notification and metrics output spec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N9YlXzOvyOs"
      },
      "source": [
        "Model Monitoring supports the following notification methods:\n",
        "\n",
        "*   Email\n",
        "*   [Notification Channel](https://cloud.google.com/monitoring/support/notification-options)\n",
        "*   [Cloud Logging](https://cloud.google.com/logging/docs)  \n",
        "\n",
        "This notebook uses email as an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jzY1mpdw-CY"
      },
      "source": [
        "Export generated metrics to the Google Cloud Storage location that you specified or, if you don't specify a location, Vertex AI creates a default bucket to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yclsJhNrsI-F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "EMAIL = \"[your-email-address]\"  # @param {type:\"string\"}\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    EMAIL = \"noreply@google.com\"\n",
        "\n",
        "NOTIFICATION_SPEC = ml_monitoring.spec.NotificationSpec(\n",
        "    user_emails=[EMAIL],\n",
        ")\n",
        "\n",
        "OUTPUT_SPEC = ml_monitoring.spec.OutputSpec(gcs_base_dir=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzbfaAFq9mV"
      },
      "source": [
        "#### Run Model Monitoring Jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaAEOio70bTZ"
      },
      "source": [
        "##### **Example 1: Feature drift & Prediction output drift detection, compares current data with the training dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knp5-4I-WKOa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "TIMESTAMP = pd.Timestamp.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "JOB_DISPLAY_NAME = f\"churn_model_monitoring_job_{TIMESTAMP}\"\n",
        "TARGET_DATASET = ml_monitoring.spec.MonitoringInput(endpoints=[endpoint.resource_name])\n",
        "model_monitoring_job_1 = my_model_monitor.run(\n",
        "    display_name=JOB_DISPLAY_NAME,\n",
        "    baseline_dataset=TRAINING_DATASET,\n",
        "    target_dataset=TARGET_DATASET,\n",
        "    tabular_objective_spec=ml_monitoring.spec.TabularObjective(\n",
        "        # Input feature drift spec.\n",
        "        feature_drift_spec=FEATURE_DRIFT_SPEC,\n",
        "        # Prediction output drift spec.\n",
        "        prediction_output_drift_spec=PREDICTION_OUTPUT_DRIFT_SPEC,\n",
        "    ),\n",
        "    notification_spec=NOTIFICATION_SPEC,\n",
        "    output_spec=OUTPUT_SPEC,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpbpwths0lf5"
      },
      "source": [
        "##### **Example 2: Feature attribution drift detection, compares current data with a Cloud Storage baseline dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw2DR7t70zkj"
      },
      "source": [
        "For feature attribution monitoring, the dataset is sent to the Vertex AI batch explanation job in the following way:\n",
        "\n",
        "*   Google Cloud Storage -> Sent directly as input to Vertex AI batch explanation job.\n",
        "*   BigQuery table -> Sent directly as input to Vertex AI batch explanation job.\n",
        "*   BigQuery Query -> Not supported.\n",
        "*   Vertex AI batch explanation job -> Input of batch prediction job is used as input for the Vertex AI batch explanation job.\n",
        "*   Vertex AI endpoint logging -> Request logging is used as input for Vertex AI batch explanation job.\n",
        "\n",
        "Check that these datasets meet the requirements for a Vertex AI batch explanation job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMM4lXtk04dL"
      },
      "source": [
        "###### Generate model metadata for Vertex Explainable AI\n",
        "You must specify the explanation specification to use a Vertex AI batch explanation job. Run the following cell to extract metadata from the exported model, which is needed for generating the explanations for a prediction request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6_tyqq307sP"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform_v1beta1.types import (ExplanationMetadata,\n",
        "                                                   ExplanationParameters,\n",
        "                                                   ExplanationSpec)\n",
        "\n",
        "EXPLANATION_SPEC = ExplanationSpec(\n",
        "    parameters=ExplanationParameters(\n",
        "        {\"sampled_shapley_attribution\": {\"path_count\": 2}}\n",
        "    ),\n",
        "    metadata=ExplanationMetadata(\n",
        "        inputs={\n",
        "            \"cnt_ad_reward\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_ad_reward\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_challenge_a_friend\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_challenge_a_friend\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_completed_5_levels\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_completed_5_levels\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_level_complete_quickplay\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_level_complete_quickplay\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_level_end_quickplay\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_level_end_quickplay\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_level_reset_quickplay\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_level_reset_quickplay\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_level_start_quickplay\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_level_start_quickplay\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_post_score\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_post_score\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_spend_virtual_currency\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_spend_virtual_currency\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_use_extra_steps\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_use_extra_steps\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"cnt_user_engagement\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"cnt_user_engagement\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"country\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"country\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"categorical\",\n",
        "                }\n",
        "            ),\n",
        "            \"dayofweek\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"dayofweek\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"julianday\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"julianday\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"language\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"language\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"categorical\",\n",
        "                }\n",
        "            ),\n",
        "            \"month\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"month\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"numeric\",\n",
        "                }\n",
        "            ),\n",
        "            \"operating_system\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"operating_system\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"categorical\",\n",
        "                }\n",
        "            ),\n",
        "            \"user_pseudo_id\": ExplanationMetadata.InputMetadata(\n",
        "                {\n",
        "                    \"input_tensor_name\": \"user_pseudo_id\",\n",
        "                    \"encoding\": \"IDENTITY\",\n",
        "                    \"modality\": \"categorical\",\n",
        "                }\n",
        "            ),\n",
        "        },\n",
        "        outputs={\n",
        "            \"churned_probs\": ExplanationMetadata.OutputMetadata(\n",
        "                {\"output_tensor_name\": \"churned_probs\"}\n",
        "            )\n",
        "        },\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fMoYeEA2lA9"
      },
      "outputs": [],
      "source": [
        "FEATURE_ATTRIBUTION_BASELINE_DATASET = (\n",
        "    f\"{BUCKET_URI}/model-monitoring/churn/churn_no_ground_truth.jsonl\"\n",
        ")\n",
        "! gsutil cp gs://cloud-samples-data/vertex-ai/model-monitoring/churn/churn_no_ground_truth.jsonl $FEATURE_ATTRIBUTION_BASELINE_DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEMPiPcs0-7p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "TIMESTAMP = pd.Timestamp.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "JOB_DISPLAY_NAME = f\"churn_model_monitoring_job_{TIMESTAMP}\"\n",
        "BASELINE_DATASET = ml_monitoring.spec.MonitoringInput(\n",
        "    gcs_uri=FEATURE_ATTRIBUTION_BASELINE_DATASET, data_format=\"jsonl\"\n",
        ")\n",
        "TARGET_DATASET = ml_monitoring.spec.MonitoringInput(endpoints=[endpoint.resource_name])\n",
        "model_monitoring_job_2 = my_model_monitor.run(\n",
        "    display_name=JOB_DISPLAY_NAME,\n",
        "    baseline_dataset=BASELINE_DATASET,\n",
        "    target_dataset=TARGET_DATASET,\n",
        "    tabular_objective_spec=ml_monitoring.spec.TabularObjective(\n",
        "        # Feature attribution spec.\n",
        "        feature_attribution_spec=FEATURE_ATTRIBUTION_SPEC\n",
        "    ),\n",
        "    # You must have a Explanation spec for feature attribution monitoring.\n",
        "    # You can specify the explanation spec in the Model, Model monitor, or the Model monitoring job.\n",
        "    explanation_spec=EXPLANATION_SPEC,\n",
        "    notification_spec=NOTIFICATION_SPEC,\n",
        "    output_spec=OUTPUT_SPEC,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV5CZSqLVBPj"
      },
      "source": [
        "##### List Model Monitoring Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urFYUjaZ7iCP"
      },
      "outputs": [],
      "source": [
        "my_model_monitor.list_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL10YABxl47v"
      },
      "source": [
        "### Step 6: Wait for the Model Monitoring Job to run and verify the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrSU6d0xFfzv"
      },
      "source": [
        "#### Verify results through email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5KodgebDVE"
      },
      "source": [
        "Once the model monitoring job begins running, you will receive an email as follows:\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/create_job_email.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37SPm_majLVj"
      },
      "source": [
        "After the monitoring job is complete, if any anomalies are detected, you receive an email similar to the following one:\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/job_anomalies_email.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPC6ZoerifM6"
      },
      "source": [
        "#### Check monitoring metrics: Google Cloud Console"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pw6Z-bVbZaE"
      },
      "source": [
        "To view Model Monitoring metrics in the [Google Cloud Console](https://console.cloud.google.com/vertex-ai/model-monitoring/model-monitors), go to the **Monitoring** tab under **Vertex AI.**\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cmm-public-data/images/endpoint_jobs_details.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFZcBnwsdSfa"
      },
      "source": [
        "#### Check monitoring metrics: Cloud Storage bucket\n",
        "\n",
        "Run the following to view Model Monitoring metrics stored in the Cloud Storage bucket.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhY20BTjjkVk"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    my_model_monitor.show_feature_drift_stats(model_monitoring_job_1.name)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm_D4BGnBQ6a"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    my_model_monitor.show_output_drift_stats(model_monitoring_job_1.name)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNpKoRoaEWQC"
      },
      "source": [
        "### Step 7: Schedule Continous Model Monitoring Jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGp6GlV29QAE"
      },
      "source": [
        "To set up continous model monitoring, follow the example below to create a schedule. You can create multiple schedules for your model monitor.\n",
        "\n",
        "\n",
        "The following example monitors drift in both input features and prediction outputs. The schedule is configured to activate the model monitoring job every hour on the hour, such as at 00:00, 01:00, and so on. Each job analyzes data from the preceding one-hour window. For instance, if a job is scheduled for 6:00 a.m., it analyzes the data collected from 5:00 a.m. to 6:00 a.m."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS8zeXVBqe13"
      },
      "source": [
        "#### Send more traffic to the endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K6ga5F2qeKh"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Here we just use subset of the training dataset as prediction data\n",
        "DATASET_BQ_URI = \"bq://storage-samples.bqmlga4.train\"\n",
        "GROUND_TRUTH = \"churned\"\n",
        "\n",
        "bqclient = bigquery.Client(project=PROJECT_ID)\n",
        "table = bigquery.TableReference.from_string(DATASET_BQ_URI[5:])\n",
        "rows = bqclient.list_rows(table, max_results=1000)\n",
        "count = 0\n",
        "for row in rows:\n",
        "    instance = {}\n",
        "    for key, value in row.items():\n",
        "        if key == GROUND_TRUTH:\n",
        "            continue\n",
        "        if value is None:\n",
        "            value = \"\"\n",
        "        instance[key] = value\n",
        "    endpoint.predict(instances=[instance])\n",
        "    # Print progress\n",
        "    if count % 100 == 0:\n",
        "        print(f\"Sent: {count} requests\")\n",
        "    count = count + 1\n",
        "    time.sleep(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7biYOYy1TCsa"
      },
      "source": [
        "#### Create a schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyPwRmCBEcSp"
      },
      "outputs": [],
      "source": [
        "# Every 1 hour at :00, for example 1:00, 2:00..\n",
        "CRON = \"0 * * * *\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8-FNVoQH6qL"
      },
      "outputs": [],
      "source": [
        "# from google.protobuf import timestamp_pb2\n",
        "\n",
        "SCHEDULE_DISPLAY_NAME = \"churn-continous-drift-detection\"\n",
        "\n",
        "# Example 1: Training dataset as baseline\n",
        "BASELINE_DATASET = TRAINING_DATASET\n",
        "\n",
        "# Example 2: Baseline with the same target dataset and with offset. Example:\n",
        "# BASELINE_DATASET=model_monitor.spec.MonitoringInput(\n",
        "#     endpoints=[endpoint.resource_name],\n",
        "#     window=\"1h\",\n",
        "#     offset=\"1h\"\n",
        "# )\n",
        "\n",
        "# Example 3: Baseline with the same target dataset and with start and end time\n",
        "# window. Example:\n",
        "# BASELINE_DATASET=model_monitor.spec.MonitoringInput(\n",
        "#     endpoints=[endpoint.resource_name],\n",
        "#     start_time=timestamp_pb2.Timestamp(seconds=xxx),\n",
        "#     end_time=timestamp_pb2.Timestamp(seconds=xxx)\n",
        "# )\n",
        "# More options are available, please check the `MonitoringInput`.\n",
        "\n",
        "TARGET_DATASET = ml_monitoring.spec.MonitoringInput(\n",
        "    endpoints=[endpoint.resource_name],\n",
        "    window=\"1h\",\n",
        ")\n",
        "\n",
        "model_monitoring_schedule = my_model_monitor.create_schedule(\n",
        "    display_name=SCHEDULE_DISPLAY_NAME,\n",
        "    cron=CRON,\n",
        "    baseline_dataset=BASELINE_DATASET,\n",
        "    target_dataset=TARGET_DATASET,\n",
        "    tabular_objective_spec=ml_monitoring.spec.TabularObjective(\n",
        "        # Input feature drift spec.\n",
        "        feature_drift_spec=FEATURE_DRIFT_SPEC,\n",
        "        # Prediction output drift spec.\n",
        "        prediction_output_drift_spec=PREDICTION_OUTPUT_DRIFT_SPEC,\n",
        "    ),\n",
        "    notification_spec=NOTIFICATION_SPEC,\n",
        "    output_spec=OUTPUT_SPEC,\n",
        ")\n",
        "\n",
        "SCHEDULE_RESOURCE_NAME = model_monitoring_schedule.name\n",
        "print(f\"Schedule {SCHEDULE_RESOURCE_NAME} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI9ZejD4S4jK"
      },
      "source": [
        "#### Pause Schedule\n",
        "\n",
        "Run the following to pause the model monitoring schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GW8pkM2S-LR"
      },
      "outputs": [],
      "source": [
        "my_model_monitor.pause_schedule(schedule_name=SCHEDULE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O4BN64KTt95"
      },
      "source": [
        "#### Resume Schedule\n",
        "\n",
        "Run the following to resume a paused model monitoring schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--WkYX_NTyhn"
      },
      "outputs": [],
      "source": [
        "my_model_monitor.resume_schedule(schedule_name=SCHEDULE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydPzrEVuT1O9"
      },
      "source": [
        "#### Update Schedule\n",
        "\n",
        "Run the following to update the model monitoring schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqz2MXYBT2-f"
      },
      "outputs": [],
      "source": [
        "# Update to run every 1 hour at :30, for example 0:30, 1:30, 2:00..\n",
        "my_model_monitor.update_schedule(\n",
        "    schedule_name=SCHEDULE_RESOURCE_NAME, cron=\"30 * * * *\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOH_UNH5NyJG"
      },
      "source": [
        "#### Check monitoring schedules in Google Cloud Console\n",
        "\n",
        "To check your Model Monitoring schedule in the Google Cloud Console, go to the Monitor tab under Vertex AI.\n",
        "\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/endpoint_schedules.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hovSbsmBmEKZ"
      },
      "source": [
        "### Step 8: Clean Up\n",
        "\n",
        "If you no longer need your model monitoring resources, run the following to delete them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejHg5PqiJPS2"
      },
      "outputs": [],
      "source": [
        "# When no jobs are running, delete the schedule and all the jobs.\n",
        "my_model_monitor.delete(force=True)\n",
        "\n",
        "# Undeploy endpoint\n",
        "endpoint.undeploy_all()\n",
        "endpoint.delete()\n",
        "\n",
        "# Delete the model\n",
        "model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_monitoring_for_custom_model_online_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
