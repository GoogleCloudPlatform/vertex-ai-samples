{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvycbGgHyLwj"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0lMq-JCyREk"
      },
      "source": [
        "# Model Monitoring for Model Outside Vertex AI\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring_v2/model_monitoring_for_model_outside_vertex.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2model_monitoring_v2%2model_monitoring_for_model_outside_vertex.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring_v2/model_monitoring_for_model_outside_vertex.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring_v2/model_monitoring_for_model_outside_vertex.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkF8nA1Kyc7N"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to use the Vertex AI SDK for Python to set up Vertex AI Model Monitoring V2 for your model. Model Monitoring V2 now supports models outside of Vertex AI (allowing you to register a referenced/placeholder model in Vertex AI without artifacts). This capability can also extend to feature store monitoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDFf5evP7U4P"
      },
      "source": [
        "### Objective\n",
        "\n",
        "The steps performed include the following:\n",
        "\n",
        "- Register a referenced/placeholder model for model outside Vertex AI\n",
        "- Create a Model Monitor\n",
        "- Run on-demand model monitoring job\n",
        "- Continous model monitoring\n",
        "\n",
        "\n",
        "### Costs\n",
        "\n",
        "Vertex AI Model Monitoring v2 is free during the public preview period, but you will still be billed for the following Google Cloud services:\n",
        "\n",
        "* [BigQuery](https://cloud.google.com/bigquery/pricing)\n",
        "* [Cloud Storage](https://cloud.google.com/storage/pricing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xt2lAuLykrI"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3848df1e5b0"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gT2fULbe7cm"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet \\\n",
        "    google-cloud-bigquery \\\n",
        "    pandas \\\n",
        "    pandas_gbq \\\n",
        "    pyarrow \\\n",
        "    tensorflow_data_validation[visualization] \\\n",
        "    google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbOQ_xi8xhCk"
      },
      "source": [
        "Check that the version of google-cloud-aiplatform is 1.51.0 or later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q72gf-JxkNY"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4o9GjHNfHdI"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaY8Q_T3fA38"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZHyMcW_y1lx"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNiB5LfBaft-"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Q7ErKNy7ya"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvY0RukOlJoi"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "875Lk5EYzFHw"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import vertexai\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "! gcloud config set ai/region $LOCATION\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVnR14LEzbvd"
      },
      "source": [
        "## Start Model Monitoring tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxqAU5Ua43GR"
      },
      "source": [
        "### Step 1: Create a Cloud Storage bucket\n",
        "\n",
        "Create a Cloud Storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_CZRJ5L60Mi"
      },
      "outputs": [],
      "source": [
        "# Create a Cloud Storage bucket\n",
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvHsyHsi7Dg8"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrHlJi-e7AyX"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZLxDjB6lYXx"
      },
      "source": [
        "### Step 2: Create a Placeholder Model in Vertex AI\n",
        "\n",
        "You can create a referenced/placeholder model for your model outside Vertex AI using only a display name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwrD1CnmmJsk"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "\n",
        "MODEL_NAME = \"penguins\"  # @param {type:\"string\"}\n",
        "\n",
        "model = aiplatform.Model.upload(display_name=MODEL_NAME, sync=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL9vDk7Is9-0"
      },
      "source": [
        "### Step 3: Prepare your Baseline and Target Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUO5gFnCtHaZ"
      },
      "source": [
        "We recommend using BigQuery to store your production dataset. Please ensure that features are stored in separate columns. The following is an example BigQuery schema:\n",
        "\n",
        "<!-- <img src=\"https://services.google.com/fh/gumdrop/preview/misc/example_bq_schema_2.png\" width=\"400\" height=\"300\"/> -->\n",
        "<img src=\"https://services.google.com/fh/files/misc/example_bq_schema_2.png\" width=\"400\" height=\"300\"/>\n",
        "\n",
        "Note: If you want to setup continous monitoring with time specification, for example a time window, a timestamp column is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT3OrZZlIXu5"
      },
      "source": [
        "Create some fake serving data for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMU57yC04CGb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the number of rows\n",
        "num_random = 100000\n",
        "\n",
        "data = {\n",
        "    \"island\": np.random.randint(0, 3, size=num_random),\n",
        "    \"culmen_length_mm\": np.random.normal(50, 3, num_random),\n",
        "    \"culmen_depth_mm\": np.random.normal(20, 3, num_random),\n",
        "    \"flipper_length_mm\": np.random.randint(160, 250, size=num_random),\n",
        "    \"body_mass_g\": np.random.randint(3000, 8000, size=num_random),\n",
        "    \"sex\": np.random.randint(0, 3, size=num_random),\n",
        "    \"predicted_species\": np.random.randint(0, 6, size=num_random),\n",
        "}\n",
        "\n",
        "# Create a DataFrame from the generated data\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the time range (start and end dates) in UTC\n",
        "# now-24h ~ now + 24h\n",
        "start_date = pd.Timestamp.utcnow() - pd.Timedelta(days=1)\n",
        "end_date = pd.Timestamp.utcnow() + pd.Timedelta(days=1)\n",
        "\n",
        "# Generate a list to store the random timestamps\n",
        "random_timestamps = []\n",
        "\n",
        "# Generate random timestamps and add them to the list\n",
        "for _ in range(num_random):\n",
        "    random_seconds = np.random.randint((end_date - start_date).total_seconds())\n",
        "    random_timestamp = start_date + pd.Timedelta(seconds=random_seconds)\n",
        "    # Format the timestamp as a string with microseconds\n",
        "    formatted_timestamp = random_timestamp.strftime(\"%Y-%m-%d %H:%M:%S.%f UTC\")\n",
        "    random_timestamps.append(formatted_timestamp)\n",
        "\n",
        "df[\"timestamp\"] = random_timestamps\n",
        "\n",
        "df.to_csv(\"production.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLqjAiRAttHV"
      },
      "source": [
        "Create a BigQuery dataset and load the fake data to a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvrX7pQK4Djj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "TIMESTAMP = pd.Timestamp.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "FAKE_DATA_BQ_DATASET = f\"penguins_production_{TIMESTAMP}\"\n",
        "!bq mk --dataset $PROJECT_ID:$FAKE_DATA_BQ_DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMZ2a7vn4EsF"
      },
      "outputs": [],
      "source": [
        "FAKE_DATA_BQ_TABLE = f\"{FAKE_DATA_BQ_DATASET}.data\"\n",
        "!bq load --autodetect --source_format=CSV $FAKE_DATA_BQ_TABLE \"production.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rj0dLO6vI0u"
      },
      "source": [
        "Check the serving logging table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UhZhEwSvJOl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "query_string = f\"SELECT * FROM `{FAKE_DATA_BQ_TABLE}` ORDER BY timestamp DESC LIMIT 10\"\n",
        "pd.read_gbq(query_string, project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuwAoHTilv1j"
      },
      "source": [
        "### Step 4: Create a Model Monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp6jVFGvC6wt"
      },
      "source": [
        "Create a model monitor to associate monitoring details the model version you just created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hH4wSCXfgoE"
      },
      "source": [
        "#### Define Model Monitoring Schema\n",
        "\n",
        "The monitoring schema is a required configuration for a model monitor. The schema consists of input features names, prediction outputs, and ground truth (if available), along with their respective data types.\n",
        "\n",
        "**Note: The schema is optional only for AutoML tables (Regression/Classification), as it will be automatically fetched when available (if Model Monitoring is unable to retrieve the schema, you will need to provide your own).**\n",
        "\n",
        "##### You can manually define the model schema as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR-4eTn3fkHk"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "MODEL_MONITORING_SCHEMA = ml_monitoring.spec.ModelMonitoringSchema(\n",
        "    feature_fields=[\n",
        "        ml_monitoring.spec.FieldSchema(name=\"island\", data_type=\"categorical\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"culmen_length_mm\", data_type=\"float\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"culmen_depth_mm\", data_type=\"float\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"flipper_length_mm\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"body_mass_g\", data_type=\"integer\"),\n",
        "        ml_monitoring.spec.FieldSchema(name=\"sex\", data_type=\"categorical\"),\n",
        "    ],\n",
        "    prediction_fields=[\n",
        "        ml_monitoring.spec.FieldSchema(\n",
        "            name=\"predicted_species\", data_type=\"categorical\"\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn7YMjRMz43K"
      },
      "source": [
        "##### Alternatively, if you have a large number of features, you can use the `transform_schema_from_bigquery` method to retrieve the schema and modify it as needed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNIb_Lat0O5L"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview.ml_monitoring.spec import schema\n",
        "\n",
        "MODEL_MONITORING_SCHEMA = schema.transform_schema_from_bigquery(\n",
        "    query=f\"select * except(timestamp) from {FAKE_DATA_BQ_TABLE}\",\n",
        "    prediction_fields=\"predicted_species\",\n",
        ")\n",
        "print(MODEL_MONITORING_SCHEMA.to_json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zn_efoq0d6T"
      },
      "source": [
        "Modify the schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbIMWCVrzz99"
      },
      "outputs": [],
      "source": [
        "# Change feature `island` to categorical\n",
        "MODEL_MONITORING_SCHEMA.feature_fields[0].data_type = \"categorical\"\n",
        "# Change feature `sex` to categorical\n",
        "MODEL_MONITORING_SCHEMA.feature_fields[5].data_type = \"categorical\"\n",
        "# Change prediction output `predicted_species` to categorical\n",
        "MODEL_MONITORING_SCHEMA.prediction_fields[0].data_type = \"categorical\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUChBL04vUY"
      },
      "outputs": [],
      "source": [
        "print(MODEL_MONITORING_SCHEMA.to_json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8KuANNbiiEV"
      },
      "source": [
        "#### (Optional) Define the training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvFZRodti3qN"
      },
      "source": [
        "The training dataset can serve as the baseline dataset to calculate monitoring metrics. You can register the training dataset in the model monitor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSqE4_roiw-q"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "# Copy files to your projects gs bucket to avoid permission issues.\n",
        "# Ignore any error(s) for bucket already exists.\n",
        "PUBLIC_TRAINING_DATASET = (\n",
        "    \"gs://cloud-samples-data/vertex-ai/model-monitoring/penguins/penguins_training.csv\"\n",
        ")\n",
        "TRAINING_URI = f\"{BUCKET_URI}/model-monitoring/penguins/penguins_training.csv\"\n",
        "\n",
        "! gsutil copy $PUBLIC_TRAINING_DATASET $TRAINING_URI\n",
        "\n",
        "TRAINING_DATASET = ml_monitoring.spec.MonitoringInput(\n",
        "    gcs_uri=TRAINING_URI, data_format=\"csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZnBZUEMjtDD"
      },
      "source": [
        "#### Create a model monitor resource"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPBdgqz6jv9_"
      },
      "source": [
        "A model monitor is a top-level resource to manage your metrics and model monitoring jobs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_d917Ory595"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "my_model_monitor = ml_monitoring.ModelMonitor.create(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    display_name=\"penguins_model_monitor\",\n",
        "    model_name=model.resource_name,\n",
        "    model_version_id=\"1\",\n",
        "    training_dataset=TRAINING_DATASET,\n",
        "    model_monitoring_schema=MODEL_MONITORING_SCHEMA,\n",
        ")\n",
        "MODEL_MONITOR_ID = my_model_monitor.name\n",
        "print(f\"MODEL MONITOR {MODEL_MONITOR_ID} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkHlwQuVli_2"
      },
      "source": [
        "### Step 5: Run an on-demand model monitoring job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0iYBC6U1ZE8"
      },
      "source": [
        "#### Define the monitoring objective configs\n",
        "\n",
        "For tabular models, Model Monitoring supports the following objectives:\n",
        "\n",
        "*   **Input feature drift detection**\n",
        "\n",
        "    Model Monitoring offers drift analysis for both categorical and numeric feature types, with the following supported metrics:\n",
        "\n",
        "    *    Categorical Feature: `Jensen Shannon Divergence`, `L Infinity`\n",
        "    *    Numeric Feature: `Jensen Shannon Divergence`\n",
        "\n",
        "    You can choose to analyze only the features of interest by specifying them in the `features` fields of the `ml_monitoring.spec.DataDriftSpec` specification. If not specified, all input features in the model schema are analyzed. Additionally, you have the option to set default thresholds for categorical or numeric features, or you can specify thresholds for individual features. If the detected drift surpasses a threshold, an alert is sent through email or another notification channel.\n",
        "\n",
        "*  **Prediction output drift detection**\n",
        "\n",
        "    Similar to input feature drift detection, prediction output drift detection identifies data drift in the prediction outputs.\n",
        "\n",
        "*   **Feature attribution drift detection**\n",
        "\n",
        "    For model outside Vertex AI which don't have the model artifact or container information, the feature attribution score drift detection is not supported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPDk-0FUdudb"
      },
      "source": [
        "In the following example, we set the `FEATURE_DRIFT_SPEC` and `PREDICTION_OUTPUT_DRIFT_SPEC`, which is assembled in the `tabular_objective_spec`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-VApGAl7FVx"
      },
      "outputs": [],
      "source": [
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "DEFAULT_THRESHOLD_VALUE = 0.001\n",
        "\n",
        "FEATURE_THRESHOLDS = {\n",
        "    \"culmen_length_mm\": DEFAULT_THRESHOLD_VALUE,\n",
        "    \"body_mass_g\": 0.002,\n",
        "}\n",
        "\n",
        "FEATURE_DRIFT_SPEC = ml_monitoring.spec.DataDriftSpec(\n",
        "    categorical_metric_type=\"l_infinity\",\n",
        "    numeric_metric_type=\"jensen_shannon_divergence\",\n",
        "    default_categorical_alert_threshold=0.001,\n",
        "    default_numeric_alert_threshold=0.002,\n",
        "    feature_alert_thresholds=FEATURE_THRESHOLDS,\n",
        ")\n",
        "\n",
        "PREDICTION_OUTPUT_DRIFT_SPEC = ml_monitoring.spec.DataDriftSpec(\n",
        "    categorical_metric_type=\"l_infinity\",\n",
        "    numeric_metric_type=\"jensen_shannon_divergence\",\n",
        "    default_categorical_alert_threshold=0.001,\n",
        "    default_numeric_alert_threshold=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avV5qcCUr9IT"
      },
      "source": [
        "#### Define the alert notification and metrics output spec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N9YlXzOvyOs"
      },
      "source": [
        "We support various methods of notification:\n",
        "\n",
        "*   Email\n",
        "*   [Notification Channel](https://cloud.google.com/monitoring/support/notification-options)\n",
        "*   [Cloud Logging](https://cloud.google.com/logging/docs?_gl=1*tdcri2*_up*MQ..&gclid=Cj0KCQjwir2xBhC_ARIsAMTXk84diOnqqpDckjOZUas26cUXUgEAgEGT9uFpz9tTvkfUjmVnRs7lQuwaAjiwEALw_wcB&gclsrc=aw.ds)  \n",
        "\n",
        "In this notebook, we use email as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yclsJhNrsI-F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "EMAIL = \"[your-email-address]\"  # @param {type:\"string\"}\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    EMAIL = \"noreply@google.com\"\n",
        "\n",
        "NOTIFICATION_SPEC = ml_monitoring.spec.NotificationSpec(\n",
        "    user_emails=[EMAIL],\n",
        ")\n",
        "\n",
        "OUTPUT_SPEC = ml_monitoring.spec.OutputSpec(gcs_base_dir=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzbfaAFq9mV"
      },
      "source": [
        "#### Run Model Monitoring Jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQm3hJHZ12nK"
      },
      "source": [
        "Let's start a monitoring job for the feature drift detection (comparing training data and serving data).\n",
        "In this example, training data is a CSV file from Google Cloud Storage and the serving data is from BigQuery. We support two options for connection:\n",
        "\n",
        "* table_uri: Consumes all the features from the table.\n",
        "* query: Using SQL query, you can select the features you are interested for analysis. Be sure to include the timestamp column if you'd like to specify the data window or set up continous monitoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpCvUgUn7Jd4"
      },
      "source": [
        "**Example 1: Use BigQuery Table Uri**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BDR8c_f7V3q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from vertexai.resources.preview import ml_monitoring\n",
        "\n",
        "TIMESTAMP = pd.Timestamp.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "JOB_DISPLAY_NAME = f\"penguins_model_monitoring_job_{TIMESTAMP}\"\n",
        "model_monitoring_job_1 = my_model_monitor.run(\n",
        "    display_name=JOB_DISPLAY_NAME,\n",
        "    baseline_dataset=TRAINING_DATASET,\n",
        "    target_dataset=ml_monitoring.spec.MonitoringInput(\n",
        "        table_uri=f\"bq://{PROJECT_ID}.{FAKE_DATA_BQ_TABLE}\"\n",
        "    ),\n",
        "    tabular_objective_spec=ml_monitoring.spec.TabularObjective(\n",
        "        # Input feature drift spec.\n",
        "        feature_drift_spec=FEATURE_DRIFT_SPEC,\n",
        "        # Prediction output drift spec.\n",
        "        prediction_output_drift_spec=PREDICTION_OUTPUT_DRIFT_SPEC,\n",
        "    ),\n",
        "    notification_spec=NOTIFICATION_SPEC,\n",
        "    output_spec=OUTPUT_SPEC,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ebZS3Dn7O4l"
      },
      "source": [
        "**Example 2: Use SQL Query**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAY1AEBZ6sT6"
      },
      "source": [
        "Let's create another model monitoring job using SQL query. Be sure to include the timestamp column if you'd like to specify the time specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b046NzvZ6qtX"
      },
      "outputs": [],
      "source": [
        "TIMESTAMP = pd.Timestamp.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "JOB_DISPLAY_NAME = f\"penguins_model_monitoring_job_{TIMESTAMP}\"\n",
        "model_monitoring_job_2 = my_model_monitor.run(\n",
        "    display_name=JOB_DISPLAY_NAME,\n",
        "    baseline_dataset=TRAINING_DATASET,\n",
        "    target_dataset=ml_monitoring.spec.MonitoringInput(\n",
        "        query=f\"select island, culmen_length_mm, body_mass_g, predicted_species, timestamp from {PROJECT_ID}.{FAKE_DATA_BQ_TABLE}\",\n",
        "        timestamp_field=\"timestamp\",\n",
        "        window=\"2h\",\n",
        "    ),\n",
        "    tabular_objective_spec=ml_monitoring.spec.TabularObjective(\n",
        "        # Input feature drift spec.\n",
        "        feature_drift_spec=FEATURE_DRIFT_SPEC,\n",
        "        # Prediction output drift spec.\n",
        "        prediction_output_drift_spec=PREDICTION_OUTPUT_DRIFT_SPEC,\n",
        "    ),\n",
        "    notification_spec=NOTIFICATION_SPEC,\n",
        "    output_spec=OUTPUT_SPEC,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlOwnrOA8Tpf"
      },
      "outputs": [],
      "source": [
        "my_model_monitor.list_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL10YABxl47v"
      },
      "source": [
        "### Step 6: Wait for the Model Monitoring Job to complete and verify the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrSU6d0xFfzv"
      },
      "source": [
        "#### Check email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5KodgebDVE"
      },
      "source": [
        "##### Once the model monitoring job begins running (it will start after the batch prediction jobs have finished), you will receive an email as follows:\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/create_job_email.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37SPm_majLVj"
      },
      "source": [
        "##### Once the monitoring job is complete, should any anomalies be detected, you will receive an email similar to the following:\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/place_holder_job_anomalies.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPC6ZoerifM6"
      },
      "source": [
        "#### Check monitoring metrics: Google Cloud Console"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pw6Z-bVbZaE"
      },
      "source": [
        "To view Model Monitoring metrics in the [Google Cloud Console](https://console.cloud.google.com/vertex-ai/model-monitoring/model-monitors), go to the **Monitoring** tab under **Vertex AI.**\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/place_holder_job_details.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFZcBnwsdSfa"
      },
      "source": [
        "#### Check monitoring metrics: Cloud Storage bucket\n",
        "\n",
        "Run the following to view Model Monitoring metrics stored in the Cloud Storage bucket.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhY20BTjjkVk"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    my_model_monitor.show_feature_drift_stats(model_monitoring_job_1.name)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UZ76MY1As5F"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    my_model_monitor.show_output_drift_stats(model_monitoring_job_1.name)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtjLw8rVcC13"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    my_model_monitor.show_feature_drift_stats(model_monitoring_job_2.name)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHyOo5rBAwAt"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    my_model_monitor.show_output_drift_stats(model_monitoring_job_2.name)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgZfvZMu74xy"
      },
      "source": [
        "### Step 7: Schedule Continous Model Monitoring\n",
        "\n",
        "To set up continous model monitoring, follow the example below to create a schedule. You can create multiple schedules for your model monitor.\n",
        "\n",
        "\n",
        "The following example monitors drift in both input features and prediction outputs. The schedule is configured to activate the model monitoring job every hour on the hour, such as at 00:00, 01:00, and so on. Each job analyzes data from the preceding one-hour window. For instance, if a job is scheduled for 6:00 a.m., it analyzes the data collected from 5:00 a.m. to 6:00 a.m."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18FjuOW17__w"
      },
      "outputs": [],
      "source": [
        "# Every 1 hour at :00, for example 1:00, 2:00..\n",
        "CRON = \"0 * * * *\"  # @param {type:\"string\"}\n",
        "SCHEDULE_DISPLAY_NAME = \"penguins-continous-drift-detection\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oGOig5y8BNI"
      },
      "outputs": [],
      "source": [
        "model_monitoring_schedule = my_model_monitor.create_schedule(\n",
        "    display_name=SCHEDULE_DISPLAY_NAME,\n",
        "    cron=CRON,\n",
        "    baseline_dataset=ml_monitoring.spec.MonitoringInput(\n",
        "        table_uri=f\"bq://{PROJECT_ID}.{FAKE_DATA_BQ_TABLE}\",\n",
        "        timestamp_field=\"timestamp\",\n",
        "        window=\"1h\",\n",
        "        offset=\"1h\",\n",
        "    ),\n",
        "    target_dataset=ml_monitoring.spec.MonitoringInput(\n",
        "        table_uri=f\"bq://{PROJECT_ID}.{FAKE_DATA_BQ_TABLE}\",\n",
        "        timestamp_field=\"timestamp\",\n",
        "        window=\"1h\",\n",
        "    ),\n",
        "    tabular_objective_spec=ml_monitoring.spec.TabularObjective(\n",
        "        # Input feature drift spec.\n",
        "        feature_drift_spec=FEATURE_DRIFT_SPEC,\n",
        "        # Prediction output drift spec.\n",
        "        prediction_output_drift_spec=PREDICTION_OUTPUT_DRIFT_SPEC,\n",
        "    ),\n",
        "    notification_spec=ml_monitoring.spec.NotificationSpec(\n",
        "        user_emails=[EMAIL],\n",
        "    ),\n",
        "    output_spec=ml_monitoring.spec.OutputSpec(gcs_base_dir=BUCKET_URI),\n",
        ")\n",
        "\n",
        "SCHEDULE_RESOURCE_NAME = model_monitoring_schedule.name\n",
        "print(f\"Schedule {SCHEDULE_RESOURCE_NAME} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEPsa1ZhyYMc"
      },
      "source": [
        "#### Pause Schedule\n",
        "\n",
        "Run the following to pause the model monitoring schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ryjUl5DyZQN"
      },
      "outputs": [],
      "source": [
        "my_model_monitor.pause_schedule(SCHEDULE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0UF10HQyazl"
      },
      "source": [
        "#### Resume Schedule\n",
        "\n",
        "Run the following to resume a paused model monitoring schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STc5QWGnydEy"
      },
      "outputs": [],
      "source": [
        "my_model_monitor.resume_schedule(SCHEDULE_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-NNTbacyezA"
      },
      "source": [
        "#### Update Schedule\n",
        "\n",
        "Run the following to update the model monitoring schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXRYWEDNygR4"
      },
      "outputs": [],
      "source": [
        "# Update to run every 1 hour at :30, for example 0:30, 1:30, 2:00..\n",
        "my_model_monitor.update_schedule(\n",
        "    schedule_name=SCHEDULE_RESOURCE_NAME, cron=\"30 * * * *\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWB251IR8Jn2"
      },
      "source": [
        "#### Check monitoring schedules in Google Cloud Console\n",
        "\n",
        "To check your Model Monitoring schedule in the Google Cloud Console, go to the Monitor tab under Vertex AI.\n",
        "\n",
        "<img src=\"https://services.google.com/fh/files/misc/place_holder_schedules.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hovSbsmBmEKZ"
      },
      "source": [
        "### Step 8: Clean Up\n",
        "\n",
        "If you no longer need your model monitoring resources, run the following to delete them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejHg5PqiJPS2"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# When no jobs are running, delete the model monitor.\n",
        "my_model_monitor.delete(force=True)\n",
        "\n",
        "# Delete the model.\n",
        "model.delete()\n",
        "\n",
        "# Delete BQ logging table.\n",
        "bqclient = bigquery.Client(project=PROJECT_ID)\n",
        "# Delete the dataset (including all tables)\n",
        "bqclient.delete_dataset(FAKE_DATA_BQ_DATASET, delete_contents=True, not_found_ok=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_monitoring_for_model_outside_vertex.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
