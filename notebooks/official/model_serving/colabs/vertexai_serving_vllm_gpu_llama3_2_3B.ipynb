{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3981913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20920685",
   "metadata": {},
   "source": [
    "# Serving Open Models on Vertex AI using vLLM with GPU\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/model_serving/vertexai_serving_gpu.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fmodel_serving%2Fvertexai_serving_gpu.ipynb\">\n",
    "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_serving/vertexai_serving_gpu.ipynb\">\n",
    "      <img alt=\"GitHub logo\" src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" width=\"32px\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfac792-8eb1-42a9-a830-92535b329a72",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "There are multiple ways of serving open models such as Llama 3.2 on Google Cloud Vertex AI Platform. The Llama models are available in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama) and Model Garden allows a single click self-deployment of the models. This notebooks demonstrates how open models can be served via Vertex AI Endpoint using a custom vLLM container image built for the GPU. This notebook does the following:\n",
    "\n",
    "- Builds a custom docker container image using customized vLLM source code\n",
    "- Uploads the model to Model Registry using custom docker container image\n",
    "- Creates a public Endpoint for Online Prediction\n",
    "- Deploys model to the Endpoint\n",
    "- Llama 3.2 3B model is downloaded from Hugging Face during deployment\n",
    "\n",
    "The code in this notebook can be used for serving other open models supported by vLLM. This notebook has been tested with Python 3.10 and the latest version of `google-cloud-aiplatform` SDK, which currently is `1.101.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a3295-1af5-4b82-99e3-767f20acaecc",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e32f5b-3ace-4164-acc6-90fa26d1804a",
   "metadata": {},
   "source": [
    "### Install Vertex AI SDK for Python and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f217c8-fbe1-428d-b7b3-8cc85c24ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet google-cloud-aiplatform==1.101.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3659b67-d2ba-498f-a1be-a7489bbc653f",
   "metadata": {},
   "source": [
    "### Restart runtime (Colab only)\n",
    "\n",
    "To use the newly installed packages, you must restart the runtime on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e9a3b-fcce-4178-a427-314ea89c66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5c6ae-7562-4c61-bd8f-e4ea4531fc6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ab584-8b24-4a3e-a20d-8da00c583cda",
   "metadata": {},
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "Authenticate your environment on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5dfa5-809d-4f4f-82aa-f2387b334cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b71278-3741-4de4-8d7f-de38d5dd3925",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4cb54d-9b07-4689-aee5-9b611b7bfc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3ab69-cf2e-4fe5-b7c1-304a10bea4ea",
   "metadata": {},
   "source": [
    "## Create vLLM Customer Container Image for Vertex AI\n",
    "\n",
    "Vertex AI requires [requests](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#inference) and [responses](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#response_requirements) in specific formats. vLLM API server implements OpenAI API protocol and therefore, it does not support the Vertex AI request and response requirements. Therefore, the vLLM API server (vllm.entrypoints.openai.api_server.py) needs to be updated to support Vertex AI request and response formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf3bc7-57cf-4e93-a5a4-8f5af82d92b8",
   "metadata": {},
   "source": [
    "### Enable Artifact Registry API\n",
    "Enable the Artifact Registry API service for the Google cloud project. This tutorial requires [gcloud CLI](https://cloud.google.com/sdk/docs/install) installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9d41b-66ae-42f4-a47e-9883be841459",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud components update --quiet && gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7633a-8a61-4df8-ab24-26991b7bbb2f",
   "metadata": {},
   "source": [
    "### Create a private Docker repository\n",
    "Create a Docker repository in [Artifact Registry](https://cloud.google.com/artifact-registry/docs/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00709ce1-fe2f-42aa-bc57-8696a24d0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_REPOSITORY = \"my-docker-repo\"\n",
    "! gcloud artifacts repositories create {DOCKER_REPOSITORY} --repository-format=docker --location={LOCATION} --description=\"Vertex AI Docker repository\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb7446-ee74-4cd3-9283-01363b15760a",
   "metadata": {},
   "source": [
    "### Build vLLM Custom Docker Container Image for GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d38615-33c9-4b15-a180-a4de324bff7d",
   "metadata": {},
   "source": [
    "Build docker container image from vLLM source.\n",
    "\n",
    "**NOTE:** Building container image from a notebook/colab may cause python kernel crash, run the following commands from a shell instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f574b78-1dc4-44d7-aa76-109965b86d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_URI = f\"{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{DOCKER_REPOSITORY}/vllm-gcp-gpu\"\n",
    "! cd docker && docker build -f Dockerfile.gpu -t {DOCKER_URI} ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52202744-f90d-45bf-a487-c2464bc020e2",
   "metadata": {},
   "source": [
    "Configure the [authentication for Google Artifact Registry's Docker repository](https://cloud.google.com/artifact-registry/docs/docker/pushing-and-pulling#auth) before pushing the container image to the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5041fcf-3a09-4d88-a758-7d1688231bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {LOCATION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1c005-3567-4204-b566-22c8e2029826",
   "metadata": {},
   "source": [
    "Push docker container image to Artifact Registry repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df183e89-da69-4a40-a344-02849ee5d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker push {DOCKER_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c9c24-4682-4efb-b40c-47e9751ce043",
   "metadata": {},
   "source": [
    "## Deploy Model to Vertex AI Endpoint\n",
    "\n",
    "Following steps are required to serve model via a Vertex AI Prediction Endpoint:\n",
    "- import model to model registry\n",
    "- create a Online Prediction Endpoint\n",
    "- Deploy the model to endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579cf66-73d7-4a7d-ad63-83e864c72492",
   "metadata": {},
   "source": [
    "### Define Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baeae0-3cf8-4574-96bd-be95848eccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"[your-hugging-face-auth-token]\"  # @param {type:\"string\"}\n",
    "model_name=\"gpu-llama3_2_3B-serve-vllm\"  # @param {type:\"string\"}\n",
    "model_id = \"meta-llama/Llama-3.2-3B\"  # @param {type:\"string\"}\n",
    "machine_type = \"g2-standard-8\"  # @param {type:\"string\"}\n",
    "accelerator_type = \"NVIDIA_L4\"  # @param {type:\"string\"}\n",
    "accelerator_count = 1  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de003a84-728d-438b-8be6-d1e83317ba30",
   "metadata": {},
   "source": [
    "### Import model to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37f2fd-7aeb-4c0b-9cd8-07d0016a3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "def upload_model(\n",
    "    model_name: str,\n",
    "    model_id: str,\n",
    "    hf_token: str,\n",
    "    accelerator_count: int,\n",
    ") -> aiplatform.Model:\n",
    "\n",
    "    vllm_args = [\n",
    "        \"python\",\n",
    "        \"-m\",\n",
    "        \"vllm.entrypoints.openai.api_server\",\n",
    "        \"--host=0.0.0.0\",\n",
    "        \"--port=8080\",\n",
    "        f\"--model={model_id}\",\n",
    "        \"--max-model-len=2048\",\n",
    "        \"--gpu-memory-utilization=0.9\",\n",
    "        \"--enable-prefix-caching\",\n",
    "        f\"--tensor-parallel-size={accelerator_count}\",\n",
    "    ]\n",
    "\n",
    "    env_vars = {\n",
    "        \"HF_TOKEN\": hf_token,        \n",
    "    }\n",
    "    \n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=DOCKER_URI,\n",
    "        serving_container_args=vllm_args,\n",
    "        serving_container_ports=[8080],\n",
    "        serving_container_predict_route=\"/v1/completions\",\n",
    "        serving_container_health_route=\"/health\",\n",
    "        serving_container_environment_variables=env_vars,\n",
    "        serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n",
    "        serving_container_deployment_timeout=1800,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "vertexai_model = upload_model(model_name=model_name, model_id=model_id, hf_token=hf_token, accelerator_count=int(accelerator_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abeab45-c832-485f-8ad8-d42f76bacedf",
   "metadata": {},
   "source": [
    "### Create Vertex AI Endpoint for Online Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47f481-83fc-4cb4-af1f-09eb0fa26743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_endpoint(model_name: str) -> aiplatform.Endpoint:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "            display_name=f\"{model_name}-endpoint\",\n",
    "            dedicated_endpoint_enabled=False,\n",
    "        )\n",
    "    return endpoint\n",
    "\n",
    "vertexai_endpoint = create_model_endpoint(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391717e2-2a87-4b81-aa89-bdc596740392",
   "metadata": {},
   "source": [
    "### Deploy Model to Endpoint\n",
    "**NOTE**: The model deployment may take around 30 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af7d62-68fb-49ad-8069-c5f51d585ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model(\n",
    "    model: aiplatform.Model,\n",
    "    endpoint: aiplatform.Endpoint,\n",
    "    model_name: str,\n",
    "    machine_type: str,\n",
    "    accelerator_type: str,\n",
    "    accelerator_count: int,\n",
    "):\n",
    "    print(f\"Deploying {model_name} to endpoint: {endpoint.resource_name} using machine type: {machine_type}\")\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=model_name,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        traffic_percentage=100,\n",
    "        deploy_request_timeout=1800,\n",
    "    )\n",
    "\n",
    "deploy_model(\n",
    "    model=vertexai_model,\n",
    "    endpoint=vertexai_endpoint,\n",
    "    model_name=model_name,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=int(accelerator_count),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557b786-07db-47e6-94d7-7b905ccbdae9",
   "metadata": {},
   "source": [
    "## Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6a1ef-d13c-4b27-8822-20dcf1b2ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = (\n",
    "    \"Distance of moon from earth is \"\n",
    ")\n",
    "\n",
    "instances = [\n",
    "    {\n",
    "        \"prompt\": PROMPT,\n",
    "        \"temperature\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "response = vertexai_endpoint.predict(instances=instances)\n",
    "\n",
    "for prediction in response.predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aea34-3e7e-4c8a-98a9-9f4aed38dfe2",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, delete the resources created in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60332fef-fc3e-49c0-b5db-469769f42ca0",
   "metadata": {},
   "source": [
    "### Delete private docker repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b0e37-494a-4b2f-ba73-785f88f95032",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories delete {DOCKER_REPOSITORY} --location={LOCATION} --quiet"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
