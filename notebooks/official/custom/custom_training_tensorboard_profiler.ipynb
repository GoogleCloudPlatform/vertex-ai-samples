{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2mMvIUG9meX"
      },
      "source": [
        "# Profile model training performance using Profiler\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-training-tensorboard-profiler.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-training-tensorboard-profiler.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        " <td>\n",
        "    <a href=\"https://console.cloud.google.com/ai/platform/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/main/notebooks/official/custom/custom-training-tensorboard-profiler.ipynb\">\n",
        "        <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to enable Vertex AI TensorBoard Profiler so you can debug model training performance for your custom training jobs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfXf0r-K81Y-"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the [mnist dataset](https://www.tensorflow.org/datasets/catalog/mnist) from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmfmQL6w84pS"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to enable Vertex AI TensorBoard Profiler for custom training jobs.\n",
        "\n",
        "This tutorial uses the following Google Cloud AI services:\n",
        "\n",
        "- `Vertex AI Training`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Setup a service account and a Cloud Storage bucket\n",
        "- Create a TensorBoard instance\n",
        "- Create and run a custom training job\n",
        "- View the TensorBoard Profiler dashboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3KFLvpq87rs"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4-nDLfK4pw"
      },
      "source": [
        "### Set up your local development environment\n",
        "\n",
        "**If you are using Colab or Vertex AI Workbench Notebooks**, your environment already meets\n",
        "all the requirements to run this notebook. You can skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCuSR8GkAgzl"
      },
      "source": [
        "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
        "You need the following:\n",
        "\n",
        "* The Google Cloud SDK\n",
        "* Git\n",
        "* Python 3\n",
        "* virtualenv\n",
        "* Jupyter notebook running in a virtual environment with Python 3\n",
        "\n",
        "The Google Cloud guide to [Setting up a Python development\n",
        "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
        "installation guide](https://jupyter.org/install) provide detailed instructions\n",
        "for meeting these requirements. The following steps provide a condensed set of\n",
        "instructions:\n",
        "\n",
        "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
        "\n",
        "1. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
        "\n",
        "1. [Install\n",
        "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
        "   and create a virtual environment that uses Python 3. Activate the virtual environment.\n",
        "\n",
        "1. To install Jupyter, run `pip3 install jupyter` on the\n",
        "command-line in a terminal shell.\n",
        "\n",
        "1. To launch Jupyter, run `jupyter notebook` on the command-line in a terminal shell.\n",
        "\n",
        "1. Open this notebook in the Jupyter Notebook Dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "Install the following packages required to execute this notebook. \n",
        "\n",
        "- Ensure that you're using Tensorflow 2.4 or a later version.\n",
        "- Install the Vertex AI SDK with the cloud-profiler plugin. From your local Docker container, run `pip install google-cloud-aiplatform[cloud_profiler]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asm0sNIRjz6b"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade tensorflow {USER_FLAG} -q\n",
        "! pip3 install --upgrade google-cloud-aiplatform[cloud_profiler] {USER_FLAG} -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEdiXsJg0XY"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr--iN2kAylZ"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Vertex AI Workbench Notebooks**, your environment is already\n",
        "authenticated. Skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "1. In the Cloud Console, go to the [**Create service account key**\n",
        "   ](https://console.cloud.google.com/apis/credentials/serviceaccountkey) page.\n",
        "\n",
        "2. Click **Create service account**.\n",
        "\n",
        "3. In the **Service account name** field, enter a name, and\n",
        "   click **Create**.\n",
        "\n",
        "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"Vertex AI\"\n",
        "into the filter box, and select\n",
        "   **Vertex AI Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "5. Click *Create*. A JSON file that contains your key downloads to your\n",
        "local environment.\n",
        "\n",
        "6. Enter the path to your service account key as the\n",
        "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
        "    \"DL_ANACONDA_HOME\"\n",
        "):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYoRfYng0XZ"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riG_qUokg0XZ"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_gcloud_project_id"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWHp43-vHVgL"
      },
      "source": [
        "##### Get your project number\n",
        "\n",
        "Now that the project ID is set, you get your corresponding project number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMAT0gATHe1V"
      },
      "outputs": [],
      "source": [
        "shell_output = ! gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "PROJECT_NUMBER = shell_output[0]\n",
        "print(\"Project number:\", PROJECT_NUMBER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmPv1dw33srh"
      },
      "outputs": [],
      "source": [
        "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
        "\n",
        "if REGION == \"[your-region]\":\n",
        "    REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06571eb4063b"
      },
      "source": [
        "#### Timestamp\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "697568e92bd6"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8jPMDYIL4kc"
      },
      "source": [
        "#### Enable the Vertex AI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T-khaOxMBql"
      },
      "outputs": [],
      "source": [
        "! gcloud services enable aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG2B3DOwlNgQ"
      },
      "source": [
        "#### Set Vertex AI API endpoint\n",
        "Setup up the following constants for Vertex AI API:\n",
        "\n",
        "- `API_ENDPOINT`: The Vertex AI API service endpoint for dataset, model, job, pipeline and endpoint services.\n",
        "- `PARENT`: The Vertex AI location root path for dataset, model, job, pipeline and endpoint resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrTS-nqCNRoP"
      },
      "outputs": [],
      "source": [
        "# Vertex AI API service endpoint\n",
        "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
        "\n",
        "# Vertex AI location root path for your dataset, model and endpoint resources\n",
        "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "When you submit a training job using the Cloud SDK, you upload a Python package containing your training code to a Cloud Storage bucket. Vertex AI runs the code from this package. The Cloud Storage bucket is also used to store TensorBoard logs generated by your training jobs.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all Cloud Storage buckets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf221059d072"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
        "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucvCsknMCims"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhOb7YnwClBb"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "set_service_account"
      },
      "source": [
        "### Set up your service account\n",
        "\n",
        "The Vertex AI TensorBoard integration with custom training requires attaching a service account with the Storage Admin role (roles/storage.admin) and Vertex AI User role (roles/aiplatform.user)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZtfI9tKATVT"
      },
      "source": [
        "#### Set your service account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV1hNT8qbcY2"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT_NAME = \"[your-service-account]\"  # @param {type:\"string\"}\n",
        "SERVICE_ACCOUNT_EMAIL = \"{}@{}.iam.gserviceaccount.com\".format(\n",
        "    SERVICE_ACCOUNT_NAME[0:30], PROJECT_ID\n",
        ")\n",
        "\n",
        "print(\"Service account name: \", SERVICE_ACCOUNT_NAME)\n",
        "print(\"Service account email: \", SERVICE_ACCOUNT_EMAIL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autoset_service_account"
      },
      "outputs": [],
      "source": [
        "if (\n",
        "    SERVICE_ACCOUNT_NAME == \"\"\n",
        "    or SERVICE_ACCOUNT_NAME is None\n",
        "    or SERVICE_ACCOUNT_NAME == \"[your-service-account]\"\n",
        "):\n",
        "    # Get your service account from gcloud\n",
        "    if not IS_COLAB:\n",
        "        shell_output = ! gcloud auth list 2>/dev/null\n",
        "        SERVICE_ACCOUNT_EMAIL = shell_output[2].replace(\"*\", \"\").strip()\n",
        "\n",
        "    else:  # IS_COLAB:\n",
        "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
        "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "        SERVICE_ACCOUNT_EMAIL = (\n",
        "            f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "        )\n",
        "\n",
        "    print(\"Service account email:\", SERVICE_ACCOUNT_EMAIL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmYVMGNOJHVo"
      },
      "source": [
        "#### Set service account access for Vertex AI TensorBoard integration\n",
        "\n",
        "Run the following commands to grant your service account access to the Storage Admin role (roles/storage.admin) and Vertex AI User role (roles/aiplatform.user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esTwuE_W-WXt"
      },
      "outputs": [],
      "source": [
        "! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "   --member=\"serviceAccount:{SERVICE_ACCOUNT_EMAIL}\" \\\n",
        "   --role=\"roles/storage.admin\" \\\n",
        "   --quiet\n",
        "\n",
        "! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "   --member=\"serviceAccount:{SERVICE_ACCOUNT_EMAIL}\" \\\n",
        "   --role=\"roles/aiplatform.user\" \\\n",
        "   --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRUOFELefqf1"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cChm5w3j3srj"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHUW20OnjrEw"
      },
      "source": [
        "#### Set hardware accelerators\n",
        "\n",
        "You can set hardware accelerators for training.\n",
        "\n",
        "Set the variables `TRAIN_GPU/TRAIN_NGPU` to use a container image supporting a GPU and the number of GPUs allocated to the virtual machine (VM) instance. For example, to use a GPU container image with 4 Nvidia Tesla K80 GPUs allocated to each VM, you would specify:\n",
        "\n",
        "    (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
        "\n",
        "See the [locations where accelerators are available](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators).\n",
        "\n",
        "Otherwise specify `(None, None)` to use a container image to run on a CPU.\n",
        "\n",
        "*Note*: TensorFlow releases earlier than 2.3 for GPU support fail to load the custom model in this tutorial. This issue is caused by static graph operations that are generated in the serving function. This is a known issue, which is fixed in TensorFlow 2.3. If you encounter this issue with your own custom models, use a container image for TensorFlow 2.3 or later with GPU support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52UoZKMBjx3I"
      },
      "outputs": [],
      "source": [
        "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
        "    TRAIN_GPU, TRAIN_NGPU = (\n",
        "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
        "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
        "    )\n",
        "else:\n",
        "    TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
        "\n",
        "if os.getenv(\"IS_TESTING_DEPOLY_GPU\"):\n",
        "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
        "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
        "        int(os.getenv(\"IS_TESTING_DEPOLY_GPU\")),\n",
        "    )\n",
        "else:\n",
        "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4wlRWnJj4aR"
      },
      "source": [
        "#### Set pre-built containers\n",
        "\n",
        "\n",
        "Set the pre-built Docker container image for training and prediction.\n",
        "\n",
        "\n",
        "For the latest list, see [Pre-built containers for training](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers).\n",
        "\n",
        "For the latest list, see [Pre-built containers for prediction](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SYq7K0VcYTg"
      },
      "outputs": [],
      "source": [
        "if os.getenv(\"IS_TESTING_TF\"):\n",
        "    TF = os.getenv(\"IS_TESTING_TF\")\n",
        "else:\n",
        "    TF = \"2-4\"\n",
        "\n",
        "if TF[0] == \"2\":\n",
        "    if TRAIN_GPU:\n",
        "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
        "    else:\n",
        "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
        "    if DEPLOY_GPU:\n",
        "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
        "    else:\n",
        "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
        "else:\n",
        "    if TRAIN_GPU:\n",
        "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
        "    else:\n",
        "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
        "    if DEPLOY_GPU:\n",
        "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
        "    else:\n",
        "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
        "\n",
        "TRAIN_IMAGE = \"gcr.io/cloud-aiplatform/training/{}:latest\".format(TRAIN_VERSION)\n",
        "DEPLOY_IMAGE = \"gcr.io/cloud-aiplatform/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
        "\n",
        "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
        "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxXRyjiqkKuI"
      },
      "source": [
        "#### Set machine types\n",
        "\n",
        "Next, set the machine types to use for training.\n",
        "\n",
        "- Set the variables `TRAIN_COMPUTE` to configure your compute resources for training and prediction.\n",
        " - `machine type`\n",
        "     - `n1-standard`: 3.75GB of memory per vCPU\n",
        "     - `n1-highmem`: 6.5GB of memory per vCPU\n",
        "     - `n1-highcpu`: 0.9 GB of memory per vCPU\n",
        " - `vCPUs`: number of \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
        "\n",
        "*Note: The following is not supported for training:*\n",
        "\n",
        " - `standard`: 2 vCPUs\n",
        " - `highcpu`: 2, 4 and 8 vCPUs\n",
        "\n",
        "*Note: You may also use n2 and e2 machine types for training, but they do not support GPUs*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJiBYnScdFrK"
      },
      "outputs": [],
      "source": [
        "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
        "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
        "else:\n",
        "    MACHINE_TYPE = \"n1-standard\"\n",
        "\n",
        "VCPU = \"4\"\n",
        "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
        "print(\"Train machine type\", TRAIN_COMPUTE)\n",
        "\n",
        "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
        "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
        "else:\n",
        "    MACHINE_TYPE = \"n1-standard\"\n",
        "\n",
        "VCPU = \"4\"\n",
        "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
        "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ayTbNdi62_t"
      },
      "source": [
        "## Create a TensorBoard instance\n",
        "\n",
        "A Vertex AI TensorBoard instance, which is a regionalized resource storing your Vertex AI TensorBoard experiments, must be created before the experiments can be visualized. You can create multiple instances in a project. You can use command  `gcloud ai tensorboards list` to get a list of your existing TensorBoard instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c3QrDTZdaxk"
      },
      "source": [
        "#### Set your TensorBoard instance display name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azlwb__AX8gs"
      },
      "outputs": [],
      "source": [
        "TENSORBOARD_DISPLAY_NAME = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJrWKK0mY7H7"
      },
      "source": [
        "**Only if your TensorBoard instance doesn't already exist**: Run the following cell to create your TensorBoard instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGN2WnjNYXRz"
      },
      "outputs": [],
      "source": [
        "! gcloud ai tensorboards create --display-name {TENSORBOARD_DISPLAY_NAME} \\\n",
        "  --project {PROJECT_ID} \\\n",
        "  --region {REGION}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dECoKEBcsfu"
      },
      "source": [
        "Now that your TensorBoard instance is created, you get the corresponding ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1iO2FZgeJ10"
      },
      "outputs": [],
      "source": [
        "shell_output = ! gcloud ai tensorboards list --filter=\"displayName:'{TENSORBOARD_DISPLAY_NAME}'\"\\\n",
        "                  --region {REGION} --format='value(name)'\n",
        "TENSORBOARD_ID = shell_output[1].split(\"/\")[-1]\n",
        "TENSORBOARD_INSTANCE_NAME=\"projects/{}/locations/{}/tensorboards/{}\".format(PROJECT_NUMBER, REGION, TENSORBOARD_ID)\n",
        "\n",
        "print(\"TensorBoard instance ID:\", TENSORBOARD_ID)\n",
        "print(\"TensorBoard instance name:\", TENSORBOARD_INSTANCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoR29gW2S24w"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "There are two ways you can train a custom model using a container image:\n",
        "\n",
        "- **Use a Google Cloud prebuilt container**. If you use a prebuilt container, you will additionally specify a Python package to install into the container image. This Python package contains your code for training a custom model.\n",
        "\n",
        "- **Use your own custom container image**. If you use your own container, the container needs to contain your code for training a custom model.\n",
        "\n",
        "In this tutorial, we will train a custom model using a Google Cloud prebuild container."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AMH7MpcjPsi"
      },
      "source": [
        "### Prepare your custom job specification\n",
        "\n",
        "You create a Job Specification for your custom training job. The job specification will consist of the following:\n",
        "\n",
        "- `worker_pool_spec` : The specification of the type of machine(s) you will use for training and how many (single or distributed)\n",
        "- `python_package_spec` : The specification of the Python package to be installed with the pre-built container.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78aBKF2zluGJ"
      },
      "source": [
        "#### Prepare your machine specification\n",
        "\n",
        "Now define the machine specification for your custom training job. This tells Vertex AI what type of machine instance to provision for the training.\n",
        "  - `machine_type`: The type of GCP instance to provision -- e.g., n1-standard-8.\n",
        "  - `accelerator_type`: The type, if any, of hardware accelerator. In this tutorial if you previously set the variable `TRAIN_GPU != None`, you are using a GPU; otherwise you will use a CPU.\n",
        "  - `accelerator_count`: The number of accelerators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yNkfXM3eTQN"
      },
      "outputs": [],
      "source": [
        "if TRAIN_GPU:\n",
        "    machine_spec = {\n",
        "        \"machine_type\": TRAIN_COMPUTE,\n",
        "        \"accelerator_type\": TRAIN_GPU,\n",
        "        \"accelerator_count\": TRAIN_NGPU,\n",
        "    }\n",
        "else:\n",
        "    machine_spec = {\"machine_type\": TRAIN_COMPUTE, \"accelerator_count\": 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zW84LmKl30z"
      },
      "source": [
        "#### Define the worker pool specification\n",
        "\n",
        "Next, you define the worker pool specification for your custom training job. The worker pool specification will consist of the following:\n",
        "\n",
        "- `replica_count`: The number of instances to provision of this machine type.\n",
        "- `machine_spec`: The hardware specification.\n",
        "- `disk_spec` : (optional) The disk storage specification.\n",
        "\n",
        "- `python_package`: The Python training package to install on the VM instance(s) and which Python module to invoke, along with command line arguments for the Python module.\n",
        "\n",
        "Let's dive deeper now into the python package specification:\n",
        "\n",
        "-`executor_image_spec`: This is the docker image which is configured for your custom training job.\n",
        "\n",
        "-`package_uris`: This is a list of the locations (URIs) of your python training packages to install on the provisioned instance. The locations need to be in a Cloud Storage bucket. These can be either individual python files or a zip (archive) of an entire package. In the later case, the job service will unzip (unarchive) the contents into the docker image.\n",
        "\n",
        "-`python_module`: The Python module (script) to invoke for running the custom training job. In this example, you will be invoking `trainer.task.py` -- note that it was not necessary to append the `.py` suffix.\n",
        "\n",
        "-`args`: The command line arguments to pass to the corresponding Python module. In this example, you will be setting:\n",
        "  - `\"--epochs=\" + EPOCHS`: The number of epochs for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfMGibrWexv1"
      },
      "outputs": [],
      "source": [
        "JOB_NAME = \"custom_job_\" + TIMESTAMP\n",
        "BASE_OUTPUT_DIR = \"{}/{}\".format(BUCKET_URI, JOB_NAME)\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "CMDARGS = [\n",
        "    \"--epochs=\" + str(EPOCHS),\n",
        "]\n",
        "\n",
        "worker_pool_spec = [\n",
        "    {\n",
        "        \"replica_count\": 1,\n",
        "        \"machine_spec\": machine_spec,\n",
        "        \"python_package_spec\": {\n",
        "            \"executor_image_uri\": TRAIN_IMAGE,\n",
        "            \"package_uris\": [BUCKET_URI + \"/trainer_mnist.tar.gz\"],\n",
        "            \"python_module\": \"trainer.task\",\n",
        "            \"args\": CMDARGS,\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlKF1oyTl8iX"
      },
      "source": [
        "#### Assemble a job specification\n",
        "\n",
        "Now assemble the complete description for the custom job specification:\n",
        "\n",
        "- `display_name`: The human readable name you assign to this custom job.\n",
        "- `job_spec`: The specification for the custom job.\n",
        "    - `worker_pool_specs`: The specification for the machine VM instances.\n",
        "    - `base_output_directory`: This tells the service where you want to store the Vertex AI TensorBoard logs that's generated by your training script.\n",
        "    - `service_account`:  The service account that you created with roles/storage.admin and roles/aiplatform.user roles.\n",
        "    - `tensorboard`: the fully qualified name of the Vertex AI TensorBoard instance that you want to use with this training job. The fully qualified name has the following format:\n",
        "\n",
        "      `projects/PROJECT_NUMBER_OR_ID/locations/REGION/tensorboards/TENSORBOARD_INSTANCE_ID`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ciib_Q9veyFj"
      },
      "outputs": [],
      "source": [
        "job_spec = {\n",
        "    \"worker_pool_specs\": worker_pool_spec,\n",
        "    \"base_output_directory\": {\"output_uri_prefix\": BASE_OUTPUT_DIR},\n",
        "    \"tensorboard\": TENSORBOARD_INSTANCE_NAME,\n",
        "    \"service_account\": SERVICE_ACCOUNT_EMAIL,\n",
        "}\n",
        "\n",
        "custom_job = {\"display_name\": JOB_NAME, \"job_spec\": job_spec}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEbNcvYwmDRH"
      },
      "source": [
        "### Examine the training package\n",
        "\n",
        "#### Package layout\n",
        "\n",
        "Before you start the training, you will look at how a Python package is assembled for a custom training job. When unarchived, the package contains the following directory/file layout.\n",
        "\n",
        "- PKG-INFO\n",
        "- README.md\n",
        "- setup.cfg\n",
        "- setup.py\n",
        "- trainer\n",
        "  - \\_\\_init\\_\\_.py\n",
        "  - task.py\n",
        "\n",
        "The files `setup.cfg` and `setup.py` are the instructions for installing the package into the operating environment of the Docker image.\n",
        "\n",
        "The file `trainer/task.py` is the Python script for executing the custom training job. *Note*, when we referred to it in the worker pool specification, we replace the directory slash with a dot (`trainer.task`) and dropped the file suffix (`.py`).\n",
        "\n",
        "#### Package Assembly\n",
        "\n",
        "In the following cells, you will assemble the training package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDilgzPGeyKs"
      },
      "outputs": [],
      "source": [
        "# Make folder for Python training script\n",
        "! rm -rf custom\n",
        "! mkdir custom\n",
        "\n",
        "# Add package information\n",
        "! touch custom/README.md\n",
        "\n",
        "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
        "! echo \"$setup_cfg\" > custom/setup.cfg\n",
        "\n",
        "pkg_info = \"Metadata-Version: 1.0\\n\\nName: MNIST image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demonstration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: \\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
        "! echo \"$pkg_info\" > custom/PKG-INFO\n",
        "\n",
        "# Make the training subfolder\n",
        "! mkdir custom/trainer\n",
        "! touch custom/trainer/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUdYmL3txmcq"
      },
      "outputs": [],
      "source": [
        "%%writefile ./custom/setup.py\n",
        "\n",
        "import setuptools\n",
        "\n",
        "setuptools.setup(\n",
        "    install_requires=[\n",
        "                    'tensorflow==2.4',\n",
        "                    'google-cloud-aiplatform[cloud_profiler]',\n",
        "                    'protobuf==3.19',\n",
        "                    ],\n",
        "    packages=setuptools.find_packages()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyAwgsoQmaYI"
      },
      "source": [
        "### Prepare the training script\n",
        "\n",
        "Your training code must be configured to write TensorBoard logs to the Cloud Storage bucket, the location of which the Vertex AI Training Service will automatically make available via a predefined environment variable `AIP_TENSORBOARD_LOG_DIR`. \n",
        "\n",
        "This can usually be done by providing `os.environ['AIP_TENSORBOARD_LOG_DIR']` as the log directory to the open source TensorBoard log writing APIs. \n",
        "\n",
        "For example, in TensorFlow 2.x, you can use following code to create a tensorboard_callback: \n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard( \n",
        "      log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'], \n",
        "      histogram_freq=1) \n",
        "`AIP_TENSORBOARD_LOG_DIR` will be in the `BASE_OUTPUT_DIR` that you provided below when creating the custom training job. \n",
        "\n",
        "To enable Vertex AI TensorBoard Profiler for your training job, add the following to your training script:\n",
        "\n",
        "Add the cloud_profiler import at your top level imports:\n",
        "\n",
        "    from google.cloud.aiplatform.training_utils import cloud_profiler\n",
        "\n",
        "\n",
        "Initialize the cloud_profiler plugin by adding:\n",
        "\n",
        "\n",
        "    cloud_profiler.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JCgWW7Au1w8"
      },
      "outputs": [],
      "source": [
        "%%writefile custom/trainer/task.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import os\n",
        "from google.cloud.aiplatform.training_utils import cloud_profiler\n",
        "import time\n",
        "\n",
        "\"\"\"Train an mnist model and use cloud_profiler for profiling.\"\"\"\n",
        "\n",
        "def _create_model():\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(10),\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    strategy = None\n",
        "    if args.distributed:\n",
        "        strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "    if args.distributed:\n",
        "        strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "        with strategy.scope():\n",
        "            model = _create_model()\n",
        "            model.compile(\n",
        "                optimizer=\"adam\",\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=[\"accuracy\"],\n",
        "            )\n",
        "    else:\n",
        "        model = _create_model()\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "\n",
        "    # Initialize the profiler.\n",
        "    cloud_profiler.init()\n",
        "\n",
        "    # Use AIP_TENSORBOARD_LOG_DIR to update where logs are written to.\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "       log_dir=os.environ[\"AIP_TENSORBOARD_LOG_DIR\"], histogram_freq=1\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        epochs=args.epochs,\n",
        "        verbose=0,\n",
        "        callbacks=[tensorboard_callback],\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--epochs\", type=int, default=100, help=\"Number of epochs to run model.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--distributed\", action=\"store_true\", help=\"Use MultiWorkerMirroredStrategy\"\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_tXf3fSmijU"
      },
      "source": [
        "#### Store training script on your Cloud Storage bucket\n",
        "\n",
        "Next, you package the training folder into a compressed tar ball, and then store it in your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRnjp3X1e88l"
      },
      "outputs": [],
      "source": [
        "! rm -f custom.tar custom.tar.gz\n",
        "! tar cvf custom.tar custom\n",
        "! gzip custom.tar\n",
        "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_mnist.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4e6OYmimqTR"
      },
      "source": [
        "## Run the custom training job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59D9MLWtqfgD"
      },
      "source": [
        "#### Set up an API client\n",
        "\n",
        "The Vertex AI client library works as a client/server model. On your side (the Python script) you will create a client that sends requests and receives responses from the server.\n",
        "\n",
        "You will use `JobServiceClient` for custom training in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MONoG6aik0a"
      },
      "outputs": [],
      "source": [
        "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
        "\n",
        "client = aiplatform.gapic.JobServiceClient(client_options=client_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTJinFggnM96"
      },
      "source": [
        "### Create a custom training job\n",
        "\n",
        "Now start the training of your custom training job on Vertex AI. Use this helper function `create_custom_job`, which takes the following parameter:\n",
        "\n",
        "-`custom_job`: The specification for the custom job.\n",
        "\n",
        "The helper function calls job client service's `create_custom_job` method, with the following parameters:\n",
        "\n",
        "-`parent`: The Vertex location path to `Dataset`, `Model` and `Endpoint` resources.\n",
        "-`custom_job`: The specification for the custom job.\n",
        "\n",
        "You will display a handful of the fields returned in `response` object, with the two that are of most interest are:\n",
        "\n",
        "`response.name`: The Vertex fully qualified identifier assigned to this custom training job. You save this identifier for using in subsequent steps.\n",
        "\n",
        "`response.state`: The current state of the custom training job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQlzbWF8uqxb"
      },
      "outputs": [],
      "source": [
        "def create_custom_job(custom_job):\n",
        "    response = client.create_custom_job(parent=PARENT, custom_job=custom_job)\n",
        "    print(\"name:\", response.name)\n",
        "    print(\"display_name:\", response.display_name)\n",
        "    print(\"state:\", response.state)\n",
        "    print(\"create_time:\", response.create_time)\n",
        "    print(\"update_time:\", response.update_time)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6HBqDw6e9Av"
      },
      "outputs": [],
      "source": [
        "response = create_custom_job(custom_job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXZ0nPyne9Ea"
      },
      "outputs": [],
      "source": [
        "# The full unique ID for the custom job\n",
        "job_id = response.name\n",
        "\n",
        "# The short numeric ID for the custom job\n",
        "job_short_id = job_id.split(\"/\")[-1]\n",
        "\n",
        "print(job_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_vEmdc7nD0F"
      },
      "source": [
        "### Get information on a custom training job\n",
        "\n",
        "Next, use this helper function `get_custom_job`, which takes the following parameter:\n",
        "\n",
        "- `name`: The Vertex fully qualified identifier for the custom job.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj93F2V3uy-Q"
      },
      "outputs": [],
      "source": [
        "def get_custom_job(name, silent=False):\n",
        "    response = client.get_custom_job(name=name)\n",
        "    if silent:\n",
        "        return response\n",
        "\n",
        "    print(\"name:\", response.name)\n",
        "    print(\"display_name:\", response.display_name)\n",
        "    print(\"state:\", response.state)\n",
        "    print(\"create_time:\", response.create_time)\n",
        "    print(\"update_time:\", response.update_time)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AWS5SH3pQpp"
      },
      "outputs": [],
      "source": [
        "response = get_custom_job(job_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkEe2Nb_85UD"
      },
      "source": [
        "## View the TensorBoard Profiler dashboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cE5UCYgdRxx"
      },
      "source": [
        "When the job state switches to `JOB_STATE_RUNNING`, you can access the Vertex AI TensorBoard Profiler dashboard through the Custom jobs page or the Experiments page on the Google Cloud console. \n",
        "\n",
        "The Google Cloud guide to [Profile model training performance using Profiler](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-profiler) provides detailed instructions for accessing the Vertex AI TensorBoard Profiler dashboard and capturing a profiling session. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "- Training job\n",
        "- TensorBoard instance\n",
        "- Cloud Storage bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR-ZhQ9XwpRI"
      },
      "outputs": [],
      "source": [
        "delete_customjob = False\n",
        "delete_tensorboard = False\n",
        "delete_bucket = False\n",
        "\n",
        "try:\n",
        "    if delete_customjob and \"job_id\" in globals():\n",
        "        client.delete_custom_job(name=job_id)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "if delete_tensorboard and \"TENSORBOARD_ID\" in globals():\n",
        "    ! gcloud ai tensorboards delete {TENSORBOARD_ID}\n",
        "\n",
        "if delete_bucket and \"BUCKET_NAME\" in globals():\n",
        "    ! gsutil -m rm -r $BUCKET_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_training_tensorboard_profiler.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
