{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.S\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl-text-classification.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl-text-classification.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        " <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl-text-classification.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0259a7ce8120"
      },
      "source": [
        "# Vertex AI: Create, train, and deploy an AutoML text classification model\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook walks you through the major phases of building and using an AutoML text classification model on [Vertex AI](https://cloud.google.com/vertex-ai/docs/). \n",
        "\n",
        "### Dataset\n",
        "\n",
        "In this notebook, you use the \"Happy Moments\" sample dataset to train a model. The resulting model classifies happy moments into categores that reflect the causes of happiness. \n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to use `AutoML` to train a text classification model.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `AutoML Training`\n",
        "- `Vertex AI Model` resource\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Create a `Vertex AI Dataset`.\n",
        "* Train an `AutoML` text classification `Model` resource.\n",
        "* Obtain the evaluation metrics for the `Model` resource.\n",
        "* Create an `Endpoint` resource.\n",
        "* Deploy the `Model` resource to the `Endpoint` resource.\n",
        "* Make an online prediction\n",
        "* Make a batch prediction\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI Training and Serving\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEdiXsJg0XY"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "**Note:** This notebook does not require a GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5cb73702a9b"
      },
      "source": [
        "### Set up your local development environment\n",
        "\n",
        "**If you are using Colab or Workbench AI Notebooks**, your environment already meets\n",
        "all the requirements to run this notebook. You can skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCuSR8GkAgzl"
      },
      "source": [
        "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
        "You need the following:\n",
        "\n",
        "* The Google Cloud SDK\n",
        "* Git\n",
        "* Python 3\n",
        "* virtualenv\n",
        "* Jupyter notebook running in a virtual environment with Python 3\n",
        "\n",
        "The Google Cloud guide to [Setting up a Python development\n",
        "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
        "installation guide](https://jupyter.org/install) provide detailed instructions\n",
        "for meeting these requirements. The following steps provide a condensed set of\n",
        "instructions:\n",
        "\n",
        "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
        "\n",
        "1. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
        "\n",
        "1. [Install\n",
        "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
        "   and create a virtual environment that uses Python 3. Activate the virtual environment.\n",
        "\n",
        "1. To install Jupyter, run `pip install jupyter` on the\n",
        "command-line in a terminal shell.\n",
        "\n",
        "1. To launch Jupyter, run `jupyter notebook` on the command-line in a terminal shell.\n",
        "\n",
        "1. Open this notebook in the Jupyter Notebook Dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db52a0a61fca"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "Install the following packages for executing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b75757581291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "! pip3 install {USER_FLAG} --upgrade google-cloud-aiplatform google-cloud-storage jsonlines -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9255e3b156f"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0c0b2427998a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "435b8e413535"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI, BigQuery, Compute Engine and Cloud Storage APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,bigquery,compute_component,storage_component).\n",
        "\n",
        "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands.\n",
        "\n",
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "be175254a715"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "db65832f7c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project ID: vertex-ai-dev\n"
          ]
        }
      ],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
        "    # Get your GCP project id from gcloud\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ea86e5a1da1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e6b8b324ce1"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ae43d96c4b1b"
      },
      "outputs": [],
      "source": [
        "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
        "\n",
        "if REGION == \"[your-region]\":\n",
        "    REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f4f5cccf897"
      },
      "source": [
        "#### Timestamp\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "953fa6e5ddda"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c43a8673066"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Vertex AI Workbench Notebooks**, your environment is already authenticated. Skip this step.\n",
        "\n",
        "**If you are using Colab**, run the cell below and follow the instructions when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "In the Cloud Console, go to the [Create service account key](https://console.cloud.google.com/apis/credentials/serviceaccountkey) page.\n",
        "\n",
        "1. **Click Create service account**.\n",
        "\n",
        "2. In the **Service account name** field, enter a name, and click **Create**.\n",
        "\n",
        "3. In the **Grant this service account access to project** section, click the Role drop-down list. Type \"Vertex AI\" into the filter box, and select **Vertex AI Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "4. Click Create. A JSON file that contains your key downloads to your local environment.\n",
        "\n",
        "5. Enter the path to your service account key as the GOOGLE_APPLICATION_CREDENTIALS variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
        "    \"DL_ANACONDA_HOME\"\n",
        "):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5755d1a554f"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "When you initialize the Vertex SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "d2de92accb67"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "5ba09496accc"
      },
      "outputs": [],
      "source": [
        "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
        "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b72bfdf29dae"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "a4453435d115"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0728 09:01:56.406179345     176 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating gs://vertex-ai-devaip-20220728090135/...\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4cf2cdebb50"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "96ad3d416327"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0728 09:02:35.929826112     176 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
          ]
        }
      ],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93d685084cf2"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "152013538e59"
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "from google.cloud import aiplatform, storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03101a4492f3"
      },
      "source": [
        "### Initialize Vertex AI \n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "740cd5c67c79"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32c971919605"
      },
      "source": [
        "## Create a `Dataset` resource and import your data\n",
        "\n",
        "The notebook uses the 'Happy Moments' dataset for demonstration purposes. You can change it to another text classification dataset that [conforms to the data preparation requirements](https://cloud.google.com/vertex-ai/docs/datasets/prepare-text#classification).\n",
        "\n",
        "Using the Python SDK, you create a dataset and import the dataset in one call to `TextDataset.create()`, as shown in the following cell.\n",
        "\n",
        "Creating and importing data is a long-running operation. This next step can take a while. The `create()` method waits for the operation to complete, outputting statements as the operation progresses. The statements contain the full name of the dataset that you will use in the following section.\n",
        "\n",
        "**Note**: You can close the noteboook while you wait for this operation to complete. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6caf82e5e84e"
      },
      "outputs": [],
      "source": [
        "# Use a timestamp to ensure unique resources\n",
        "src_uris = \"gs://cloud-ml-data/NL-classification/happiness.csv\"\n",
        "display_name = f\"e2e-text-dataset-{TIMESTAMP}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d35b8b6b94ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating TextDataset\n",
            "Create TextDataset backing LRO: projects/931647533046/locations/us-central1/datasets/5685867097322684416/operations/6056760475637514240\n",
            "TextDataset created. Resource name: projects/931647533046/locations/us-central1/datasets/5685867097322684416\n",
            "To use this TextDataset in another session:\n",
            "ds = aiplatform.TextDataset('projects/931647533046/locations/us-central1/datasets/5685867097322684416')\n",
            "Importing TextDataset data: projects/931647533046/locations/us-central1/datasets/5685867097322684416\n",
            "Import TextDataset data backing LRO: projects/931647533046/locations/us-central1/datasets/5685867097322684416/operations/1276189471183732736\n",
            "TextDataset data imported. Resource name: projects/931647533046/locations/us-central1/datasets/5685867097322684416\n"
          ]
        }
      ],
      "source": [
        "ds = aiplatform.TextDataset.create(\n",
        "    display_name=display_name,\n",
        "    gcs_source=src_uris,\n",
        "    import_schema_uri=aiplatform.schema.dataset.ioformat.text.single_label_classification,\n",
        "    sync=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b3cc427353a"
      },
      "source": [
        "## Train your text classification model\n",
        "\n",
        "Once your dataset has finished importing data, you are ready to train your model. To do this, you first need the full resource name of your dataset, where the full name has the format `projects/[YOUR_PROJECT]/locations/[YOUR_REGIO)N]/datasets/[YOUR_DATASET_ID]`. If you don't have the resource name handy, you can list all of the datasets in your project using `TextDataset.list()`. \n",
        "\n",
        "As shown in the following code block, you can pass in the display name of your dataset in the call to `list()` to filter the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "52cf56f1c8a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<google.cloud.aiplatform.datasets.text_dataset.TextDataset object at 0x7f3e558c84c0> \n",
            "resource name: projects/931647533046/locations/us-central1/datasets/5685867097322684416]\n"
          ]
        }
      ],
      "source": [
        "datasets = aiplatform.TextDataset.list(filter=f'display_name=\"{display_name}\"')\n",
        "print(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58df3e02df82"
      },
      "source": [
        "When you create a new model, you need a reference to the `TextDataset` object that corresponds to your dataset. You can use the `ds` variable you created previously when you created the dataset or you can also list all of your datasets to get a reference to your dataset. Each item returned from `TextDataset.list()` is an instance of `TextDataset`.\n",
        "\n",
        "The following code block shows how to instantiate a `TextDataset` object using a dataset ID. Note that this code is intentionally verbose for demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aa667203da03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ID: 5685867097322684416\n"
          ]
        }
      ],
      "source": [
        "# Get the dataset ID if it's not available\n",
        "dataset_id = \"[your-dataset-id]\"\n",
        "\n",
        "if dataset_id == \"[your-dataset-id]\":\n",
        "    # Use the reference to the new dataset captured when we created it\n",
        "    dataset_id = ds.resource_name.split(\"/\")[-1]\n",
        "    print(f\"Dataset ID: {dataset_id}\")\n",
        "\n",
        "text_dataset = aiplatform.TextDataset(dataset_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68f10356cab9"
      },
      "source": [
        "Now you can begin training your model. Training the model is a two part process:\n",
        "\n",
        "1. **Define the training job.** You must provide a display name and the type of training you want when you define the training job.\n",
        "2. **Run the training job.** When you run the training job, you need to supply a reference to the dataset to use for training. At this step, you can also configure the data split percentages.\n",
        "\n",
        "You do not need to specify [data splits](https://cloud.google.com/vertex-ai/docs/general/ml-use). The training job has a default setting of  training 80%/ testing 10%/ validate 10% if you don't provide these values.\n",
        "\n",
        "To train your model, you call `AutoMLTextTrainingJob.run()` as shown in the following snippets. The method returns a reference to your new `Model` object.\n",
        "\n",
        "As with importing data into the dataset, training your model can take a substantial amount of time. The client library prints out operation status messages while the training pipeline operation processes. You must wait for the training process to complete before you can get the resource name and ID of your new model, which is required for model evaluation and model deployment.\n",
        "\n",
        "**Note**: You can close the notebook while you wait for the operation to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0aa0f01805ea"
      },
      "outputs": [],
      "source": [
        "# Define the training job\n",
        "training_job_display_name = f\"e2e-text-training-job-{TIMESTAMP}\"\n",
        "job = aiplatform.AutoMLTextTrainingJob(\n",
        "    display_name=training_job_display_name,\n",
        "    prediction_type=\"classification\",\n",
        "    multi_label=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1ec60baf2c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View Training:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8245297345198030848?project=931647533046\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "AutoMLTextTrainingJob run completed. Resource name: projects/931647533046/locations/us-central1/trainingPipelines/8245297345198030848\n",
            "Model available at projects/931647533046/locations/us-central1/models/2451026922591748096\n"
          ]
        }
      ],
      "source": [
        "model_display_name = f\"e2e-text-classification-model-{TIMESTAMP}\"\n",
        "\n",
        "# Run the training job\n",
        "model = job.run(\n",
        "    dataset=text_dataset,\n",
        "    model_display_name=model_display_name,\n",
        "    training_fraction_split=0.7,\n",
        "    validation_fraction_split=0.2,\n",
        "    test_fraction_split=0.1,\n",
        "    sync=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caaa3f32b12e"
      },
      "source": [
        "## Review model evaluation scores\n",
        "\n",
        "After your model training has finished, you can review the evaluation scores for it using the `list_model_evaluations()` method. This method will return an iterator for each evaluation slice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b0bb6be8621a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'projects/931647533046/locations/us-central1/models/2451026922591748096@1/evaluations/8286069572818173952', 'metricsSchemaUri': 'gs://google-cloud-aiplatform/schema/modelevaluation/classification_metrics_1.0.0.yaml', 'metrics': {'auPrc': 0.95271105, 'confusionMatrix': {'rows': [[177.0, 2.0, 31.0, 0.0, 8.0, 1.0, 32.0], [4.0, 399.0, 17.0, 0.0, 25.0, 1.0, 6.0], [20.0, 7.0, 1108.0, 8.0, 34.0, 8.0, 42.0], [1.0, 1.0, 9.0, 47.0, 0.0, 2.0, 0.0], [3.0, 8.0, 40.0, 0.0, 1322.0, 2.0, 16.0], [3.0, 0.0, 5.0, 0.0, 3.0, 80.0, 7.0], [22.0, 3.0, 76.0, 2.0, 17.0, 6.0, 314.0]], 'annotationSpecs': [{'id': '349744203435081728', 'displayName': 'leisure'}, {'id': '1790896084193640448', 'displayName': 'bonding'}, {'displayName': 'achievement', 'id': '2943817588800487424'}, {'displayName': 'exercise', 'id': '4096739093407334400'}, {'displayName': 'affection', 'id': '6402582102621028352'}, {'id': '7555503607227875328', 'displayName': 'nature'}, {'displayName': 'enjoy_the_moment', 'id': '8708425111834722304'}]}, 'logLoss': 0.09505192, 'confidenceMetrics': [{'recallAt1': 0.8795611, 'f1ScoreAt1': 0.8795611, 'precisionAt1': 0.8795611, 'precision': 0.14285715, 'recall': 1.0, 'f1Score': 0.25}, {'precisionAt1': 0.8795611, 'recallAt1': 0.8795611, 'f1Score': 0.8179654, 'recall': 0.9642766, 'f1ScoreAt1': 0.8795611, 'confidenceThreshold': 0.05, 'precision': 0.71020484}, {'f1Score': 0.84693295, 'precision': 0.7643796, 'f1ScoreAt1': 0.8795611, 'recall': 0.9494769, 'confidenceThreshold': 0.1, 'precisionAt1': 0.8795611, 'recallAt1': 0.8795611}, {'recall': 0.9341669, 'confidenceThreshold': 0.15, 'precisionAt1': 0.8795611, 'recallAt1': 0.8795611, 'f1Score': 0.8614118, 'f1ScoreAt1': 0.8795611, 'precision': 0.7991705}, {'confidenceThreshold': 0.2, 'recall': 0.9226844, 'f1Score': 0.86808306, 'recallAt1': 0.8795611, 'precision': 0.81958294, 'precisionAt1': 0.8795611, 'f1ScoreAt1': 0.8795611}, {'precision': 0.8353929, 'f1Score': 0.8730507, 'recall': 0.91426384, 'recallAt1': 0.8795611, 'precisionAt1': 0.8795611, 'confidenceThreshold': 0.25, 'f1ScoreAt1': 0.8795611}, {'f1Score': 0.87597185, 'confidenceThreshold': 0.3, 'recall': 0.90558815, 'f1ScoreAt1': 0.87967336, 'recallAt1': 0.8795611, 'precision': 0.8482314, 'precisionAt1': 0.8797856}, {'recallAt1': 0.87930596, 'precision': 0.86035705, 'confidenceThreshold': 0.35, 'f1Score': 0.87862134, 'f1ScoreAt1': 0.8797549, 'precisionAt1': 0.8802043, 'recall': 0.89767796}, {'precisionAt1': 0.8817507, 'precision': 0.8702271, 'f1ScoreAt1': 0.8803987, 'recall': 0.8897678, 'f1Score': 0.879889, 'recallAt1': 0.8790508, 'confidenceThreshold': 0.4}, {'confidenceThreshold': 0.45, 'precisionAt1': 0.88347024, 'f1ScoreAt1': 0.8808701, 'recall': 0.8836438, 'recallAt1': 0.8782853, 'precision': 0.8791571, 'f1Score': 0.88139474}, {'confidenceThreshold': 0.5, 'recall': 0.87471294, 'f1Score': 0.8816873, 'f1ScoreAt1': 0.8816873, 'precisionAt1': 0.8887737, 'precision': 0.8887737, 'recallAt1': 0.87471294}, {'precisionAt1': 0.9019712, 'recallAt1': 0.8639959, 'f1Score': 0.8825753, 'precision': 0.9019712, 'f1ScoreAt1': 0.8825753, 'confidenceThreshold': 0.55, 'recall': 0.8639959}, {'recallAt1': 0.85429955, 'recall': 0.85429955, 'f1Score': 0.87989485, 'precision': 0.90707123, 'precisionAt1': 0.90707123, 'confidenceThreshold': 0.6, 'f1ScoreAt1': 0.87989485}, {'f1ScoreAt1': 0.87685776, 'confidenceThreshold': 0.65, 'recallAt1': 0.84307224, 'recall': 0.84307224, 'precisionAt1': 0.9134642, 'precision': 0.9134642, 'f1Score': 0.87685776}, {'f1Score': 0.8727175, 'precision': 0.92094076, 'confidenceThreshold': 0.7, 'recall': 0.8292932, 'f1ScoreAt1': 0.8727175, 'recallAt1': 0.8292932, 'precisionAt1': 0.92094076}, {'recall': 0.8150038, 'f1ScoreAt1': 0.8686429, 'recallAt1': 0.8150038, 'precisionAt1': 0.9298399, 'confidenceThreshold': 0.75, 'f1Score': 0.8686429, 'precision': 0.9298399}, {'confidenceThreshold': 0.8, 'f1ScoreAt1': 0.86195475, 'f1Score': 0.86195475, 'precisionAt1': 0.9389474, 'recallAt1': 0.7966318, 'recall': 0.7966318, 'precision': 0.9389474}, {'f1ScoreAt1': 0.8540995, 'confidenceThreshold': 0.85, 'f1Score': 0.8540995, 'recallAt1': 0.77749425, 'precision': 0.9474502, 'precisionAt1': 0.9474502, 'recall': 0.77749425}, {'precisionAt1': 0.95614594, 'f1ScoreAt1': 0.8482181, 'recallAt1': 0.7621842, 'recall': 0.7621842, 'confidenceThreshold': 0.875, 'f1Score': 0.8482181, 'precision': 0.95614594}, {'precision': 0.9613223, 'recall': 0.74202603, 'f1ScoreAt1': 0.8375576, 'f1Score': 0.8375576, 'recallAt1': 0.74202603, 'confidenceThreshold': 0.9, 'precisionAt1': 0.9613223}, {'confidenceThreshold': 0.91, 'recall': 0.7346262, 'precisionAt1': 0.96255434, 'precision': 0.96255434, 'recallAt1': 0.7346262, 'f1Score': 0.8332851, 'f1ScoreAt1': 0.8332851}, {'f1Score': 0.8268417, 'f1ScoreAt1': 0.8268417, 'precision': 0.96525884, 'recallAt1': 0.72314364, 'precisionAt1': 0.96525884, 'confidenceThreshold': 0.92, 'recall': 0.72314364}, {'precisionAt1': 0.9666435, 'confidenceThreshold': 0.93, 'precision': 0.9666435, 'f1Score': 0.8185965, 'recall': 0.709875, 'f1ScoreAt1': 0.8185965, 'recallAt1': 0.709875}, {'recall': 0.6986476, 'recallAt1': 0.6986476, 'confidenceThreshold': 0.94, 'f1Score': 0.811981, 'f1ScoreAt1': 0.811981, 'precisionAt1': 0.96920353, 'precision': 0.96920353}, {'recall': 0.6846134, 'confidenceThreshold': 0.95, 'precisionAt1': 0.96999276, 'recallAt1': 0.6846134, 'f1ScoreAt1': 0.8026926, 'precision': 0.96999276, 'f1Score': 0.8026926}, {'recallAt1': 0.66828275, 'precision': 0.97324413, 'recall': 0.66828275, 'confidenceThreshold': 0.96, 'f1ScoreAt1': 0.7924357, 'f1Score': 0.7924357, 'precisionAt1': 0.97324413}, {'precision': 0.9755909, 'precisionAt1': 0.9755909, 'f1ScoreAt1': 0.77476925, 'confidenceThreshold': 0.97, 'recall': 0.64251083, 'recallAt1': 0.64251083, 'f1Score': 0.77476925}, {'confidenceThreshold': 0.98, 'precisionAt1': 0.979918, 'precision': 0.979918, 'f1ScoreAt1': 0.75200504, 'recall': 0.6101046, 'f1Score': 0.75200504, 'recallAt1': 0.6101046}, {'f1ScoreAt1': 0.70738494, 'precisionAt1': 0.98720294, 'recall': 0.551161, 'recallAt1': 0.551161, 'confidenceThreshold': 0.99, 'f1Score': 0.70738494, 'precision': 0.98720294}, {'confidenceThreshold': 0.995, 'recall': 0.4883899, 'recallAt1': 0.4883899, 'f1ScoreAt1': 0.6550308, 'precision': 0.9942857, 'f1Score': 0.6550308, 'precisionAt1': 0.9942857}, {'precision': 0.99405724, 'f1Score': 0.6377816, 'recallAt1': 0.46950752, 'recall': 0.46950752, 'precisionAt1': 0.99405724, 'f1ScoreAt1': 0.6377816, 'confidenceThreshold': 0.996}, {'precision': 0.994233, 'precisionAt1': 0.994233, 'confidenceThreshold': 0.997, 'recall': 0.43990815, 'f1ScoreAt1': 0.60994166, 'recallAt1': 0.43990815, 'f1Score': 0.60994166}, {'precisionAt1': 0.9968254, 'precision': 0.9968254, 'f1Score': 0.5715326, 'recall': 0.4006124, 'f1ScoreAt1': 0.5715326, 'confidenceThreshold': 0.998, 'recallAt1': 0.4006124}, {'recall': 0.33707577, 'precision': 0.99698114, 'f1ScoreAt1': 0.50381386, 'f1Score': 0.50381386, 'recallAt1': 0.33707577, 'confidenceThreshold': 0.999, 'precisionAt1': 0.99698114}, {'f1ScoreAt1': 0.03164239, 'confidenceThreshold': 1.0, 'precision': 1.0, 'precisionAt1': 1.0, 'recallAt1': 0.01607553, 'recall': 0.01607553, 'f1Score': 0.03164239}]}, 'createTime': '2022-07-28T06:07:57.248219Z', 'sliceDimensions': ['annotationSpec'], 'annotationSchemaUri': 'gs://google-cloud-aiplatform/schema/dataset/annotation/text_classification_1.0.0.yaml'}\n"
          ]
        }
      ],
      "source": [
        "model_evaluations = model.list_model_evaluations()\n",
        "\n",
        "for model_evaluation in model_evaluations:\n",
        "    print(model_evaluation.to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5dbe4dbaa60"
      },
      "source": [
        "## Deploy your text classification model\n",
        "\n",
        "Once your model has completed training, you must deploy it to an _endpoint_ to get online predictions from it. When you deploy the model to an endpoint, a copy of the model is made on the endpoint with a new resource name and display name.\n",
        "\n",
        "You can deploy multiple models to the same endpoint and split traffic between the various models assigned to the endpoint. However, you must deploy one model at a time to the endpoint. To change the traffic split percentages, you must assign new values on your second (and subsequent) models each time you deploy a new model.\n",
        "\n",
        "The following code block demonstrates how to deploy a model. The code snippet relies on the Python SDK to create a new endpoint for deployment. The call to `modely.deploy()` returns a reference to an `Endpoint` object--you need this reference for online predictions in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "19bc4a55ccfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Endpoint\n",
            "Create Endpoint backing LRO: projects/931647533046/locations/us-central1/endpoints/3673310018725216256/operations/7336345719764156416\n",
            "Endpoint created. Resource name: projects/931647533046/locations/us-central1/endpoints/3673310018725216256\n",
            "To use this Endpoint in another session:\n",
            "endpoint = aiplatform.Endpoint('projects/931647533046/locations/us-central1/endpoints/3673310018725216256')\n",
            "Deploying model to Endpoint : projects/931647533046/locations/us-central1/endpoints/3673310018725216256\n",
            "Deploy Endpoint model backing LRO: projects/931647533046/locations/us-central1/endpoints/3673310018725216256/operations/765593863430602752\n",
            "Endpoint model deployed. Resource name: projects/931647533046/locations/us-central1/endpoints/3673310018725216256\n"
          ]
        }
      ],
      "source": [
        "deployed_model_display_name = f\"e2e-deployed-text-classification-model-{TIMESTAMP}\"\n",
        "\n",
        "endpoint = model.deploy(\n",
        "    deployed_model_display_name=deployed_model_display_name, sync=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "531da446035b"
      },
      "source": [
        "In case you didn't record the name of the new endpoint, you can get a list of all your endpoints as you did before with datasets and models. For each endpoint, you can list the models deployed to that endpoint. To get a reference to the model that you just deployed, you can check the `display_name` of each model deployed to the endpoint against the model you're looking for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "f61fb44181b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<google.cloud.aiplatform.models.Endpoint object at 0x7f3e4dbd43a0> \n",
            "resource name: projects/931647533046/locations/us-central1/endpoints/3673310018725216256]\n"
          ]
        }
      ],
      "source": [
        "endpoints = aiplatform.Endpoint.list()\n",
        "\n",
        "endpoint_with_deployed_model = []\n",
        "\n",
        "for endpoint_ in endpoints:\n",
        "    for model in endpoint_.list_models():\n",
        "        if model.display_name.find(deployed_model_display_name) == 0:\n",
        "            endpoint_with_deployed_model.append(endpoint_)\n",
        "\n",
        "print(endpoint_with_deployed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "351a6e8be3a5"
      },
      "source": [
        "## Get online predictions from your model\n",
        "\n",
        "Now that you have your endpoint's resource name, you can get online predictions from the text classification model. To get the online prediction, you send a prediction request to your endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "953b333fc0fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint name: projects/931647533046/locations/us-central1/endpoints/3673310018725216256\n",
            "Prediction ID: 6402582102621028352\n",
            "Prediction display name: affection\n",
            "Prediction confidence score: 4.414122304297052e-05\n",
            "Prediction ID: 2943817588800487424\n",
            "Prediction display name: achievement\n",
            "Prediction confidence score: 0.9998748302459717\n",
            "Prediction ID: 8708425111834722304\n",
            "Prediction display name: enjoy_the_moment\n",
            "Prediction confidence score: 3.9748832932673395e-05\n",
            "Prediction ID: 1790896084193640448\n",
            "Prediction display name: bonding\n",
            "Prediction confidence score: 2.3478048660763307e-06\n",
            "Prediction ID: 349744203435081728\n",
            "Prediction display name: leisure\n",
            "Prediction confidence score: 3.584425212466158e-05\n",
            "Prediction ID: 7555503607227875328\n",
            "Prediction display name: nature\n",
            "Prediction confidence score: 2.5153858018711617e-07\n",
            "Prediction ID: 4096739093407334400\n",
            "Prediction display name: exercise\n",
            "Prediction confidence score: 2.8233748707862105e-06\n"
          ]
        }
      ],
      "source": [
        "endpoint_name = \"[your-endpoint-name]\"\n",
        "if endpoint_name == \"[your-endpoint-name]\":\n",
        "    endpoint_name = endpoint.resource_name\n",
        "\n",
        "print(f\"Endpoint name: {endpoint_name}\")\n",
        "\n",
        "endpoint = aiplatform.Endpoint(endpoint_name)\n",
        "content = \"I got a high score on my math final!\"\n",
        "\n",
        "response = endpoint.predict(instances=[{\"content\": content}])\n",
        "\n",
        "for prediction_ in response.predictions:\n",
        "    ids = prediction_[\"ids\"]\n",
        "    display_names = prediction_[\"displayNames\"]\n",
        "    confidence_scores = prediction_[\"confidences\"]\n",
        "    for count, id in enumerate(ids):\n",
        "        print(f\"Prediction ID: {id}\")\n",
        "        print(f\"Prediction display name: {display_names[count]}\")\n",
        "        print(f\"Prediction confidence score: {confidence_scores[count]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f18811cd0477"
      },
      "source": [
        "## Get batch predictions from your model\n",
        "\n",
        "You can get batch predictions from a text classification model without deploying it. You must first format all of your prediction instances (prediction input) in JSONL format and you must store the JSONL file in a Google Cloud Storage bucket. You must also provide a Google Cloud Storage bucket to hold your prediction output.\n",
        "\n",
        "To start, you must first create your predictions input file in JSONL format. Each line in the JSONL document needs to be formatted like so:\n",
        "\n",
        "```\n",
        "{ \"content\": \"gs://sourcebucket/datasets/texts/source_text.txt\", \"mimeType\": \"text/plain\"}\n",
        "```\n",
        "\n",
        "The `content` field in the JSON structure must be a Google Cloud Storage URI to another document that contains the text input for prediction.\n",
        "[See the documentation for more information.](https://cloud.google.com/ai-platform-unified/docs/predictions/batch-predictions#text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "e4b838cbcd99"
      },
      "outputs": [],
      "source": [
        "instances = [\n",
        "    \"We hiked through the woods and up the hill to the ice caves\",\n",
        "    \"My kitten is so cute\",\n",
        "]\n",
        "input_file_name = \"batch-prediction-input.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76ac422ab8dd"
      },
      "source": [
        "For batch prediction, you must supply the following:\n",
        "\n",
        "+ All of your prediction instances as individual files on Google Cloud Storage, as TXT files for your instances\n",
        "+ A JSONL file that lists the URIs of all your prediction instances\n",
        "+ A Google Cloud Storage bucket to hold the output from batch prediction\n",
        "\n",
        "For this tutorial, the following cells create a new Storage bucket, upload individual prediction instances as text files to the bucket, and then create the JSONL file with the URIs of your prediction instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "8b7cabbb86ad"
      },
      "outputs": [],
      "source": [
        "# Instantiate the Storage client and create the new bucket\n",
        "# from google.cloud import  storage\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(BUCKET_NAME)\n",
        "# Iterate over the prediction instances, creating a new TXT file\n",
        "# for each.\n",
        "input_file_data = []\n",
        "for count, instance in enumerate(instances):\n",
        "    instance_name = f\"input_{count}.txt\"\n",
        "    instance_file_uri = f\"{BUCKET_URI}/{instance_name}\"\n",
        "    # Add the data to store in the JSONL input file.\n",
        "    tmp_data = {\"content\": instance_file_uri, \"mimeType\": \"text/plain\"}\n",
        "    input_file_data.append(tmp_data)\n",
        "\n",
        "    # Create the new instance file\n",
        "    blob = bucket.blob(instance_name)\n",
        "    blob.upload_from_string(instance)\n",
        "\n",
        "input_str = \"\\n\".join([str(d) for d in input_file_data])\n",
        "file_blob = bucket.blob(f\"{input_file_name}\")\n",
        "file_blob.upload_from_string(input_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31c262320610"
      },
      "source": [
        "Now that you have the bucket with the prediction instances ready, you can send a batch prediction rhttps://storage.googleapis.com/upload/storage/v1/b/gs://vertex-ai-devaip-20220728004429/o?uploadType=multipartequest to Vertex AI. When you send a request to the service, you must provide the URI of your JSONL file and your output bucket, including the `gs://` protocols.\n",
        "\n",
        "With the Python SDK, you can create a batch prediction job by calling `Model.batch_predict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "f5ab2139d52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating BatchPredictionJob\n",
            "BatchPredictionJob created. Resource name: projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\n",
            "To use this BatchPredictionJob in another session:\n",
            "bpj = aiplatform.BatchPredictionJob('projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296')\n",
            "View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/369768234322231296?project=931647533046\n",
            "BatchPredictionJob projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296 current state:\n",
            "JobState.JOB_STATE_SUCCEEDED\n",
            "BatchPredictionJob run completed. Resource name: projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\n"
          ]
        }
      ],
      "source": [
        "job_display_name = \"e2e-text-classification-batch-prediction-job\"\n",
        "model = aiplatform.Model(model_name=model.model)\n",
        "batch_prediction_job = model.batch_predict(\n",
        "    job_display_name=job_display_name,\n",
        "    gcs_source=f\"{BUCKET_URI}/{input_file_name}\",\n",
        "    gcs_destination_prefix=f\"{BUCKET_URI}/output\",\n",
        "    sync=True,\n",
        ")\n",
        "batch_prediction_job_name = batch_prediction_job.resource_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11503f2e08a2"
      },
      "source": [
        "Once the batch prediction job completes, the Python SDK prints out the resource name of the batch prediction job in the format `projects/[PROJECT_ID]/locations/[LOCATION]/batchPredictionJobs/[BATCH_PREDICTION_JOB_ID]`. You can query the Vertex AI service for the status of the batch prediction job using its ID.\n",
        "\n",
        "The following code snippet demonstrates how to create an instance of the `BatchPredictionJob` class to review its status. Note that you need the full resource name printed out from the Python SDK for this snippet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "bf6e614723ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch prediction job state: JobState.JOB_STATE_SUCCEEDED\n"
          ]
        }
      ],
      "source": [
        "from google.cloud.aiplatform import jobs\n",
        "\n",
        "batch_job = jobs.BatchPredictionJob(batch_prediction_job_name)\n",
        "print(f\"Batch prediction job state: {str(batch_job.state)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f9a12dadf6f"
      },
      "source": [
        "After the batch job has completed, you can view the results of the job in your output Storage bucket. You might want to first list all of the files in your output bucket to find the URI of the output file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "8ff1ec03205c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0728 10:00:29.091150251     176 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://vertex-ai-devaip-20220728090135/output/prediction-e2e-text-classification-model-20220726065605-2022-07-28T09:54:35.262891Z/\n"
          ]
        }
      ],
      "source": [
        "BUCKET_OUTPUT = f\"{BUCKET_URI}/output\"\n",
        "\n",
        "! gsutil ls -a $BUCKET_OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52f3f8af2e41"
      },
      "source": [
        "The output from the batch prediction job should be contained in a folder (or _prefix_) that includes the name of the batch prediction job plus a time stamp for when it was created.\n",
        "\n",
        "For example, if your batch prediction job name is `my-job` and your bucket name is `my-bucket`, the URI of the folder containing your output might look like the following:\n",
        "\n",
        "```\n",
        "gs://my-bucket/output/prediction-my-job-2021-06-04T19:54:25.889262Z/\n",
        "```\n",
        "\n",
        "To read the batch prediction results, you must download the file locally and open the file. The next cell copies all of the files in the `BUCKET_OUTPUT_FOLDER` into a local folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "4bb16e040942"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0728 10:01:09.207265811     176 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://vertex-ai-devaip-20220728090135/output/prediction-e2e-text-classification-model-20220726065605-2022-07-28T09:54:35.262891Z/predictions_00001.jsonl...\n",
            "/ [1/1 files][  959.0 B/  959.0 B] 100% Done                                    \n",
            "Operation completed over 1 objects/959.0 B.                                      \n",
            "Local results folder: prediction_results/output/prediction-e2e-text-classification-model-20220726065605-2022-07-28T09:54:35.262891Z\n"
          ]
        }
      ],
      "source": [
        "RESULTS_DIRECTORY = \"prediction_results\"\n",
        "RESULTS_DIRECTORY_FULL = f\"{RESULTS_DIRECTORY}/output\"\n",
        "\n",
        "# Create missing directories\n",
        "os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
        "\n",
        "# Get the Cloud Storage paths for each result\n",
        "! gsutil -m cp -r $BUCKET_OUTPUT $RESULTS_DIRECTORY\n",
        "\n",
        "# Get most recently modified directory\n",
        "latest_directory = max(\n",
        "    (\n",
        "        os.path.join(RESULTS_DIRECTORY_FULL, d)\n",
        "        for d in os.listdir(RESULTS_DIRECTORY_FULL)\n",
        "    ),\n",
        "    key=os.path.getmtime,\n",
        ")\n",
        "\n",
        "print(f\"Local results folder: {latest_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f406e1e4d5ec"
      },
      "source": [
        "With all of the results files downloaded locally, you can open them and read the results. In this tutorial, you use the [`jsonlines`](https://jsonlines.readthedocs.io/en/latest/) library to read the output results.\n",
        "\n",
        "The following cell opens up the JSONL output file and then prints the predictions for each instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "91d7f2a74a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "instance: gs://vertex-ai-devaip-20220728090135/input_1.txt\n",
            "\n",
            "ids: ['8022892806055919616', '1105363778414837760', '6869971301449072640', '3411206787628531712', '4564128292235378688', '5717049796842225664', '2258285283021684736']\n",
            "\n",
            "displayNames: ['affection', 'achievement', 'enjoy_the_moment', 'bonding', 'leisure', 'nature', 'exercise']\n",
            "\n",
            "confidences: [0.98783094, 0.009668145, 0.0023065973, 0.0001260451, 3.435437e-05, 1.7344602e-05, 1.6450787e-05]\n",
            "\n",
            "instance: gs://vertex-ai-devaip-20220728090135/input_0.txt\n",
            "\n",
            "ids: ['5717049796842225664', '6869971301449072640', '1105363778414837760', '4564128292235378688', '8022892806055919616', '2258285283021684736', '3411206787628531712']\n",
            "\n",
            "displayNames: ['nature', 'enjoy_the_moment', 'achievement', 'leisure', 'affection', 'exercise', 'bonding']\n",
            "\n",
            "confidences: [0.47380814, 0.30582574, 0.16660185, 0.050528545, 0.0021286055, 0.00087396626, 0.0002331497]\n"
          ]
        }
      ],
      "source": [
        "# Get downloaded results in directory\n",
        "results_files = []\n",
        "for dirpath, _, files in os.walk(latest_directory):\n",
        "    for file in files:\n",
        "        if file.find(\"predictions\") >= 0:\n",
        "            results_files.append(os.path.join(dirpath, file))\n",
        "\n",
        "\n",
        "# Consolidate all the results into a list\n",
        "results = []\n",
        "for results_file in results_files:\n",
        "    # Open each result\n",
        "    with jsonlines.open(results_file) as reader:\n",
        "        for result in reader.iter(type=dict, skip_invalid=True):\n",
        "            instance = result[\"instance\"]\n",
        "            prediction = result[\"prediction\"]\n",
        "            print(f\"\\ninstance: {instance['content']}\")\n",
        "            for key, output in prediction.items():\n",
        "                print(f\"\\n{key}: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af3874f08502"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "* Dataset\n",
        "* Training job\n",
        "* Model\n",
        "* Endpoint\n",
        "* Batch prediction\n",
        "* Batch prediction bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "adce73b48b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting BatchPredictionJob : projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\n"
          ]
        },
        {
          "ename": "NotFound",
          "evalue": "404 The BatchPredictionJob \"projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\" does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:50\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m state, call, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"The BatchPredictionJob \"projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\" does not exist.\"\n\tdebug_error_string = \"{\"created\":\"@1659003789.428268452\",\"description\":\"Error received from peer ipv4:108.177.98.95:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":903,\"grpc_message\":\"The BatchPredictionJob \"projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\" does not exist.\",\"grpc_status\":5}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "Input \u001b[0;32mIn [152]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delete_bucket \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIS_TESTING\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m gsutil rm -r $BUCKET_URI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mbatch_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# `force` parameter ensures that models are undeployed before deletion\u001b[39;00m\n\u001b[1;32m      9\u001b[0m endpoint\u001b[38;5;241m.\u001b[39mdelete(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/google/cloud/aiplatform/base.py:793\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    792\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    796\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/google/cloud/aiplatform/base.py:1211\u001b[0m, in \u001b[0;36mVertexAiResourceNounWithFutureManager.delete\u001b[0;34m(self, sync)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124;03m\"\"\"Deletes this Vertex AI resource. WARNING: This deletion is\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mpermanent.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;124;03m        be immediately returned and synced when the Future has completed.\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_start_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleting\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1211\u001b[0m lro \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delete_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_started_against_resource_with_lro(\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelete\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, lro\n\u001b[1;32m   1214\u001b[0m )\n\u001b[1;32m   1215\u001b[0m lro\u001b[38;5;241m.\u001b[39mresult()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/job_service/client.py:2748\u001b[0m, in \u001b[0;36mJobServiceClient.delete_batch_prediction_job\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2743\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   2744\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mname),)),\n\u001b[1;32m   2745\u001b[0m )\n\u001b[1;32m   2747\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2753\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;66;03m# Wrap the response in an operation future.\u001b[39;00m\n\u001b[1;32m   2756\u001b[0m response \u001b[38;5;241m=\u001b[39m gac_operation\u001b[38;5;241m.\u001b[39mfrom_gapic(\n\u001b[1;32m   2757\u001b[0m     response,\n\u001b[1;32m   2758\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39moperations_client,\n\u001b[1;32m   2759\u001b[0m     empty_pb2\u001b[38;5;241m.\u001b[39mEmpty,\n\u001b[1;32m   2760\u001b[0m     metadata_type\u001b[38;5;241m=\u001b[39mgca_operation\u001b[38;5;241m.\u001b[39mDeleteOperationMetadata,\n\u001b[1;32m   2761\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:154\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    152\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:52\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 The BatchPredictionJob \"projects/931647533046/locations/us-central1/batchPredictionJobs/369768234322231296\" does not exist."
          ]
        }
      ],
      "source": [
        "delete_bucket = False\n",
        "\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -r $BUCKET_URI\n",
        "\n",
        "batch_job.delete()\n",
        "endpoint.undeploy_all()\n",
        "# `force` parameter ensures that models are undeployed before deletion\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "model.delete()\n",
        "\n",
        "text_dataset.delete()\n",
        "\n",
        "# Training job\n",
        "job.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa6a8c434c79"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "After completing this tutorial, see the following documentation pages to learn more about Vertex AI:\n",
        "\n",
        "* [Preparing text training data](https://cloud.google.com/vertex-ai/docs/datasets/prepare-text)\n",
        "* [Training an AutoML model using the API](https://cloud.google.com/vertex-ai/docs/training/automl-api#text)\n",
        "* [Evaluating AutoML models](https://cloud.google.com/vertex-ai/docs/training/evaluating-automl-models#text)\n",
        "* [Deploying a model using ther Vertex AI API](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#aiplatform_create_endpoint_sample-python)\n",
        "* [Getting online predictions from AutoML models](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#aiplatform_create_endpoint_sample-python)\n",
        "* [Getting batch predictions](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions#text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "automl-text-classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
