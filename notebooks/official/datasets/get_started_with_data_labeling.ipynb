{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "copyright"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title:generic,gcp"
      },
      "source": [
        "# Get started with Vertex AI Data Labeling\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/datasets/get_started_with_data_labeling.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/datasets/get_started_with_data_labeling.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/datasets/get_started_with_data_labeling.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview:mlops"
      },
      "source": [
        "## Overview\n",
        "\n",
        "\n",
        "This tutorial demonstrates how to use Vertex AI in production. This tutorial covers data management: get started with Vertex AI Data Labeling service.\n",
        "\n",
        "Learn more about [Vertex AI Data Labeling](https://cloud.google.com/vertex-ai/docs/datasets/data-labeling-job)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "objective:mlops,stage3,get_started_automl_pipeline_components"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to use the `Vertex AI Data Labeling` service.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Data Labeling`\n",
        "- `Vertex AI Dataset`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Create a Specialist Pool for data labelers.\n",
        "- Create a data labeling job.\n",
        "- Submit the data labeling job.\n",
        "- List data labeling jobs.\n",
        "- Cancel a data labeling job.\n",
        "\n",
        "Learn more about [Request a Vertex AI Data Labeling job](https://cloud.google.com/vertex-ai/docs/datasets/data-labeling-job)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset:flowers,icn"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the [Flowers dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers) from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview). The version of the dataset you use in this tutorial is stored in a public Cloud Storage bucket. The trained model predicts the type of flower an image is from a class of five flowers: daisy, dandelion, rose, sunflower, or tulip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c997d8d92ce"
      },
      "source": [
        "### Costs \n",
        "\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_aip"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_mlops"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Install the packages\n",
        "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
        "                                 google-cloud-storage \n",
        "\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    ! pip3 install --upgrade --quiet google-api-core==2.10 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "restart"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-ZBOjErv5mM"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfEglUHQk9S3"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d29f41c6619e"
      },
      "source": [
        "#### Email\n",
        "\n",
        "You need an email address to send labeling job request to. This is the email address will be the manager of the data labeling specialist pool.\n",
        "\n",
        "In this tutorial, if you don't specify an email address, the email address associated with your project ID will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e443c02540c"
      },
      "outputs": [],
      "source": [
        "EMAIL = \"[your-email-address]\"  # @param {type: \"string\"}\n",
        "\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    EMAIL = \"noreply@google.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca885f17d6ac"
      },
      "outputs": [],
      "source": [
        "if EMAIL == \"[your-email-address]\":\n",
        "    shell_output = ! gcloud auth list 2>/dev/null\n",
        "    EMAIL = shell_output[2].replace(\"*\", \"\").strip()\n",
        "\n",
        "print(EMAIL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcp_authenticate"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n",
        "\n",
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated.\n",
        "\n",
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce6043da7b33"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0367eac06a10"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ad4dbb4a61"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13224697bfb"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:mbsdk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_vars"
      },
      "source": [
        "### Set up variables\n",
        "\n",
        "Next, set up some variables used throughout the tutorial.\n",
        "### Import libraries and define constants\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "import_aip"
      },
      "source": [
        "#### Import Vertex AI SDK\n",
        "\n",
        "Import the Vertex AI SDK into our Python environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97-XQPkv_i_7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import google.cloud.aiplatform as aip\n",
        "from google.cloud import storage\n",
        "from google.cloud.aiplatform import gapic\n",
        "from google.protobuf.json_format import ParseDict\n",
        "from google.protobuf.struct_pb2 import Value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "750d53e37094"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adcc964aaaa1"
      },
      "outputs": [],
      "source": [
        "aip.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aip_constants"
      },
      "source": [
        "#### Vertex AI constants\n",
        "\n",
        "Setup up the following constants for Vertex AI:\n",
        "\n",
        "- `API_ENDPOINT`: The Vertex AI API service endpoint for dataset, model, job, pipeline and endpoint services.\n",
        "- `PARENT`: The Vertex AI location root path for dataset, model and endpoint resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBBYqHEd_i_8"
      },
      "outputs": [],
      "source": [
        "# API Endpoint\n",
        "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
        "\n",
        "# Vertex AI location root path for your dataset, model and endpoint resources\n",
        "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "automl_constants:automl"
      },
      "source": [
        "#### Schema constants\n",
        "\n",
        "Next, setup constants for schemas related image classification datasets:\n",
        "\n",
        "- Data Labeling (Annotations) Schemas: Tells the managed dataset service how the data is labeled (annotated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "automl_constants:automl,icn"
      },
      "outputs": [],
      "source": [
        "# Image labeling task\n",
        "LABELING_SCHEMA_IMAGE = \"gs://google-cloud-aiplatform/schema/datalabelingjob/inputs/image_classification_1.0.0.yaml\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clients"
      },
      "source": [
        "## Create clients\n",
        "\n",
        "The Vertex AI SDK works as a client/server model. On your side (the Python script) you create a client that sends requests and receives responses from the server (Vertex AI).\n",
        "\n",
        "You use several clients in this tutorial, so set them all up upfront.\n",
        "\n",
        "- Specialist pool service for specialist pools\n",
        "- Job Service for data labeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2p2VYUz_i_-"
      },
      "outputs": [],
      "source": [
        "# client options same for all services\n",
        "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
        "\n",
        "clients = {}\n",
        "clients[\"job\"] = gapic.JobServiceClient(client_options=client_options)\n",
        "\n",
        "# add client for specialist pool\n",
        "clients[\"specialist_pool\"] = gapic.SpecialistPoolServiceClient(\n",
        "    client_options=client_options\n",
        ")\n",
        "\n",
        "for client in clients.items():\n",
        "    print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d4b33eb3c71"
      },
      "source": [
        "### Create a CSV file for examples to label\n",
        "\n",
        "Next, you will create a CSV file for the examples you are requesting to be labeled. \n",
        "\n",
        "In this example, the examples to label are images. For each row in the CSV file, you specify the Cloud Storage location of the image to label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_file:flowers,csv,icn"
      },
      "outputs": [],
      "source": [
        "test_filename = \"labeling.csv\"\n",
        "LABELING_FILES = [\n",
        "    \"gs://cloud-samples-data/vision/automl_classification/flowers/daisy/100080576_f52e8ee070_n.jpg\",\n",
        "    \"gs://cloud-samples-data/vision/automl_classification/flowers/daisy/102841525_bd6628ae3c.jpg\",\n",
        "]\n",
        "\n",
        "IMPORT_FILE = BUCKET_URI + \"/labeling.csv\"\n",
        "\n",
        "bucket = storage.Client(project=PROJECT_ID).bucket(BUCKET_URI.replace(\"gs://\", \"\"))\n",
        "\n",
        "# creating a blob\n",
        "blob = bucket.blob(blob_name=test_filename)\n",
        "\n",
        "# creating data variable\n",
        "data = LABELING_FILES[0] + \"\\n\" + LABELING_FILES[1] + \"\\n\"\n",
        "\n",
        "# uploading data variable content to bucket\n",
        "blob.upload_from_string(data, content_type=\"text/csv\")\n",
        "\n",
        "# printing path of uploaded file\n",
        "print(IMPORT_FILE)\n",
        "\n",
        "# printing content of uploaded file\n",
        "! gsutil cat $IMPORT_FILE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_a_dataset:migration"
      },
      "source": [
        "## Create a unlabeled dataset\n",
        "\n",
        "Next, you create a dataset for the data to be labeled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9af8aed4e3ab"
      },
      "outputs": [],
      "source": [
        "dataset = aip.ImageDataset.create(\"labeling\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92909927fe7e"
      },
      "source": [
        "## Import the unlabeled data\n",
        "\n",
        "Now, import the unlabeled data to the dataset, i.e., the examples to be labeled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c137a55b822e"
      },
      "outputs": [],
      "source": [
        "dataset.import_data(\n",
        "    gcs_source=[IMPORT_FILE],\n",
        "    import_schema_uri=aip.schema.dataset.ioformat.image.single_label_classification,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trainingpipelines_create:migration,new"
      },
      "source": [
        "## Create a new data specialist pool\n",
        "\n",
        "Your data labeling job will be sent to a data specialist pool. You may have one or more multiple specialist pools. \n",
        "\n",
        "In this next step, you create a new specialist pool with the method `create_specialist_pool()`. The request includes the parameters:\n",
        "\n",
        "- `name`: The resource name of the specialist pool.\n",
        "- `display_name`: A human readable name for the specialist pool.\n",
        "- `specialist_manager_emails`: A list of the email addresses of the manager(s) for the specialist pool.\n",
        "\n",
        "*Note:* You can use an existing specialist pool if one already existed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsXOMVOMq3jO"
      },
      "outputs": [],
      "source": [
        "specialist_pool = {\n",
        "    \"name\": \"labeling\",\n",
        "    \"display_name\": \"labeling\",\n",
        "    \"specialist_manager_emails\": [EMAIL],\n",
        "}\n",
        "\n",
        "request = clients[\"specialist_pool\"].create_specialist_pool(\n",
        "    parent=PARENT, specialist_pool=specialist_pool\n",
        ")\n",
        "\n",
        "result = request.result()\n",
        "print(result)\n",
        "\n",
        "specialist_name = result.name\n",
        "\n",
        "specialist_id = specialist_name.split(\"/\")[-1]\n",
        "\n",
        "print(specialist_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_a_model:migration"
      },
      "source": [
        "## Create data labeling job\n",
        "\n",
        "Now that you have a specialist pool, you can send a data labeling request using the `create_data_labeling_job()` method.\n",
        "\n",
        "Your request will consist of the following:\n",
        "\n",
        "- The Vertex AI Dataset with the unlabeled data.\n",
        "- Instructions for labeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AY3SJjQq3jQ"
      },
      "outputs": [],
      "source": [
        "# create placeholder file for instructions for data labeling\n",
        "! echo \"this is instruction\" >> instruction.txt | gsutil cp instruction.txt $BUCKET_URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trainingpipelines_create:migration,new,request,icn"
      },
      "outputs": [],
      "source": [
        "LABLEING_SCHEMA = LABELING_SCHEMA_IMAGE\n",
        "INSTRUCTION_FILE = BUCKET_URI + \"/instruction.txt\"\n",
        "\n",
        "inputs = ParseDict({\"annotation_specs\": [\"rose\"]}, Value())\n",
        "\n",
        "data_labeling_job = {\n",
        "    \"display_name\": \"labeling\",\n",
        "    \"datasets\": [dataset.resource_name],\n",
        "    \"labeler_count\": 1,\n",
        "    \"instruction_uri\": INSTRUCTION_FILE,\n",
        "    \"inputs_schema_uri\": LABLEING_SCHEMA,\n",
        "    \"inputs\": inputs,\n",
        "    \"annotation_labels\": {\n",
        "        \"aiplatform.googleapis.com/annotation_set_name\": \"data_labeling_job_specialist_pool\"\n",
        "    },\n",
        "    \"specialist_pools\": [specialist_name],\n",
        "}\n",
        "\n",
        "print(data_labeling_job)\n",
        "\n",
        "request = clients[\"job\"].create_data_labeling_job(\n",
        "    parent=PARENT, data_labeling_job=data_labeling_job\n",
        ")\n",
        "\n",
        "print(request)\n",
        "\n",
        "labeling_task_name = request.name\n",
        "\n",
        "print(labeling_task_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3jRv70o_jAN"
      },
      "source": [
        "### Get a data labeling job\n",
        "\n",
        "You can get information on your data labeling job using the `get_data_labeling_job()` method, with the following parameters:\n",
        "\n",
        "- `name`: The name of the labeling task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPnMOftyq3jS"
      },
      "outputs": [],
      "source": [
        "request = clients[\"job\"].get_data_labeling_job(name=labeling_task_name)\n",
        "print(request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ0TVlokq3jS"
      },
      "source": [
        "### Cancel a data labeling task\n",
        "\n",
        "You can cancel a data labeling request using the `cancel_data_labeling_job()` method, with the following parameters:\n",
        "\n",
        "- `name`: The name of the labeling task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ3dlKJjq3jT"
      },
      "outputs": [],
      "source": [
        "request = clients[\"job\"].cancel_data_labeling_job(name=labeling_task_name)\n",
        "print(request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d37f8ede2327"
      },
      "source": [
        "### Wait for labeling job to be canceled\n",
        "\n",
        "The cancel request is asyncrhonous. The code below polls on the labeling job status until the status is CANCELED."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trainingpipelines_get:migration,new,wait"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    response = clients[\"job\"].get_data_labeling_job(name=labeling_task_name)\n",
        "    if response.state == gapic.JobState.JOB_STATE_CANCELLED:\n",
        "        print(\"Labeling job CANCELED\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Canceling labeling job:\", response.state)\n",
        "        time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup:migration,new"
      },
      "source": [
        "# Cleaning up\n",
        "\n",
        "To clean up all GCP resources used in this project, you can [delete the GCP\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoJ18d8Y_jAy"
      },
      "outputs": [],
      "source": [
        "# Set this to true only if you'd like to delete your bucket\n",
        "delete_bucket = False\n",
        "\n",
        "# Delete the dataset using the Vertex AI fully qualified identifier for the dataset\n",
        "dataset.delete()\n",
        "\n",
        "# Delete the labeling job using the Vertex AI fully qualified identifier for the dataset\n",
        "request = clients[\"job\"].delete_data_labeling_job(name=labeling_task_name)\n",
        "\n",
        "# Delete the specialist pool using the Vertex AI fully qualified identifier for the dataset\n",
        "clients[\"specialist_pool\"].delete_specialist_pool(name=specialist_name)\n",
        "\n",
        "# Delete the bucket created\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "timestamp",
        "gcp_authenticate",
        "bucket:batch_prediction",
        "setup_vars",
        "import_aip",
        "aip_constants",
        "automl_constants:automl",
        "datasets_create:migration,new",
        "request:migration",
        "call:migration",
        "response:migration",
        "datasets_import:migration,new",
        "oJtL08_Q_jAF",
        "rnhDF5vW_jAG",
        "zQoFJ2K0_jAH",
        "trainingpipelines_create:migration,new",
        "m5igPySU_jAJ",
        "xhuR86RL_jAK",
        "S8zP7wju_jAL",
        "trainingpipelines_get:migration,new",
        "A3jRv70o_jAN",
        "XC5I2xxt_jAN",
        "models_evaluations_list:migration,new",
        "Ngn6qqVy_jAQ",
        "F0ryqI3F_jAQ",
        "models_evaluations_get:migration,new",
        "_NXujm2U_jAR",
        "0RLTdCfj_jAS",
        "make_batch_prediction_file:migration,new",
        "make_batch_file:automl,image",
        "batchpredictionjobs_create:migration,new",
        "htIpycBi_jAX",
        "8QO3y-36_jAY",
        "DmClxRYK_jAY",
        "batchpredictionjobs_get:migration,new",
        "aSE_wqES_jAa",
        "LUy0NIF__jAa",
        "endpoints_create:migration,new",
        "Ph5S0j4v_jAc",
        "yjsSo1cM_jAd",
        "ijvF_HGd_jAe",
        "endpoints_deploymodel:migration,new",
        "NFIRI0XT_jAf",
        "c3_4BVyW_jAh",
        "7NmySa8R_jAh",
        "endpoints_predict:migration,new",
        "6fb84nKh_jAk",
        "h6IskqWe_jAo",
        "KHf2BSMR_jAo",
        "endpoints_undeploymodel:migration,new",
        "KrVZz6Uw_jAp",
        "wvFK-kir_jAq",
        "5bwEQMKT_jAr",
        "LOsxiKj4_jAs",
        "PWMEUCbF_jAt",
        "OalQ6m9P_jAu",
        "models_export:migration,new",
        "lqJoqYMI_jAv",
        "v6isqzPQ_jAw",
        "ZCyd1qAb_jAx"
      ],
      "name": "get_started_with_data_labeling.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
