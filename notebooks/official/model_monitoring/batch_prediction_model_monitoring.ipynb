{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d3069d95"
      },
      "outputs": [],
      "source": [
        "# @title Copyright & License (click to expand)\n",
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "546c53de"
      },
      "source": [
        "# Vertex AI Batch Prediction with Model Monitoring\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/batch_prediction_model_monitoring.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/batch_prediction_model_monitoring.ipynb\">\n",
        "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "    <td>\n",
        "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/model_monitoring/batch_prediction_model_monitoring.ipynb\" target='_blank'>\n",
        "       <img src=\"https://www.gstatic.com/cloud/images/navigation/vertex-ai.svg\" alt=\"Vertex AI logo\">Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td> \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53fd1070"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, you learn how to use Model Monitoring with batch prediction requests on a deployed Vertex AI Model resource. In a companion notebook, <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\" target=\"_blank\">Vertex AI Model Monitoring with Explainable AI Feature Attributions</a>, you can learn about how to apply model monitoring to streaming, real-time predictions.\n",
        "\n",
        "Learn more about [Vertex AI Model Monitoring for batch predictions](https://cloud.google.com/vertex-ai/docs/model-monitoring/model-monitoring-batch-predictions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b26c855"
      },
      "source": [
        "### Objective\n",
        "In this notebook, you learn to use the `Vertex AI Model Monitoring` service to detect drift and anomalies in batch prediction.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- Vertex AI Model Monitoring\n",
        "- Vertex AI Batch Prediction\n",
        "- Vertex AI Model resource\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Upload a pre-trained model as a Vertex AI Model resource.\n",
        "- Generate batch prediction requests.\n",
        "- Interpret the statistics, visualizations, other data reported by the model monitoring feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35b52a5fba4a"
      },
      "source": [
        "### Model\n",
        "\n",
        "This tutorial uses a pre-trained model, where the model artifacts are stored in a public Cloud Storage bucket. The model predicts for an online gaming site, the probability that a player may churn, i.e. stop being an active player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5508f7979954"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertext AI\n",
        "* Google Cloud Storage\n",
        "\n",
        "Learn about [Vertext AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d52ba95b"
      },
      "source": [
        "### What is Vertex AI batch prediction?\n",
        "\n",
        "<a href=\"https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions\" target=\"_blank\">Batch Prediction</a> is a service that processes a collection (i.e. a batch) of machine learning inference requests in bulk, with less stringent response time requirements than real-time or streaming predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64fb18a"
      },
      "source": [
        "### What is Vertex AI model monitoring?\n",
        "\n",
        "<a href=\"https://cloud.google.com/vertex-ai/docs/model-monitoring\" target=\"_blank\">Model Monitoring</a> is a service that automatically determines \n",
        "whether production machine learning traffic differs from  training data, or varies substantially over time, in terms of model predictions or feature attributions. When that happens, you can be alerted automatically and responsively, whereby, you can detect model decay which may negatively impact your operations -- such as your customer experience and/or revenue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d839347"
      },
      "source": [
        "### The example model\n",
        "\n",
        "The model you use in this notebook is based on [this blog post](https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game-developers-using-google-analytics-4-ga4-and-bigquery-ml). The idea behind this model is that your company has extensive log data describing how your game users have interacted with the site. The raw data contains the following categories of information:\n",
        "\n",
        "- identity - unique player identitity numbers\n",
        "- demographic features - information about the player, such as the geographic region in which a player is located\n",
        "- behavioral features - counts of the number of times a  player has triggered certain game events, such as reaching a new level\n",
        "- churn propensity - this is the label or target feature, it provides an estimated probability that this player churns, i.e. stop being an active player.\n",
        "\n",
        "The blog article referenced above explains how to use BigQuery to store the raw data, pre-process it for use in machine learning, and train a model. Because this notebook focuses on model monitoring, rather than training models, you're going to reuse a pre-trained version of this model, which has been exported to Google Cloud Storage. In the next section, you setup your environment and import this model into your own project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "738fce1f"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the packages required for executing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4536fe4e"
      },
      "outputs": [],
      "source": [
        "# Install Python package dependencies.\n",
        "! pip3 install --upgrade --quiet google-cloud-aiplatform\n",
        "\n",
        "! pip3 install --upgrade tensorflow-data-validation==1.12.0\n",
        "\n",
        "! pip3 install --quiet cachetools==5.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "restart"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-ZBOjErv5mM"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "before_you_begin:nogpu"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e383c269bcf"
      },
      "source": [
        "### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dw8q9fdQEH5"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71404c9f"
      },
      "source": [
        "#### Set your email address\n",
        "This is used for delivering model monitoring notifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b1d2b69"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "EMAIL_ADDRESS = \"[your-email-address]\"  # @param {type:\"string\"}\n",
        "if not EMAIL_ADDRESS or EMAIL_ADDRESS == \"[your-email-address]\":\n",
        "    if os.getenv(\"IS_TESTING\"):\n",
        "        EMAIL_ADDRESS = \"noreply@google.com\"\n",
        "    else:\n",
        "        print(\"EMAIL_ADDRESS not specified, please correct before proceeding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcp_authenticate"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n",
        "\n",
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated.\n",
        "\n",
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce6043da7b33"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0367eac06a10"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ad4dbb4a61"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13224697bfb"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:mbsdk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "autoset_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91c46850b49b"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0d294ff6d10"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd7a633296eb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import google.cloud.aiplatform as aiplatform\n",
        "import tensorflow_data_validation as tfdv\n",
        "from google.cloud.aiplatform_v1beta1.services.job_service import \\\n",
        "    JobServiceClient\n",
        "from google.cloud.aiplatform_v1beta1.types import (\n",
        "    BatchDedicatedResources, BatchPredictionJob, GcsDestination, GcsSource,\n",
        "    MachineSpec, ModelMonitoringAlertConfig, ModelMonitoringConfig,\n",
        "    ModelMonitoringObjectiveConfig, ThresholdConfig)\n",
        "from tensorflow_data_validation.utils import io_util\n",
        "from tensorflow_metadata.proto.v0 import statistics_pb2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accelerators:training,prediction"
      },
      "source": [
        "#### Set hardware accelerators\n",
        "\n",
        "You can set hardware accelerators for prediction (e.g., GPUs) or choose not to use any (CPU). Hardware accelertors lower the latency response for a prediction request. When choosing a hardware accelerators, consider the additional cost trade-off over latency.\n",
        "\n",
        "Set the variables `DEPLOY_GPU/DEPLOY_NGPU` to use a container image supporting a GPU and the number of GPUs allocated to the virtual machine (VM) instance. For example, to use a GPU container image with 4 Nvidia Tesla K80 GPUs allocated to each VM, you would specify:\n",
        "\n",
        "    (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
        "\n",
        "See the [locations where accelerators are available](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators).\n",
        "\n",
        "Otherwise specify `(None, None)` to use a container image to run on a CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd5PLXDTlugv"
      },
      "outputs": [],
      "source": [
        "GPU = False\n",
        "if GPU:\n",
        "    DEPLOY_GPU, DEPLOY_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
        "else:\n",
        "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "container:training,prediction"
      },
      "source": [
        "#### Set pre-built containers\n",
        "\n",
        "Set the pre-built Docker container image for prediction.\n",
        "\n",
        "For the latest list, see [Pre-built containers for prediction](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u1mr18jlugv"
      },
      "outputs": [],
      "source": [
        "if GPU:\n",
        "    DEPLOY_VERSION = \"tf2-gpu.2-9\"\n",
        "else:\n",
        "    DEPLOY_VERSION = \"tf2-cpu.2-9\"\n",
        "\n",
        "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
        "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
        ")\n",
        "\n",
        "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "machine:training,prediction"
      },
      "source": [
        "#### Set machine types\n",
        "\n",
        "Next, set the machine types to use for training and prediction.\n",
        "\n",
        "- Set the variable `DEPLOY_COMPUTE` to configure your compute resources for prediction.\n",
        " - `machine type`\n",
        "     - `n1-standard`: 3.75GB of memory per vCPU\n",
        "     - `n1-highmem`: 6.5GB of memory per vCPU\n",
        "     - `n1-highcpu`: 0.9 GB of memory per vCPU\n",
        " - `vCPUs`: number of \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
        "\n",
        "*Note: You may also use n2 and e2 machine types for training and deployment, but they do not support GPUs*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAXwbqKKlugv"
      },
      "outputs": [],
      "source": [
        "TRAIN_COMPUTE = \"n1-standard-4\"\n",
        "print(\"Train machine type\", TRAIN_COMPUTE)\n",
        "\n",
        "DEPLOY_COMPUTE = \"n1-standard-4\"\n",
        "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bf06cd476e9"
      },
      "source": [
        "### Upload the model artifacts as a `Vertex AI Model` resource\n",
        "\n",
        "First, you upload the pre-trained custom tabular model artifacts as a `Vertex AI Model` resource using the `upload()` method, with the following parameters:\n",
        "\n",
        "- `display_name`: The human readable name for the `Model` resource.\n",
        "- `artifact_uri`: The Cloud Storage location of the model artifacts.\n",
        "- `serving_container_image`: The serving container image to use when the model is deployed to a `Vertex AI Endpoint` resource.\n",
        "- `sync`: Whether to wait for the process to complete, or return immediately (async)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0193f247e216"
      },
      "outputs": [],
      "source": [
        "MODEL_ARTIFACT_URI = \"gs://mco-mm/churn\"\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=\"churn\",\n",
        "    artifact_uri=MODEL_ARTIFACT_URI,\n",
        "    serving_container_image_uri=DEPLOY_IMAGE,\n",
        "    sync=True,\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4305ddf"
      },
      "source": [
        "## Submit a batch prediction request with model monitoring enabled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "053fde99"
      },
      "source": [
        "### Create Cloud Storage buckets\n",
        "\n",
        "This cell creates two Cloud Storage buckets:\n",
        "\n",
        "- `gs://PROJECT_ID_bp_mm_input` contains the batch prediction request data.\n",
        "- `gs://PROJECT_ID_bp_mm_output` contains the batch prediction output as well as the model monitoring results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b832ad31"
      },
      "outputs": [],
      "source": [
        "# Copy files to your projects gs bucket to avoid permission issues.\n",
        "# Ignore any error(s) for bucket already exists.\n",
        "OUTPUT_GS_PATH = f\"{BUCKET_URI}/bp_mm_output\"\n",
        "INPUT_GS_PATH = f\"{BUCKET_URI}/bp_mm_input\"\n",
        "PUBLIC_TRAINING_DATASET = \"gs://bp_mm_public_data/churn/churn_bp_insample.csv\"\n",
        "TRAINING_DATASET = f\"{INPUT_GS_PATH}/churn_bp_insample.csv\"\n",
        "TRAINING_DATASET_FORMAT = \"csv\"\n",
        "\n",
        "! gsutil copy $PUBLIC_TRAINING_DATASET $TRAINING_DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34c95126"
      },
      "source": [
        "### Create batch prediction job\n",
        "\n",
        "This step parameterizes and builds the data structure representing the batch prediction request, with model monitoring enabled.\n",
        "\n",
        "The BatchPredictionJob object specifies the input source, the data format, and the computing resources requests for the batch prediction. Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/samples/aiplatform-create-batch-prediction-job-sample\" target=\"_blank\">BatchPredictionJob</a>.\n",
        "\n",
        "The ModelMonitoringConfig object specifies the alerting email address, the training dataset, the features to be monitored, and their associated alerting thresholds. Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/model-monitoring\" target=\"_blank\">ModelMonitoringConfig</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a54368a"
      },
      "outputs": [],
      "source": [
        "INPUT_URI = \"gs://bp_mm_public_data/churn/churn_bp_outsample.jsonl\"\n",
        "OUTPUT_URI = OUTPUT_GS_PATH\n",
        "INSTANCES_FORMAT = \"jsonl\"\n",
        "PREDICTIONS_FORMAT = \"jsonl\"\n",
        "JOB_NAME_PREFIX = \"bp_mm_demo\"\n",
        "MODEL_NAME = model.resource_name\n",
        "BATCH_PREDICTION_JOB_NAME = JOB_NAME_PREFIX\n",
        "\n",
        "batch_prediction_job = BatchPredictionJob(\n",
        "    display_name=BATCH_PREDICTION_JOB_NAME,\n",
        "    model=MODEL_NAME,\n",
        "    input_config=BatchPredictionJob.InputConfig(\n",
        "        instances_format=INSTANCES_FORMAT, gcs_source=GcsSource(uris=[INPUT_URI])\n",
        "    ),\n",
        "    output_config=BatchPredictionJob.OutputConfig(\n",
        "        predictions_format=PREDICTIONS_FORMAT,\n",
        "        gcs_destination=GcsDestination(output_uri_prefix=OUTPUT_URI),\n",
        "    ),\n",
        "    dedicated_resources=BatchDedicatedResources(\n",
        "        machine_spec=MachineSpec(machine_type=DEPLOY_COMPUTE),\n",
        "        starting_replica_count=1,\n",
        "        max_replica_count=1,\n",
        "    ),\n",
        "    # Model monitoring service is triggerred if provide following configs.\n",
        "    model_monitoring_config=ModelMonitoringConfig(\n",
        "        alert_config=ModelMonitoringAlertConfig(\n",
        "            email_alert_config=ModelMonitoringAlertConfig.EmailAlertConfig(\n",
        "                user_emails=[EMAIL_ADDRESS]\n",
        "            )\n",
        "        ),\n",
        "        objective_configs=[\n",
        "            ModelMonitoringObjectiveConfig(\n",
        "                training_dataset=ModelMonitoringObjectiveConfig.TrainingDataset(\n",
        "                    data_format=TRAINING_DATASET_FORMAT,\n",
        "                    gcs_source=GcsSource(uris=[TRAINING_DATASET]),\n",
        "                ),\n",
        "                training_prediction_skew_detection_config=ModelMonitoringObjectiveConfig.TrainingPredictionSkewDetectionConfig(\n",
        "                    skew_thresholds={\n",
        "                        \"cnt_user_engagement\": ThresholdConfig(value=0.001),\n",
        "                        \"julianday\": ThresholdConfig(value=0.001),\n",
        "                    }\n",
        "                ),\n",
        "            )\n",
        "        ],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cae39778"
      },
      "source": [
        "### Submit batch prediction job\n",
        "\n",
        "This step submits the batch prediction request created in the previous step. If successful, it returns a JSON document summarizing the request, which is displayed in the cell output below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcdd4a47"
      },
      "outputs": [],
      "source": [
        "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
        "client = JobServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
        "out = client.create_batch_prediction_job(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
        "    batch_prediction_job=batch_prediction_job,\n",
        ")\n",
        "BATCH_PREDICTION_JOB_ID = out.name.split(\"/\")[-1]\n",
        "print(\"BATCH_PREDICTION_JOB_ID:\", BATCH_PREDICTION_JOB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ec90a0"
      },
      "source": [
        "## Verify prediction results\n",
        "\n",
        "The batch prediction request gets completed after about **17 mins**, and the model monitoring result is available **10 mins** post that. The request below obtains the batch prediction job id, which is a unique number associated with asynchronous requests like this one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c30496b5"
      },
      "outputs": [],
      "source": [
        "# If auto-testing, wait for request completion\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    time.sleep(3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831651c2"
      },
      "source": [
        "### Browse storage bucket\n",
        "\n",
        "Click on the link below, which opens the Cloud Storage object viewer on the output bucket you created above, to see the results of your batch prediction request.\n",
        "\n",
        "When everything is ready, you see two folders in the bucket:\n",
        "\n",
        "- `prediction-batch_prediction_monitoring_test_model_<timestmap>` - this folder contains the your batch prediction results, i.e. the predictions produced by your model for each input in the batch\n",
        "- `job-<id>` - this folder contains the model monitoring results, including the model schema, monitoring thresholds and other config settings, statistics, and anomalies\n",
        "\n",
        "*Note:* Until the request and the monitoring job are completed, you may see empty or partial results in this bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a705c10b"
      },
      "outputs": [],
      "source": [
        "print(f\"https://console.cloud.google.com/storage/browser/{OUTPUT_URI.lstrip('gs://')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bbdddac"
      },
      "source": [
        "### Visualize the batch prediction result\n",
        "\n",
        "Run the following cell to examine the batch prediction results with a tabular and visual analysis using the <a href=\"https://www.tensorflow.org/tfx/data_validation/get_started\" target=\"_blank\">TensorFlow Data Validation</a> package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6c674e9"
      },
      "outputs": [],
      "source": [
        "! rm -f ./training_stats.pb\n",
        "! rm -f ./prediction_stats.pb\n",
        "\n",
        "TRAINING_STATS_SUBPATH = \"stats_training/stats/training_stats\"\n",
        "PREDICTION_STATS_SUBPATH = \"stats_and_anomalies/stats/current_stats\"\n",
        "STATS_GCS_FOLDER = OUTPUT_URI = (\n",
        "    OUTPUT_GS_PATH + \"/job-\" + BATCH_PREDICTION_JOB_ID + \"/bp_monitoring/\"\n",
        ")\n",
        "TRAINING_STATS_GCS_PATH = STATS_GCS_FOLDER + TRAINING_STATS_SUBPATH\n",
        "print(\"Looking up statistics from: \" + TRAINING_STATS_GCS_PATH)\n",
        "PREDICTION_STATS_GCS_PATH = STATS_GCS_FOLDER + PREDICTION_STATS_SUBPATH\n",
        "print(\"Looking up statistics from: \" + PREDICTION_STATS_GCS_PATH)\n",
        "\n",
        "! gsutil cp $TRAINING_STATS_GCS_PATH ./training_stats.pb\n",
        "! gsutil cp $PREDICTION_STATS_GCS_PATH ./prediction_stats.pb\n",
        "\n",
        "\n",
        "# util function to load stats binary file from GCS\n",
        "def load_stats_binary(input_path):\n",
        "    stats_proto = statistics_pb2.DatasetFeatureStatisticsList()\n",
        "    stats_proto.ParseFromString(\n",
        "        io_util.read_file_to_string(input_path, binary_mode=True)\n",
        "    )\n",
        "    return stats_proto\n",
        "\n",
        "\n",
        "tfdv.visualize_statistics(load_stats_binary(\"./training_stats.pb\"))\n",
        "tfdv.visualize_statistics(load_stats_binary(\"./prediction_stats.pb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233b1266"
      },
      "source": [
        "### Check skew results\n",
        "\n",
        "Finally, you can check the skew results by examining a file in the output bucket. The JSON file contains a report indicating how much the batch prediction data deviates from the training data, on a feature-by-feature basis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e8c00a7"
      },
      "outputs": [],
      "source": [
        "SKEW_GS_PATH = (\n",
        "    STATS_GCS_FOLDER\n",
        "    + \"stats_and_anomalies/anomalies/training_prediction_skew_anomalies\"\n",
        ")\n",
        "! gsutil cat $SKEW_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aa0219d"
      },
      "source": [
        "## Learn more\n",
        "\n",
        "**Congratulations!** You've now learned how to monitor batch predictions, and how to find and interpret the results. Check out the following resources to learn more about model monitoring and ML Ops.\n",
        "\n",
        "- [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv)\n",
        "- [Data Understanding, Validation, and Monitoring At Scale](https://blog.tensorflow.org/2018/09/introducing-tensorflow-data-validation.html)\n",
        "- [Vertex Product Documentation](https://cloud.google.com/vertex-ai)\n",
        "- [Vertex AI Model Monitoring Reference Docs](https://cloud.google.com/vertex-ai/docs/reference)\n",
        "- [Vertex AI Model Monitoring blog article](https://cloud.google.com/blog/topics/developers-practitioners/monitor-models-training-serving-skew-vertex-ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "497a0016"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "- Vertex AI Model\n",
        "- Batch prediction job\n",
        "- Cloud Storage bucket (set `delete_bucket` to *True* for deletion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eabc3f81"
      },
      "outputs": [],
      "source": [
        "# Delete model resource\n",
        "model.delete()\n",
        "\n",
        "# Get the batch prediction job resource\n",
        "batch_job = aiplatform.BatchPredictionJob(\n",
        "    batch_prediction_job_name=BATCH_PREDICTION_JOB_ID\n",
        ")\n",
        "# Delete the job\n",
        "batch_job.delete()\n",
        "\n",
        "# Delete Cloud Storage bucket\n",
        "delete_bucket = False\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "batch_prediction_model_monitoring.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
