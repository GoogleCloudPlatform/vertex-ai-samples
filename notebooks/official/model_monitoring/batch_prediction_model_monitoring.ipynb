{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d3069d95"
      },
      "outputs": [],
      "source": [
        "# @title Copyright & License (click to expand)\n",
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "546c53de"
      },
      "source": [
        "# Vertex AI Batch Prediction with Model Monitoring\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/batch_prediction_model_monitoring.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/batch_prediction_model_monitoring.ipynb\">\n",
        "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "    <td>\n",
        "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/model_monitoring/batch_prediction_model_monitoring.ipynb\" target='_blank'>\n",
        "       <img src=\"https://www.gstatic.com/cloud/images/navigation/vertex-ai.svg\" alt=\"Vertex AI logo\">Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td> \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53fd1070"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, you will learn how to use Model Monitoring with batch prediction requests on a deployed Vertex AI Model resource. In a companion notebook, <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\" target=\"_blank\">Vertex AI Model Monitoring with Explainable AI Feature Attributions</a>, you can learn about how to apply model monitoring to streaming, real-time predictions.\n",
        "\n",
        "Learn more about [Vertex AI Model Monitoring for batch predictions](https://cloud.google.com/vertex-ai/docs/model-monitoring/model-monitoring-batch-predictions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b26c855"
      },
      "source": [
        "### Objective\n",
        "In this notebook, you learn to use the `Vertex AI Model Monitoring` service to detect drift and anomalies in batch prediction.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- Vertex AI Model Monitoring\n",
        "- Vertex AI Batch Prediction\n",
        "- Vertex AI Model resource\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Upload a pre-trained model as a Vertex AI Model resource.\n",
        "- Generate batch prediction requests.\n",
        "- Interpret the statistics, visualizations, other data reported by the model monitoring feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35b52a5fba4a"
      },
      "source": [
        "### Model\n",
        "\n",
        "This tutorial uses a pre-trained model, where the model artifacts are stored in a public Cloud Storage bucket. The model predicts for an online gaming site, the probability that a player may churn, i.e. stop being an active player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5508f7979954"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertext AI\n",
        "* Google Cloud Storage\n",
        "\n",
        "Learn about [Vertext AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d52ba95b"
      },
      "source": [
        "### What is Vertex AI batch prediction?\n",
        "\n",
        "<a href=\"https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions\" target=\"_blank\">Batch Prediction</a> is a service that processes a collection (i.e. a batch) of machine learning inference requests in bulk, with less stringent response time requirements than real-time or streaming predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64fb18a"
      },
      "source": [
        "### What is Vertex AI model monitoring?\n",
        "\n",
        "<a href=\"https://cloud.google.com/vertex-ai/docs/model-monitoring\" target=\"_blank\">Model Monitoring</a> is a service that automatically determines \n",
        "whether production machine learning traffic differs from  training data, or varies substantially over time, in terms of model predictions or feature attributions. When that happens, you can be alerted automatically and responsively, whereby, you can detect model decay which may negatively impact your operations -- such as your customer experience and/or revenue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d839347"
      },
      "source": [
        "### The example model\n",
        "\n",
        "The model you'll use in this notebook is based on [this blog post](https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game-developers-using-google-analytics-4-ga4-and-bigquery-ml). The idea behind this model is that your company has extensive log data describing how your game users have interacted with the site. The raw data contains the following categories of information:\n",
        "\n",
        "- identity - unique player identitity numbers\n",
        "- demographic features - information about the player, such as the geographic region in which a player is located\n",
        "- behavioral features - counts of the number of times a  player has triggered certain game events, such as reaching a new level\n",
        "- churn propensity - this is the label or target feature, it provides an estimated probability that this player will churn, i.e. stop being an active player.\n",
        "\n",
        "The blog article referenced above explains how to use BigQuery to store the raw data, pre-process it for use in machine learning, and train a model. Because this notebook focuses on model monitoring, rather than training models, you're going to reuse a pre-trained version of this model, which has been exported to Google Cloud Storage. In the next section, you will setup your environment and import this model into your own project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "738fce1f"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the packages required for executing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4536fe4e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "assert sys.version_info.major == 3, \"This notebook requires Python 3.\"\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "# Install Python package dependencies.\n",
        "! pip3 install -q {USER_FLAG} google-cloud-aiplatform \\\n",
        "                              tensorflow-data-validation \\\n",
        "                              protobuf==3.20.3\n",
        "\n",
        "! pip3 install -q {USER_FLAG} cachetools==5.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e98402b"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the SDK, you need to restart the notebook kernel so it can find the packages. You can restart kernel from *Kernel -> Restart Kernel*, or running the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9775c9ff"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5737134"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.7\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfb1a1d5"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8535e4"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c2be4bd"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "    # Get your GCP project id from gcloud\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c129705c"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83340af4"
      },
      "source": [
        "#### Set your region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4814ea21"
      },
      "outputs": [],
      "source": [
        "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
        "\n",
        "if REGION == \"[your-region]\":\n",
        "    REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06571eb4063b"
      },
      "source": [
        "#### UUID\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e166d927e36"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "\n",
        "# Generate a uuid of a specifed length(default=8)\n",
        "def generate_uuid(length: int = 8) -> str:\n",
        "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
        "\n",
        "\n",
        "UUID = generate_uuid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71404c9f"
      },
      "source": [
        "#### Set your email address\n",
        "This is used for delivering model monitoring notifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b1d2b69"
      },
      "outputs": [],
      "source": [
        "EMAIL_ADDRESS = \"[your-email-address]\"  # @param {type:\"string\"}\n",
        "if not EMAIL_ADDRESS or EMAIL_ADDRESS == \"[your-email-address]\":\n",
        "    print(\"EMAIL_ADDRESS not specified, please correct before proceeding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a546c3"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Vertex AI Workbench notebooks**, your environment is already\n",
        "authenticated.\n",
        "\n",
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "1. In the Cloud Console, go to the [**Create service account key**\n",
        "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
        "\n",
        "2. Click **Create service account**.\n",
        "\n",
        "3. In the **Service account name** field, enter a name, and\n",
        "   click **Create**.\n",
        "\n",
        "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"Vertex AI\"\n",
        "into the filter box, and select\n",
        "   **Vertex AI Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "5. Click **Create**. A JSON file that contains your key downloads to your\n",
        "local environment.\n",
        "\n",
        "6. Enter the path to your service account key as the\n",
        "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06c51076"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Determine notebook environment.\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "if not IS_WORKBENCH_NOTEBOOK and not IS_USER_MANAGED_WORKBENCH_NOTEBOOK:\n",
        "    if IS_COLAB:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:custom"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "Set the name of your Cloud Storage bucket below, which you use in this tutorial to upload the `input schema` for the monitoring service.\n",
        "\n",
        "Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autoset_bucket"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
        "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "validate_bucket"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validate_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0d294ff6d10"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd7a633296eb"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "import tensorflow_data_validation as tfdv\n",
        "from tensorflow_data_validation.utils import io_util\n",
        "from tensorflow_metadata.proto.v0 import statistics_pb2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accelerators:training,prediction"
      },
      "source": [
        "#### Set hardware accelerators\n",
        "\n",
        "You can set hardware accelerators for prediction (e.g., GPUs) or choose not to use any (CPU). Hardware accelertors lower the latency response for a prediction request. When choosing a hardware accelerators, consider the additional cost trade-off over latency.\n",
        "\n",
        "Set the variables `DEPLOY_GPU/DEPLOY_NGPU` to use a container image supporting a GPU and the number of GPUs allocated to the virtual machine (VM) instance. For example, to use a GPU container image with 4 Nvidia Tesla K80 GPUs allocated to each VM, you would specify:\n",
        "\n",
        "    (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
        "\n",
        "See the [locations where accelerators are available](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators).\n",
        "\n",
        "Otherwise specify `(None, None)` to use a container image to run on a CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd5PLXDTlugv"
      },
      "outputs": [],
      "source": [
        "GPU = False\n",
        "if GPU:\n",
        "    DEPLOY_GPU, DEPLOY_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
        "else:\n",
        "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "container:training,prediction"
      },
      "source": [
        "#### Set pre-built containers\n",
        "\n",
        "Set the pre-built Docker container image for prediction.\n",
        "\n",
        "For the latest list, see [Pre-built containers for prediction](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u1mr18jlugv"
      },
      "outputs": [],
      "source": [
        "if GPU:\n",
        "    DEPLOY_VERSION = \"tf2-gpu.2-5\"\n",
        "else:\n",
        "    DEPLOY_VERSION = \"tf2-cpu.2-5\"\n",
        "\n",
        "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
        "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
        ")\n",
        "\n",
        "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "machine:training,prediction"
      },
      "source": [
        "#### Set machine types\n",
        "\n",
        "Next, set the machine types to use for training and prediction.\n",
        "\n",
        "- Set the variable `DEPLOY_COMPUTE` to configure your compute resources for prediction.\n",
        " - `machine type`\n",
        "     - `n1-standard`: 3.75GB of memory per vCPU\n",
        "     - `n1-highmem`: 6.5GB of memory per vCPU\n",
        "     - `n1-highcpu`: 0.9 GB of memory per vCPU\n",
        " - `vCPUs`: number of \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
        "\n",
        "*Note: You may also use n2 and e2 machine types for training and deployment, but they do not support GPUs*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAXwbqKKlugv"
      },
      "outputs": [],
      "source": [
        "MACHINE_TYPE = \"n1-standard\"\n",
        "\n",
        "VCPU = \"4\"\n",
        "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
        "print(\"Train machine type\", TRAIN_COMPUTE)\n",
        "\n",
        "MACHINE_TYPE = \"n1-standard\"\n",
        "\n",
        "VCPU = \"4\"\n",
        "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
        "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bf06cd476e9"
      },
      "source": [
        "### Upload the model artifacts as a `Vertex AI Model` resource\n",
        "\n",
        "First, you upload the pre-trained custom tabular model artifacts as a `Vertex AI Model` resource using the `upload()` method, with the following parameters:\n",
        "\n",
        "- `display_name`: The human readable name for the `Model` resource.\n",
        "- `artifact_uri`: The Cloud Storage location of the model artifacts.\n",
        "- `serving_container_image`: The serving container image to use when the model is deployed to a `Vertex AI Endpoint` resource.\n",
        "- `sync`: Whether to wait for the process to complete, or return immediately (async)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0193f247e216"
      },
      "outputs": [],
      "source": [
        "MODEL_ARTIFACT_URI = \"gs://mco-mm/churn\"\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=\"churn_\" + UUID,\n",
        "    artifact_uri=MODEL_ARTIFACT_URI,\n",
        "    serving_container_image_uri=DEPLOY_IMAGE,\n",
        "    sync=True,\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4305ddf"
      },
      "source": [
        "## Submit a batch prediction request with model monitoring enabled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "053fde99"
      },
      "source": [
        "### Create Cloud Storage buckets\n",
        "\n",
        "This cell creates two Cloud Storage buckets:\n",
        "\n",
        "- `gs://PROJECT_ID_bp_mm_input` contains the batch prediction request data.\n",
        "- `gs://PROJECT_ID_bp_mm_output` contains the batch prediction output as well as the model monitoring results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b832ad31"
      },
      "outputs": [],
      "source": [
        "# Copy files to your projects gs bucket to avoid permission issues.\n",
        "# Ignore any error(s) for bucket already exists.\n",
        "OUTPUT_GS_PATH = f\"{BUCKET_URI}/bp_mm_output\"\n",
        "INPUT_GS_PATH = f\"{BUCKET_URI}/bp_mm_input\"\n",
        "PUBLIC_TRAINING_DATASET = \"gs://bp_mm_public_data/churn/churn_bp_insample.csv\"\n",
        "TRAINING_DATASET = f\"{INPUT_GS_PATH}/churn_bp_insample.csv\"\n",
        "TRAINING_DATASET_FORMAT = \"csv\"\n",
        "\n",
        "! gsutil copy $PUBLIC_TRAINING_DATASET $INPUT_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34c95126"
      },
      "source": [
        "### Create batch prediction job\n",
        "\n",
        "This step parameterizes and builds the data structure representing the batch prediction request, with model monitoring enabled.\n",
        "\n",
        "The BatchPredictionJob object specifies the input source, the data format, and the computing resources requests for the batch prediction. Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/samples/aiplatform-create-batch-prediction-job-sample\" target=\"_blank\">BatchPredictionJob</a>.\n",
        "\n",
        "The ModelMonitoringConfig object specifies the alerting email address, the training dataset, the features to be monitored, and their associated alerting thresholds. Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/model-monitoring\" target=\"_blank\">ModelMonitoringConfig</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a54368a"
      },
      "outputs": [],
      "source": [
        "INPUT_URI = \"gs://bp_mm_public_data/churn/churn_bp_outsample.jsonl\"\n",
        "OUTPUT_URI = OUTPUT_GS_PATH\n",
        "INSTANCES_FORMAT = \"jsonl\"\n",
        "PREDICTIONS_FORMAT = \"jsonl\"\n",
        "JOB_NAME_PREFIX = \"bp_mm_demo\"\n",
        "MODEL_NAME = model.resource_name\n",
        "BATCH_PREDICTION_JOB_NAME = JOB_NAME_PREFIX + \"_\" + UUID\n",
        "\n",
        "from google.cloud.aiplatform_v1beta1.types import (\n",
        "    BatchDedicatedResources, BatchPredictionJob, GcsDestination, GcsSource,\n",
        "    MachineSpec, ModelMonitoringAlertConfig, ModelMonitoringConfig,\n",
        "    ModelMonitoringObjectiveConfig, ThresholdConfig)\n",
        "\n",
        "batch_prediction_job = BatchPredictionJob(\n",
        "    display_name=BATCH_PREDICTION_JOB_NAME,\n",
        "    model=MODEL_NAME,\n",
        "    input_config=BatchPredictionJob.InputConfig(\n",
        "        instances_format=INSTANCES_FORMAT, gcs_source=GcsSource(uris=[INPUT_URI])\n",
        "    ),\n",
        "    output_config=BatchPredictionJob.OutputConfig(\n",
        "        predictions_format=PREDICTIONS_FORMAT,\n",
        "        gcs_destination=GcsDestination(output_uri_prefix=OUTPUT_URI),\n",
        "    ),\n",
        "    dedicated_resources=BatchDedicatedResources(\n",
        "        machine_spec=MachineSpec(machine_type=DEPLOY_COMPUTE),\n",
        "        starting_replica_count=1,\n",
        "        max_replica_count=1,\n",
        "    ),\n",
        "    # Model monitoring service will be triggerred if provide following configs.\n",
        "    model_monitoring_config=ModelMonitoringConfig(\n",
        "        alert_config=ModelMonitoringAlertConfig(\n",
        "            email_alert_config=ModelMonitoringAlertConfig.EmailAlertConfig(\n",
        "                user_emails=[EMAIL_ADDRESS]\n",
        "            )\n",
        "        ),\n",
        "        objective_configs=[\n",
        "            ModelMonitoringObjectiveConfig(\n",
        "                training_dataset=ModelMonitoringObjectiveConfig.TrainingDataset(\n",
        "                    data_format=TRAINING_DATASET_FORMAT,\n",
        "                    gcs_source=GcsSource(uris=[TRAINING_DATASET]),\n",
        "                ),\n",
        "                training_prediction_skew_detection_config=ModelMonitoringObjectiveConfig.TrainingPredictionSkewDetectionConfig(\n",
        "                    skew_thresholds={\n",
        "                        \"cnt_user_engagement\": ThresholdConfig(value=0.001),\n",
        "                        \"julianday\": ThresholdConfig(value=0.001),\n",
        "                    }\n",
        "                ),\n",
        "            )\n",
        "        ],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cae39778"
      },
      "source": [
        "### Submit batch prediction job\n",
        "\n",
        "This step submits the batch prediction request created in the previous step. If successful, it returns a JSON document summarizing the request, which is displayed in the cell output below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcdd4a47"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform_v1beta1.services.job_service import \\\n",
        "    JobServiceClient\n",
        "\n",
        "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
        "client = JobServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
        "out = client.create_batch_prediction_job(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
        "    batch_prediction_job=batch_prediction_job,\n",
        ")\n",
        "BATCH_PREDICTION_JOB_ID = out.name.split(\"/\")[-1]\n",
        "print(\"BATCH_PREDICTION_JOB_ID:\", BATCH_PREDICTION_JOB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ec90a0"
      },
      "source": [
        "## Verify prediction results\n",
        "\n",
        "The batch prediction request will be completed after about **17 mins**, and the model monitoring result will be available **10 mins** after that. The request below obtains the batch prediction job id, which is a unique number associated with asynchronous requests like this one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c30496b5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# If auto-testing, wait for request completion\n",
        "if os.getenv(\"IS_TESTING\"):\n",
        "    time.sleep(1800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831651c2"
      },
      "source": [
        "### Browse storage bucket\n",
        "\n",
        "Click on the link below, which opens the Cloud Storage object viewer on the output bucket you created above, to see the results of your batch prediction request.\n",
        "\n",
        "When everything is ready, you'll see two folders in this bucket (the precise names will vary):\n",
        "\n",
        "- `prediction-batch_prediction_monitoring_test_model_20220714100939-2022_07_14T03_10_10_069Z` - this folder contains the your batch prediction results, i.e. the predictions produced by your model for each input in the batch\n",
        "- `job-8794345073597743104` - this folder contains the model monitoring results, including the model schema, monitoring thresholds and other config settings, statistics, and anomalies\n",
        "\n",
        "*Note:* that until the request and the monitoring job are completed, you may see empty or partial results in this bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a705c10b"
      },
      "outputs": [],
      "source": [
        "print(f\"https://console.cloud.google.com/storage/browser/{OUTPUT_URI.lstrip('gs://')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bbdddac"
      },
      "source": [
        "### Visualize the batch prediction result\n",
        "\n",
        "Run the following cell to examine the batch prediction results with a tabular and visual analysis using the <a href=\"https://www.tensorflow.org/tfx/data_validation/get_started\" target=\"_blank\">TensorFlow Data Validation</a> package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6c674e9"
      },
      "outputs": [],
      "source": [
        "! rm -f ./training_stats.pb\n",
        "! rm -f ./prediction_stats.pb\n",
        "\n",
        "TRAINING_STATS_SUBPATH = \"stats_training/stats/training_stats\"\n",
        "PREDICTION_STATS_SUBPATH = \"stats_and_anomalies/stats/current_stats\"\n",
        "STATS_GCS_FOLDER = OUTPUT_URI = (\n",
        "    OUTPUT_GS_PATH + \"/job-\" + BATCH_PREDICTION_JOB_ID + \"/bp_monitoring/\"\n",
        ")\n",
        "TRAINING_STATS_GCS_PATH = STATS_GCS_FOLDER + TRAINING_STATS_SUBPATH\n",
        "print(\"Looking up statistics from: \" + TRAINING_STATS_GCS_PATH)\n",
        "PREDICTION_STATS_GCS_PATH = STATS_GCS_FOLDER + PREDICTION_STATS_SUBPATH\n",
        "print(\"Looking up statistics from: \" + PREDICTION_STATS_GCS_PATH)\n",
        "\n",
        "! gsutil cp $TRAINING_STATS_GCS_PATH ./training_stats.pb\n",
        "! gsutil cp $PREDICTION_STATS_GCS_PATH ./prediction_stats.pb\n",
        "\n",
        "\n",
        "# util function to load stats binary file from GCS\n",
        "def load_stats_binary(input_path):\n",
        "    stats_proto = statistics_pb2.DatasetFeatureStatisticsList()\n",
        "    stats_proto.ParseFromString(\n",
        "        io_util.read_file_to_string(input_path, binary_mode=True)\n",
        "    )\n",
        "    return stats_proto\n",
        "\n",
        "\n",
        "tfdv.visualize_statistics(load_stats_binary(\"./training_stats.pb\"))\n",
        "tfdv.visualize_statistics(load_stats_binary(\"./prediction_stats.pb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233b1266"
      },
      "source": [
        "### Check skew results\n",
        "\n",
        "Finally, you can check the skew results by examining a file in the output bucket. The JSON file contains a report indicating how much the batch prediction data deviates from the training data, on a feature-by-feature basis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e8c00a7"
      },
      "outputs": [],
      "source": [
        "SKEW_GS_PATH = (\n",
        "    STATS_GCS_FOLDER\n",
        "    + \"stats_and_anomalies/anomalies/training_prediction_skew_anomalies\"\n",
        ")\n",
        "! gsutil cat $SKEW_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "497a0016"
      },
      "source": [
        "## Clean up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eabc3f81"
      },
      "outputs": [],
      "source": [
        "# Delete model resource\n",
        "! gcloud ai models delete $MODEL_NAME --quiet\n",
        "\n",
        "# Delete Cloud Storage resources\n",
        "! gsutil -m rm -r $INPUT_GS_PATH\n",
        "! gsutil -m rm -r $OUTPUT_GS_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aa0219d"
      },
      "source": [
        "## Learn more...\n",
        "\n",
        "**Congratulations!** You've now learned how to monitor batch predictions, and how to find and interpret the results. Check out the following resources to learn more about model monitoring and ML Ops.\n",
        "\n",
        "- [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv)\n",
        "- [Data Understanding, Validation, and Monitoring At Scale](https://blog.tensorflow.org/2018/09/introducing-tensorflow-data-validation.html)\n",
        "- [Vertex Product Documentation](https://cloud.google.com/vertex-ai)\n",
        "- [Vertex AI Model Monitoring Reference Docs](https://cloud.google.com/vertex-ai/docs/reference)\n",
        "- [Vertex AI Model Monitoring blog article](https://cloud.google.com/blog/topics/developers-practitioners/monitor-models-training-serving-skew-vertex-ai)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "batch_prediction_model_monitoring.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
