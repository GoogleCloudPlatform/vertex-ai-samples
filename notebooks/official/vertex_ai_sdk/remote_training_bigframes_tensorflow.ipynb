{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Train a Tensorflow Keras model with Vertex AI SDK and Bigframes \n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/vertex_ai_sdk/remote_training_bigframes_tensorflow.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/vertex_ai_sdk/remote_training_bigframes_tensorflow.ipynb\">\n",
        "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "    <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/vertex_ai_sdk/remote_training_bigframes_tensorflow.ipynb\">\n",
        "       <img src=\"https://www.gstatic.com/cloud/images/navigation/vertex-ai.svg\" alt=\"Vertex AI logo\">Open in Vertex AI Workbench\n",
        "    </a>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to train a tensorflow keras model using Vertex AI local-to-remote training with Vertex AI SDK and BigQuery Bigframes as the data source.\n",
        "\n",
        "Learn more about [bigframes](https://cloud.google.com/bigquery/docs/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn to use `Vertex AI SDK` with Bigframes as input data source.\n",
        "\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Training`\n",
        "- `Vertex AI Remote Training`\n",
        "\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Initialize a dataframe from a BigQuery table and split the dataset\n",
        "- Perform transformations as a Vertex AI remote training.\n",
        "- Train the model remotely and evaluate the model locally\n",
        "\n",
        "**Local-to-remote training**\n",
        "\n",
        "```\n",
        "import vertexai\n",
        "from my_module import MyModelClass\n",
        "\n",
        "vertexai.preview.init(remote=True, project=\"my-project\", location=\"my-location\", staging_bucket=\"gs://my-bucket\")\n",
        "\n",
        "# Wrap the model class with `vertex_ai.preview.remote`\n",
        "MyModelClass = vertexai.preview.remote(MyModelClass)\n",
        "\n",
        "# Instantiate the class\n",
        "model = MyModelClass(...)\n",
        "\n",
        "# Optional set remote config\n",
        "model.fit.vertex.remote_config.display_name = \"MyModelClass-remote-training\"\n",
        "model.fit.vertex.remote_config.staging_bucket = \"gs://my-bucket\"\n",
        "\n",
        "# This `fit` call will be executed remotely\n",
        "model.fit(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial uses the <a href=\"https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\">IRIS dataset</a>, which predicts the iris species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* BigQuery\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "[BigQuery pricing](https://cloud.google.com/bigquery/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), \n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade --quiet google-cloud-aiplatform[preview]\n",
        "! pip3 install --upgrade --quiet bigframes\n",
        "! pip3 install --upgrade --quiet tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6b2ccc891ed"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import bigframes.pandas as bf\n",
        "import tensorflow as tf\n",
        "import vertexai\n",
        "from tensorflow import keras\n",
        "\n",
        "bf.options.bigquery.location = \"us\"  # Dataset is in 'us' not 'us-central1'\n",
        "bf.options.bigquery.project = PROJECT_ID\n",
        "\n",
        "from bigframes.ml.model_selection import \\\n",
        "    train_test_split as bf_train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "## Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "outputs": [],
      "source": [
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=BUCKET_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105334524e96"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "Now load the Iris dataset and split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94576deccd8c"
      },
      "outputs": [],
      "source": [
        "df = bf.read_gbq(\"bigquery-public-data.ml_datasets.iris\")\n",
        "\n",
        "species_categories = {\n",
        "    \"versicolor\": 0,\n",
        "    \"virginica\": 1,\n",
        "    \"setosa\": 2,\n",
        "}\n",
        "df[\"species\"] = df[\"species\"].map(species_categories)\n",
        "\n",
        "train, test = bf_train_test_split(df, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcbce726efa"
      },
      "source": [
        "## Remote training with GPU\n",
        "\n",
        "First, train a TensorFlow model as a remote training job:\n",
        "\n",
        "- Reinitialize Vertex AI for remote training.\n",
        "- Instantiate the tensorflow keras model for the remote training job.\n",
        "- Invoke the tensorflow keras model.fit() locally which will launch the remote training job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd865b0c4e8b"
      },
      "outputs": [],
      "source": [
        "# Switch to remote mode for training\n",
        "vertexai.preview.init(remote=True)\n",
        "\n",
        "Sequential = vertexai.preview.remote(keras.Sequential)\n",
        "\n",
        "# Instantiate model\n",
        "model = Sequential([keras.layers.Dense(5, input_shape=(4,)), keras.layers.Softmax()])\n",
        "\n",
        "# Specify optimizer and loss function\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "\n",
        "# (Optional) Manually set GPU compute resources\n",
        "model.fit.vertex.remote_config.enable_cuda = True\n",
        "model.fit.vertex.remote_config.machine_type = \"n1-highmem-4\"\n",
        "model.fit.vertex.remote_config.accelerator_type = \"NVIDIA_TESLA_K80\"\n",
        "model.fit.vertex.remote_config.accelerator_count = 4\n",
        "\n",
        "# (Optional) Set batch_size, target_col\n",
        "model.fit.vertex.remote_config.serializer_args[train] = {\n",
        "    \"batch_size\": 32,\n",
        "    \"target_col\": \"species\",\n",
        "}\n",
        "\n",
        "# Train model on Vertex\n",
        "model.fit(train, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1af94ac1477"
      },
      "source": [
        "## Remote prediction\n",
        "\n",
        "Obtain predictions from the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d75879948b5"
      },
      "outputs": [],
      "source": [
        "# Remote prediction\n",
        "vertexai.preview.init(remote=True)\n",
        "\n",
        "# Disable GPU for remote prediction\n",
        "model.predict.vertex.remote_config.enable_cuda = False\n",
        "\n",
        "# (Optional) Set batch_size, target_col\n",
        "model.predict.vertex.remote_config.serializer_args[train] = {\n",
        "    \"batch_size\": 32,\n",
        "    \"target_col\": \"species\",\n",
        "}\n",
        "\n",
        "predictions = model.predict(train)\n",
        "\n",
        "print(f\"Remote predictions: {predictions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "798b77c95067"
      },
      "source": [
        "## Local evaluation\n",
        "\n",
        "Evaluate model results locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88e734e30791"
      },
      "outputs": [],
      "source": [
        "# User must convert bigframes to pandas dataframe for local evaluation\n",
        "feature_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "label_columns = [\"species\"]\n",
        "\n",
        "train_X_np = train[feature_columns].to_pandas().values.astype(float)\n",
        "train_y_np = train[label_columns].to_pandas().values.astype(float)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_X_np, train_y_np))\n",
        "\n",
        "test_X_np = test[feature_columns].to_pandas().values.astype(float)\n",
        "test_y_np = test[label_columns].to_pandas().values.astype(float)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_X_np, test_y_np))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb8637f783ad"
      },
      "outputs": [],
      "source": [
        "# Switch to local mode for evaluation\n",
        "vertexai.preview.init(remote=False)\n",
        "\n",
        "# Evaluate model's mean square errors\n",
        "print(f\"Train loss: {model.evaluate(train_ds.batch(32))}\")\n",
        "\n",
        "print(f\"Test loss: {model.evaluate(test_ds.batch(32))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "delete_bucket = False\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "remote_training_bigframes_tensorflow.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
