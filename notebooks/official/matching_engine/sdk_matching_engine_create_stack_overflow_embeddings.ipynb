{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Using Vertex AI Matching Engine for StackOverflow Questions\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_create_stack_overflow_embeddings.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_create_stack_overflow_embeddings.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "      <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/sdk_matching_engine_create_stack_overflow_embeddings.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a74aaf1481"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example demonstrates how to create text-to-image embeddings using the StackOverflow dataset and the sentence-T5 model. These are uploaded to the Vertex AI Matching Engine service. It is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. Moreover, it is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
        "\n",
        "**Pre-requisite**: This notebook requires you to already have a VPC network set up. See the \"Prepare a VPC network\" section in [Create Vertex AI Matching Engine index notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb).\n",
        "\n",
        "Learn more about [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34a4b245e795"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to encode custom text embeddings, create an Approximate Nearest Neighbor (ANN) index, and query against indexes.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Matching Engine`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Create ANN index\n",
        "* Create an index endpoint with VPC Network\n",
        "* Deploy ANN index\n",
        "* Perform online query\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the [StackOverflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow).\n",
        "\n",
        "> Stack Overflow is the largest online community for programmers to learn, share their knowledge, and advance their careers. Updated on a quarterly basis, this BigQuery dataset includes an archive of Stack Overflow content, including posts, votes, tags, and badges. This dataset is updated to mirror the Stack Overflow content on the Internet Archive, and is also available through the Stack Exchange Data Explorer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f1bea346db"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the latest version of Cloud Storage, BigQuery, and the Vertex AI SDK for Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfbccc635a17"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform \\\n",
        "                        google-cloud-storage \\\n",
        "                        'google-cloud-bigquery[pandas]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae34c2a9ce7"
      },
      "source": [
        "Install the latest version of tensorflow and tensorflow_text to encode embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f329eff0fe39"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade tensorflow \\\n",
        "                        tensorflow_text \\\n",
        "                        tensorflow-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b08ba354c6e"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bea801acf6b5"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd28c9e4f067"
      },
      "source": [
        "## Before you begin\n",
        "#### Set your project ID\n",
        "\n",
        "If you don't know your project ID, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80c0215f05a0"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[YOUR-PROJECT-ID]\"\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4512bf63b3"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "474be5183c27"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "949271bfebe3"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b65b4ce80d9a"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "985cdbfe7372"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fbc9cd30cc4b"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79efab26ad02"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a336a05c6149"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c0a44fa330f"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uj8x73nDX_"
      },
      "source": [
        "* Authentication: Rerun the `gcloud auth login` command in the Vertex AI Workbench notebook terminal when you are logged out and need the credential again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = \"gs://your-bucket-name-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR6Wwv-hCCN-"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "You will use [Stack Overflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) of question and answers hosted on BigQuery.\n",
        "\n",
        "> This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wzS85TeB9dG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "NUM_ROWS = 1000\n",
        "\n",
        "QUERY = f\"\"\"\n",
        "        SELECT distinct q.id, q.title, q.body, q.tags, a.body as answers, a.score \n",
        "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` where Score>0 ORDER BY View_Count desc) AS q \n",
        "        INNER JOIN (SELECT * FROM `bigquery-public-data.stackoverflow.posts_answers`  where Score>0 ORDER BY Score desc) AS a ON q.id = a.parent_id \n",
        "        where q.tags like '%python%'\n",
        "        LIMIT {NUM_ROWS};\n",
        "        \"\"\"\n",
        "\n",
        "query_job = client.query(QUERY)\n",
        "rows = query_job.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b43937b6065d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>tags</th>\n",
              "      <th>answers</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28819470</td>\n",
              "      <td>Numbers of Day in Month</td>\n",
              "      <td>&lt;p&gt;I have a data frame with a date time index,...</td>\n",
              "      <td>python|pandas</td>\n",
              "      <td>&lt;p&gt;There is now a &lt;a href=\"https://pandas.pyda...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35064304</td>\n",
              "      <td>\"RuntimeError: Make sure the Graphviz executab...</td>\n",
              "      <td>&lt;p&gt;I downloaded &lt;code&gt;Graphviz 2.38&lt;/code&gt; MSI...</td>\n",
              "      <td>python|installation|graphviz</td>\n",
              "      <td>&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Install Graphviz b...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18783390</td>\n",
              "      <td>python pip specify a library directory and an ...</td>\n",
              "      <td>&lt;p&gt;I am using pip and trying to install a pyth...</td>\n",
              "      <td>python|shared-libraries|pip|include-path|pyodbc</td>\n",
              "      <td>&lt;p&gt;Another way to indicate the location of inc...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1066933</td>\n",
              "      <td>How to extract top-level domain name (TLD) fro...</td>\n",
              "      <td>&lt;p&gt;how would you extract the domain name from ...</td>\n",
              "      <td>python|url|parsing|dns|extract</td>\n",
              "      <td>&lt;p&gt;No, there is no \"intrinsic\" way of knowing ...</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3817529</td>\n",
              "      <td>syntax for creating a dictionary into another ...</td>\n",
              "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;&lt;strong&gt;Possible Duplicate:...</td>\n",
              "      <td>python</td>\n",
              "      <td>&lt;p&gt;You can declare a dictionary inside a dicti...</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                              title  \\\n",
              "0  28819470                            Numbers of Day in Month   \n",
              "1  35064304  \"RuntimeError: Make sure the Graphviz executab...   \n",
              "2  18783390  python pip specify a library directory and an ...   \n",
              "3   1066933  How to extract top-level domain name (TLD) fro...   \n",
              "4   3817529  syntax for creating a dictionary into another ...   \n",
              "\n",
              "                                                body  \\\n",
              "0  <p>I have a data frame with a date time index,...   \n",
              "1  <p>I downloaded <code>Graphviz 2.38</code> MSI...   \n",
              "2  <p>I am using pip and trying to install a pyth...   \n",
              "3  <p>how would you extract the domain name from ...   \n",
              "4  <blockquote>\\n  <p><strong>Possible Duplicate:...   \n",
              "\n",
              "                                              tags  \\\n",
              "0                                    python|pandas   \n",
              "1                     python|installation|graphviz   \n",
              "2  python|shared-libraries|pip|include-path|pyodbc   \n",
              "3                   python|url|parsing|dns|extract   \n",
              "4                                           python   \n",
              "\n",
              "                                             answers  score  \n",
              "0  <p>There is now a <a href=\"https://pandas.pyda...     11  \n",
              "1  <p><strong>Step 1:</strong> Install Graphviz b...     22  \n",
              "2  <p>Another way to indicate the location of inc...     19  \n",
              "3  <p>No, there is no \"intrinsic\" way of knowing ...     52  \n",
              "4  <p>You can declare a dictionary inside a dicti...    106  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to a dataframe\n",
        "df = rows.to_dataframe()\n",
        "\n",
        "# Examine the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cacd9869ee5"
      },
      "outputs": [],
      "source": [
        "# Extract the question ids and question text\n",
        "ids = df.id.tolist()\n",
        "questions = df.title.tolist()\n",
        "\n",
        "# Verify the length\n",
        "len(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1124422cc200"
      },
      "source": [
        "#### Instantiate the text encoding model\n",
        "\n",
        "Use the [sentence-t5 encoder](https://tfhub.dev/google/sentence-t5/st5-base/1) developed by Google for converting text to embeddings.\n",
        "\n",
        "> The sentence-T5 family of models encode text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language processing tasks.\n",
        ">\n",
        "> Our model is built on top of T5 (i.e. the Text-To-Text Transfer Transformer). It is trained on a variety of data sources and initialized from pre-trained T5 models with different model sizes. The input is variable-length English text and the output is a 768-dimensional vector. The sentence-T5 base model employs a 12-layer transformer architecture as the T5 base model does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed41c7712930"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "# Registers the ops.\n",
        "import tensorflow_text as text  # noqa: F401\n",
        "\n",
        "hub_url = \"https://tfhub.dev/google/sentence-t5/st5-base/1\"\n",
        "\n",
        "encoder = hub.KerasLayer(hub_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43088937e820"
      },
      "source": [
        "#### Defining an encoding function\n",
        "\n",
        "Define a function to be used later that will take sentences and convert them to embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0370bd840d2"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def encode_text_to_embedding(\n",
        "    text_encoder: hub.KerasLayer, sentences: List[str], batch_size: int = 100\n",
        ") -> np.ndarray:\n",
        "    embeddings_list = []\n",
        "\n",
        "    # Process data in chunks to prevent out-of-memory errors\n",
        "    for i in tqdm(range(0, len(sentences), batch_size)):\n",
        "        batch = sentences[i : i + batch_size]\n",
        "        embeddings_list.append(text_encoder(tf.constant(batch)))\n",
        "\n",
        "    return np.squeeze(np.column_stack(embeddings_list))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ba45d58bf96e"
      },
      "source": [
        "#### Test the encoding function\n",
        "\n",
        "Encode a subset of data and see if the embeddings and distance metrics make sense.\n",
        "\n",
        "According to the [sentence-T5 research paper](https://arxiv.org/pdf/2108.08877.pdf), the similarity of embeddings is calculated using the dot-product. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b01baa906b5"
      },
      "outputs": [],
      "source": [
        "# Encode 500 questions\n",
        "questions = df.title.tolist()[:500]\n",
        "question_embeddings = encode_text_to_embedding(\n",
        "    text_encoder=encoder, sentences=questions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3761f56648b"
      },
      "source": [
        "Save the dimension size for later usage when creating the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "d296e181205d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DIMENSIONS = len(question_embeddings[0])\n",
        "\n",
        "DIMENSIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "95e408daf219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query question = Numbers of Day in Month\n",
            "\t0: Numbers of Day in Month: 0.9999998807907104\n",
            "\t1: Python: Number of the Week in a Month: 0.8649452924728394\n",
            "\t2: Simulate Poisson arrival times given count of arrivals per day: 0.8294509053230286\n",
            "\t3: How to workout if a datetime is older than x months in Python: 0.808755099773407\n",
            "\t4: How to efficiently add seconds place to date time: 0.7867542505264282\n",
            "\t5: Show if restaurant is open or closed based on weekday, opening and closing time: 0.7858442068099976\n",
            "\t6: How to subtract datetimes based on transition events in another column: 0.7808101177215576\n",
            "\t7: Doing DateTime Comparisons in Filter SQLAlchemy: 0.7684456706047058\n",
            "\t8: Python datetime module and getting current time: 0.7682346701622009\n",
            "\t9: Multiples of 10 in a list: 0.7647985816001892\n",
            "\t10: Counting differences between two strings: 0.7633612155914307\n",
            "\t11: Function That Computes Sum of Squares of Numbers in List: 0.7624084949493408\n",
            "\t12: Python/Matplotlib - Colorbar Range and Display Values: 0.7616406679153442\n",
            "\t13: Most computationally efficient way to count consecutive repeating values: 0.7592378854751587\n",
            "\t14: Plotting data with a string as the x-axis: 0.758903980255127\n",
            "\t15: How to write an efficient hit counter for websites: 0.758114755153656\n",
            "\t16: Number of channels in convLSTM for classifying videos: 0.7568756937980652\n",
            "\t17: Sort a set with four pieces of data per element: 0.7568261623382568\n",
            "\t18: Interactive Data Visualiation - Python: 0.7562029957771301\n",
            "\t19: How to make Images/PDF of Timetable using Python: 0.7535030841827393\n"
          ]
        }
      ],
      "source": [
        "question_index = 0\n",
        "\n",
        "print(f\"Query question = {questions[question_index]}\")\n",
        "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
        "\n",
        "# Print top 20 matches\n",
        "for index, (question, score) in enumerate(\n",
        "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
        "):\n",
        "    print(f\"\\t{index}: {question}: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIQSyF9GtSv"
      },
      "source": [
        "#### Save the train split in JSONL format.\n",
        "\n",
        "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
        "\n",
        "See more information in the docs at [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup#input-data-format)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c1193aca5d1"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "# Create temporary file to write embeddings to\n",
        "embeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
        "\n",
        "embeddings_file.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "307f468a3ecd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "with open(embeddings_file.name, \"a\") as f:\n",
        "    for i in tqdm(range(0, len(questions), BATCH_SIZE)):\n",
        "        id_chunk = ids[i : i + BATCH_SIZE]\n",
        "\n",
        "        question_chunk_embeddings = encode_text_to_embedding(\n",
        "            text_encoder=encoder, sentences=questions[i : i + BATCH_SIZE]\n",
        "        )\n",
        "\n",
        "        # Append to file\n",
        "        embeddings_formatted = [\n",
        "            json.dumps(\n",
        "                {\n",
        "                    \"id\": str(id),\n",
        "                    \"embedding\": [str(value) for value in embedding],\n",
        "                }\n",
        "            )\n",
        "            + \"\\n\"\n",
        "            for id, embedding in zip(id_chunk, question_chunk_embeddings)\n",
        "        ]\n",
        "        f.writelines(embeddings_formatted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVl8DrWG8NS"
      },
      "source": [
        "Upload the training data to a Google Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PgsA_vbI8Vg"
      },
      "outputs": [],
      "source": [
        "UNIQUE_FOLDER_NAME = \"embeddings_folder_unique\"\n",
        "remote_folder = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
        "! gsutil cp {embeddings_file.name} {remote_folder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglUPwHpJH98"
      },
      "source": [
        "## Create Indexes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIBCQ7dDSbW"
      },
      "source": [
        "### Create ANN Index (for Production Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qiIg9b5zJLi1"
      },
      "outputs": [],
      "source": [
        "DISPLAY_NAME = \"stack_overflow\"\n",
        "DESCRIPTION = \"questions from stackoverflow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLYiDf0OD2G"
      },
      "source": [
        "Create the ANN index configuration:\n",
        "\n",
        "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup#input-data-format).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Y4zooldkGoM4"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dffb00b23f5a"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=remote_folder,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=80,\n",
        "    description=DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17jrQi501QyX"
      },
      "outputs": [],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1a9fbecabb"
      },
      "source": [
        "Using the resource name, you can retrieve an existing MatchingEngineIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ddb70647d98"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2xjAnDDObD"
      },
      "source": [
        "## Create an IndexEndpoint with VPC Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpZQoJyxDlbO"
      },
      "outputs": [],
      "source": [
        "# Retrieve the project number\n",
        "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "\n",
        "VPC_NETWORK = \"[your-network-name]\"\n",
        "VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
        "VPC_NETWORK_FULL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuARXzJVGyQX"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    description=DISPLAY_NAME,\n",
        "    network=VPC_NETWORK_FULL,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np2cgVuuIe9k"
      },
      "source": [
        "## Deploy Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ew1UgcIIiJG"
      },
      "source": [
        "### Deploy ANN Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLOYTGygIlMK"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = \"deployed_index_id_unique\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uK4WOgqN1NG"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCGvBNvBd8D"
      },
      "source": [
        "## Create Online Queries\n",
        "\n",
        "After you built your indexes, you may query against the deployed index to find nearest neighbors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae9996f185fe"
      },
      "outputs": [],
      "source": [
        "test_embeddings = encode_text_to_embedding(\n",
        "    text_encoder=encoder, sentences=[\"How do I install tensorflow with GPU support?\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3KYVw5HB-4v"
      },
      "outputs": [],
      "source": [
        "# Test query\n",
        "NUM_NEIGHBOURS = 20\n",
        "\n",
        "response = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=[test_embeddings.tolist()],\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce2cf0297369"
      },
      "source": [
        "Print titles to verify neighbors make sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c8682079e21"
      },
      "outputs": [],
      "source": [
        "neighbor_ids = [neighbor.id for neighbor in response[0]]\n",
        "neighbor_distances = [neighbor.distance for neighbor in response[0]]\n",
        "\n",
        "for match_index, neighbor in enumerate(response[0]):\n",
        "    titles = df[df.id.astype(str) == neighbor.id].title.tolist()\n",
        "\n",
        "    if len(titles) > 0:\n",
        "        print(\n",
        "            f\"{match_index}: title = '{titles[0]}', distance = {neighbor.distance:0.2f}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "You can also manually delete resources that you created by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Force undeployment of indexes and delete endpoint\n",
        "my_index_endpoint.delete(force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omj7N9iWv-Tq"
      },
      "outputs": [],
      "source": [
        "# Delete indexes\n",
        "tree_ah_index.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk_matching_engine_create_stack_overflow_embeddings.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
