{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex AI Matching Engine using Text-Based Product Embeddings\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/similar_products_recommender_using_matching_engine.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/similar_products_recommender_using_matching_engine.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>                                                                                               \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a74aaf1481"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example demonstrates how to use the  Vertex AI Matching Engine's Approximate Nearest Neighbor (ANN) service to create a similar products recommender. Vertex AI Matching Engine's ANN Service is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. It is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34a4b245e795"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to generate embeddings for the tabular data, create Approximate Nearest Neighbor (ANN) Index, query against indexes, and validate the performance of the index. \n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- VPC network\n",
        "- BigQuery\n",
        "- Vertex AI Matching Engine's Approximate Nearest Neighbor (ANN) service\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Generate embeddings for the data\n",
        "* Create ANN index and brute force index\n",
        "* Create an index endpoint\n",
        "* Deploy ANN index and brute force index\n",
        "* Perform online query\n",
        "* Compute recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the [theLook eCommerce](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce).\n",
        "\n",
        "The dataset contains information about customers, products, orders, logistics, web events and digital marketing campaigns. The contents of this dataset are synthetic, and are provided to industry practitioners for the purpose of product discovery, testing, and evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e2eba58ad71"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* BigQuery\n",
        "* VPC network\n",
        "* Cloud Storage\n",
        "\n",
        "\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing), [BigQuery pricing](https://cloud.google.com/bigquery/pricing), [VPC network pricing](https://cloud.google.com/vpc/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6bed8c6a6b3"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager).\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API, and Service Networking API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,servicenetworking.googleapis.com).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands.\n",
        "\n",
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Vertex AI Workbench Notebooks**, your environment is already authenticated.\n",
        "\n",
        "**If you are using Colab**, run the cell below and follow the instructions when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "- In the Cloud Console, go to the [Create service account key](https://console.cloud.google.com/apis/credentials/serviceaccountkey) page.\n",
        "\n",
        "- **Click Create service account**.\n",
        "\n",
        "- In the **Service account name** field, enter a name, and click **Create**.\n",
        "\n",
        "- In the **Grant this service account access to project** section, click the Role drop-down list. Type \"Vertex\" into the filter box, and select **Vertex Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "- Click Create. A JSON file that contains your key downloads to your local environment.\n",
        "\n",
        "- Enter the path to your service account key as the GOOGLE_APPLICATION_CREDENTIALS variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e2b43c2d2bf"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
        "    \"DL_ANACONDA_HOME\"\n",
        "):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS '[your-service-account-key-path]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beb72f394541"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c170d17deb17"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
        "    # Get your GCP project id from gcloud\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67b067d116ad"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4962667eec8e"
      },
      "source": [
        "* **Prepare a VPC network**.  To reduce any network overhead that might lead to unnecessary increase in overhead latency, it is best to call the ANN endpoints from your VPC via a direct [VPC Peering](https://cloud.google.com/vertex-ai/docs/general/vpc-peering) connection. \n",
        "  * The following section describes how to setup a VPC Peering connection if you don't have one. \n",
        "  * This is a one-time initial setup task. You can also reuse existing VPC network and skip this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDH8CgQiSxhv"
      },
      "outputs": [],
      "source": [
        "VPC_NETWORK = \"[your-vpc-network-name]\"  # @param {type:\"string\"}\n",
        "\n",
        "PEERING_RANGE_NAME = \"ann-haystack-range\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW2LneA5mmmP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Remove the if condition to run the encapsulated code\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Create a VPC network\n",
        "    ! gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}\n",
        "\n",
        "    # Add necessary firewall rules\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp\n",
        "\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9\n",
        "\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389\n",
        "\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22\n",
        "\n",
        "    # Reserve IP range\n",
        "    ! gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description=\"peering range\"\n",
        "\n",
        "    # Set up peering with service networking\n",
        "    # Your account must have the \"Compute Network Admin\" role to run the following.\n",
        "    ! gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uj8x73nDX_"
      },
      "source": [
        "* Authentication: Rerun the `gcloud auth login` command in the Vertex AI Workbench notebook terminal when you are logged out and need the credential again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5de53b31bf1"
      },
      "source": [
        "## Make sure the following cells are run from inside the VPC network that you created in the previous step\n",
        "\n",
        "* **WARNING:** The MatchingIndexEndpoint.match method (to create online queries against your deployed index) has to be executed in a Vertex AI Workbench notebook instance that is created with the following requirements:\n",
        "  * **In the same region as where your ANN service is deployed** (for example, if you set `REGION = \"us-central1\"` as same as the tutorial, the notebook instance has to be in `us-central1`).\n",
        "  * **Make sure you select the VPC network you created for ANN service** (instead of using the \"default\" one). You will have to create the VPC network below and then create a new notebook instance that uses that VPC.  \n",
        "  * If you run it in a Vertex AI Workbench notebook instance in a different VPC network or region, \"Create Online Queries\" section will fail.\n",
        "  \n",
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d68ee9e5fec0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "    \n",
        "! pip3 install --upgrade --quiet {USER_FLAG} tensorflow-gpu \\\n",
        "                                    tensorflow-hub \\\n",
        "                                    pandas-gbq \\\n",
        "                                    'google-cloud-bigquery[bqstorage,pandas]' \\\n",
        "                                    matplotlib \\\n",
        "                                    google-cloud-aiplatform \\\n",
        "                                    grpcio-tools \\\n",
        "                                    protobuf==3.19.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages.\n",
        "\n",
        "**Note: You may get a message saying \"Your session crashed for an unknown reason\", this is expected. Once this cell has finished running, continue on. You do not need to re-run any of the cells above.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bd7dc5e6118"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eae48aa325ce"
      },
      "outputs": [],
      "source": [
        "REGION = \"[your-region]\"\n",
        "if REGION == \"[your-region]\":\n",
        "    REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7tcBkCDI1_M"
      },
      "source": [
        "#### UUID\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpIK91y1IzDr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "\n",
        "# Generate a uuid of a specifed length(default=8)\n",
        "def generate_uuid(length: int = 8) -> str:\n",
        "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
        "\n",
        "\n",
        "UUID = generate_uuid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9cdf8fc36a2"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "When you initialize the Vertex AI SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c33e028f3ad"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f63fad70682"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
        "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
        "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d359349e4ec1"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1584aaae6d3"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3b749f2e82"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b83d9e848ac1"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9b7633e10dc"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "\n",
        "import google.cloud.aiplatform as aiplatform\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "from google.cloud.bigquery import Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87835101eb47"
      },
      "source": [
        "Initialize the Vertex SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4253ec42617a"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b3254a72031"
      },
      "source": [
        "Initiate the BigQuery client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1a116979ff6"
      },
      "outputs": [],
      "source": [
        "client = Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76f7b9ffde0b"
      },
      "source": [
        "Use gcloud to retrieve the project number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRUOFELefqf1"
      },
      "outputs": [],
      "source": [
        "shell_output = ! gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "PROJECT_NUMBER = shell_output[0]\n",
        "print(\"Project Number:\", PROJECT_NUMBER)\n",
        "\n",
        "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)\n",
        "\n",
        "print(\"PROJECT_ID: {}\".format(PROJECT_ID))\n",
        "print(\"REGION: {}\".format(REGION))\n",
        "\n",
        "!gcloud config set project {PROJECT_ID} --quiet\n",
        "!gcloud config set ai_platform/region {REGION} --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c61c4b113165"
      },
      "source": [
        "## Explore Data\n",
        "View the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb575964108b"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT * FROM `bigquery-public-data.thelook_ecommerce.products`\n",
        "\"\"\"\n",
        "df = client.query(query).to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92ce75968731"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b0b4b5099a7"
      },
      "source": [
        "Check data types and null counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b15baa826c73"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597c054e8095"
      },
      "source": [
        "The current dataset doesn't have any null or empty fields in it.\n",
        "Select the required_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa1fcbf4ea95"
      },
      "outputs": [],
      "source": [
        "required_columns = [\"category\", \"name\", \"brand\", \"department\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ca6de106fa"
      },
      "source": [
        "Separate categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26ff3f8ce494"
      },
      "outputs": [],
      "source": [
        "categorical_columns = [\"category\", \"department\"]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "02c758dcddfa"
      },
      "source": [
        "Plot the level distribution for the categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b3761daf677"
      },
      "outputs": [],
      "source": [
        "for i in categorical_columns:\n",
        "    df[i].value_counts().plot(kind=\"bar\")\n",
        "    plt.title(i)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34c025f6e0af"
      },
      "source": [
        "## Create embeddings for the data\n",
        "\n",
        "The Vertex AI Matching Engine's ANN service expects embeddings in order to give nearest neighbours. Here you convert each row in the dataframe to a sentence and convert sentence to the embedding using universal sentence encoder. One way to create sentences is by concatenating fields from the dataset. Start by converting each row to a sentence by concatenating required columns separating each column value by a space.\n",
        "\n",
        "Convert each row to a sentence by concatenating required columns separating each column value by a space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84a1479a322e"
      },
      "outputs": [],
      "source": [
        "sentences_list = []  # list to store sentences of each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebf886c09abd"
      },
      "outputs": [],
      "source": [
        "sentence_to_product_id = {}\n",
        "for i in range(len(df[\"id\"])):\n",
        "    sentence = \"\"\n",
        "    for column in required_columns:\n",
        "        if df[column][i] is not None:\n",
        "            sentence = sentence + df[column][i] + \" \"\n",
        "    if len(sentence) == 0:\n",
        "        continue\n",
        "\n",
        "    sentence = sentence[0:-1]  # remove last space\n",
        "    if sentence not in sentence_to_product_id:  # remove duplicate sentences\n",
        "        sentence_to_product_id[sentence] = df[\"id\"][i]\n",
        "        sentences_list.append(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2537f636dc19"
      },
      "source": [
        "### Universal Sentence Encoder\n",
        "\n",
        "The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The pre-trained Universal Sentence Encoder is publicly available in [Tensorflow-hub](https://tfhub.dev/).\n",
        "\n",
        "The model is available to us via the TFHub. \n",
        "\n",
        "Load the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b6ce84f82e1"
      },
      "outputs": [],
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)\n",
        "print(\"module %s loaded\" % module_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca614d320c3c"
      },
      "source": [
        "Generate embeddings for the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2999997d1e89"
      },
      "outputs": [],
      "source": [
        "sentence_embeddings = []\n",
        "for sent in sentences_list:\n",
        "    sentence_embeddings.append(\n",
        "        list(model([sent])[0].numpy())\n",
        "    )  # model(sentence)->gives a tensor->convert it to a numpy array, then convert it to a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bfc26b85bf6"
      },
      "source": [
        "View the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dc4f9cf710b"
      },
      "outputs": [],
      "source": [
        "sentence_embeddings[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ3JQTS6CN-3"
      },
      "outputs": [],
      "source": [
        "# The number of nearest neighbors to be retrieved from database for each query.\n",
        "NUM_NEIGHBOURS = 1000\n",
        "for embedding in sentence_embeddings[:5]:\n",
        "    print(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIQSyF9GtSv"
      },
      "source": [
        "Save the data in JSONL format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "261187d034f9"
      },
      "outputs": [],
      "source": [
        "with open(\"item.json\", \"w\") as f:\n",
        "    index = 0\n",
        "    for embedding in sentence_embeddings:\n",
        "        f.write('{\"id\":\"' + str(index) + '\",')\n",
        "        f.write('\"embedding\":[' + \",\".join(str(x) for x in embedding) + \"]}\")\n",
        "        f.write(\"\\n\")\n",
        "        index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVl8DrWG8NS"
      },
      "source": [
        "Upload the data to GCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PgsA_vbI8Vg"
      },
      "outputs": [],
      "source": [
        "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine/initial/\"\n",
        "! gsutil cp item.json {EMBEDDINGS_INITIAL_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglUPwHpJH98"
      },
      "source": [
        "## Create Indexes\n",
        "\n",
        "A ANN index is a collection of vectors deployed together for similarity search. Vectors can be added to an index or removed from an index. Similarity search queries are issued to a specific index and will search over the vectors in that index.\n",
        "\n",
        "\n",
        "Firstly you have to create a ANN index and feed your embeddings to the index.\n",
        "\n",
        "\n",
        "### Create ANN Index (for Production Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiIg9b5zJLi1"
      },
      "outputs": [],
      "source": [
        "DIMENSIONS = 512\n",
        "DISPLAY_NAME = \"item\"\n",
        "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a19f7c3b11a"
      },
      "source": [
        "Create the ANN index configuration:\n",
        "\n",
        "Please read the documentation to understand the various configuration parameters that can be used to tune the index\n",
        "\n",
        "\n",
        "Now, create a index by passing the following arguments:\n",
        "\n",
        "- `display_name`: The display name of the Index.\n",
        "- `contents_delta_uri`: Allows inserting, updating  or deleting the contents of the Matching Engine Index.\n",
        "The string must be a valid Google Cloud Storage directory path.\n",
        "- `dimensions`: The number of dimensions of the input vectors. \n",
        "- `approximate_neighbors_count`(Optional): The default number of neighbors to find via approximate search before exact reordering is performed. Exact reordering is a procedure where results returned by an approximate search algorithm are reordered via a more expensive distance computation.\n",
        "- `distance_measure_type`: The distance measure used in nearest neighbor search.\n",
        "- `leaf_node_embedding_count`: Number of embeddings on each leaf node. The default value is 1000 if not set.\n",
        "- `leaf_nodes_to_search_percent`: The default percentage of leaf nodes that any query may be searched.\n",
        "- `description`: The description of the Index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzY7TpUSJcTV"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description=\"Item ANN index\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17jrQi501QyX"
      },
      "outputs": [],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1a9fbecabb"
      },
      "source": [
        "Using the resource name, you can retrieve an existing MatchingEngineIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ddb70647d98"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsqZuyoA1SG"
      },
      "source": [
        "### Create Brute Force Index (for Ground Truth)\n",
        "\n",
        "The brute force index uses a naive brute force method to find the nearest neighbors. This method is not fast or efficient. Hence brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors, so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure apples to apples comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
        "\n",
        "Create the brute force index configuration:\n",
        "\n",
        "Now, create a index by passing the following arguments:\n",
        "\n",
        "- `display_name`: The display name of the Index.\n",
        "- `contents_delta_uri`: Allows inserting, updating  or deleting the contents of the Matching Engine Index.\n",
        "The string must be a valid Google Cloud Storage directory path.\n",
        "- `dimensions`: The number of dimensions of the input vectors. \n",
        "- `distance_measure_type`: The distance measure used in nearest neighbor search.\n",
        "- `description`: The description of the Index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXnBLqjXBsv8"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    description=\"Item index (brute force)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oD5SieYJbbW"
      },
      "outputs": [],
      "source": [
        "INDEX_BRUTE_FORCE_RESOURCE_NAME = brute_force_index.resource_name\n",
        "INDEX_BRUTE_FORCE_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "865fcad494d7"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex(\n",
        "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2xjAnDDObD"
      },
      "source": [
        "## Create an Index Endpoint with VPC network\n",
        "\n",
        "You have to create a index endpoint and deploy the index to the endpoint. Then from the endpoint you can call the match service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpZQoJyxDlbO"
      },
      "outputs": [],
      "source": [
        "VPC_NETWORK = \"[your-network-name]\"\n",
        "VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
        "VPC_NETWORK_FULL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54b9daa0c7d9"
      },
      "source": [
        "Now, create a index point by passing the following arguments:\n",
        "\n",
        "- `display_name`: The display name of the IndexEndpoint.\n",
        "- `network`: The full name of the Google Compute Engine [network](https://cloud.google.com/compute/docs/networks-and-firewalls#networks) to which the index endpoint should be peered. Private services access must already be configured for the\n",
        "network. If left unspecified, the Endpoint is not peered with any network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuARXzJVGyQX"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=\"index_endpoint\",\n",
        "    network=VPC_NETWORK_FULL,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ3bcZqi-cfM"
      },
      "outputs": [],
      "source": [
        "INDEX_ENDPOINT_NAME = my_index_endpoint.resource_name\n",
        "INDEX_ENDPOINT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np2cgVuuIe9k"
      },
      "source": [
        "## Deploy Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ew1UgcIIiJG"
      },
      "source": [
        "### Deploy ANN Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLOYTGygIlMK"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = f\"tree_ah_item_deployed_{UUID}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf73c6b60ddc"
      },
      "source": [
        "Deploy ANN index to the endpoint by passing the following arguments:\n",
        "\n",
        "- `index`: Index which is to be deployed.\n",
        "- `deployed_index_id`: The user specified ID of the deployed index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uK4WOgqN1NG"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNZnXmO5AhDO"
      },
      "source": [
        "### Deploy Brute Force Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p9e4828AkSv"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_BRUTE_FORCE_INDEX_ID = f\"item_brute_force_deployed_{UUID}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cb2ca54240f"
      },
      "source": [
        "Deploy Brute Force index to the endpoint by passing the following arguments:\n",
        "\n",
        "- `index`: Index which is to be deployed.\n",
        "- `deployed_index_id`: The user specified ID of the deployed index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2kgd01SA4rk"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=brute_force_index, deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCGvBNvBd8D"
      },
      "source": [
        "## Create Online Queries\n",
        "\n",
        "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match Service) within the virtual machine instances from the same region (for example 'us-central1' in this tutorial).\n",
        "\n",
        "### Give top 10 recommendations for a user search query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "335223758c04"
      },
      "outputs": [],
      "source": [
        "sentence = \"Men's Swim Wear\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b682482a30b5"
      },
      "source": [
        "Generate embedding by passing a sentence to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38b9d6288e44"
      },
      "outputs": [],
      "source": [
        "query_vec = list(model([sentence])[0].numpy())  # convert tensor to a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a6a73c31083"
      },
      "source": [
        "Convert list to a 2d list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d8e9ece004c"
      },
      "outputs": [],
      "source": [
        "query_vec = [query_vec]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59984df2ad9c"
      },
      "source": [
        "#### Test query\n",
        "\n",
        "##### Response\n",
        "The response from the match() call is a Python list with the following entries:\n",
        "\n",
        "1. First item from the list is a list of nearest neighbours in sorted order. First neighbour is the nearest neighbour.\n",
        "2. Each item from the nearest neighbour's list is a `google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchNeighbor` class which contains `id` variable(id of the embedding you assigned before) and `distance` variable (gives dot product distance) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28f521876b1f"
      },
      "outputs": [],
      "source": [
        "response_for_search_query = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID, queries=query_vec, num_neighbors=NUM_NEIGHBOURS\n",
        ")\n",
        "\n",
        "response_for_search_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075b5f68dedc"
      },
      "source": [
        "Store similar product IDs in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a854873de5a"
      },
      "outputs": [],
      "source": [
        "results_id_list = []\n",
        "for i in response_for_search_query[0][:10]:\n",
        "    sent = sentences_list[int(i.id)]\n",
        "    print(sent)\n",
        "    results_id_list.append(sentence_to_product_id[sent])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89a7cbccb1d2"
      },
      "source": [
        "Print product IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7d52ae1be1d"
      },
      "outputs": [],
      "source": [
        "results_id_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0854af0f4fd"
      },
      "source": [
        "View top 10 similar products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ba5cc9fa26d"
      },
      "outputs": [],
      "source": [
        "df.set_index(\"id\").loc[results_id_list].reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fba82154bc1a"
      },
      "source": [
        "#### Recommend almost similar products \n",
        "\n",
        "Store words of current sentence in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50d53fc6c2de"
      },
      "outputs": [],
      "source": [
        "words_present = []\n",
        "for word in sentence.split():\n",
        "    if \"'\" in word:\n",
        "        word = word.split(\"'\")[\n",
        "            0\n",
        "        ]  # remove single quotes from a word and take singular word\n",
        "    if word not in words_present:  # remove duplicate words\n",
        "        words_present.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fedfacd25a7b"
      },
      "source": [
        "View unique words present in the query sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "899cd904cc3f"
      },
      "outputs": [],
      "source": [
        "words_present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4d478064197"
      },
      "source": [
        "Calculate length of the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84dc275b5206"
      },
      "outputs": [],
      "source": [
        "no_words_present_given_sentence = len(words_present)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcc968ab97b6"
      },
      "source": [
        "##### Perform this process for every sentence of the response\n",
        "- For every sentence check how many words of the sentence matched with the words of the query sentence\n",
        "- If 25% to 50% words are matched, then append corresponding id of the product associated with the sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63dc1d41d20f"
      },
      "outputs": [],
      "source": [
        "results_id_list = []  # list to store almost similar products id's\n",
        "count = 0\n",
        "for i in response_for_search_query[0]:\n",
        "    e += 1\n",
        "    words_matched_in_current_sentence = 0\n",
        "    for word in sentences_list[int(i.id)].split():\n",
        "        if \"'\" in word:\n",
        "            word = word.split(\"'\")[0]\n",
        "        if word in words_present:\n",
        "            words_matched_in_current_sentence += 1\n",
        "    # if a sentence has 25% to 50% match of similar words wth given sentence words\n",
        "    if words_matched_in_current_sentence <= math.floor(\n",
        "        no_words_present_given_sentence / 2\n",
        "    ) and words_matched_in_current_sentence > math.floor(\n",
        "        no_words_present_given_sentence / 4\n",
        "    ):\n",
        "        count += 1\n",
        "        sent = sentences_list[int(i.id)]\n",
        "        results_id_list.append(sentence_to_product_id[sent])\n",
        "    if count == 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f4c9b60875f"
      },
      "source": [
        "View top 10 almost similar products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73fd5a840610"
      },
      "outputs": [],
      "source": [
        "df.set_index(\"id\").loc[results_id_list].reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeUZO3bAGoM-"
      },
      "source": [
        "### Compute Recall\n",
        "\n",
        "Use the deployed brute force Index as the ground truth to calculate the recall of ANN Index. Note that you can run multiple queries in a single match call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9dNIbkEGoM-"
      },
      "outputs": [],
      "source": [
        "# Retrieve nearest neighbors for both the tree-AH index and the brute-force index\n",
        "tree_ah_response_test = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=sentence_embeddings[:1000],\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "brute_force_response_test = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
        "    queries=sentence_embeddings[:1000],\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-eMF05UGoM-"
      },
      "outputs": [],
      "source": [
        "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
        "recalled_neighbors = 0\n",
        "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
        "    tree_ah_response_test, brute_force_response_test\n",
        "):\n",
        "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
        "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
        "\n",
        "    recalled_neighbors += len(\n",
        "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
        "    )\n",
        "\n",
        "recall = recalled_neighbors / len(\n",
        "    [neighbor for neighbors in brute_force_response_test for neighbor in neighbors]\n",
        ")\n",
        "\n",
        "print(\"Recall: {}\".format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "You can also manually delete resources that you created by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omj7N9iWv-Tq"
      },
      "outputs": [],
      "source": [
        "# Force undeployment of indexes and delete endpoint\n",
        "my_index_endpoint.delete(force=True)\n",
        "\n",
        "# Delete indexes\n",
        "tree_ah_index.delete()\n",
        "brute_force_index.delete()\n",
        "\n",
        "delete_bucket = False\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "similar_products_recommender_using_matching_engine.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
