{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Using Vertex AI Feature Store (Legacy) with Pandas Dataframe\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store_legacy/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ffeature_store_legacy%2Fsdk-feature-store-pandas.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/feature_store_legacy/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store_legacy/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "962e636b5cee"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook introduces Pandas support for Vertex AI Feature Store (Legacy) using the Vertex AI SDK. For pre-requisites and introduction on Vertex AI SDK and Vertex AI Feature Store (Legacy) native support, please go through this [Colab notebook](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/feature_store/sdk-feature-store.ipynb). \n",
        "\n",
        "Learn more about [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxF5JWRVT5PP"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to use `Vertex AI Feature Store (Legacy)` with pandas Dataframe.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- Vertex AI Feature Store (Legacy)\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Create `Featurestore`, `EntityType`, and `Feature` resources.\n",
        "- Import feature values from Pandas DataFrame into the entity type.\n",
        "- Read entity feature values from the online feature store into Pandas DataFrame.\n",
        "- Batch serve feature values from your featurestore into Pandas DataFrame.\n",
        "\n",
        "You also learn how Vertex AI Feature Store (Legacy) is useful in the below scenarios:\n",
        "\n",
        "- Online serving with updated feature values.\n",
        "- Point-in-time correctness to fetch feature values for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ZNLaf6T0lN"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial is a part of the Vertex AI Feature Store (Legacy) tutorial notebooks. It uses a movie recommendation dataset as an example for demonstrating various functionalities of Vertex AI Feature Store (Legacy). The original task is to train a model to predict if a user is going to watch a movie, and serve the model online."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2Bj_QpT2Ud"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ea81ac77f0"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet --upgrade google-cloud-aiplatform \\\n",
        "                                google-cloud-bigquery \\\n",
        "                                google-cloud-bigquery-storage \\\n",
        "                                avro \\\n",
        "                                pyarrow \\\n",
        "                                pandas \\\n",
        "                                fsspec \\\n",
        "                                gcsfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16220914acc5"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "157953ab28f0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b96b39fd4d7b"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff666ce4051c"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc7251520a07"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8575d303471"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:mbsdk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to serve as a staging bucket for Vertex AI and to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdct_Lm7x2I_"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from avro.datafile import DataFileReader\n",
        "from avro.io import DatumReader\n",
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "138407556b22"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2077ffee78"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQBIv3ZL3A0"
      },
      "source": [
        "## Create a featurestore\n",
        "\n",
        "Vertex AI Feature Store (Legacy) serves as a centralised and organised repository for your ML features. You can store, serve and monitor certain aspects of your features like their distributions and drift. Learn more about the [Vertex AI Feature Store (Legacy) data model](https://cloud.google.com/vertex-ai/docs/featurestore/concepts), and [benefits of Vertex AI Feature Store (Legacy)](https://cloud.google.com/vertex-ai/docs/featurestore/overview#benefits).\n",
        "\n",
        "To begin this tutorial, you create a featurestore using the Vertex AI SDK for Python. A featurestore is a top-level container for your features and their values. For this, you use the [`Featurestore.create()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Featurestore) method which returns a LRO ([long-running operation](https://google.aip.dev/151)). A LRO starts an asynchronous job. LROs are returned for other API methods too, such as updating or deleting a featurestore. \n",
        "\n",
        "You pass the below parameters while creating the featurestore:\n",
        "\n",
        "- `featurestore_id`: A unique name or id for your featurestore.\n",
        "- `online_store_fixed_node_count`: Config for online serving resources. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6uIWQeoBSr8"
      },
      "outputs": [],
      "source": [
        "# set the id or name for the featurestore\n",
        "featurestore_id = \"movie_predictions_unique\"  # @param {type:\"string\"}\n",
        "\n",
        "# Create featurestore\n",
        "movie_predictions_feature_store = aiplatform.Featurestore.create(\n",
        "    featurestore_id=featurestore_id, online_store_fixed_node_count=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmJq75zXjmT"
      },
      "source": [
        "## Create entity types\n",
        "\n",
        "Using Vertex AI Feature Store (Legacy), you can create and manage feature stores, entity types, and features. An entity type is a collection of semantically related features. You define your own entity types, based on the concepts that are relevant to your use case. For example, a movie service might have the entity types movie and user, which group related features that correspond to movies or customers.\n",
        "\n",
        "Learn more about [entity types](https://cloud.google.com/vertex-ai/docs/featurestore/concepts#entity_type).\n",
        "\n",
        "Entity types are created within the `Featurestore class. Below, you create the following entity types `users` and `movies` for the movie recommendation dataset.\n",
        "\n",
        "You pass the following parameters while creating the entity types:\n",
        "\n",
        "- `entity_type_id`: A unique name or id for your entity type.\n",
        "- `description`: (Optional) Description for your entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU0oXvINBgPV"
      },
      "outputs": [],
      "source": [
        "# Create users entity type\n",
        "users_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"users\",\n",
        "    description=\"Users entity\",\n",
        ")\n",
        "\n",
        "# Create movies entity type\n",
        "movies_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"movies\",\n",
        "    description=\"Movies entity\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJW4q-0jO2Xf"
      },
      "source": [
        "## Create features\n",
        "\n",
        "A feature is a measurable property or attribute of an entity type. For example, the movie entity type has features such as average_rating and title that track various properties of movies. Features are associated with entity types. \n",
        "\n",
        "Learn more about [Features](https://cloud.google.com/vertex-ai/docs/featurestore/concepts#feature).\n",
        "\n",
        "Add the defined features to the entity types `users` and `movies` using the following methods.\n",
        "\n",
        "### Add features using `create_feature` method\n",
        "\n",
        "You provide the following parameters for creating features:\n",
        "\n",
        "- `feature_id`: Resource name or an id for the feature.\n",
        "- `value_type`: Type of feature value. One of BOOL, BOOL_ARRAY, DOUBLE, DOUBLE_ARRAY, INT64, INT64_ARRAY, STRING, STRING_ARRAY, BYTES.\n",
        "- `description`: Description of the feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvjwT84iVSps"
      },
      "outputs": [],
      "source": [
        "# Create age feature\n",
        "users_feature_age = users_entity_type.create_feature(\n",
        "    feature_id=\"age\",\n",
        "    value_type=\"INT64\",\n",
        "    description=\"User age\",\n",
        ")\n",
        "\n",
        "# Create gender feature\n",
        "users_feature_gender = users_entity_type.create_feature(\n",
        "    feature_id=\"gender\",\n",
        "    value_type=\"STRING\",\n",
        "    description=\"User gender\",\n",
        ")\n",
        "\n",
        "# Create liked_genres feature\n",
        "users_feature_liked_genres = users_entity_type.create_feature(\n",
        "    feature_id=\"liked_genres\",\n",
        "    value_type=\"STRING_ARRAY\",\n",
        "    description=\"An array of genres this user liked\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecb141839033"
      },
      "source": [
        "### Add features using `batch_create_features` method\n",
        "\n",
        "You can also add multiple features at a time using a config map in a dictionary format. For this, you use the `batch_create_features` method. \n",
        "\n",
        "Below, you define create `title`, `genres` and `average_rating` features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llTT9_Dgbac2"
      },
      "outputs": [],
      "source": [
        "# define the features\n",
        "movies_feature_configs = {\n",
        "    \"title\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The title of the movie\",\n",
        "    },\n",
        "    \"genres\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The genre of the movie\",\n",
        "    },\n",
        "    \"average_rating\": {\n",
        "        \"value_type\": \"DOUBLE\",\n",
        "        \"description\": \"The average rating for the movie, range is [1.0-5.0]\",\n",
        "    },\n",
        "}\n",
        "# create the features\n",
        "movie_features = movies_entity_type.batch_create_features(\n",
        "    feature_configs=movies_feature_configs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3n5XdK8Xjmw"
      },
      "source": [
        "## Import feature values into entity types from dataframes\n",
        "\n",
        "A featurestore captures feature values for a feature belonging to an entity type at a specific point in time. After importing your feature values to feature store, you can later `read` (online) or `batch serve` (offline) the feature values from the entity type. \n",
        "\n",
        "In this section, you learn how to import feature values from a [Pandas dataframe](https://pandas.pydata.org/) into an entity type. \n",
        "\n",
        "Learn more about [feature values](https://cloud.google.com/vertex-ai/docs/featurestore/concepts#feature_value).\n",
        "\n",
        "Note: You can also import feature values from BigQuery or Google Cloud Storage.\n",
        "\n",
        "### Get movie recommendation data from source\n",
        "\n",
        "Define the data sources for users and movies and copy them locally into **.avro** files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uNrHqiGXrff"
      },
      "outputs": [],
      "source": [
        "# set the users file source\n",
        "GCS_USERS_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
        ")\n",
        "# set the movies file source\n",
        "GCS_MOVIES_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
        ")\n",
        "# set the local file names\n",
        "USERS_AVRO_FN = \"users.avro\"\n",
        "MOVIES_AVRO_FN = \"movies.avro\"\n",
        "# copy the files using gsutil\n",
        "! gsutil cp $GCS_USERS_AVRO_URI $USERS_AVRO_FN\n",
        "! gsutil cp $GCS_MOVIES_AVRO_URI $MOVIES_AVRO_FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6Z0jfR5OW5"
      },
      "source": [
        "### Load data from avro files \n",
        "\n",
        "Load users and movies data from the downloaded avro files into Pandas dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrB7bnqbZYaC"
      },
      "outputs": [],
      "source": [
        "# Define a class for reading the avro data\n",
        "\n",
        "\n",
        "class AvroReader:\n",
        "    def __init__(self, data_file):\n",
        "        self.avro_reader = DataFileReader(open(data_file, \"rb\"), DatumReader())\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        records = [record for record in self.avro_reader]\n",
        "        return pd.DataFrame.from_records(data=records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdlWJhUt5OW5"
      },
      "outputs": [],
      "source": [
        "# Load users data from avro file\n",
        "users_avro_reader = AvroReader(data_file=USERS_AVRO_FN)\n",
        "users_source_df = users_avro_reader.to_dataframe()\n",
        "users_source_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ49cPS35OW5"
      },
      "outputs": [],
      "source": [
        "# Load movies data from avro file\n",
        "movies_avro_reader = AvroReader(data_file=MOVIES_AVRO_FN)\n",
        "movies_source_df = movies_avro_reader.to_dataframe()\n",
        "movies_source_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb0WGwX5OW6"
      },
      "source": [
        "### Import feature values into entity types\n",
        "\n",
        "Load the feature values into `users` entity type from the dataframe.\n",
        "\n",
        "You provide the following parameters for importing the data:\n",
        "\n",
        "- `feature_ids`: List of ids of the Feature to import values of. The Features must exist in the target EntityType, or the request will fail.\n",
        "- `feature_time`: The source column that holds the Feature timestamp for all Feature values in each entity. It can also be a single Feature timestamp for all entities being imported.\n",
        "- `df_source`: Pandas DataFrame containing the source data to import.\n",
        "- `entity_id_field`: Source column that holds entity IDs.\n",
        "\n",
        "Learn more about the [`EntityType.ingest_from_df()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.EntityType#google_cloud_aiplatform_EntityType_ingest_from_df) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b813uj5OW6"
      },
      "outputs": [],
      "source": [
        "# Import the data for users\n",
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=users_source_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCAdQ3cF5OW6"
      },
      "source": [
        "Similarly, load the feature values for `movies` entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DYlKe4e5OW6"
      },
      "outputs": [],
      "source": [
        "# Import the data for movies\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=movies_source_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYLZwao5OW6"
      },
      "source": [
        "## Read feature values online from an entity within a featurestore\n",
        "\n",
        "Vertex AI Feature Store (Legacy) includes online serving, which lets you read feature values for small batches of entities. It is beneficial when you want to read values of selected features from an entity or multiple entities in an entity type.\n",
        "\n",
        "Note: An entity is an instance of an entity type. For example, movie_01 and movie_02 are entities of the entity type movie.\n",
        "\n",
        "Learn more about [online serving in Vertex AI Feature Store (Legacy)](https://cloud.google.com/vertex-ai/docs/featurestore/serving-online).\n",
        "\n",
        "### Read feature values for users\n",
        "\n",
        "Call the [`EntityType.read()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.EntityType#google_cloud_aiplatform_EntityType_read) method with the required entity ids from the entity type `users`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrR-SY3i58rh"
      },
      "outputs": [],
      "source": [
        "# read the data to a dataframe\n",
        "users_read_df = users_entity_type.read(\n",
        "    entity_ids=[\"dave\", \"alice\", \"charlie\", \"bob\", \"eve\"],\n",
        ")\n",
        "# dispaly the dataframe\n",
        "users_read_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2cfa09ef11d"
      },
      "source": [
        "### Read feature values for movies\n",
        "\n",
        "Call the [`EntityType.read()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.EntityType#google_cloud_aiplatform_EntityType_read) method with the required entity ids from the entity type `movies`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTW6kBxN5OW7"
      },
      "outputs": [],
      "source": [
        "# read the data to a dataframe\n",
        "movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "# display the dataframe\n",
        "movies_read_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK2Glzkq5OW7"
      },
      "source": [
        "## Batch serve feature values from featurestore\n",
        "\n",
        "Vertex AI Feature Store (Legacy) can also serve the feature values in large batches for high throughput. Batch serving is typically used for training a model or batch prediction. \n",
        "\n",
        "Learn more about [batch serving in Vertex AI Feature Store (Legacy)](https://cloud.google.com/vertex-ai/docs/featurestore/serving-batch#batch_serving_inputs).\n",
        "\n",
        "In this section, you learn how to prepare training examples by using the batch serve function in Vertex AI Feature Store (Legacy).\n",
        "\n",
        "### Load read instances from source file\n",
        "\n",
        "Define the source file path that consists of some samples with feature values. Here, you load some feature values from the `movie_prediction.csv` file in the dataset using Pandas. This data serves as read instances while calling the batch serve function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4k2QVN-5OW7"
      },
      "outputs": [],
      "source": [
        "# set the gcs source for samples\n",
        "GCS_READ_INSTANCES_CSV_URI = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d9fdcbc90fc"
      },
      "source": [
        "While loading the data, parse the `timestamp` column as datetime field. This is because the feature store expects a timestamp field in the read instances when batch serving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqQVfRnC5OW7"
      },
      "outputs": [],
      "source": [
        "# load the data using pandas\n",
        "read_instances_df = pd.read_csv(GCS_READ_INSTANCES_CSV_URI, parse_dates=[\"timestamp\"])\n",
        "# display the dataframe\n",
        "read_instances_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1dC5Pc5OW8"
      },
      "source": [
        "### Batch serve feature values\n",
        "\n",
        "Serve the batch response to a dataframe using the `batch_serve_to_df` method by providing the following parameters:\n",
        "\n",
        "- `serving_feature_ids`: A user defined dictionary to define the entity_types and their features for batch serve/read. The keys of the dictionary are the serving entity_type ids and the values are lists of serving feature ids in each entity_type.\n",
        "        \n",
        "- `read_instances_df`: A pandas DataFrame containing the read instances. Each read instance should consist of exactly one read timestamp and one or more entity IDs identifying entities of the corresponding entity types whose features are requested. Each output instance contains feature values of requested entities concatenated together as of the read time. \n",
        "\n",
        "    An example read_instances_df may be:\n",
        "\n",
        "    ```\n",
        "    pd.DataFrame( data=[ { \n",
        "            \"my_entity_type_id_1\": \"my_entity_type_id_1_entity_1\", \n",
        "            \"my_entity_type_id_2\": \"my_entity_type_id_2_entity_1\", \n",
        "            \"timestamp\": \"2020-01-01T10:00:00.123Z\" ], ) \n",
        "    ```\n",
        "    An example batch_serve_output_df may be \n",
        "    \n",
        "    ```\n",
        "    pd.DataFrame( data=[ { \n",
        "            \"my_entity_type_id_1\": \"my_entity_type_id_1_entity_1\", \n",
        "            \"my_entity_type_id_2\": \"my_entity_type_id_2_entity_1\", \n",
        "            \"foo\": \"feature_id_1_1_feature_value\", \n",
        "            \"feature_id_1_2\": \"feature_id_1_2_feature_value\", \n",
        "            \"feature_id_2_1\": \"feature_id_2_1_feature_value\", \n",
        "            \"bar\": \"feature_id_2_2_feature_value\", \n",
        "            \"timestamp\": \"2020-01-01T10:00:00.123Z\" ], ) \n",
        "    ``` \n",
        "        \n",
        "\n",
        "Note: Calling the `batch_serve_to_df` method automatically creates and deletes a temporary bigquery dataset in the same GCP project, which is used as the intermediary storage for batch serve feature values from Vertex AI Feature Store (Legacy) to dataframe.\n",
        "\n",
        "Learn more about [Batch serving from Vertex AI Feature Store (Legacy) to a dataframe](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Featurestore#google_cloud_aiplatform_Featurestore_batch_serve_to_df). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZSJ-Sbl5OW8"
      },
      "outputs": [],
      "source": [
        "# call the batch serve method\n",
        "movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "# display the dataframe\n",
        "movie_predictions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN84znoI5OW8"
      },
      "source": [
        "## Read the latest feature values\n",
        "\n",
        "In Vertex AI Feature Store (Legacy), you access the latest or the last available feature values unless a specific time is provided. \n",
        "\n",
        "Now, you test this feature by importing new data to the entity types and reading it from the featurestore.\n",
        "\n",
        "### Import updated feature values\n",
        "\n",
        "Now, you update the feature values by running the following cell. \n",
        "\n",
        "**Note:** For comparison, you can try printing the feature values read from the entity types earlier (those in `movies_read_df` variable). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y-iMUFH5OW9"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe for the new data\n",
        "update_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_03\", 4.3], [\"movie_04\", 4.8]],\n",
        "    columns=[\"movie_id\", \"average_rating\"],\n",
        ")\n",
        "\n",
        "# Import the new data from the dataframe\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\"],\n",
        "    feature_time=datetime.datetime.now(),  # provide the current timestamp\n",
        "    df_source=update_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s47WCIvL5OW9"
      },
      "source": [
        "### Fetch the latest feature values\n",
        "\n",
        "Reading from the entity type gives you the updated feature values from the latest import.\n",
        "\n",
        "Running the below cell should fetch the latest values for all the requested entities including `movie_03` and `movie_04` which you added in the last cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2IPEY7S5OW9"
      },
      "outputs": [],
      "source": [
        "# read the feature values from the entity type\n",
        "update_movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "# display the dataframe\n",
        "update_movies_read_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1YGRNsW5OW9"
      },
      "source": [
        "## Point-in-time correctness\n",
        "\n",
        "Vertex AI Feature Store (Legacy) captures feature values for a feature at a [specific point in time](https://cloud.google.com/vertex-ai/docs/featurestore/serving-batch#example_point-in-time_lookup). In case there are missing values in your past data, you can backfill them using batch serving.\n",
        "\n",
        "### Check missing data\n",
        "Recall that response from the batch serve from last import has some missing data in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueXYomBr5OW-"
      },
      "outputs": [],
      "source": [
        "# check the missing data\n",
        "movie_predictions_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abQRF6mx5OW-"
      },
      "source": [
        "### Backfill / correct point-in-time data\n",
        "\n",
        "Impute the missing data based on the timestamps.\n",
        "\n",
        "Note: The timestamp field should must use the RFC 3339 format(e.g. 2012-07-30T10:43:17.123Z) or should be compatible with the Timestamp datatype when loaded to BigQuery. This is because Vertex AI Feature Store (Legacy) loads to a temporary BigQuery table as an intermediate step when batch serving. Learn more about [loading data to BigQuery from dataframe](https://cloud.google.com/bigquery/docs/samples/bigquery-load-table-dataframe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehZhc4ZP5OW-"
      },
      "outputs": [],
      "source": [
        "# Impute the users data\n",
        "backfill_users_df = pd.DataFrame(\n",
        "    data=[[\"bob\", 34, \"Male\", [\"Drama\"], \"2020-02-13 09:35:15+00:00\"]],\n",
        "    columns=[\"user_id\", \"age\", \"gender\", \"liked_genres\", \"update_time\"],\n",
        ")\n",
        "# convert the timefield to datetime64[ns] (with timezone info)\n",
        "backfill_users_df[\"update_time\"] = pd.to_datetime(backfill_users_df[\"update_time\"])\n",
        "# display the dataframe\n",
        "backfill_users_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhdTzl5k5OW-"
      },
      "outputs": [],
      "source": [
        "# Impute the movies data\n",
        "backfill_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_04\", 4.2, \"The Dark Knight\", \"Action\", \"2020-02-13 09:35:15+00:00\"]],\n",
        "    columns=[\"movie_id\", \"average_rating\", \"title\", \"genres\", \"update_time\"],\n",
        ")\n",
        "# convert the timefield to datetime64[ns] (with timezone info)\n",
        "backfill_movies_df[\"update_time\"] = pd.to_datetime(backfill_movies_df[\"update_time\"])\n",
        "# display the dataframe\n",
        "backfill_movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXb4JUhu5OW-"
      },
      "source": [
        "### Import the backfilled / corrected data\n",
        "\n",
        "Import the imputed point-in-time data from dataframe to the entity types in the featureImpostore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM1ejZMa5OW-"
      },
      "outputs": [],
      "source": [
        "# Import the users data\n",
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_users_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnrNbv75OW-"
      },
      "outputs": [],
      "source": [
        "# Import the users data\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e62Ku6W5OW_"
      },
      "source": [
        "### Fetch the latest data\n",
        "Batch serve the imported backfilled data to a dataframe to ensure the featurestore is updated. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3njvLv2wbZok"
      },
      "outputs": [],
      "source": [
        "# batch serve the latest data to a dataframe\n",
        "backfill_movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "# display the dataframe\n",
        "backfill_movie_predictions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "- Vertex AI Feature Store (Legacy)\n",
        "- Cloud Storage bucket (set `delete_bucket` to True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBTNfN8vxz4x"
      },
      "outputs": [],
      "source": [
        "# Delete the featurestore\n",
        "movie_predictions_feature_store.delete(force=True)\n",
        "\n",
        "# remove the local users and movies avro files\n",
        "! rm {USERS_AVRO_FN} {MOVIES_AVRO_FN}\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "delete_bucket = False  # Set True for deletion\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk-feature-store-pandas.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
